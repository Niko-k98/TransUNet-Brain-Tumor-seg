calling trainer
Namespace(base_lr=0.01, batch_size=24, dataset='Synapse', deterministic=1, exp='TU_Synapse224', img_size=224, is_pretrain=True, list_dir='./lists/lists_Synapse', max_epochs=200, max_iterations=30000, n_gpu=1, n_skip=3, num_classes=9, root_path='../data/Synapse/train_npz', seed=1234, vit_name='R50-ViT-B_16', vit_patches_size=16)
The length of train set is: 2211
93 iterations per epoch. 18600 max iterations 
  0%|                                         | 0/200 [00:00<?, ?it/s]iteration 1 : loss : 1.464503, loss_ce: 1.995603
iteration 2 : loss : 1.420081, loss_ce: 1.912339
iteration 3 : loss : 1.335437, loss_ce: 1.751870
iteration 4 : loss : 1.226745, loss_ce: 1.549746
iteration 5 : loss : 1.110485, loss_ce: 1.328507
iteration 6 : loss : 0.984821, loss_ce: 1.086880
iteration 7 : loss : 0.880549, loss_ce: 0.903188
iteration 8 : loss : 0.793940, loss_ce: 0.738153
iteration 9 : loss : 0.712694, loss_ce: 0.578284
iteration 10 : loss : 0.645113, loss_ce: 0.448461
iteration 11 : loss : 0.609974, loss_ce: 0.379274
iteration 12 : loss : 0.547687, loss_ce: 0.238418
iteration 13 : loss : 0.580791, loss_ce: 0.315063
iteration 14 : loss : 0.547550, loss_ce: 0.246830
iteration 15 : loss : 0.542818, loss_ce: 0.240256
iteration 16 : loss : 0.508510, loss_ce: 0.164233
iteration 17 : loss : 0.521758, loss_ce: 0.193790
iteration 18 : loss : 0.529653, loss_ce: 0.214125
iteration 19 : loss : 0.516406, loss_ce: 0.189890
iteration 20 : loss : 0.496703, loss_ce: 0.149968
iteration 21 : loss : 0.522966, loss_ce: 0.222047
iteration 22 : loss : 0.508849, loss_ce: 0.197171
iteration 23 : loss : 0.501802, loss_ce: 0.195104
iteration 24 : loss : 0.486834, loss_ce: 0.159344
iteration 25 : loss : 0.520327, loss_ce: 0.222457
iteration 26 : loss : 0.510327, loss_ce: 0.214418
iteration 27 : loss : 0.473814, loss_ce: 0.162422
iteration 28 : loss : 0.470534, loss_ce: 0.154237
iteration 29 : loss : 0.501282, loss_ce: 0.209958
iteration 30 : loss : 0.509897, loss_ce: 0.224965
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9e47dc2ee0>
Traceback (most recent call last):
  File "/home/koutsoubn8/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 961, in __del__
    self._shutdown_workers()
  File "/home/koutsoubn8/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 928, in _shutdown_workers
    self._worker_result_queue.put((None, None))
  File "/usr/lib/python3.8/multiprocessing/queues.py", line 88, in put
    self._start_thread()
  File "/usr/lib/python3.8/multiprocessing/queues.py", line 163, in _start_thread
    self._thread = threading.Thread(
  File "/usr/lib/python3.8/threading.py", line 761, in __init__
    def __init__(self, group=None, target=None, name=None,
KeyboardInterrupt: 
  0%|                                         | 0/200 [00:20<?, ?it/s]
Traceback (most recent call last):
  File "train.py", line 95, in <module>
    trainer[dataset_name](args, net, snapshot_path)
  File "/home/koutsoubn8/Transunet_project/TransUNet/trainer.py", line 75, in trainer_synapse
    loss.backward()
  File "/home/koutsoubn8/.local/lib/python3.8/site-packages/torch/tensor.py", line 195, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/koutsoubn8/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 97, in backward
    Variable._execution_engine.run_backward(
KeyboardInterrupt
calling trainer
Namespace(base_lr=0.01, batch_size=24, dataset='Synapse', deterministic=1, exp='TU_Synapse224', img_size=224, is_pretrain=True, list_dir='./lists/lists_Synapse', max_epochs=200, max_iterations=30000, n_gpu=1, n_skip=3, num_classes=9, root_path='../data/Synapse/train_npz', seed=1234, vit_name='R50-ViT-B_16', vit_patches_size=16)
The length of train set is: 2211
93 iterations per epoch. 18600 max iterations 
  0%|                                         | 0/200 [00:00<?, ?it/s]iteration 1 : loss : 1.464503, loss_ce: 1.995603
iteration 2 : loss : 1.420081, loss_ce: 1.912339
iteration 3 : loss : 1.335441, loss_ce: 1.751878
iteration 4 : loss : 1.227378, loss_ce: 1.550919
iteration 5 : loss : 1.110633, loss_ce: 1.329034
iteration 6 : loss : 0.983710, loss_ce: 1.085227
iteration 7 : loss : 0.880063, loss_ce: 0.901819
iteration 8 : loss : 0.794124, loss_ce: 0.738447
iteration 9 : loss : 0.709933, loss_ce: 0.574288
iteration 10 : loss : 0.641388, loss_ce: 0.446196
iteration 11 : loss : 0.605906, loss_ce: 0.377179
iteration 12 : loss : 0.546259, loss_ce: 0.238580
iteration 13 : loss : 0.572124, loss_ce: 0.305802
iteration 14 : loss : 0.537174, loss_ce: 0.238093
iteration 15 : loss : 0.531683, loss_ce: 0.227315
iteration 16 : loss : 0.501622, loss_ce: 0.160433
iteration 17 : loss : 0.512523, loss_ce: 0.187651
iteration 18 : loss : 0.516385, loss_ce: 0.204111
iteration 19 : loss : 0.504289, loss_ce: 0.175829
iteration 20 : loss : 0.480537, loss_ce: 0.141740
iteration 21 : loss : 0.516940, loss_ce: 0.215963
iteration 22 : loss : 0.495939, loss_ce: 0.179477
iteration 23 : loss : 0.494697, loss_ce: 0.186829
iteration 24 : loss : 0.492698, loss_ce: 0.161619
iteration 25 : loss : 0.514722, loss_ce: 0.221586
iteration 26 : loss : 0.511734, loss_ce: 0.221426
iteration 27 : loss : 0.474360, loss_ce: 0.166923
iteration 28 : loss : 0.466984, loss_ce: 0.153032
iteration 29 : loss : 0.514699, loss_ce: 0.220233
iteration 30 : loss : 0.518102, loss_ce: 0.231791
iteration 31 : loss : 0.510749, loss_ce: 0.221570
iteration 32 : loss : 0.528424, loss_ce: 0.265004
iteration 33 : loss : 0.504169, loss_ce: 0.213041
iteration 34 : loss : 0.482031, loss_ce: 0.172388
iteration 35 : loss : 0.475181, loss_ce: 0.162936
iteration 36 : loss : 0.483239, loss_ce: 0.163659
iteration 37 : loss : 0.505978, loss_ce: 0.203549
iteration 38 : loss : 0.494763, loss_ce: 0.185489
iteration 39 : loss : 0.462702, loss_ce: 0.141081
iteration 40 : loss : 0.512273, loss_ce: 0.225366
iteration 41 : loss : 0.454475, loss_ce: 0.140778
iteration 42 : loss : 0.457486, loss_ce: 0.126748
iteration 43 : loss : 0.463801, loss_ce: 0.135500
iteration 44 : loss : 0.455309, loss_ce: 0.113033
iteration 45 : loss : 0.494768, loss_ce: 0.178219
iteration 46 : loss : 0.489518, loss_ce: 0.182891
iteration 47 : loss : 0.498336, loss_ce: 0.204377
iteration 48 : loss : 0.466457, loss_ce: 0.154403
iteration 49 : loss : 0.509020, loss_ce: 0.229763
iteration 50 : loss : 0.469179, loss_ce: 0.172005
iteration 51 : loss : 0.453816, loss_ce: 0.138680
iteration 52 : loss : 0.467989, loss_ce: 0.149126
iteration 53 : loss : 0.465529, loss_ce: 0.146213
iteration 54 : loss : 0.449831, loss_ce: 0.125843
iteration 55 : loss : 0.465217, loss_ce: 0.142504
iteration 56 : loss : 0.474108, loss_ce: 0.147061
iteration 57 : loss : 0.445718, loss_ce: 0.120489
iteration 58 : loss : 0.450917, loss_ce: 0.122409
iteration 59 : loss : 0.464704, loss_ce: 0.137681
iteration 60 : loss : 0.452007, loss_ce: 0.135192
iteration 61 : loss : 0.500327, loss_ce: 0.218088
iteration 62 : loss : 0.441912, loss_ce: 0.110113
iteration 63 : loss : 0.464470, loss_ce: 0.144389
iteration 64 : loss : 0.496690, loss_ce: 0.193554
iteration 65 : loss : 0.443908, loss_ce: 0.114926
iteration 66 : loss : 0.449184, loss_ce: 0.129218
iteration 67 : loss : 0.458141, loss_ce: 0.145636
iteration 68 : loss : 0.460612, loss_ce: 0.139757
iteration 69 : loss : 0.470775, loss_ce: 0.164771
iteration 70 : loss : 0.465392, loss_ce: 0.139898
iteration 71 : loss : 0.518538, loss_ce: 0.241749
iteration 72 : loss : 0.448571, loss_ce: 0.120954
iteration 73 : loss : 0.462307, loss_ce: 0.147323
iteration 74 : loss : 0.462529, loss_ce: 0.145622
iteration 75 : loss : 0.473743, loss_ce: 0.171172
iteration 76 : loss : 0.459648, loss_ce: 0.156018
iteration 77 : loss : 0.442834, loss_ce: 0.107526
iteration 78 : loss : 0.462078, loss_ce: 0.142028
iteration 79 : loss : 0.463678, loss_ce: 0.149259
iteration 80 : loss : 0.461763, loss_ce: 0.141246
iteration 81 : loss : 0.433227, loss_ce: 0.087451
iteration 82 : loss : 0.468969, loss_ce: 0.153803
iteration 83 : loss : 0.479752, loss_ce: 0.158458
iteration 84 : loss : 0.501516, loss_ce: 0.206601
iteration 85 : loss : 0.472831, loss_ce: 0.156902
iteration 86 : loss : 0.471849, loss_ce: 0.170596
iteration 87 : loss : 0.437304, loss_ce: 0.104440
iteration 88 : loss : 0.455625, loss_ce: 0.144382
iteration 89 : loss : 0.448494, loss_ce: 0.125741
iteration 90 : loss : 0.446760, loss_ce: 0.123576
iteration 91 : loss : 0.479529, loss_ce: 0.175511
iteration 92 : loss : 0.484559, loss_ce: 0.187110
iteration 93 : loss : 0.463858, loss_ce: 0.053837
  0%|▏                              | 1/200 [00:59<3:17:03, 59.41s/it]iteration 94 : loss : 0.470083, loss_ce: 0.161387
iteration 95 : loss : 0.483109, loss_ce: 0.185023
iteration 96 : loss : 0.450623, loss_ce: 0.123502
iteration 97 : loss : 0.458397, loss_ce: 0.140830
iteration 98 : loss : 0.470183, loss_ce: 0.164586
iteration 99 : loss : 0.466352, loss_ce: 0.170005
iteration 100 : loss : 0.433409, loss_ce: 0.103148
iteration 101 : loss : 0.439855, loss_ce: 0.105268
iteration 102 : loss : 0.433720, loss_ce: 0.108305
iteration 103 : loss : 0.441167, loss_ce: 0.102563
iteration 104 : loss : 0.453212, loss_ce: 0.123355
iteration 105 : loss : 0.431055, loss_ce: 0.100927
iteration 106 : loss : 0.452428, loss_ce: 0.130721
iteration 107 : loss : 0.452377, loss_ce: 0.130540
iteration 108 : loss : 0.458975, loss_ce: 0.157126
iteration 109 : loss : 0.433267, loss_ce: 0.117557
iteration 110 : loss : 0.439951, loss_ce: 0.113635
iteration 111 : loss : 0.443676, loss_ce: 0.137702
iteration 112 : loss : 0.436430, loss_ce: 0.122610
iteration 113 : loss : 0.460217, loss_ce: 0.158007
iteration 114 : loss : 0.433379, loss_ce: 0.121088
iteration 115 : loss : 0.425769, loss_ce: 0.093430
iteration 116 : loss : 0.442431, loss_ce: 0.113791
iteration 117 : loss : 0.433387, loss_ce: 0.115091
iteration 118 : loss : 0.426281, loss_ce: 0.102444
iteration 119 : loss : 0.458381, loss_ce: 0.165862
iteration 120 : loss : 0.433000, loss_ce: 0.119463
iteration 121 : loss : 0.414038, loss_ce: 0.110551
iteration 122 : loss : 0.443634, loss_ce: 0.159692
iteration 123 : loss : 0.413974, loss_ce: 0.114644
iteration 124 : loss : 0.412012, loss_ce: 0.119261
iteration 125 : loss : 0.419061, loss_ce: 0.092712
iteration 126 : loss : 0.402068, loss_ce: 0.099637
iteration 127 : loss : 0.389561, loss_ce: 0.070908
iteration 128 : loss : 0.410275, loss_ce: 0.109477
iteration 129 : loss : 0.441009, loss_ce: 0.146882
iteration 130 : loss : 0.407832, loss_ce: 0.117345
iteration 131 : loss : 0.414676, loss_ce: 0.124337
iteration 132 : loss : 0.418422, loss_ce: 0.126820
iteration 133 : loss : 0.396830, loss_ce: 0.092655
iteration 134 : loss : 0.415339, loss_ce: 0.123971
iteration 135 : loss : 0.429461, loss_ce: 0.150021
iteration 136 : loss : 0.408354, loss_ce: 0.113710
iteration 137 : loss : 0.400997, loss_ce: 0.104744
iteration 138 : loss : 0.414883, loss_ce: 0.105855
iteration 139 : loss : 0.404953, loss_ce: 0.086355
iteration 140 : loss : 0.389422, loss_ce: 0.075607
iteration 141 : loss : 0.425186, loss_ce: 0.128601
iteration 142 : loss : 0.414772, loss_ce: 0.105130
iteration 143 : loss : 0.404638, loss_ce: 0.103077
iteration 144 : loss : 0.399606, loss_ce: 0.089011
iteration 145 : loss : 0.429754, loss_ce: 0.142488
iteration 146 : loss : 0.394783, loss_ce: 0.095634
iteration 147 : loss : 0.414367, loss_ce: 0.130038
iteration 148 : loss : 0.402302, loss_ce: 0.106881
iteration 149 : loss : 0.432296, loss_ce: 0.161332
iteration 150 : loss : 0.422078, loss_ce: 0.136371
iteration 151 : loss : 0.424373, loss_ce: 0.154291
iteration 152 : loss : 0.387525, loss_ce: 0.102021
iteration 153 : loss : 0.401657, loss_ce: 0.102158
iteration 154 : loss : 0.391248, loss_ce: 0.089867
iteration 155 : loss : 0.415968, loss_ce: 0.121087
iteration 156 : loss : 0.405127, loss_ce: 0.091789
iteration 157 : loss : 0.396142, loss_ce: 0.089536
iteration 158 : loss : 0.393193, loss_ce: 0.088153
iteration 159 : loss : 0.399135, loss_ce: 0.100263
iteration 160 : loss : 0.422303, loss_ce: 0.125848
iteration 161 : loss : 0.403399, loss_ce: 0.109531
iteration 162 : loss : 0.409065, loss_ce: 0.115979
iteration 163 : loss : 0.396755, loss_ce: 0.097613
iteration 164 : loss : 0.395436, loss_ce: 0.094935
iteration 165 : loss : 0.405209, loss_ce: 0.118629
iteration 166 : loss : 0.411576, loss_ce: 0.128227
iteration 167 : loss : 0.404914, loss_ce: 0.115397
iteration 168 : loss : 0.406425, loss_ce: 0.124252
iteration 169 : loss : 0.394919, loss_ce: 0.090187
iteration 170 : loss : 0.411401, loss_ce: 0.132216
iteration 171 : loss : 0.396186, loss_ce: 0.098226
iteration 172 : loss : 0.396612, loss_ce: 0.100976
iteration 173 : loss : 0.404249, loss_ce: 0.118651
iteration 174 : loss : 0.403054, loss_ce: 0.106130
iteration 175 : loss : 0.385708, loss_ce: 0.081321
iteration 176 : loss : 0.404133, loss_ce: 0.106578
iteration 177 : loss : 0.398302, loss_ce: 0.095327
iteration 178 : loss : 0.401182, loss_ce: 0.114138
iteration 179 : loss : 0.382245, loss_ce: 0.088158
iteration 180 : loss : 0.406743, loss_ce: 0.107502
iteration 181 : loss : 0.410746, loss_ce: 0.131923
iteration 182 : loss : 0.396252, loss_ce: 0.106211
iteration 183 : loss : 0.392410, loss_ce: 0.074882
iteration 184 : loss : 0.398340, loss_ce: 0.102222
iteration 185 : loss : 0.411784, loss_ce: 0.093676
iteration 186 : loss : 0.502356, loss_ce: 0.193252
  1%|▎                              | 2/200 [01:59<3:17:41, 59.91s/it]iteration 187 : loss : 0.386281, loss_ce: 0.064142
iteration 188 : loss : 0.392610, loss_ce: 0.079225
iteration 189 : loss : 0.404467, loss_ce: 0.101817
iteration 190 : loss : 0.410553, loss_ce: 0.112221
iteration 191 : loss : 0.401791, loss_ce: 0.105934
iteration 192 : loss : 0.400325, loss_ce: 0.102997
iteration 193 : loss : 0.401981, loss_ce: 0.093018
iteration 194 : loss : 0.406525, loss_ce: 0.102112
iteration 195 : loss : 0.382145, loss_ce: 0.065368
iteration 196 : loss : 0.392203, loss_ce: 0.093412
iteration 197 : loss : 0.385263, loss_ce: 0.082515
iteration 198 : loss : 0.378012, loss_ce: 0.075296
iteration 199 : loss : 0.384228, loss_ce: 0.091864
iteration 200 : loss : 0.384786, loss_ce: 0.087832
iteration 201 : loss : 0.406505, loss_ce: 0.125203
iteration 202 : loss : 0.373292, loss_ce: 0.065919
iteration 203 : loss : 0.391869, loss_ce: 0.091847
iteration 204 : loss : 0.411742, loss_ce: 0.128197
iteration 205 : loss : 0.377414, loss_ce: 0.084456
iteration 206 : loss : 0.391864, loss_ce: 0.096475
iteration 207 : loss : 0.404505, loss_ce: 0.116601
iteration 208 : loss : 0.402851, loss_ce: 0.122878
iteration 209 : loss : 0.392304, loss_ce: 0.106215
iteration 210 : loss : 0.391639, loss_ce: 0.109007
iteration 211 : loss : 0.401728, loss_ce: 0.115491
iteration 212 : loss : 0.386531, loss_ce: 0.100717
iteration 213 : loss : 0.382917, loss_ce: 0.097105
iteration 214 : loss : 0.391398, loss_ce: 0.099094
iteration 215 : loss : 0.387270, loss_ce: 0.097608
iteration 216 : loss : 0.371590, loss_ce: 0.069664
iteration 217 : loss : 0.391603, loss_ce: 0.099628
iteration 218 : loss : 0.397072, loss_ce: 0.102458
iteration 219 : loss : 0.355498, loss_ce: 0.044249
iteration 220 : loss : 0.385490, loss_ce: 0.089272
iteration 221 : loss : 0.395308, loss_ce: 0.106682
iteration 222 : loss : 0.369423, loss_ce: 0.072657
iteration 223 : loss : 0.382422, loss_ce: 0.094277
iteration 224 : loss : 0.390343, loss_ce: 0.106474
iteration 225 : loss : 0.379244, loss_ce: 0.088563
iteration 226 : loss : 0.378933, loss_ce: 0.084372
iteration 227 : loss : 0.374237, loss_ce: 0.070951
iteration 228 : loss : 0.365549, loss_ce: 0.076973
iteration 229 : loss : 0.378094, loss_ce: 0.091130
iteration 230 : loss : 0.385488, loss_ce: 0.098526
iteration 231 : loss : 0.399652, loss_ce: 0.126429
iteration 232 : loss : 0.393229, loss_ce: 0.113369
iteration 233 : loss : 0.385171, loss_ce: 0.113334
iteration 234 : loss : 0.377122, loss_ce: 0.094284
iteration 235 : loss : 0.382660, loss_ce: 0.096965
iteration 236 : loss : 0.376113, loss_ce: 0.098311
iteration 237 : loss : 0.362415, loss_ce: 0.063825
iteration 238 : loss : 0.364239, loss_ce: 0.069771
iteration 239 : loss : 0.394478, loss_ce: 0.105881
iteration 240 : loss : 0.367887, loss_ce: 0.073525
iteration 241 : loss : 0.384390, loss_ce: 0.095267
iteration 242 : loss : 0.404243, loss_ce: 0.137912
iteration 243 : loss : 0.386612, loss_ce: 0.111721
iteration 244 : loss : 0.386968, loss_ce: 0.109052
iteration 245 : loss : 0.388150, loss_ce: 0.112203
iteration 246 : loss : 0.366417, loss_ce: 0.090540
iteration 247 : loss : 0.380587, loss_ce: 0.107622
iteration 248 : loss : 0.382173, loss_ce: 0.101759
iteration 249 : loss : 0.376646, loss_ce: 0.102582
iteration 250 : loss : 0.381325, loss_ce: 0.093849
iteration 251 : loss : 0.378495, loss_ce: 0.102926
iteration 252 : loss : 0.371659, loss_ce: 0.086007
iteration 253 : loss : 0.394856, loss_ce: 0.111624
iteration 254 : loss : 0.391510, loss_ce: 0.117505
iteration 255 : loss : 0.348688, loss_ce: 0.055474
iteration 256 : loss : 0.398365, loss_ce: 0.133275
iteration 257 : loss : 0.357676, loss_ce: 0.078884
iteration 258 : loss : 0.358943, loss_ce: 0.070414
iteration 259 : loss : 0.382901, loss_ce: 0.115716
iteration 260 : loss : 0.360054, loss_ce: 0.069570
iteration 261 : loss : 0.367406, loss_ce: 0.089587
iteration 262 : loss : 0.392415, loss_ce: 0.106302
iteration 263 : loss : 0.364441, loss_ce: 0.096869
iteration 264 : loss : 0.363356, loss_ce: 0.084147
iteration 265 : loss : 0.355918, loss_ce: 0.082972
iteration 266 : loss : 0.363654, loss_ce: 0.097222
iteration 267 : loss : 0.380991, loss_ce: 0.114073
iteration 268 : loss : 0.359961, loss_ce: 0.084916
iteration 269 : loss : 0.347056, loss_ce: 0.065804
iteration 270 : loss : 0.363142, loss_ce: 0.067832
iteration 271 : loss : 0.381421, loss_ce: 0.084276
iteration 272 : loss : 0.362638, loss_ce: 0.083249
iteration 273 : loss : 0.367739, loss_ce: 0.084380
iteration 274 : loss : 0.374267, loss_ce: 0.103623
iteration 275 : loss : 0.369618, loss_ce: 0.094451
iteration 276 : loss : 0.374824, loss_ce: 0.112720
iteration 277 : loss : 0.361037, loss_ce: 0.096215
iteration 278 : loss : 0.356340, loss_ce: 0.076053
iteration 279 : loss : 0.425131, loss_ce: 0.107939
  2%|▍                              | 3/200 [03:00<3:17:51, 60.26s/it]iteration 280 : loss : 0.373989, loss_ce: 0.103112
iteration 281 : loss : 0.367346, loss_ce: 0.096070
iteration 282 : loss : 0.365878, loss_ce: 0.090694
iteration 283 : loss : 0.363942, loss_ce: 0.079053
iteration 284 : loss : 0.350394, loss_ce: 0.063790
iteration 285 : loss : 0.381889, loss_ce: 0.105479
iteration 286 : loss : 0.369644, loss_ce: 0.096371
iteration 287 : loss : 0.363083, loss_ce: 0.086255
iteration 288 : loss : 0.375973, loss_ce: 0.097824
iteration 289 : loss : 0.364732, loss_ce: 0.102746
iteration 290 : loss : 0.349393, loss_ce: 0.081619
iteration 291 : loss : 0.356791, loss_ce: 0.079120
iteration 292 : loss : 0.376634, loss_ce: 0.095453
iteration 293 : loss : 0.395370, loss_ce: 0.129273
iteration 294 : loss : 0.344007, loss_ce: 0.058564
iteration 295 : loss : 0.375987, loss_ce: 0.091899
iteration 296 : loss : 0.357617, loss_ce: 0.074663
iteration 297 : loss : 0.348603, loss_ce: 0.066439
iteration 298 : loss : 0.385428, loss_ce: 0.115858
iteration 299 : loss : 0.371024, loss_ce: 0.100150
iteration 300 : loss : 0.355378, loss_ce: 0.084843
iteration 301 : loss : 0.346924, loss_ce: 0.072065
iteration 302 : loss : 0.363703, loss_ce: 0.084658
iteration 303 : loss : 0.352161, loss_ce: 0.076116
iteration 304 : loss : 0.356236, loss_ce: 0.058744
iteration 305 : loss : 0.357686, loss_ce: 0.060855
iteration 306 : loss : 0.335954, loss_ce: 0.053439
iteration 307 : loss : 0.378023, loss_ce: 0.091972
iteration 308 : loss : 0.369982, loss_ce: 0.077828
iteration 309 : loss : 0.361316, loss_ce: 0.074500
iteration 310 : loss : 0.373510, loss_ce: 0.111723
iteration 311 : loss : 0.362706, loss_ce: 0.092477
iteration 312 : loss : 0.357403, loss_ce: 0.091411
iteration 313 : loss : 0.361304, loss_ce: 0.082093
iteration 314 : loss : 0.368489, loss_ce: 0.105684
iteration 315 : loss : 0.372656, loss_ce: 0.124435
iteration 316 : loss : 0.363567, loss_ce: 0.083114
iteration 317 : loss : 0.371798, loss_ce: 0.075685
iteration 318 : loss : 0.357450, loss_ce: 0.079975
iteration 319 : loss : 0.361982, loss_ce: 0.090886
iteration 320 : loss : 0.350998, loss_ce: 0.063509
iteration 321 : loss : 0.358969, loss_ce: 0.077331
iteration 322 : loss : 0.361126, loss_ce: 0.082657
iteration 323 : loss : 0.354971, loss_ce: 0.084543
iteration 324 : loss : 0.350070, loss_ce: 0.077865
iteration 325 : loss : 0.362148, loss_ce: 0.089089
iteration 326 : loss : 0.351049, loss_ce: 0.071273
iteration 327 : loss : 0.361546, loss_ce: 0.093643
iteration 328 : loss : 0.354325, loss_ce: 0.081279
iteration 329 : loss : 0.335326, loss_ce: 0.059233
iteration 330 : loss : 0.336975, loss_ce: 0.058542
iteration 331 : loss : 0.337593, loss_ce: 0.068634
iteration 332 : loss : 0.375682, loss_ce: 0.110074
iteration 333 : loss : 0.348491, loss_ce: 0.078621
iteration 334 : loss : 0.346316, loss_ce: 0.070249
iteration 335 : loss : 0.378359, loss_ce: 0.124402
iteration 336 : loss : 0.352252, loss_ce: 0.085327
iteration 337 : loss : 0.349278, loss_ce: 0.064325
iteration 338 : loss : 0.364933, loss_ce: 0.089094
iteration 339 : loss : 0.341502, loss_ce: 0.068457
iteration 340 : loss : 0.351983, loss_ce: 0.081175
iteration 341 : loss : 0.357397, loss_ce: 0.102390
iteration 342 : loss : 0.348452, loss_ce: 0.068575
iteration 343 : loss : 0.347455, loss_ce: 0.080641
iteration 344 : loss : 0.396915, loss_ce: 0.148777
iteration 345 : loss : 0.343985, loss_ce: 0.065627
iteration 346 : loss : 0.326608, loss_ce: 0.056715
iteration 347 : loss : 0.356576, loss_ce: 0.084067
iteration 348 : loss : 0.331054, loss_ce: 0.055776
iteration 349 : loss : 0.333021, loss_ce: 0.062519
iteration 350 : loss : 0.341359, loss_ce: 0.064513
iteration 351 : loss : 0.350484, loss_ce: 0.089452
iteration 352 : loss : 0.346245, loss_ce: 0.079764
iteration 353 : loss : 0.350301, loss_ce: 0.097643
iteration 354 : loss : 0.355241, loss_ce: 0.089430
iteration 355 : loss : 0.337029, loss_ce: 0.071721
iteration 356 : loss : 0.332780, loss_ce: 0.062743
iteration 357 : loss : 0.359920, loss_ce: 0.109082
iteration 358 : loss : 0.334999, loss_ce: 0.073920
iteration 359 : loss : 0.347498, loss_ce: 0.082420
iteration 360 : loss : 0.344406, loss_ce: 0.089171
iteration 361 : loss : 0.333811, loss_ce: 0.080788
iteration 362 : loss : 0.343774, loss_ce: 0.093728
iteration 363 : loss : 0.353966, loss_ce: 0.113729
iteration 364 : loss : 0.326247, loss_ce: 0.070919
iteration 365 : loss : 0.317514, loss_ce: 0.063183
iteration 366 : loss : 0.334396, loss_ce: 0.075230
iteration 367 : loss : 0.337222, loss_ce: 0.079366
iteration 368 : loss : 0.325869, loss_ce: 0.079063
iteration 369 : loss : 0.349721, loss_ce: 0.112815
iteration 370 : loss : 0.337777, loss_ce: 0.092240
iteration 371 : loss : 0.320882, loss_ce: 0.070580
iteration 372 : loss : 0.380435, loss_ce: 0.046720
  2%|▌                              | 4/200 [04:01<3:17:45, 60.54s/it]iteration 373 : loss : 0.314346, loss_ce: 0.069367
iteration 374 : loss : 0.336908, loss_ce: 0.056756
iteration 375 : loss : 0.321300, loss_ce: 0.072899
iteration 376 : loss : 0.308757, loss_ce: 0.047225
iteration 377 : loss : 0.336370, loss_ce: 0.081754
iteration 378 : loss : 0.321775, loss_ce: 0.072165
iteration 379 : loss : 0.340070, loss_ce: 0.072223
iteration 380 : loss : 0.312545, loss_ce: 0.078661
iteration 381 : loss : 0.324466, loss_ce: 0.072217
iteration 382 : loss : 0.337037, loss_ce: 0.094537
iteration 383 : loss : 0.326436, loss_ce: 0.086448
iteration 384 : loss : 0.323481, loss_ce: 0.080558
iteration 385 : loss : 0.326965, loss_ce: 0.099355
iteration 386 : loss : 0.304412, loss_ce: 0.065269
iteration 387 : loss : 0.334602, loss_ce: 0.055860
iteration 388 : loss : 0.329038, loss_ce: 0.077038
iteration 389 : loss : 0.303961, loss_ce: 0.056840
iteration 390 : loss : 0.342726, loss_ce: 0.111020
iteration 391 : loss : 0.321677, loss_ce: 0.092314
iteration 392 : loss : 0.315373, loss_ce: 0.081783
iteration 393 : loss : 0.308564, loss_ce: 0.078417
iteration 394 : loss : 0.309491, loss_ce: 0.081902
iteration 395 : loss : 0.328283, loss_ce: 0.044334
iteration 396 : loss : 0.325178, loss_ce: 0.090754
iteration 397 : loss : 0.317585, loss_ce: 0.070593
iteration 398 : loss : 0.316961, loss_ce: 0.081894
iteration 399 : loss : 0.301025, loss_ce: 0.052463
iteration 400 : loss : 0.315058, loss_ce: 0.055347
iteration 401 : loss : 0.296614, loss_ce: 0.049451
iteration 402 : loss : 0.300029, loss_ce: 0.057316
iteration 403 : loss : 0.314928, loss_ce: 0.073853
iteration 404 : loss : 0.311386, loss_ce: 0.061490
iteration 405 : loss : 0.301700, loss_ce: 0.047557
iteration 406 : loss : 0.308672, loss_ce: 0.066946
iteration 407 : loss : 0.309050, loss_ce: 0.084734
iteration 408 : loss : 0.317848, loss_ce: 0.056079
iteration 409 : loss : 0.297613, loss_ce: 0.060427
iteration 410 : loss : 0.301457, loss_ce: 0.062863
iteration 411 : loss : 0.300864, loss_ce: 0.060316
iteration 412 : loss : 0.303104, loss_ce: 0.064327
iteration 413 : loss : 0.313941, loss_ce: 0.081166
iteration 414 : loss : 0.312959, loss_ce: 0.034834
iteration 415 : loss : 0.310808, loss_ce: 0.085884
iteration 416 : loss : 0.318037, loss_ce: 0.052861
iteration 417 : loss : 0.308878, loss_ce: 0.070702
iteration 418 : loss : 0.316533, loss_ce: 0.080199
iteration 419 : loss : 0.318705, loss_ce: 0.082706
iteration 420 : loss : 0.325371, loss_ce: 0.101686
iteration 421 : loss : 0.289733, loss_ce: 0.059431
iteration 422 : loss : 0.310697, loss_ce: 0.067756
iteration 423 : loss : 0.306317, loss_ce: 0.074969
iteration 424 : loss : 0.297118, loss_ce: 0.063442
iteration 425 : loss : 0.318250, loss_ce: 0.076713
iteration 426 : loss : 0.294574, loss_ce: 0.061856
iteration 427 : loss : 0.297627, loss_ce: 0.065206
iteration 428 : loss : 0.301013, loss_ce: 0.075236
iteration 429 : loss : 0.321881, loss_ce: 0.099139
iteration 430 : loss : 0.298402, loss_ce: 0.062640
iteration 431 : loss : 0.325186, loss_ce: 0.100111
iteration 432 : loss : 0.303163, loss_ce: 0.056566
iteration 433 : loss : 0.286774, loss_ce: 0.041483
iteration 434 : loss : 0.344338, loss_ce: 0.120895
iteration 435 : loss : 0.336325, loss_ce: 0.090536
iteration 436 : loss : 0.298604, loss_ce: 0.063141
iteration 437 : loss : 0.302938, loss_ce: 0.073981
iteration 438 : loss : 0.307007, loss_ce: 0.080577
iteration 439 : loss : 0.323371, loss_ce: 0.071496
iteration 440 : loss : 0.301933, loss_ce: 0.077487
iteration 441 : loss : 0.296870, loss_ce: 0.076773
iteration 442 : loss : 0.302543, loss_ce: 0.078379
iteration 443 : loss : 0.321706, loss_ce: 0.102693
iteration 444 : loss : 0.294138, loss_ce: 0.063404
iteration 445 : loss : 0.317406, loss_ce: 0.097008
iteration 446 : loss : 0.282653, loss_ce: 0.040931
iteration 447 : loss : 0.283753, loss_ce: 0.038944
iteration 448 : loss : 0.294763, loss_ce: 0.073240
iteration 449 : loss : 0.283804, loss_ce: 0.042797
iteration 450 : loss : 0.283224, loss_ce: 0.037458
iteration 451 : loss : 0.293433, loss_ce: 0.052188
iteration 452 : loss : 0.311124, loss_ce: 0.074488
iteration 453 : loss : 0.312522, loss_ce: 0.085043
iteration 454 : loss : 0.291187, loss_ce: 0.054411
iteration 455 : loss : 0.292444, loss_ce: 0.066237
iteration 456 : loss : 0.308027, loss_ce: 0.089670
iteration 457 : loss : 0.298420, loss_ce: 0.065705
iteration 458 : loss : 0.294430, loss_ce: 0.052439
iteration 459 : loss : 0.316625, loss_ce: 0.103412
iteration 460 : loss : 0.305571, loss_ce: 0.084922
iteration 461 : loss : 0.294028, loss_ce: 0.066018
iteration 462 : loss : 0.303447, loss_ce: 0.061348
iteration 463 : loss : 0.304334, loss_ce: 0.076319
iteration 464 : loss : 0.290994, loss_ce: 0.070342
iteration 465 : loss : 0.386764, loss_ce: 0.044455
  2%|▊                              | 5/200 [05:02<3:17:38, 60.81s/it]iteration 466 : loss : 0.298024, loss_ce: 0.069135
iteration 467 : loss : 0.298883, loss_ce: 0.057226
iteration 468 : loss : 0.291395, loss_ce: 0.058761
iteration 469 : loss : 0.298599, loss_ce: 0.057384
iteration 470 : loss : 0.297535, loss_ce: 0.077399
iteration 471 : loss : 0.285274, loss_ce: 0.042093
iteration 472 : loss : 0.295715, loss_ce: 0.072205
iteration 473 : loss : 0.297809, loss_ce: 0.046245
iteration 474 : loss : 0.295651, loss_ce: 0.051372
iteration 475 : loss : 0.301560, loss_ce: 0.076870
iteration 476 : loss : 0.303467, loss_ce: 0.076304
iteration 477 : loss : 0.307872, loss_ce: 0.068434
iteration 478 : loss : 0.307239, loss_ce: 0.073808
iteration 479 : loss : 0.285499, loss_ce: 0.056664
iteration 480 : loss : 0.293389, loss_ce: 0.064341
iteration 481 : loss : 0.275465, loss_ce: 0.045579
iteration 482 : loss : 0.289887, loss_ce: 0.056352
iteration 483 : loss : 0.319379, loss_ce: 0.078604
iteration 484 : loss : 0.289506, loss_ce: 0.050714
iteration 485 : loss : 0.304868, loss_ce: 0.075686
iteration 486 : loss : 0.297950, loss_ce: 0.063008
iteration 487 : loss : 0.299081, loss_ce: 0.082815
iteration 488 : loss : 0.302422, loss_ce: 0.068217
iteration 489 : loss : 0.287027, loss_ce: 0.058667
iteration 490 : loss : 0.320612, loss_ce: 0.036885
iteration 491 : loss : 0.304840, loss_ce: 0.055900
iteration 492 : loss : 0.300697, loss_ce: 0.081359
iteration 493 : loss : 0.279835, loss_ce: 0.049241
iteration 494 : loss : 0.289198, loss_ce: 0.055059
iteration 495 : loss : 0.308863, loss_ce: 0.076404
iteration 496 : loss : 0.303574, loss_ce: 0.061830
iteration 497 : loss : 0.284730, loss_ce: 0.055090
iteration 498 : loss : 0.291566, loss_ce: 0.060143
iteration 499 : loss : 0.304455, loss_ce: 0.085587
iteration 500 : loss : 0.299547, loss_ce: 0.053720
iteration 501 : loss : 0.302653, loss_ce: 0.051381
iteration 502 : loss : 0.299569, loss_ce: 0.059633
iteration 503 : loss : 0.295794, loss_ce: 0.053487
iteration 504 : loss : 0.284578, loss_ce: 0.045859
iteration 505 : loss : 0.298413, loss_ce: 0.068746
iteration 506 : loss : 0.289210, loss_ce: 0.065372
iteration 507 : loss : 0.289674, loss_ce: 0.059301
iteration 508 : loss : 0.290328, loss_ce: 0.073334
iteration 509 : loss : 0.276975, loss_ce: 0.047606
iteration 510 : loss : 0.291230, loss_ce: 0.066840
iteration 511 : loss : 0.296768, loss_ce: 0.074421
iteration 512 : loss : 0.286491, loss_ce: 0.067433
iteration 513 : loss : 0.289392, loss_ce: 0.079155
iteration 514 : loss : 0.279190, loss_ce: 0.052144
iteration 515 : loss : 0.286961, loss_ce: 0.047929
iteration 516 : loss : 0.291198, loss_ce: 0.064770
iteration 517 : loss : 0.277023, loss_ce: 0.055081
iteration 518 : loss : 0.292624, loss_ce: 0.077376
iteration 519 : loss : 0.288868, loss_ce: 0.075871
iteration 520 : loss : 0.287290, loss_ce: 0.080440
iteration 521 : loss : 0.283287, loss_ce: 0.070672
iteration 522 : loss : 0.292900, loss_ce: 0.079292
iteration 523 : loss : 0.288561, loss_ce: 0.079158
iteration 524 : loss : 0.305299, loss_ce: 0.095562
iteration 525 : loss : 0.285484, loss_ce: 0.063121
iteration 526 : loss : 0.280492, loss_ce: 0.060134
iteration 527 : loss : 0.287085, loss_ce: 0.062644
iteration 528 : loss : 0.282472, loss_ce: 0.064079
iteration 529 : loss : 0.278491, loss_ce: 0.055210
iteration 530 : loss : 0.271803, loss_ce: 0.043658
iteration 531 : loss : 0.273160, loss_ce: 0.041261
iteration 532 : loss : 0.258915, loss_ce: 0.032997
iteration 533 : loss : 0.288857, loss_ce: 0.069301
iteration 534 : loss : 0.277168, loss_ce: 0.058130
iteration 535 : loss : 0.276849, loss_ce: 0.046689
iteration 536 : loss : 0.257902, loss_ce: 0.048853
iteration 537 : loss : 0.276879, loss_ce: 0.066518
iteration 538 : loss : 0.276963, loss_ce: 0.057638
iteration 539 : loss : 0.271674, loss_ce: 0.061176
iteration 540 : loss : 0.261358, loss_ce: 0.041524
iteration 541 : loss : 0.291214, loss_ce: 0.069288
iteration 542 : loss : 0.277742, loss_ce: 0.062617
iteration 543 : loss : 0.271455, loss_ce: 0.055553
iteration 544 : loss : 0.269360, loss_ce: 0.043726
iteration 545 : loss : 0.278449, loss_ce: 0.052560
iteration 546 : loss : 0.270345, loss_ce: 0.054440
iteration 547 : loss : 0.272119, loss_ce: 0.061759
iteration 548 : loss : 0.281185, loss_ce: 0.061620
iteration 549 : loss : 0.264326, loss_ce: 0.043354
iteration 550 : loss : 0.273327, loss_ce: 0.045983
iteration 551 : loss : 0.271395, loss_ce: 0.063479
iteration 552 : loss : 0.265602, loss_ce: 0.047725
iteration 553 : loss : 0.261403, loss_ce: 0.053297
iteration 554 : loss : 0.262555, loss_ce: 0.037912
iteration 555 : loss : 0.274339, loss_ce: 0.072380
iteration 556 : loss : 0.250752, loss_ce: 0.048544
iteration 557 : loss : 0.245486, loss_ce: 0.047011
iteration 558 : loss : 0.334317, loss_ce: 0.055191
  3%|▉                              | 6/200 [06:04<3:17:34, 61.11s/it]iteration 559 : loss : 0.254884, loss_ce: 0.053479
iteration 560 : loss : 0.272670, loss_ce: 0.056190
iteration 561 : loss : 0.269900, loss_ce: 0.067532
iteration 562 : loss : 0.246992, loss_ce: 0.047923
iteration 563 : loss : 0.277593, loss_ce: 0.062835
iteration 564 : loss : 0.260787, loss_ce: 0.060601
iteration 565 : loss : 0.255707, loss_ce: 0.056625
iteration 566 : loss : 0.268382, loss_ce: 0.078141
iteration 567 : loss : 0.257761, loss_ce: 0.060562
iteration 568 : loss : 0.257747, loss_ce: 0.041201
iteration 569 : loss : 0.268636, loss_ce: 0.064565
iteration 570 : loss : 0.253085, loss_ce: 0.040957
iteration 571 : loss : 0.267708, loss_ce: 0.059290
iteration 572 : loss : 0.254809, loss_ce: 0.054349
iteration 573 : loss : 0.254375, loss_ce: 0.045199
iteration 574 : loss : 0.249771, loss_ce: 0.049311
iteration 575 : loss : 0.259732, loss_ce: 0.064837
iteration 576 : loss : 0.259933, loss_ce: 0.059264
iteration 577 : loss : 0.251728, loss_ce: 0.062168
iteration 578 : loss : 0.256730, loss_ce: 0.074256
iteration 579 : loss : 0.240191, loss_ce: 0.045878
iteration 580 : loss : 0.259141, loss_ce: 0.051613
iteration 581 : loss : 0.270740, loss_ce: 0.064704
iteration 582 : loss : 0.241723, loss_ce: 0.034642
iteration 583 : loss : 0.259967, loss_ce: 0.051312
iteration 584 : loss : 0.244241, loss_ce: 0.038462
iteration 585 : loss : 0.256905, loss_ce: 0.057829
iteration 586 : loss : 0.277377, loss_ce: 0.051716
iteration 587 : loss : 0.287699, loss_ce: 0.062428
iteration 588 : loss : 0.251623, loss_ce: 0.064775
iteration 589 : loss : 0.257356, loss_ce: 0.064038
iteration 590 : loss : 0.252798, loss_ce: 0.055141
iteration 591 : loss : 0.257414, loss_ce: 0.053641
iteration 592 : loss : 0.273204, loss_ce: 0.073337
iteration 593 : loss : 0.264329, loss_ce: 0.061977
iteration 594 : loss : 0.238782, loss_ce: 0.044117
iteration 595 : loss : 0.237710, loss_ce: 0.037955
iteration 596 : loss : 0.254624, loss_ce: 0.048536
iteration 597 : loss : 0.253987, loss_ce: 0.051780
iteration 598 : loss : 0.243235, loss_ce: 0.048964
iteration 599 : loss : 0.264257, loss_ce: 0.065538
iteration 600 : loss : 0.269744, loss_ce: 0.073538
iteration 601 : loss : 0.252538, loss_ce: 0.067467
iteration 602 : loss : 0.252021, loss_ce: 0.067483
iteration 603 : loss : 0.256776, loss_ce: 0.055248
iteration 604 : loss : 0.272023, loss_ce: 0.052026
iteration 605 : loss : 0.256336, loss_ce: 0.059209
iteration 606 : loss : 0.258934, loss_ce: 0.059415
iteration 607 : loss : 0.245555, loss_ce: 0.043063
iteration 608 : loss : 0.262866, loss_ce: 0.054908
iteration 609 : loss : 0.276570, loss_ce: 0.073072
iteration 610 : loss : 0.259429, loss_ce: 0.063743
iteration 611 : loss : 0.263103, loss_ce: 0.071104
iteration 612 : loss : 0.243633, loss_ce: 0.053399
iteration 613 : loss : 0.257390, loss_ce: 0.054913
iteration 614 : loss : 0.245983, loss_ce: 0.053419
iteration 615 : loss : 0.244991, loss_ce: 0.065995
iteration 616 : loss : 0.254054, loss_ce: 0.056355
iteration 617 : loss : 0.272194, loss_ce: 0.047006
iteration 618 : loss : 0.246535, loss_ce: 0.053892
iteration 619 : loss : 0.273390, loss_ce: 0.094424
iteration 620 : loss : 0.238756, loss_ce: 0.046354
iteration 621 : loss : 0.234703, loss_ce: 0.040126
iteration 622 : loss : 0.251231, loss_ce: 0.065043
iteration 623 : loss : 0.272610, loss_ce: 0.063554
iteration 624 : loss : 0.268200, loss_ce: 0.063976
iteration 625 : loss : 0.224848, loss_ce: 0.044091
iteration 626 : loss : 0.253543, loss_ce: 0.050932
iteration 627 : loss : 0.247575, loss_ce: 0.062393
iteration 628 : loss : 0.240506, loss_ce: 0.056845
iteration 629 : loss : 0.237785, loss_ce: 0.036039
iteration 630 : loss : 0.251380, loss_ce: 0.050213
iteration 631 : loss : 0.242717, loss_ce: 0.055254
iteration 632 : loss : 0.239280, loss_ce: 0.042546
iteration 633 : loss : 0.256897, loss_ce: 0.063551
iteration 634 : loss : 0.220392, loss_ce: 0.032865
iteration 635 : loss : 0.232594, loss_ce: 0.056592
iteration 636 : loss : 0.267079, loss_ce: 0.052203
iteration 637 : loss : 0.246728, loss_ce: 0.039405
iteration 638 : loss : 0.251518, loss_ce: 0.065400
iteration 639 : loss : 0.224686, loss_ce: 0.044472
iteration 640 : loss : 0.241490, loss_ce: 0.036219
iteration 641 : loss : 0.251377, loss_ce: 0.087816
iteration 642 : loss : 0.222352, loss_ce: 0.046710
iteration 643 : loss : 0.252157, loss_ce: 0.052792
iteration 644 : loss : 0.232619, loss_ce: 0.043936
iteration 645 : loss : 0.230808, loss_ce: 0.041703
iteration 646 : loss : 0.231732, loss_ce: 0.026976
iteration 647 : loss : 0.239879, loss_ce: 0.031144
iteration 648 : loss : 0.277487, loss_ce: 0.080198
iteration 649 : loss : 0.240328, loss_ce: 0.057271
iteration 650 : loss : 0.253412, loss_ce: 0.055110
iteration 651 : loss : 0.352204, loss_ce: 0.017083
  4%|█                              | 7/200 [07:06<3:17:25, 61.37s/it]iteration 652 : loss : 0.257227, loss_ce: 0.050297
iteration 653 : loss : 0.294907, loss_ce: 0.084442
iteration 654 : loss : 0.241115, loss_ce: 0.060115
iteration 655 : loss : 0.241326, loss_ce: 0.065371
iteration 656 : loss : 0.230673, loss_ce: 0.050550
iteration 657 : loss : 0.237960, loss_ce: 0.051759
iteration 658 : loss : 0.229759, loss_ce: 0.042334
iteration 659 : loss : 0.235584, loss_ce: 0.054229
iteration 660 : loss : 0.237006, loss_ce: 0.050338
iteration 661 : loss : 0.239110, loss_ce: 0.047236
iteration 662 : loss : 0.229538, loss_ce: 0.052041
iteration 663 : loss : 0.238486, loss_ce: 0.059750
iteration 664 : loss : 0.247089, loss_ce: 0.071973
iteration 665 : loss : 0.275425, loss_ce: 0.044410
iteration 666 : loss : 0.233450, loss_ce: 0.057238
iteration 667 : loss : 0.235316, loss_ce: 0.055032
iteration 668 : loss : 0.253030, loss_ce: 0.054362
iteration 669 : loss : 0.232229, loss_ce: 0.061840
iteration 670 : loss : 0.219077, loss_ce: 0.045619
iteration 671 : loss : 0.227754, loss_ce: 0.045923
iteration 672 : loss : 0.230743, loss_ce: 0.056356
iteration 673 : loss : 0.243366, loss_ce: 0.043031
iteration 674 : loss : 0.254210, loss_ce: 0.075521
iteration 675 : loss : 0.223276, loss_ce: 0.046802
iteration 676 : loss : 0.236041, loss_ce: 0.049266
iteration 677 : loss : 0.235849, loss_ce: 0.083595
iteration 678 : loss : 0.236388, loss_ce: 0.064182
iteration 679 : loss : 0.243580, loss_ce: 0.050550
iteration 680 : loss : 0.224921, loss_ce: 0.057557
iteration 681 : loss : 0.234212, loss_ce: 0.048409
iteration 682 : loss : 0.223383, loss_ce: 0.045019
iteration 683 : loss : 0.221816, loss_ce: 0.046802
iteration 684 : loss : 0.213129, loss_ce: 0.037871
iteration 685 : loss : 0.231174, loss_ce: 0.049596
iteration 686 : loss : 0.230761, loss_ce: 0.059765
iteration 687 : loss : 0.237167, loss_ce: 0.059745
iteration 688 : loss : 0.267982, loss_ce: 0.066456
iteration 689 : loss : 0.228564, loss_ce: 0.044303
iteration 690 : loss : 0.265152, loss_ce: 0.061699
iteration 691 : loss : 0.202776, loss_ce: 0.036697
iteration 692 : loss : 0.229202, loss_ce: 0.056446
iteration 693 : loss : 0.220139, loss_ce: 0.057078
iteration 694 : loss : 0.213710, loss_ce: 0.032291
iteration 695 : loss : 0.215264, loss_ce: 0.027677
iteration 696 : loss : 0.211452, loss_ce: 0.043118
iteration 697 : loss : 0.245932, loss_ce: 0.070234
iteration 698 : loss : 0.223864, loss_ce: 0.061402
iteration 699 : loss : 0.211628, loss_ce: 0.037362
iteration 700 : loss : 0.227329, loss_ce: 0.056605
iteration 701 : loss : 0.216176, loss_ce: 0.028417
iteration 702 : loss : 0.240669, loss_ce: 0.055823
iteration 703 : loss : 0.236006, loss_ce: 0.060165
iteration 704 : loss : 0.225028, loss_ce: 0.041466
iteration 705 : loss : 0.220758, loss_ce: 0.047162
iteration 706 : loss : 0.212115, loss_ce: 0.043296
iteration 707 : loss : 0.232012, loss_ce: 0.056085
iteration 708 : loss : 0.225338, loss_ce: 0.052043
iteration 709 : loss : 0.230403, loss_ce: 0.047798
iteration 710 : loss : 0.239952, loss_ce: 0.034637
iteration 711 : loss : 0.213453, loss_ce: 0.051958
iteration 712 : loss : 0.244263, loss_ce: 0.041415
iteration 713 : loss : 0.204258, loss_ce: 0.047454
iteration 714 : loss : 0.214661, loss_ce: 0.036999
iteration 715 : loss : 0.232553, loss_ce: 0.045670
iteration 716 : loss : 0.217678, loss_ce: 0.054943
iteration 717 : loss : 0.205004, loss_ce: 0.035434
iteration 718 : loss : 0.209263, loss_ce: 0.039963
iteration 719 : loss : 0.210061, loss_ce: 0.044178
iteration 720 : loss : 0.215739, loss_ce: 0.033751
iteration 721 : loss : 0.233490, loss_ce: 0.040171
iteration 722 : loss : 0.212634, loss_ce: 0.037467
iteration 723 : loss : 0.253470, loss_ce: 0.038020
iteration 724 : loss : 0.232052, loss_ce: 0.052002
iteration 725 : loss : 0.217825, loss_ce: 0.044845
iteration 726 : loss : 0.208116, loss_ce: 0.038719
iteration 727 : loss : 0.218862, loss_ce: 0.051143
iteration 728 : loss : 0.244566, loss_ce: 0.058717
iteration 729 : loss : 0.234915, loss_ce: 0.052568
iteration 730 : loss : 0.219115, loss_ce: 0.041375
iteration 731 : loss : 0.235234, loss_ce: 0.046077
iteration 732 : loss : 0.223543, loss_ce: 0.047076
iteration 733 : loss : 0.213326, loss_ce: 0.032969
iteration 734 : loss : 0.237692, loss_ce: 0.053239
iteration 735 : loss : 0.229713, loss_ce: 0.051882
iteration 736 : loss : 0.206547, loss_ce: 0.040426
iteration 737 : loss : 0.234144, loss_ce: 0.068857
iteration 738 : loss : 0.210437, loss_ce: 0.039012
iteration 739 : loss : 0.219700, loss_ce: 0.052581
iteration 740 : loss : 0.217528, loss_ce: 0.038386
iteration 741 : loss : 0.217389, loss_ce: 0.044938
iteration 742 : loss : 0.223874, loss_ce: 0.054124
iteration 743 : loss : 0.200093, loss_ce: 0.027173
iteration 744 : loss : 0.397003, loss_ce: 0.005290
  4%|█▏                             | 8/200 [08:08<3:17:07, 61.60s/it]iteration 745 : loss : 0.241166, loss_ce: 0.066564
iteration 746 : loss : 0.231758, loss_ce: 0.057135
iteration 747 : loss : 0.227953, loss_ce: 0.030296
iteration 748 : loss : 0.227518, loss_ce: 0.061297
iteration 749 : loss : 0.239177, loss_ce: 0.027811
iteration 750 : loss : 0.219380, loss_ce: 0.049169
iteration 751 : loss : 0.205247, loss_ce: 0.035775
iteration 752 : loss : 0.219658, loss_ce: 0.045625
iteration 753 : loss : 0.216735, loss_ce: 0.043876
iteration 754 : loss : 0.211947, loss_ce: 0.041187
iteration 755 : loss : 0.239970, loss_ce: 0.050399
iteration 756 : loss : 0.223519, loss_ce: 0.046645
iteration 757 : loss : 0.222318, loss_ce: 0.035233
iteration 758 : loss : 0.210115, loss_ce: 0.044028
iteration 759 : loss : 0.236929, loss_ce: 0.056220
iteration 760 : loss : 0.209970, loss_ce: 0.038424
iteration 761 : loss : 0.207115, loss_ce: 0.040715
iteration 762 : loss : 0.217539, loss_ce: 0.051453
iteration 763 : loss : 0.217477, loss_ce: 0.041706
iteration 764 : loss : 0.210715, loss_ce: 0.032771
iteration 765 : loss : 0.206602, loss_ce: 0.049158
iteration 766 : loss : 0.199555, loss_ce: 0.035993
iteration 767 : loss : 0.211879, loss_ce: 0.039514
iteration 768 : loss : 0.220705, loss_ce: 0.054293
iteration 769 : loss : 0.210922, loss_ce: 0.041834
iteration 770 : loss : 0.202412, loss_ce: 0.033415
iteration 771 : loss : 0.218809, loss_ce: 0.044968
iteration 772 : loss : 0.230385, loss_ce: 0.043176
iteration 773 : loss : 0.222619, loss_ce: 0.038795
iteration 774 : loss : 0.198606, loss_ce: 0.026730
iteration 775 : loss : 0.204991, loss_ce: 0.056593
iteration 776 : loss : 0.217089, loss_ce: 0.040391
iteration 777 : loss : 0.201216, loss_ce: 0.045839
iteration 778 : loss : 0.193259, loss_ce: 0.028881
iteration 779 : loss : 0.210623, loss_ce: 0.056445
iteration 780 : loss : 0.199429, loss_ce: 0.041399
iteration 781 : loss : 0.230153, loss_ce: 0.039364
iteration 782 : loss : 0.202253, loss_ce: 0.024066
iteration 783 : loss : 0.217890, loss_ce: 0.047895
iteration 784 : loss : 0.206588, loss_ce: 0.047300
iteration 785 : loss : 0.199329, loss_ce: 0.043601
iteration 786 : loss : 0.206581, loss_ce: 0.049261
iteration 787 : loss : 0.224989, loss_ce: 0.055989
iteration 788 : loss : 0.199889, loss_ce: 0.031925
iteration 789 : loss : 0.199458, loss_ce: 0.034562
iteration 790 : loss : 0.214363, loss_ce: 0.051001
iteration 791 : loss : 0.204648, loss_ce: 0.042401
iteration 792 : loss : 0.202129, loss_ce: 0.036685
iteration 793 : loss : 0.200792, loss_ce: 0.034230
iteration 794 : loss : 0.220158, loss_ce: 0.044921
iteration 795 : loss : 0.198966, loss_ce: 0.032599
iteration 796 : loss : 0.212506, loss_ce: 0.035365
iteration 797 : loss : 0.228932, loss_ce: 0.051794
iteration 798 : loss : 0.201240, loss_ce: 0.030703
iteration 799 : loss : 0.221309, loss_ce: 0.053303
iteration 800 : loss : 0.208653, loss_ce: 0.031898
iteration 801 : loss : 0.206307, loss_ce: 0.043301
iteration 802 : loss : 0.209586, loss_ce: 0.047732
iteration 803 : loss : 0.214915, loss_ce: 0.059062
iteration 804 : loss : 0.219792, loss_ce: 0.047195
iteration 805 : loss : 0.218343, loss_ce: 0.053535
iteration 806 : loss : 0.216237, loss_ce: 0.049085
iteration 807 : loss : 0.212482, loss_ce: 0.042043
iteration 808 : loss : 0.203248, loss_ce: 0.046741
iteration 809 : loss : 0.216019, loss_ce: 0.040390
iteration 810 : loss : 0.210585, loss_ce: 0.027672
iteration 811 : loss : 0.230710, loss_ce: 0.055189
iteration 812 : loss : 0.212197, loss_ce: 0.025798
iteration 813 : loss : 0.225763, loss_ce: 0.042746
iteration 814 : loss : 0.225635, loss_ce: 0.032536
iteration 815 : loss : 0.225044, loss_ce: 0.038311
iteration 816 : loss : 0.210124, loss_ce: 0.050566
iteration 817 : loss : 0.200693, loss_ce: 0.043978
iteration 818 : loss : 0.212426, loss_ce: 0.058945
iteration 819 : loss : 0.208473, loss_ce: 0.044859
iteration 820 : loss : 0.196228, loss_ce: 0.025900
iteration 821 : loss : 0.199653, loss_ce: 0.049071
iteration 822 : loss : 0.210409, loss_ce: 0.040526
iteration 823 : loss : 0.234889, loss_ce: 0.044244
iteration 824 : loss : 0.203797, loss_ce: 0.046246
iteration 825 : loss : 0.198444, loss_ce: 0.032941
iteration 826 : loss : 0.240931, loss_ce: 0.032906
iteration 827 : loss : 0.210131, loss_ce: 0.043446
iteration 828 : loss : 0.199538, loss_ce: 0.039063
iteration 829 : loss : 0.221645, loss_ce: 0.038727
iteration 830 : loss : 0.218093, loss_ce: 0.031860
iteration 831 : loss : 0.230016, loss_ce: 0.066968
iteration 832 : loss : 0.217097, loss_ce: 0.023100
iteration 833 : loss : 0.218655, loss_ce: 0.064040
iteration 834 : loss : 0.222775, loss_ce: 0.041824
iteration 835 : loss : 0.204807, loss_ce: 0.047855
iteration 836 : loss : 0.208016, loss_ce: 0.042169
iteration 837 : loss : 0.264093, loss_ce: 0.107154
  4%|█▍                             | 9/200 [09:10<3:16:26, 61.71s/it]iteration 838 : loss : 0.217315, loss_ce: 0.053714
iteration 839 : loss : 0.225017, loss_ce: 0.055286
iteration 840 : loss : 0.224967, loss_ce: 0.061289
iteration 841 : loss : 0.211715, loss_ce: 0.041713
iteration 842 : loss : 0.230643, loss_ce: 0.058000
iteration 843 : loss : 0.222453, loss_ce: 0.050849
iteration 844 : loss : 0.206903, loss_ce: 0.042437
iteration 845 : loss : 0.189940, loss_ce: 0.034349
iteration 846 : loss : 0.198599, loss_ce: 0.032141
iteration 847 : loss : 0.191633, loss_ce: 0.036600
iteration 848 : loss : 0.231747, loss_ce: 0.041492
iteration 849 : loss : 0.193479, loss_ce: 0.028737
iteration 850 : loss : 0.219675, loss_ce: 0.051758
iteration 851 : loss : 0.175767, loss_ce: 0.026881
iteration 852 : loss : 0.208461, loss_ce: 0.032395
iteration 853 : loss : 0.202923, loss_ce: 0.050368
iteration 854 : loss : 0.200270, loss_ce: 0.038960
iteration 855 : loss : 0.211627, loss_ce: 0.047091
iteration 856 : loss : 0.200102, loss_ce: 0.039522
iteration 857 : loss : 0.201026, loss_ce: 0.034522
iteration 858 : loss : 0.189846, loss_ce: 0.038951
iteration 859 : loss : 0.212457, loss_ce: 0.047370
iteration 860 : loss : 0.207140, loss_ce: 0.037108
iteration 861 : loss : 0.201858, loss_ce: 0.045669
iteration 862 : loss : 0.202573, loss_ce: 0.041657
iteration 863 : loss : 0.196662, loss_ce: 0.058383
iteration 864 : loss : 0.197990, loss_ce: 0.034066
iteration 865 : loss : 0.194272, loss_ce: 0.027987
iteration 866 : loss : 0.235818, loss_ce: 0.084191
iteration 867 : loss : 0.194766, loss_ce: 0.033504
iteration 868 : loss : 0.197888, loss_ce: 0.033061
iteration 869 : loss : 0.193876, loss_ce: 0.023320
iteration 870 : loss : 0.216919, loss_ce: 0.065551
iteration 871 : loss : 0.203375, loss_ce: 0.049763
iteration 872 : loss : 0.229655, loss_ce: 0.062735
iteration 873 : loss : 0.200475, loss_ce: 0.045255
iteration 874 : loss : 0.202563, loss_ce: 0.047674
iteration 875 : loss : 0.196838, loss_ce: 0.042735
iteration 876 : loss : 0.214364, loss_ce: 0.046724
iteration 877 : loss : 0.199043, loss_ce: 0.054122
iteration 878 : loss : 0.186362, loss_ce: 0.049704
iteration 879 : loss : 0.179767, loss_ce: 0.035653
iteration 880 : loss : 0.202306, loss_ce: 0.045766
iteration 881 : loss : 0.184515, loss_ce: 0.027928
iteration 882 : loss : 0.191268, loss_ce: 0.047210
iteration 883 : loss : 0.194115, loss_ce: 0.045327
iteration 884 : loss : 0.197290, loss_ce: 0.038771
iteration 885 : loss : 0.181237, loss_ce: 0.041676
iteration 886 : loss : 0.202333, loss_ce: 0.042667
iteration 887 : loss : 0.210749, loss_ce: 0.037548
iteration 888 : loss : 0.193661, loss_ce: 0.048353
iteration 889 : loss : 0.188200, loss_ce: 0.039619
iteration 890 : loss : 0.201683, loss_ce: 0.048553
iteration 891 : loss : 0.187201, loss_ce: 0.031005
iteration 892 : loss : 0.188992, loss_ce: 0.043281
iteration 893 : loss : 0.173828, loss_ce: 0.027875
iteration 894 : loss : 0.199506, loss_ce: 0.022758
iteration 895 : loss : 0.190158, loss_ce: 0.042117
iteration 896 : loss : 0.173502, loss_ce: 0.031264
iteration 897 : loss : 0.187951, loss_ce: 0.037919
iteration 898 : loss : 0.170471, loss_ce: 0.030380
iteration 899 : loss : 0.169941, loss_ce: 0.028672
iteration 900 : loss : 0.185863, loss_ce: 0.044374
iteration 901 : loss : 0.192962, loss_ce: 0.039515
iteration 902 : loss : 0.185301, loss_ce: 0.035715
iteration 903 : loss : 0.180005, loss_ce: 0.034228
iteration 904 : loss : 0.194687, loss_ce: 0.029813
iteration 905 : loss : 0.172375, loss_ce: 0.035918
iteration 906 : loss : 0.192268, loss_ce: 0.057517
iteration 907 : loss : 0.179879, loss_ce: 0.044594
iteration 908 : loss : 0.164238, loss_ce: 0.032565
iteration 909 : loss : 0.162156, loss_ce: 0.033403
iteration 910 : loss : 0.169614, loss_ce: 0.026663
iteration 911 : loss : 0.225434, loss_ce: 0.029226
iteration 912 : loss : 0.166864, loss_ce: 0.029588
iteration 913 : loss : 0.184691, loss_ce: 0.039743
iteration 914 : loss : 0.178486, loss_ce: 0.034611
iteration 915 : loss : 0.244128, loss_ce: 0.030151
iteration 916 : loss : 0.176938, loss_ce: 0.025757
iteration 917 : loss : 0.201952, loss_ce: 0.045661
iteration 918 : loss : 0.185459, loss_ce: 0.028574
iteration 919 : loss : 0.174121, loss_ce: 0.036706
iteration 920 : loss : 0.201499, loss_ce: 0.060371
iteration 921 : loss : 0.185671, loss_ce: 0.045655
iteration 922 : loss : 0.208445, loss_ce: 0.038654
iteration 923 : loss : 0.212191, loss_ce: 0.049671
iteration 924 : loss : 0.232504, loss_ce: 0.019113
iteration 925 : loss : 0.200733, loss_ce: 0.025973
iteration 926 : loss : 0.176745, loss_ce: 0.022594
iteration 927 : loss : 0.200302, loss_ce: 0.044956
iteration 928 : loss : 0.187911, loss_ce: 0.050280
iteration 929 : loss : 0.191247, loss_ce: 0.053105
iteration 930 : loss : 0.231673, loss_ce: 0.085772
  5%|█▌                            | 10/200 [10:12<3:15:29, 61.74s/it]iteration 931 : loss : 0.192242, loss_ce: 0.032175
iteration 932 : loss : 0.174326, loss_ce: 0.032421
iteration 933 : loss : 0.172750, loss_ce: 0.032811
iteration 934 : loss : 0.205076, loss_ce: 0.056814
iteration 935 : loss : 0.191677, loss_ce: 0.037835
iteration 936 : loss : 0.188987, loss_ce: 0.041809
iteration 937 : loss : 0.180073, loss_ce: 0.044363
iteration 938 : loss : 0.171464, loss_ce: 0.033724
iteration 939 : loss : 0.168634, loss_ce: 0.036291
iteration 940 : loss : 0.183695, loss_ce: 0.058930
iteration 941 : loss : 0.164532, loss_ce: 0.027062
iteration 942 : loss : 0.169892, loss_ce: 0.028880
iteration 943 : loss : 0.188732, loss_ce: 0.047231
iteration 944 : loss : 0.164575, loss_ce: 0.044939
iteration 945 : loss : 0.168365, loss_ce: 0.031411
iteration 946 : loss : 0.172090, loss_ce: 0.044191
iteration 947 : loss : 0.167525, loss_ce: 0.042746
iteration 948 : loss : 0.187401, loss_ce: 0.035009
iteration 949 : loss : 0.149392, loss_ce: 0.033513
iteration 950 : loss : 0.156249, loss_ce: 0.030397
iteration 951 : loss : 0.157777, loss_ce: 0.032487
iteration 952 : loss : 0.159554, loss_ce: 0.023460
iteration 953 : loss : 0.164151, loss_ce: 0.030630
iteration 954 : loss : 0.167509, loss_ce: 0.031593
iteration 955 : loss : 0.180383, loss_ce: 0.036519
iteration 956 : loss : 0.161126, loss_ce: 0.038324
iteration 957 : loss : 0.165813, loss_ce: 0.042308
iteration 958 : loss : 0.156509, loss_ce: 0.032826
iteration 959 : loss : 0.156510, loss_ce: 0.034198
iteration 960 : loss : 0.145500, loss_ce: 0.037854
iteration 961 : loss : 0.169294, loss_ce: 0.046764
iteration 962 : loss : 0.174853, loss_ce: 0.024890
iteration 963 : loss : 0.170814, loss_ce: 0.046066
iteration 964 : loss : 0.154972, loss_ce: 0.029532
iteration 965 : loss : 0.152460, loss_ce: 0.044524
iteration 966 : loss : 0.158514, loss_ce: 0.046128
iteration 967 : loss : 0.160380, loss_ce: 0.034201
iteration 968 : loss : 0.154971, loss_ce: 0.035340
iteration 969 : loss : 0.182829, loss_ce: 0.037358
iteration 970 : loss : 0.152205, loss_ce: 0.042788
iteration 971 : loss : 0.158575, loss_ce: 0.041145
iteration 972 : loss : 0.166621, loss_ce: 0.032276
iteration 973 : loss : 0.167573, loss_ce: 0.033927
iteration 974 : loss : 0.151778, loss_ce: 0.028617
iteration 975 : loss : 0.147987, loss_ce: 0.037203
iteration 976 : loss : 0.165921, loss_ce: 0.050929
iteration 977 : loss : 0.136618, loss_ce: 0.033702
iteration 978 : loss : 0.149974, loss_ce: 0.031314
iteration 979 : loss : 0.178143, loss_ce: 0.022657
iteration 980 : loss : 0.154223, loss_ce: 0.035782
iteration 981 : loss : 0.140894, loss_ce: 0.038098
iteration 982 : loss : 0.135448, loss_ce: 0.022902
iteration 983 : loss : 0.139905, loss_ce: 0.049891
iteration 984 : loss : 0.136387, loss_ce: 0.029989
iteration 985 : loss : 0.149140, loss_ce: 0.039792
iteration 986 : loss : 0.176221, loss_ce: 0.023341
iteration 987 : loss : 0.136694, loss_ce: 0.027707
iteration 988 : loss : 0.149250, loss_ce: 0.042423
iteration 989 : loss : 0.139602, loss_ce: 0.030365
iteration 990 : loss : 0.124694, loss_ce: 0.030781
iteration 991 : loss : 0.149316, loss_ce: 0.034825
iteration 992 : loss : 0.125025, loss_ce: 0.029698
iteration 993 : loss : 0.153713, loss_ce: 0.046109
iteration 994 : loss : 0.141215, loss_ce: 0.031787
iteration 995 : loss : 0.143869, loss_ce: 0.031476
iteration 996 : loss : 0.139701, loss_ce: 0.037778
iteration 997 : loss : 0.162691, loss_ce: 0.033303
iteration 998 : loss : 0.138131, loss_ce: 0.032337
iteration 999 : loss : 0.121349, loss_ce: 0.019809
iteration 1000 : loss : 0.171912, loss_ce: 0.042651
iteration 1001 : loss : 0.145072, loss_ce: 0.023017
iteration 1002 : loss : 0.151479, loss_ce: 0.031679
iteration 1003 : loss : 0.152904, loss_ce: 0.055450
iteration 1004 : loss : 0.125318, loss_ce: 0.030060
iteration 1005 : loss : 0.136880, loss_ce: 0.039478
iteration 1006 : loss : 0.138772, loss_ce: 0.027119
iteration 1007 : loss : 0.138454, loss_ce: 0.031905
iteration 1008 : loss : 0.150145, loss_ce: 0.054506
iteration 1009 : loss : 0.140307, loss_ce: 0.046596
iteration 1010 : loss : 0.128166, loss_ce: 0.028849
iteration 1011 : loss : 0.134667, loss_ce: 0.041713
iteration 1012 : loss : 0.137543, loss_ce: 0.046892
iteration 1013 : loss : 0.123417, loss_ce: 0.040766
iteration 1014 : loss : 0.137674, loss_ce: 0.035618
iteration 1015 : loss : 0.119913, loss_ce: 0.030742
iteration 1016 : loss : 0.149233, loss_ce: 0.032399
iteration 1017 : loss : 0.115279, loss_ce: 0.039462
iteration 1018 : loss : 0.135653, loss_ce: 0.048251
iteration 1019 : loss : 0.128003, loss_ce: 0.029960
iteration 1020 : loss : 0.134740, loss_ce: 0.023409
iteration 1021 : loss : 0.170925, loss_ce: 0.027352
iteration 1022 : loss : 0.123020, loss_ce: 0.025554
iteration 1023 : loss : 0.243736, loss_ce: 0.018362
  6%|█▋                            | 11/200 [11:13<3:14:34, 61.77s/it]iteration 1024 : loss : 0.132445, loss_ce: 0.027635
iteration 1025 : loss : 0.155556, loss_ce: 0.040854
iteration 1026 : loss : 0.122469, loss_ce: 0.034609
iteration 1027 : loss : 0.119282, loss_ce: 0.039192
iteration 1028 : loss : 0.104633, loss_ce: 0.026381
iteration 1029 : loss : 0.114042, loss_ce: 0.033784
iteration 1030 : loss : 0.133417, loss_ce: 0.054814
iteration 1031 : loss : 0.162063, loss_ce: 0.041043
iteration 1032 : loss : 0.105016, loss_ce: 0.025382
iteration 1033 : loss : 0.124988, loss_ce: 0.024886
iteration 1034 : loss : 0.138624, loss_ce: 0.033099
iteration 1035 : loss : 0.123968, loss_ce: 0.034300
iteration 1036 : loss : 0.129319, loss_ce: 0.040529
iteration 1037 : loss : 0.127380, loss_ce: 0.029161
iteration 1038 : loss : 0.114179, loss_ce: 0.019921
iteration 1039 : loss : 0.092815, loss_ce: 0.022248
iteration 1040 : loss : 0.129543, loss_ce: 0.022406
iteration 1041 : loss : 0.146096, loss_ce: 0.032989
iteration 1042 : loss : 0.121772, loss_ce: 0.036344
iteration 1043 : loss : 0.119883, loss_ce: 0.022229
iteration 1044 : loss : 0.104622, loss_ce: 0.025487
iteration 1045 : loss : 0.123769, loss_ce: 0.040331
iteration 1046 : loss : 0.118869, loss_ce: 0.024942
iteration 1047 : loss : 0.098803, loss_ce: 0.026196
iteration 1048 : loss : 0.132056, loss_ce: 0.034319
iteration 1049 : loss : 0.124051, loss_ce: 0.046590
iteration 1050 : loss : 0.131629, loss_ce: 0.033291
iteration 1051 : loss : 0.148762, loss_ce: 0.035698
iteration 1052 : loss : 0.144648, loss_ce: 0.039279
iteration 1053 : loss : 0.140859, loss_ce: 0.038965
iteration 1054 : loss : 0.109269, loss_ce: 0.031543
iteration 1055 : loss : 0.112777, loss_ce: 0.029848
iteration 1056 : loss : 0.079861, loss_ce: 0.022018
iteration 1057 : loss : 0.118984, loss_ce: 0.037524
iteration 1058 : loss : 0.127547, loss_ce: 0.038119
iteration 1059 : loss : 0.129885, loss_ce: 0.021959
iteration 1060 : loss : 0.117366, loss_ce: 0.039294
iteration 1061 : loss : 0.104214, loss_ce: 0.034052
iteration 1062 : loss : 0.131828, loss_ce: 0.039355
iteration 1063 : loss : 0.114481, loss_ce: 0.035388
iteration 1064 : loss : 0.117308, loss_ce: 0.041878
iteration 1065 : loss : 0.099775, loss_ce: 0.032467
iteration 1066 : loss : 0.115851, loss_ce: 0.032894
iteration 1067 : loss : 0.092406, loss_ce: 0.030070
iteration 1068 : loss : 0.143294, loss_ce: 0.025417
iteration 1069 : loss : 0.145952, loss_ce: 0.036785
iteration 1070 : loss : 0.107886, loss_ce: 0.025878
iteration 1071 : loss : 0.090010, loss_ce: 0.026678
iteration 1072 : loss : 0.158693, loss_ce: 0.025746
iteration 1073 : loss : 0.189110, loss_ce: 0.028811
iteration 1074 : loss : 0.123290, loss_ce: 0.042665
iteration 1075 : loss : 0.125525, loss_ce: 0.042269
iteration 1076 : loss : 0.162702, loss_ce: 0.016184
iteration 1077 : loss : 0.122094, loss_ce: 0.037235
iteration 1078 : loss : 0.103451, loss_ce: 0.041865
iteration 1079 : loss : 0.122234, loss_ce: 0.044572
iteration 1080 : loss : 0.116666, loss_ce: 0.040861
iteration 1081 : loss : 0.162703, loss_ce: 0.044291
iteration 1082 : loss : 0.165902, loss_ce: 0.038840
iteration 1083 : loss : 0.120049, loss_ce: 0.025172
iteration 1084 : loss : 0.120741, loss_ce: 0.033413
iteration 1085 : loss : 0.124176, loss_ce: 0.044537
iteration 1086 : loss : 0.105593, loss_ce: 0.033910
iteration 1087 : loss : 0.121531, loss_ce: 0.052368
iteration 1088 : loss : 0.121536, loss_ce: 0.031886
iteration 1089 : loss : 0.107140, loss_ce: 0.032697
iteration 1090 : loss : 0.151998, loss_ce: 0.027039
iteration 1091 : loss : 0.107406, loss_ce: 0.027479
iteration 1092 : loss : 0.126158, loss_ce: 0.056997
iteration 1093 : loss : 0.145441, loss_ce: 0.038451
iteration 1094 : loss : 0.085427, loss_ce: 0.025922
iteration 1095 : loss : 0.095799, loss_ce: 0.033890
iteration 1096 : loss : 0.109450, loss_ce: 0.030855
iteration 1097 : loss : 0.105379, loss_ce: 0.030750
iteration 1098 : loss : 0.145211, loss_ce: 0.039267
iteration 1099 : loss : 0.142119, loss_ce: 0.019287
iteration 1100 : loss : 0.122829, loss_ce: 0.043205
iteration 1101 : loss : 0.153291, loss_ce: 0.032875
iteration 1102 : loss : 0.121692, loss_ce: 0.034598
iteration 1103 : loss : 0.103907, loss_ce: 0.030178
iteration 1104 : loss : 0.156451, loss_ce: 0.036533
iteration 1105 : loss : 0.110600, loss_ce: 0.041173
iteration 1106 : loss : 0.115891, loss_ce: 0.029166
iteration 1107 : loss : 0.135387, loss_ce: 0.032483
iteration 1108 : loss : 0.101798, loss_ce: 0.027983
iteration 1109 : loss : 0.159505, loss_ce: 0.038692
iteration 1110 : loss : 0.140900, loss_ce: 0.058995
iteration 1111 : loss : 0.110016, loss_ce: 0.045425
iteration 1112 : loss : 0.125846, loss_ce: 0.045534
iteration 1113 : loss : 0.142324, loss_ce: 0.037339
iteration 1114 : loss : 0.112983, loss_ce: 0.027957
iteration 1115 : loss : 0.150179, loss_ce: 0.023730
iteration 1116 : loss : 0.297339, loss_ce: 0.042831
  6%|█▊                            | 12/200 [12:15<3:13:21, 61.71s/it]iteration 1117 : loss : 0.146429, loss_ce: 0.024787
iteration 1118 : loss : 0.144172, loss_ce: 0.034469
iteration 1119 : loss : 0.119022, loss_ce: 0.037102
iteration 1120 : loss : 0.150525, loss_ce: 0.030968
iteration 1121 : loss : 0.152819, loss_ce: 0.059295
iteration 1122 : loss : 0.116077, loss_ce: 0.028951
iteration 1123 : loss : 0.113288, loss_ce: 0.028623
iteration 1124 : loss : 0.108847, loss_ce: 0.049085
iteration 1125 : loss : 0.120474, loss_ce: 0.024646
iteration 1126 : loss : 0.126867, loss_ce: 0.028971
iteration 1127 : loss : 0.126149, loss_ce: 0.054643
iteration 1128 : loss : 0.095844, loss_ce: 0.025394
iteration 1129 : loss : 0.124579, loss_ce: 0.033047
iteration 1130 : loss : 0.108031, loss_ce: 0.036514
iteration 1131 : loss : 0.098567, loss_ce: 0.034910
iteration 1132 : loss : 0.116421, loss_ce: 0.024908
iteration 1133 : loss : 0.105124, loss_ce: 0.030053
iteration 1134 : loss : 0.105350, loss_ce: 0.026866
iteration 1135 : loss : 0.105614, loss_ce: 0.037395
iteration 1136 : loss : 0.105055, loss_ce: 0.029317
iteration 1137 : loss : 0.105531, loss_ce: 0.033152
iteration 1138 : loss : 0.226992, loss_ce: 0.020455
iteration 1139 : loss : 0.126547, loss_ce: 0.026278
iteration 1140 : loss : 0.079700, loss_ce: 0.028681
iteration 1141 : loss : 0.077993, loss_ce: 0.027141
iteration 1142 : loss : 0.111311, loss_ce: 0.040130
iteration 1143 : loss : 0.117936, loss_ce: 0.029701
iteration 1144 : loss : 0.095626, loss_ce: 0.039143
iteration 1145 : loss : 0.133770, loss_ce: 0.036762
iteration 1146 : loss : 0.121746, loss_ce: 0.028270
iteration 1147 : loss : 0.093054, loss_ce: 0.037032
iteration 1148 : loss : 0.126284, loss_ce: 0.030933
iteration 1149 : loss : 0.090339, loss_ce: 0.029991
iteration 1150 : loss : 0.100285, loss_ce: 0.031386
iteration 1151 : loss : 0.128189, loss_ce: 0.027566
iteration 1152 : loss : 0.133306, loss_ce: 0.036952
iteration 1153 : loss : 0.111225, loss_ce: 0.039768
iteration 1154 : loss : 0.118583, loss_ce: 0.034981
iteration 1155 : loss : 0.107652, loss_ce: 0.029316
iteration 1156 : loss : 0.131014, loss_ce: 0.022185
iteration 1157 : loss : 0.105214, loss_ce: 0.030206
iteration 1158 : loss : 0.124342, loss_ce: 0.024275
iteration 1159 : loss : 0.108742, loss_ce: 0.038247
iteration 1160 : loss : 0.107231, loss_ce: 0.024424
iteration 1161 : loss : 0.118643, loss_ce: 0.031785
iteration 1162 : loss : 0.131174, loss_ce: 0.055314
iteration 1163 : loss : 0.114801, loss_ce: 0.021673
iteration 1164 : loss : 0.091083, loss_ce: 0.023504
iteration 1165 : loss : 0.094746, loss_ce: 0.020032
iteration 1166 : loss : 0.117830, loss_ce: 0.031598
iteration 1167 : loss : 0.085948, loss_ce: 0.026243
iteration 1168 : loss : 0.106416, loss_ce: 0.031193
iteration 1169 : loss : 0.106979, loss_ce: 0.025461
iteration 1170 : loss : 0.109525, loss_ce: 0.036476
iteration 1171 : loss : 0.107760, loss_ce: 0.022917
iteration 1172 : loss : 0.085913, loss_ce: 0.021171
iteration 1173 : loss : 0.128070, loss_ce: 0.031475
iteration 1174 : loss : 0.104458, loss_ce: 0.036141
iteration 1175 : loss : 0.115323, loss_ce: 0.037880
iteration 1176 : loss : 0.105784, loss_ce: 0.042503
iteration 1177 : loss : 0.110604, loss_ce: 0.028111
iteration 1178 : loss : 0.093614, loss_ce: 0.034233
iteration 1179 : loss : 0.110476, loss_ce: 0.024885
iteration 1180 : loss : 0.131316, loss_ce: 0.032581
iteration 1181 : loss : 0.102484, loss_ce: 0.041880
iteration 1182 : loss : 0.091966, loss_ce: 0.022301
iteration 1183 : loss : 0.100397, loss_ce: 0.028017
iteration 1184 : loss : 0.080771, loss_ce: 0.027581
iteration 1185 : loss : 0.130597, loss_ce: 0.030235
iteration 1186 : loss : 0.144804, loss_ce: 0.025829
iteration 1187 : loss : 0.084494, loss_ce: 0.021951
iteration 1188 : loss : 0.117838, loss_ce: 0.019249
iteration 1189 : loss : 0.136331, loss_ce: 0.028675
iteration 1190 : loss : 0.078918, loss_ce: 0.020043
iteration 1191 : loss : 0.137516, loss_ce: 0.027741
iteration 1192 : loss : 0.111716, loss_ce: 0.038313
iteration 1193 : loss : 0.111212, loss_ce: 0.020961
iteration 1194 : loss : 0.089239, loss_ce: 0.038406
iteration 1195 : loss : 0.129717, loss_ce: 0.022771
iteration 1196 : loss : 0.099452, loss_ce: 0.042689
iteration 1197 : loss : 0.123546, loss_ce: 0.020633
iteration 1198 : loss : 0.094415, loss_ce: 0.020110
iteration 1199 : loss : 0.122349, loss_ce: 0.040566
iteration 1200 : loss : 0.095933, loss_ce: 0.027663
iteration 1201 : loss : 0.094368, loss_ce: 0.040565
iteration 1202 : loss : 0.089172, loss_ce: 0.028978
iteration 1203 : loss : 0.076782, loss_ce: 0.025665
iteration 1204 : loss : 0.099998, loss_ce: 0.032165
iteration 1205 : loss : 0.103718, loss_ce: 0.034904
iteration 1206 : loss : 0.120507, loss_ce: 0.021692
iteration 1207 : loss : 0.119804, loss_ce: 0.035249
iteration 1208 : loss : 0.073049, loss_ce: 0.029820
iteration 1209 : loss : 0.242745, loss_ce: 0.028727
  6%|█▉                            | 13/200 [13:17<3:12:11, 61.67s/it]iteration 1210 : loss : 0.107927, loss_ce: 0.023397
iteration 1211 : loss : 0.100259, loss_ce: 0.043159
iteration 1212 : loss : 0.102604, loss_ce: 0.039122
iteration 1213 : loss : 0.107172, loss_ce: 0.032657
iteration 1214 : loss : 0.083052, loss_ce: 0.027505
iteration 1215 : loss : 0.098049, loss_ce: 0.026864
iteration 1216 : loss : 0.076801, loss_ce: 0.030512
iteration 1217 : loss : 0.086324, loss_ce: 0.031455
iteration 1218 : loss : 0.132255, loss_ce: 0.039780
iteration 1219 : loss : 0.082846, loss_ce: 0.028877
iteration 1220 : loss : 0.077896, loss_ce: 0.025275
iteration 1221 : loss : 0.074513, loss_ce: 0.024961
iteration 1222 : loss : 0.105453, loss_ce: 0.031312
iteration 1223 : loss : 0.087405, loss_ce: 0.033541
iteration 1224 : loss : 0.101159, loss_ce: 0.037138
iteration 1225 : loss : 0.088040, loss_ce: 0.028641
iteration 1226 : loss : 0.129019, loss_ce: 0.036404
iteration 1227 : loss : 0.103726, loss_ce: 0.031751
iteration 1228 : loss : 0.110041, loss_ce: 0.037602
iteration 1229 : loss : 0.154921, loss_ce: 0.025880
iteration 1230 : loss : 0.130722, loss_ce: 0.028995
iteration 1231 : loss : 0.116422, loss_ce: 0.036904
iteration 1232 : loss : 0.111741, loss_ce: 0.022078
iteration 1233 : loss : 0.114543, loss_ce: 0.025798
iteration 1234 : loss : 0.121142, loss_ce: 0.035984
iteration 1235 : loss : 0.069208, loss_ce: 0.017919
iteration 1236 : loss : 0.081854, loss_ce: 0.023885
iteration 1237 : loss : 0.102526, loss_ce: 0.025500
iteration 1238 : loss : 0.128163, loss_ce: 0.021511
iteration 1239 : loss : 0.074271, loss_ce: 0.024414
iteration 1240 : loss : 0.066081, loss_ce: 0.026792
iteration 1241 : loss : 0.104519, loss_ce: 0.047225
iteration 1242 : loss : 0.104473, loss_ce: 0.035735
iteration 1243 : loss : 0.117964, loss_ce: 0.034477
iteration 1244 : loss : 0.090572, loss_ce: 0.030041
iteration 1245 : loss : 0.104862, loss_ce: 0.031524
iteration 1246 : loss : 0.131552, loss_ce: 0.028561
iteration 1247 : loss : 0.085837, loss_ce: 0.029518
iteration 1248 : loss : 0.084416, loss_ce: 0.037927
iteration 1249 : loss : 0.093019, loss_ce: 0.024365
iteration 1250 : loss : 0.107090, loss_ce: 0.026043
iteration 1251 : loss : 0.083757, loss_ce: 0.034253
iteration 1252 : loss : 0.135322, loss_ce: 0.023704
iteration 1253 : loss : 0.079253, loss_ce: 0.026819
iteration 1254 : loss : 0.080023, loss_ce: 0.027926
iteration 1255 : loss : 0.103820, loss_ce: 0.034833
iteration 1256 : loss : 0.108249, loss_ce: 0.040412
iteration 1257 : loss : 0.083864, loss_ce: 0.027947
iteration 1258 : loss : 0.094754, loss_ce: 0.034075
iteration 1259 : loss : 0.111057, loss_ce: 0.030968
iteration 1260 : loss : 0.111518, loss_ce: 0.033144
iteration 1261 : loss : 0.099511, loss_ce: 0.036523
iteration 1262 : loss : 0.101056, loss_ce: 0.039152
iteration 1263 : loss : 0.119579, loss_ce: 0.026713
iteration 1264 : loss : 0.118194, loss_ce: 0.021261
iteration 1265 : loss : 0.109226, loss_ce: 0.033883
iteration 1266 : loss : 0.106953, loss_ce: 0.024807
iteration 1267 : loss : 0.079713, loss_ce: 0.033137
iteration 1268 : loss : 0.123501, loss_ce: 0.033494
iteration 1269 : loss : 0.102386, loss_ce: 0.022666
iteration 1270 : loss : 0.115314, loss_ce: 0.026891
iteration 1271 : loss : 0.102129, loss_ce: 0.026051
iteration 1272 : loss : 0.101728, loss_ce: 0.034146
iteration 1273 : loss : 0.109000, loss_ce: 0.024385
iteration 1274 : loss : 0.088847, loss_ce: 0.031184
iteration 1275 : loss : 0.168608, loss_ce: 0.022483
iteration 1276 : loss : 0.086617, loss_ce: 0.027269
iteration 1277 : loss : 0.122945, loss_ce: 0.040313
iteration 1278 : loss : 0.091209, loss_ce: 0.024782
iteration 1279 : loss : 0.133922, loss_ce: 0.020420
iteration 1280 : loss : 0.108471, loss_ce: 0.033893
iteration 1281 : loss : 0.099512, loss_ce: 0.024640
iteration 1282 : loss : 0.112965, loss_ce: 0.024810
iteration 1283 : loss : 0.107467, loss_ce: 0.028961
iteration 1284 : loss : 0.201456, loss_ce: 0.015812
iteration 1285 : loss : 0.078335, loss_ce: 0.032163
iteration 1286 : loss : 0.169485, loss_ce: 0.017762
iteration 1287 : loss : 0.057807, loss_ce: 0.017455
iteration 1288 : loss : 0.160666, loss_ce: 0.013882
iteration 1289 : loss : 0.127724, loss_ce: 0.031336
iteration 1290 : loss : 0.102116, loss_ce: 0.055051
iteration 1291 : loss : 0.085519, loss_ce: 0.025414
iteration 1292 : loss : 0.082733, loss_ce: 0.035984
iteration 1293 : loss : 0.157002, loss_ce: 0.022880
iteration 1294 : loss : 0.152386, loss_ce: 0.041319
iteration 1295 : loss : 0.131621, loss_ce: 0.033333
iteration 1296 : loss : 0.126200, loss_ce: 0.044445
iteration 1297 : loss : 0.140703, loss_ce: 0.043734
iteration 1298 : loss : 0.110572, loss_ce: 0.034529
iteration 1299 : loss : 0.111196, loss_ce: 0.031141
iteration 1300 : loss : 0.107466, loss_ce: 0.032337
iteration 1301 : loss : 0.097814, loss_ce: 0.029479
iteration 1302 : loss : 0.396941, loss_ce: 0.011386
  7%|██                            | 14/200 [14:18<3:11:10, 61.67s/it]iteration 1303 : loss : 0.124964, loss_ce: 0.032513
iteration 1304 : loss : 0.146494, loss_ce: 0.025936
iteration 1305 : loss : 0.102272, loss_ce: 0.030544
iteration 1306 : loss : 0.062086, loss_ce: 0.022403
iteration 1307 : loss : 0.093808, loss_ce: 0.030095
iteration 1308 : loss : 0.108696, loss_ce: 0.028286
iteration 1309 : loss : 0.096365, loss_ce: 0.047143
iteration 1310 : loss : 0.108936, loss_ce: 0.033016
iteration 1311 : loss : 0.066842, loss_ce: 0.023246
iteration 1312 : loss : 0.103963, loss_ce: 0.031749
iteration 1313 : loss : 0.117905, loss_ce: 0.037614
iteration 1314 : loss : 0.082963, loss_ce: 0.025550
iteration 1315 : loss : 0.080216, loss_ce: 0.026204
iteration 1316 : loss : 0.100970, loss_ce: 0.027251
iteration 1317 : loss : 0.127566, loss_ce: 0.041445
iteration 1318 : loss : 0.073083, loss_ce: 0.022041
iteration 1319 : loss : 0.123744, loss_ce: 0.040295
iteration 1320 : loss : 0.079156, loss_ce: 0.022034
iteration 1321 : loss : 0.068876, loss_ce: 0.022514
iteration 1322 : loss : 0.092016, loss_ce: 0.022283
iteration 1323 : loss : 0.068326, loss_ce: 0.014553
iteration 1324 : loss : 0.127993, loss_ce: 0.027220
iteration 1325 : loss : 0.115049, loss_ce: 0.024912
iteration 1326 : loss : 0.101397, loss_ce: 0.037821
iteration 1327 : loss : 0.099378, loss_ce: 0.028255
iteration 1328 : loss : 0.102719, loss_ce: 0.053985
iteration 1329 : loss : 0.072211, loss_ce: 0.025657
iteration 1330 : loss : 0.090143, loss_ce: 0.037643
iteration 1331 : loss : 0.116777, loss_ce: 0.027006
iteration 1332 : loss : 0.096932, loss_ce: 0.031278
iteration 1333 : loss : 0.089458, loss_ce: 0.025850
iteration 1334 : loss : 0.076514, loss_ce: 0.030833
iteration 1335 : loss : 0.078745, loss_ce: 0.025465
iteration 1336 : loss : 0.131846, loss_ce: 0.032193
iteration 1337 : loss : 0.125659, loss_ce: 0.035002
iteration 1338 : loss : 0.119107, loss_ce: 0.021666
iteration 1339 : loss : 0.087095, loss_ce: 0.030458
iteration 1340 : loss : 0.092130, loss_ce: 0.023389
iteration 1341 : loss : 0.082494, loss_ce: 0.024277
iteration 1342 : loss : 0.085863, loss_ce: 0.028733
iteration 1343 : loss : 0.093514, loss_ce: 0.032615
iteration 1344 : loss : 0.101656, loss_ce: 0.031386
iteration 1345 : loss : 0.119812, loss_ce: 0.022478
iteration 1346 : loss : 0.120540, loss_ce: 0.037224
iteration 1347 : loss : 0.076145, loss_ce: 0.031529
iteration 1348 : loss : 0.096288, loss_ce: 0.040706
iteration 1349 : loss : 0.116511, loss_ce: 0.025210
iteration 1350 : loss : 0.063940, loss_ce: 0.023320
iteration 1351 : loss : 0.065483, loss_ce: 0.018431
iteration 1352 : loss : 0.058797, loss_ce: 0.014780
iteration 1353 : loss : 0.080354, loss_ce: 0.027669
iteration 1354 : loss : 0.064128, loss_ce: 0.015293
iteration 1355 : loss : 0.071925, loss_ce: 0.017470
iteration 1356 : loss : 0.103126, loss_ce: 0.024027
iteration 1357 : loss : 0.076578, loss_ce: 0.019826
iteration 1358 : loss : 0.075066, loss_ce: 0.015694
iteration 1359 : loss : 0.103100, loss_ce: 0.039909
iteration 1360 : loss : 0.063995, loss_ce: 0.028495
iteration 1361 : loss : 0.095110, loss_ce: 0.022869
iteration 1362 : loss : 0.090584, loss_ce: 0.027520
iteration 1363 : loss : 0.127651, loss_ce: 0.021425
iteration 1364 : loss : 0.061131, loss_ce: 0.023778
iteration 1365 : loss : 0.085026, loss_ce: 0.020593
iteration 1366 : loss : 0.079202, loss_ce: 0.026995
iteration 1367 : loss : 0.087139, loss_ce: 0.037527
iteration 1368 : loss : 0.107011, loss_ce: 0.024410
iteration 1369 : loss : 0.088153, loss_ce: 0.033168
iteration 1370 : loss : 0.073213, loss_ce: 0.019249
iteration 1371 : loss : 0.082969, loss_ce: 0.028220
iteration 1372 : loss : 0.078973, loss_ce: 0.017725
iteration 1373 : loss : 0.078397, loss_ce: 0.025500
iteration 1374 : loss : 0.112361, loss_ce: 0.022175
iteration 1375 : loss : 0.092466, loss_ce: 0.016220
iteration 1376 : loss : 0.093898, loss_ce: 0.019415
iteration 1377 : loss : 0.088520, loss_ce: 0.019976
iteration 1378 : loss : 0.091748, loss_ce: 0.043350
iteration 1379 : loss : 0.080705, loss_ce: 0.021490
iteration 1380 : loss : 0.126663, loss_ce: 0.018712
iteration 1381 : loss : 0.085591, loss_ce: 0.028798
iteration 1382 : loss : 0.117821, loss_ce: 0.030632
iteration 1383 : loss : 0.116155, loss_ce: 0.022187
iteration 1384 : loss : 0.101990, loss_ce: 0.026201
iteration 1385 : loss : 0.095697, loss_ce: 0.027636
iteration 1386 : loss : 0.087242, loss_ce: 0.029397
iteration 1387 : loss : 0.084764, loss_ce: 0.019287
iteration 1388 : loss : 0.144503, loss_ce: 0.033838
iteration 1389 : loss : 0.144060, loss_ce: 0.021330
iteration 1390 : loss : 0.132617, loss_ce: 0.028527
iteration 1391 : loss : 0.115508, loss_ce: 0.038875
iteration 1392 : loss : 0.097733, loss_ce: 0.028951
iteration 1393 : loss : 0.078081, loss_ce: 0.028090
iteration 1394 : loss : 0.072113, loss_ce: 0.025173
iteration 1395 : loss : 0.398303, loss_ce: 0.014370
  8%|██▎                           | 15/200 [15:20<3:10:10, 61.68s/it]iteration 1396 : loss : 0.147347, loss_ce: 0.026217
iteration 1397 : loss : 0.096617, loss_ce: 0.023745
iteration 1398 : loss : 0.104697, loss_ce: 0.035985
iteration 1399 : loss : 0.107747, loss_ce: 0.021715
iteration 1400 : loss : 0.108618, loss_ce: 0.038354
iteration 1401 : loss : 0.084159, loss_ce: 0.034671
iteration 1402 : loss : 0.098545, loss_ce: 0.027834
iteration 1403 : loss : 0.117576, loss_ce: 0.034212
iteration 1404 : loss : 0.135983, loss_ce: 0.036755
iteration 1405 : loss : 0.112911, loss_ce: 0.023627
iteration 1406 : loss : 0.153835, loss_ce: 0.039037
iteration 1407 : loss : 0.079133, loss_ce: 0.036009
iteration 1408 : loss : 0.092785, loss_ce: 0.035522
iteration 1409 : loss : 0.097948, loss_ce: 0.022537
iteration 1410 : loss : 0.093682, loss_ce: 0.038564
iteration 1411 : loss : 0.063802, loss_ce: 0.017097
iteration 1412 : loss : 0.097505, loss_ce: 0.029249
iteration 1413 : loss : 0.125783, loss_ce: 0.021981
iteration 1414 : loss : 0.101243, loss_ce: 0.019925
iteration 1415 : loss : 0.076541, loss_ce: 0.033669
iteration 1416 : loss : 0.073213, loss_ce: 0.022109
iteration 1417 : loss : 0.080512, loss_ce: 0.028147
iteration 1418 : loss : 0.105582, loss_ce: 0.023374
iteration 1419 : loss : 0.079738, loss_ce: 0.026388
iteration 1420 : loss : 0.111269, loss_ce: 0.029884
iteration 1421 : loss : 0.075003, loss_ce: 0.032600
iteration 1422 : loss : 0.110065, loss_ce: 0.023524
iteration 1423 : loss : 0.096611, loss_ce: 0.025916
iteration 1424 : loss : 0.105651, loss_ce: 0.036714
iteration 1425 : loss : 0.113878, loss_ce: 0.029451
iteration 1426 : loss : 0.088165, loss_ce: 0.029610
iteration 1427 : loss : 0.081988, loss_ce: 0.016682
iteration 1428 : loss : 0.077228, loss_ce: 0.023636
iteration 1429 : loss : 0.074946, loss_ce: 0.030966
iteration 1430 : loss : 0.106130, loss_ce: 0.038488
iteration 1431 : loss : 0.072584, loss_ce: 0.024429
iteration 1432 : loss : 0.081680, loss_ce: 0.025909
iteration 1433 : loss : 0.079792, loss_ce: 0.022965
iteration 1434 : loss : 0.081117, loss_ce: 0.020400
iteration 1435 : loss : 0.108235, loss_ce: 0.028670
iteration 1436 : loss : 0.076819, loss_ce: 0.019855
iteration 1437 : loss : 0.093432, loss_ce: 0.018939
iteration 1438 : loss : 0.107368, loss_ce: 0.018050
iteration 1439 : loss : 0.093207, loss_ce: 0.018724
iteration 1440 : loss : 0.109892, loss_ce: 0.023556
iteration 1441 : loss : 0.084242, loss_ce: 0.026200
iteration 1442 : loss : 0.103743, loss_ce: 0.025909
iteration 1443 : loss : 0.081428, loss_ce: 0.034117
iteration 1444 : loss : 0.085880, loss_ce: 0.018096
iteration 1445 : loss : 0.078080, loss_ce: 0.015592
iteration 1446 : loss : 0.113697, loss_ce: 0.020897
iteration 1447 : loss : 0.083385, loss_ce: 0.016737
iteration 1448 : loss : 0.096726, loss_ce: 0.023952
iteration 1449 : loss : 0.068527, loss_ce: 0.018349
iteration 1450 : loss : 0.060724, loss_ce: 0.015551
iteration 1451 : loss : 0.083468, loss_ce: 0.026083
iteration 1452 : loss : 0.084043, loss_ce: 0.030848
iteration 1453 : loss : 0.103111, loss_ce: 0.020155
iteration 1454 : loss : 0.136376, loss_ce: 0.015645
iteration 1455 : loss : 0.065659, loss_ce: 0.021198
iteration 1456 : loss : 0.091971, loss_ce: 0.021282
iteration 1457 : loss : 0.061113, loss_ce: 0.018661
iteration 1458 : loss : 0.085189, loss_ce: 0.020382
iteration 1459 : loss : 0.079932, loss_ce: 0.014122
iteration 1460 : loss : 0.078817, loss_ce: 0.019979
iteration 1461 : loss : 0.078017, loss_ce: 0.031634
iteration 1462 : loss : 0.103901, loss_ce: 0.036948
iteration 1463 : loss : 0.086996, loss_ce: 0.023517
iteration 1464 : loss : 0.072243, loss_ce: 0.026219
iteration 1465 : loss : 0.074219, loss_ce: 0.028204
iteration 1466 : loss : 0.063232, loss_ce: 0.025382
iteration 1467 : loss : 0.134886, loss_ce: 0.018979
iteration 1468 : loss : 0.068136, loss_ce: 0.024310
iteration 1469 : loss : 0.075632, loss_ce: 0.032634
iteration 1470 : loss : 0.079175, loss_ce: 0.024234
iteration 1471 : loss : 0.075247, loss_ce: 0.027656
iteration 1472 : loss : 0.071258, loss_ce: 0.027779
iteration 1473 : loss : 0.098290, loss_ce: 0.040012
iteration 1474 : loss : 0.082204, loss_ce: 0.015757
iteration 1475 : loss : 0.076309, loss_ce: 0.032705
iteration 1476 : loss : 0.081744, loss_ce: 0.022272
iteration 1477 : loss : 0.091882, loss_ce: 0.030244
iteration 1478 : loss : 0.104759, loss_ce: 0.018256
iteration 1479 : loss : 0.140924, loss_ce: 0.024614
iteration 1480 : loss : 0.068837, loss_ce: 0.031536
iteration 1481 : loss : 0.083633, loss_ce: 0.031311
iteration 1482 : loss : 0.138624, loss_ce: 0.021979
iteration 1483 : loss : 0.093807, loss_ce: 0.035084
iteration 1484 : loss : 0.090248, loss_ce: 0.025533
iteration 1485 : loss : 0.165200, loss_ce: 0.018811
iteration 1486 : loss : 0.116905, loss_ce: 0.032940
iteration 1487 : loss : 0.077315, loss_ce: 0.024117
iteration 1488 : loss : 0.132471, loss_ce: 0.077288
  8%|██▍                           | 16/200 [16:21<3:08:56, 61.61s/it]iteration 1489 : loss : 0.153784, loss_ce: 0.022866
iteration 1490 : loss : 0.084267, loss_ce: 0.027091
iteration 1491 : loss : 0.092991, loss_ce: 0.022173
iteration 1492 : loss : 0.120695, loss_ce: 0.028157
iteration 1493 : loss : 0.069953, loss_ce: 0.026229
iteration 1494 : loss : 0.070796, loss_ce: 0.020356
iteration 1495 : loss : 0.092454, loss_ce: 0.036346
iteration 1496 : loss : 0.096467, loss_ce: 0.037812
iteration 1497 : loss : 0.096885, loss_ce: 0.024449
iteration 1498 : loss : 0.064263, loss_ce: 0.019883
iteration 1499 : loss : 0.074016, loss_ce: 0.017820
iteration 1500 : loss : 0.110375, loss_ce: 0.018134
iteration 1501 : loss : 0.095048, loss_ce: 0.028393
iteration 1502 : loss : 0.097220, loss_ce: 0.035988
iteration 1503 : loss : 0.083323, loss_ce: 0.028776
iteration 1504 : loss : 0.087803, loss_ce: 0.026823
iteration 1505 : loss : 0.107101, loss_ce: 0.023715
iteration 1506 : loss : 0.080496, loss_ce: 0.024826
iteration 1507 : loss : 0.064511, loss_ce: 0.021329
iteration 1508 : loss : 0.072571, loss_ce: 0.021017
iteration 1509 : loss : 0.135037, loss_ce: 0.019172
iteration 1510 : loss : 0.074672, loss_ce: 0.032355
iteration 1511 : loss : 0.079886, loss_ce: 0.027883
iteration 1512 : loss : 0.059905, loss_ce: 0.020006
iteration 1513 : loss : 0.073630, loss_ce: 0.018776
iteration 1514 : loss : 0.070984, loss_ce: 0.025023
iteration 1515 : loss : 0.089778, loss_ce: 0.032948
iteration 1516 : loss : 0.078143, loss_ce: 0.022317
iteration 1517 : loss : 0.086571, loss_ce: 0.026024
iteration 1518 : loss : 0.076912, loss_ce: 0.032144
iteration 1519 : loss : 0.076007, loss_ce: 0.024392
iteration 1520 : loss : 0.078801, loss_ce: 0.020502
iteration 1521 : loss : 0.099430, loss_ce: 0.034005
iteration 1522 : loss : 0.065408, loss_ce: 0.024650
iteration 1523 : loss : 0.060082, loss_ce: 0.019006
iteration 1524 : loss : 0.108243, loss_ce: 0.035551
iteration 1525 : loss : 0.112699, loss_ce: 0.027181
iteration 1526 : loss : 0.117016, loss_ce: 0.032060
iteration 1527 : loss : 0.104211, loss_ce: 0.040171
iteration 1528 : loss : 0.087666, loss_ce: 0.025280
iteration 1529 : loss : 0.082200, loss_ce: 0.020714
iteration 1530 : loss : 0.081176, loss_ce: 0.024387
iteration 1531 : loss : 0.083163, loss_ce: 0.024217
iteration 1532 : loss : 0.104567, loss_ce: 0.015512
iteration 1533 : loss : 0.081601, loss_ce: 0.019449
iteration 1534 : loss : 0.069925, loss_ce: 0.032354
iteration 1535 : loss : 0.072992, loss_ce: 0.019955
iteration 1536 : loss : 0.067311, loss_ce: 0.026000
iteration 1537 : loss : 0.077143, loss_ce: 0.021850
iteration 1538 : loss : 0.087541, loss_ce: 0.018941
iteration 1539 : loss : 0.105017, loss_ce: 0.016978
iteration 1540 : loss : 0.085654, loss_ce: 0.040535
iteration 1541 : loss : 0.070682, loss_ce: 0.022080
iteration 1542 : loss : 0.078062, loss_ce: 0.026248
iteration 1543 : loss : 0.069635, loss_ce: 0.030245
iteration 1544 : loss : 0.086534, loss_ce: 0.026052
iteration 1545 : loss : 0.074898, loss_ce: 0.026919
iteration 1546 : loss : 0.068732, loss_ce: 0.016596
iteration 1547 : loss : 0.099651, loss_ce: 0.034658
iteration 1548 : loss : 0.240971, loss_ce: 0.011977
iteration 1549 : loss : 0.121773, loss_ce: 0.031549
iteration 1550 : loss : 0.091729, loss_ce: 0.013355
iteration 1551 : loss : 0.100799, loss_ce: 0.034149
iteration 1552 : loss : 0.062436, loss_ce: 0.021978
iteration 1553 : loss : 0.073630, loss_ce: 0.026555
iteration 1554 : loss : 0.061720, loss_ce: 0.023192
iteration 1555 : loss : 0.097296, loss_ce: 0.016774
iteration 1556 : loss : 0.088640, loss_ce: 0.030763
iteration 1557 : loss : 0.080832, loss_ce: 0.025010
iteration 1558 : loss : 0.077678, loss_ce: 0.020270
iteration 1559 : loss : 0.096584, loss_ce: 0.020108
iteration 1560 : loss : 0.119304, loss_ce: 0.013896
iteration 1561 : loss : 0.133400, loss_ce: 0.028786
iteration 1562 : loss : 0.070085, loss_ce: 0.021145
iteration 1563 : loss : 0.084167, loss_ce: 0.031785
iteration 1564 : loss : 0.067826, loss_ce: 0.018536
iteration 1565 : loss : 0.107752, loss_ce: 0.016888
iteration 1566 : loss : 0.105240, loss_ce: 0.021164
iteration 1567 : loss : 0.103667, loss_ce: 0.016831
iteration 1568 : loss : 0.064626, loss_ce: 0.019757
iteration 1569 : loss : 0.092060, loss_ce: 0.023897
iteration 1570 : loss : 0.092989, loss_ce: 0.030162
iteration 1571 : loss : 0.116072, loss_ce: 0.036540
iteration 1572 : loss : 0.124289, loss_ce: 0.016810
iteration 1573 : loss : 0.138715, loss_ce: 0.024146
iteration 1574 : loss : 0.074499, loss_ce: 0.025452
iteration 1575 : loss : 0.089567, loss_ce: 0.035684
iteration 1576 : loss : 0.111273, loss_ce: 0.020764
iteration 1577 : loss : 0.080175, loss_ce: 0.024850
iteration 1578 : loss : 0.063907, loss_ce: 0.031297
iteration 1579 : loss : 0.085216, loss_ce: 0.041962
iteration 1580 : loss : 0.103389, loss_ce: 0.014455
iteration 1581 : loss : 0.131788, loss_ce: 0.029986
  8%|██▌                           | 17/200 [17:23<3:07:44, 61.55s/it]iteration 1582 : loss : 0.077699, loss_ce: 0.024352
iteration 1583 : loss : 0.101243, loss_ce: 0.020959
iteration 1584 : loss : 0.113699, loss_ce: 0.019846
iteration 1585 : loss : 0.099340, loss_ce: 0.029925
iteration 1586 : loss : 0.079791, loss_ce: 0.032004
iteration 1587 : loss : 0.112462, loss_ce: 0.030910
iteration 1588 : loss : 0.089849, loss_ce: 0.032639
iteration 1589 : loss : 0.060259, loss_ce: 0.025587
iteration 1590 : loss : 0.079295, loss_ce: 0.040995
iteration 1591 : loss : 0.079006, loss_ce: 0.027218
iteration 1592 : loss : 0.112956, loss_ce: 0.019823
iteration 1593 : loss : 0.104938, loss_ce: 0.017952
iteration 1594 : loss : 0.078076, loss_ce: 0.027139
iteration 1595 : loss : 0.083061, loss_ce: 0.027697
iteration 1596 : loss : 0.110895, loss_ce: 0.015018
iteration 1597 : loss : 0.078177, loss_ce: 0.031641
iteration 1598 : loss : 0.113796, loss_ce: 0.016271
iteration 1599 : loss : 0.095516, loss_ce: 0.024101
iteration 1600 : loss : 0.065108, loss_ce: 0.026848
iteration 1601 : loss : 0.064106, loss_ce: 0.030984
iteration 1602 : loss : 0.076168, loss_ce: 0.021769
iteration 1603 : loss : 0.087756, loss_ce: 0.025857
iteration 1604 : loss : 0.066353, loss_ce: 0.018505
iteration 1605 : loss : 0.115773, loss_ce: 0.024712
iteration 1606 : loss : 0.103226, loss_ce: 0.018682
iteration 1607 : loss : 0.082966, loss_ce: 0.020948
iteration 1608 : loss : 0.076241, loss_ce: 0.022095
iteration 1609 : loss : 0.060831, loss_ce: 0.027283
iteration 1610 : loss : 0.065767, loss_ce: 0.024282
iteration 1611 : loss : 0.066613, loss_ce: 0.016968
iteration 1612 : loss : 0.075998, loss_ce: 0.020191
iteration 1613 : loss : 0.060216, loss_ce: 0.021436
iteration 1614 : loss : 0.107822, loss_ce: 0.021236
iteration 1615 : loss : 0.064705, loss_ce: 0.013303
iteration 1616 : loss : 0.074335, loss_ce: 0.028422
iteration 1617 : loss : 0.050746, loss_ce: 0.019309
iteration 1618 : loss : 0.112638, loss_ce: 0.020316
iteration 1619 : loss : 0.051273, loss_ce: 0.022518
iteration 1620 : loss : 0.076594, loss_ce: 0.024831
iteration 1621 : loss : 0.092632, loss_ce: 0.016490
iteration 1622 : loss : 0.054964, loss_ce: 0.011622
iteration 1623 : loss : 0.081498, loss_ce: 0.038541
iteration 1624 : loss : 0.088678, loss_ce: 0.021544
iteration 1625 : loss : 0.067678, loss_ce: 0.022849
iteration 1626 : loss : 0.081803, loss_ce: 0.018896
iteration 1627 : loss : 0.084964, loss_ce: 0.013848
iteration 1628 : loss : 0.068186, loss_ce: 0.018841
iteration 1629 : loss : 0.051093, loss_ce: 0.012875
iteration 1630 : loss : 0.082627, loss_ce: 0.022717
iteration 1631 : loss : 0.062987, loss_ce: 0.020806
iteration 1632 : loss : 0.061083, loss_ce: 0.033066
iteration 1633 : loss : 0.058821, loss_ce: 0.021423
iteration 1634 : loss : 0.103464, loss_ce: 0.025645
iteration 1635 : loss : 0.064177, loss_ce: 0.021592
iteration 1636 : loss : 0.066690, loss_ce: 0.016978
iteration 1637 : loss : 0.080689, loss_ce: 0.017359
iteration 1638 : loss : 0.106936, loss_ce: 0.017266
iteration 1639 : loss : 0.064527, loss_ce: 0.021404
iteration 1640 : loss : 0.070827, loss_ce: 0.024953
iteration 1641 : loss : 0.069681, loss_ce: 0.019822
iteration 1642 : loss : 0.192857, loss_ce: 0.009082
iteration 1643 : loss : 0.074251, loss_ce: 0.020042
iteration 1644 : loss : 0.064289, loss_ce: 0.020968
iteration 1645 : loss : 0.124454, loss_ce: 0.027463
iteration 1646 : loss : 0.070993, loss_ce: 0.013910
iteration 1647 : loss : 0.087470, loss_ce: 0.021171
iteration 1648 : loss : 0.077789, loss_ce: 0.022420
iteration 1649 : loss : 0.078333, loss_ce: 0.021763
iteration 1650 : loss : 0.091642, loss_ce: 0.034222
iteration 1651 : loss : 0.071466, loss_ce: 0.015001
iteration 1652 : loss : 0.063494, loss_ce: 0.017332
iteration 1653 : loss : 0.064333, loss_ce: 0.023256
iteration 1654 : loss : 0.062784, loss_ce: 0.024874
iteration 1655 : loss : 0.085418, loss_ce: 0.011660
iteration 1656 : loss : 0.068357, loss_ce: 0.021880
iteration 1657 : loss : 0.061168, loss_ce: 0.030544
iteration 1658 : loss : 0.064973, loss_ce: 0.032312
iteration 1659 : loss : 0.074469, loss_ce: 0.020769
iteration 1660 : loss : 0.054620, loss_ce: 0.027373
iteration 1661 : loss : 0.128224, loss_ce: 0.028494
iteration 1662 : loss : 0.079884, loss_ce: 0.013557
iteration 1663 : loss : 0.102563, loss_ce: 0.030365
iteration 1664 : loss : 0.068005, loss_ce: 0.028518
iteration 1665 : loss : 0.076078, loss_ce: 0.018377
iteration 1666 : loss : 0.111801, loss_ce: 0.018375
iteration 1667 : loss : 0.078742, loss_ce: 0.019211
iteration 1668 : loss : 0.078012, loss_ce: 0.033331
iteration 1669 : loss : 0.101200, loss_ce: 0.026804
iteration 1670 : loss : 0.075271, loss_ce: 0.020035
iteration 1671 : loss : 0.071681, loss_ce: 0.024178
iteration 1672 : loss : 0.082159, loss_ce: 0.019577
iteration 1673 : loss : 0.115499, loss_ce: 0.019695
iteration 1674 : loss : 0.164811, loss_ce: 0.082833
  9%|██▋                           | 18/200 [18:24<3:06:35, 61.52s/it]iteration 1675 : loss : 0.083382, loss_ce: 0.027501
iteration 1676 : loss : 0.088142, loss_ce: 0.027049
iteration 1677 : loss : 0.085762, loss_ce: 0.032400
iteration 1678 : loss : 0.099218, loss_ce: 0.023231
iteration 1679 : loss : 0.086409, loss_ce: 0.022133
iteration 1680 : loss : 0.073194, loss_ce: 0.024388
iteration 1681 : loss : 0.062404, loss_ce: 0.024845
iteration 1682 : loss : 0.074871, loss_ce: 0.018427
iteration 1683 : loss : 0.066280, loss_ce: 0.026059
iteration 1684 : loss : 0.077669, loss_ce: 0.031300
iteration 1685 : loss : 0.105398, loss_ce: 0.020414
iteration 1686 : loss : 0.064176, loss_ce: 0.021245
iteration 1687 : loss : 0.056040, loss_ce: 0.018277
iteration 1688 : loss : 0.087468, loss_ce: 0.021004
iteration 1689 : loss : 0.115485, loss_ce: 0.028823
iteration 1690 : loss : 0.079204, loss_ce: 0.023695
iteration 1691 : loss : 0.063825, loss_ce: 0.015709
iteration 1692 : loss : 0.080248, loss_ce: 0.020844
iteration 1693 : loss : 0.072000, loss_ce: 0.014737
iteration 1694 : loss : 0.084796, loss_ce: 0.029765
iteration 1695 : loss : 0.068012, loss_ce: 0.015904
iteration 1696 : loss : 0.094394, loss_ce: 0.048845
iteration 1697 : loss : 0.060053, loss_ce: 0.023597
iteration 1698 : loss : 0.069631, loss_ce: 0.029197
iteration 1699 : loss : 0.063580, loss_ce: 0.017858
iteration 1700 : loss : 0.079007, loss_ce: 0.032060
iteration 1701 : loss : 0.088952, loss_ce: 0.015222
iteration 1702 : loss : 0.076258, loss_ce: 0.017296
iteration 1703 : loss : 0.095093, loss_ce: 0.022521
iteration 1704 : loss : 0.053935, loss_ce: 0.014806
iteration 1705 : loss : 0.059853, loss_ce: 0.016020
iteration 1706 : loss : 0.075450, loss_ce: 0.013383
iteration 1707 : loss : 0.122952, loss_ce: 0.022349
iteration 1708 : loss : 0.060464, loss_ce: 0.024772
iteration 1709 : loss : 0.072558, loss_ce: 0.026654
iteration 1710 : loss : 0.111170, loss_ce: 0.015827
iteration 1711 : loss : 0.089673, loss_ce: 0.026535
iteration 1712 : loss : 0.152574, loss_ce: 0.011388
iteration 1713 : loss : 0.077870, loss_ce: 0.022040
iteration 1714 : loss : 0.061149, loss_ce: 0.020391
iteration 1715 : loss : 0.061883, loss_ce: 0.017886
iteration 1716 : loss : 0.065582, loss_ce: 0.018462
iteration 1717 : loss : 0.075435, loss_ce: 0.024615
iteration 1718 : loss : 0.058732, loss_ce: 0.019767
iteration 1719 : loss : 0.061922, loss_ce: 0.018037
iteration 1720 : loss : 0.064373, loss_ce: 0.012969
iteration 1721 : loss : 0.072765, loss_ce: 0.018026
iteration 1722 : loss : 0.078048, loss_ce: 0.022302
iteration 1723 : loss : 0.091728, loss_ce: 0.016834
iteration 1724 : loss : 0.069691, loss_ce: 0.025962
iteration 1725 : loss : 0.083011, loss_ce: 0.027861
iteration 1726 : loss : 0.062670, loss_ce: 0.021238
iteration 1727 : loss : 0.061072, loss_ce: 0.029509
iteration 1728 : loss : 0.059127, loss_ce: 0.024049
iteration 1729 : loss : 0.060574, loss_ce: 0.018300
iteration 1730 : loss : 0.062746, loss_ce: 0.032407
iteration 1731 : loss : 0.090490, loss_ce: 0.015147
iteration 1732 : loss : 0.061659, loss_ce: 0.025348
iteration 1733 : loss : 0.105463, loss_ce: 0.015009
iteration 1734 : loss : 0.072673, loss_ce: 0.025262
iteration 1735 : loss : 0.068982, loss_ce: 0.021069
iteration 1736 : loss : 0.081787, loss_ce: 0.036075
iteration 1737 : loss : 0.091725, loss_ce: 0.023071
iteration 1738 : loss : 0.058233, loss_ce: 0.021296
iteration 1739 : loss : 0.066308, loss_ce: 0.017308
iteration 1740 : loss : 0.094775, loss_ce: 0.015140
iteration 1741 : loss : 0.098875, loss_ce: 0.027394
iteration 1742 : loss : 0.061708, loss_ce: 0.020476
iteration 1743 : loss : 0.055797, loss_ce: 0.022682
iteration 1744 : loss : 0.121529, loss_ce: 0.022665
iteration 1745 : loss : 0.054955, loss_ce: 0.023825
iteration 1746 : loss : 0.084887, loss_ce: 0.026303
iteration 1747 : loss : 0.068434, loss_ce: 0.019566
iteration 1748 : loss : 0.072354, loss_ce: 0.025840
iteration 1749 : loss : 0.072674, loss_ce: 0.027025
iteration 1750 : loss : 0.053285, loss_ce: 0.017854
iteration 1751 : loss : 0.085023, loss_ce: 0.018305
iteration 1752 : loss : 0.142132, loss_ce: 0.011479
iteration 1753 : loss : 0.069510, loss_ce: 0.024928
iteration 1754 : loss : 0.115562, loss_ce: 0.015418
iteration 1755 : loss : 0.058610, loss_ce: 0.020585
iteration 1756 : loss : 0.077200, loss_ce: 0.025760
iteration 1757 : loss : 0.079508, loss_ce: 0.017318
iteration 1758 : loss : 0.065932, loss_ce: 0.020135
iteration 1759 : loss : 0.080897, loss_ce: 0.015045
iteration 1760 : loss : 0.074949, loss_ce: 0.029485
iteration 1761 : loss : 0.099307, loss_ce: 0.013115
iteration 1762 : loss : 0.061120, loss_ce: 0.020050
iteration 1763 : loss : 0.068250, loss_ce: 0.018299
iteration 1764 : loss : 0.051673, loss_ce: 0.015240
iteration 1765 : loss : 0.069380, loss_ce: 0.028962
iteration 1766 : loss : 0.070513, loss_ce: 0.022106
iteration 1767 : loss : 0.229656, loss_ce: 0.035131
 10%|██▊                           | 19/200 [19:26<3:05:43, 61.57s/it]iteration 1768 : loss : 0.053447, loss_ce: 0.017471
iteration 1769 : loss : 0.060601, loss_ce: 0.025173
iteration 1770 : loss : 0.112423, loss_ce: 0.021492
iteration 1771 : loss : 0.081636, loss_ce: 0.023857
iteration 1772 : loss : 0.097417, loss_ce: 0.020603
iteration 1773 : loss : 0.074288, loss_ce: 0.028273
iteration 1774 : loss : 0.077447, loss_ce: 0.019430
iteration 1775 : loss : 0.064619, loss_ce: 0.009695
iteration 1776 : loss : 0.092734, loss_ce: 0.020224
iteration 1777 : loss : 0.062059, loss_ce: 0.015047
iteration 1778 : loss : 0.072536, loss_ce: 0.026316
iteration 1779 : loss : 0.102530, loss_ce: 0.019988
iteration 1780 : loss : 0.071896, loss_ce: 0.031729
iteration 1781 : loss : 0.103033, loss_ce: 0.010997
iteration 1782 : loss : 0.061152, loss_ce: 0.023450
iteration 1783 : loss : 0.066452, loss_ce: 0.036048
iteration 1784 : loss : 0.081714, loss_ce: 0.017631
iteration 1785 : loss : 0.089617, loss_ce: 0.018796
iteration 1786 : loss : 0.119773, loss_ce: 0.012002
iteration 1787 : loss : 0.075284, loss_ce: 0.014218
iteration 1788 : loss : 0.106375, loss_ce: 0.014364
iteration 1789 : loss : 0.086742, loss_ce: 0.018771
iteration 1790 : loss : 0.068105, loss_ce: 0.008389
iteration 1791 : loss : 0.079736, loss_ce: 0.023129
iteration 1792 : loss : 0.078635, loss_ce: 0.024233
iteration 1793 : loss : 0.054752, loss_ce: 0.022194
iteration 1794 : loss : 0.064332, loss_ce: 0.027604
iteration 1795 : loss : 0.066590, loss_ce: 0.027791
iteration 1796 : loss : 0.057165, loss_ce: 0.018849
iteration 1797 : loss : 0.053189, loss_ce: 0.026611
iteration 1798 : loss : 0.056680, loss_ce: 0.023914
iteration 1799 : loss : 0.074306, loss_ce: 0.021427
iteration 1800 : loss : 0.059329, loss_ce: 0.019086
iteration 1801 : loss : 0.073537, loss_ce: 0.022161
iteration 1802 : loss : 0.065251, loss_ce: 0.016460
iteration 1803 : loss : 0.070701, loss_ce: 0.020408
iteration 1804 : loss : 0.074591, loss_ce: 0.022146
iteration 1805 : loss : 0.105282, loss_ce: 0.015716
iteration 1806 : loss : 0.085508, loss_ce: 0.015151
iteration 1807 : loss : 0.063839, loss_ce: 0.025710
iteration 1808 : loss : 0.065084, loss_ce: 0.019096
iteration 1809 : loss : 0.061444, loss_ce: 0.017959
iteration 1810 : loss : 0.104516, loss_ce: 0.018696
iteration 1811 : loss : 0.059515, loss_ce: 0.014803
iteration 1812 : loss : 0.053026, loss_ce: 0.014152
iteration 1813 : loss : 0.073993, loss_ce: 0.016978
iteration 1814 : loss : 0.068053, loss_ce: 0.023411
iteration 1815 : loss : 0.071531, loss_ce: 0.019354
iteration 1816 : loss : 0.068881, loss_ce: 0.021660
iteration 1817 : loss : 0.064261, loss_ce: 0.022385
iteration 1818 : loss : 0.075281, loss_ce: 0.018548
iteration 1819 : loss : 0.064048, loss_ce: 0.024941
iteration 1820 : loss : 0.067110, loss_ce: 0.021599
iteration 1821 : loss : 0.106617, loss_ce: 0.009842
iteration 1822 : loss : 0.094631, loss_ce: 0.021747
iteration 1823 : loss : 0.054468, loss_ce: 0.018743
iteration 1824 : loss : 0.068091, loss_ce: 0.016458
iteration 1825 : loss : 0.073961, loss_ce: 0.017801
iteration 1826 : loss : 0.059206, loss_ce: 0.023341
iteration 1827 : loss : 0.085922, loss_ce: 0.015347
iteration 1828 : loss : 0.070774, loss_ce: 0.024078
iteration 1829 : loss : 0.071469, loss_ce: 0.031973
iteration 1830 : loss : 0.056481, loss_ce: 0.025638
iteration 1831 : loss : 0.063245, loss_ce: 0.015971
iteration 1832 : loss : 0.061927, loss_ce: 0.023864
iteration 1833 : loss : 0.068915, loss_ce: 0.030055
iteration 1834 : loss : 0.049873, loss_ce: 0.017033
iteration 1835 : loss : 0.066750, loss_ce: 0.017766
iteration 1836 : loss : 0.062308, loss_ce: 0.018773
iteration 1837 : loss : 0.062065, loss_ce: 0.018534
iteration 1838 : loss : 0.059565, loss_ce: 0.017041
iteration 1839 : loss : 0.085121, loss_ce: 0.015916
iteration 1840 : loss : 0.064747, loss_ce: 0.026853
iteration 1841 : loss : 0.071158, loss_ce: 0.019624
iteration 1842 : loss : 0.052369, loss_ce: 0.019812
iteration 1843 : loss : 0.102235, loss_ce: 0.010549
iteration 1844 : loss : 0.099922, loss_ce: 0.012722
iteration 1845 : loss : 0.058006, loss_ce: 0.024822
iteration 1846 : loss : 0.056427, loss_ce: 0.021909
iteration 1847 : loss : 0.075323, loss_ce: 0.016059
iteration 1848 : loss : 0.070235, loss_ce: 0.024903
iteration 1849 : loss : 0.059081, loss_ce: 0.026918
iteration 1850 : loss : 0.059353, loss_ce: 0.022788
iteration 1851 : loss : 0.074252, loss_ce: 0.013493
iteration 1852 : loss : 0.068444, loss_ce: 0.020816
iteration 1853 : loss : 0.115822, loss_ce: 0.024709
iteration 1854 : loss : 0.077982, loss_ce: 0.023152
iteration 1855 : loss : 0.063280, loss_ce: 0.023924
iteration 1856 : loss : 0.051966, loss_ce: 0.020958
iteration 1857 : loss : 0.053955, loss_ce: 0.021040
iteration 1858 : loss : 0.051292, loss_ce: 0.020963
iteration 1859 : loss : 0.057327, loss_ce: 0.023929
iteration 1860 : loss : 0.115678, loss_ce: 0.020286
 10%|███                           | 20/200 [20:28<3:04:53, 61.63s/it]iteration 1861 : loss : 0.050053, loss_ce: 0.019924
iteration 1862 : loss : 0.059954, loss_ce: 0.013096
iteration 1863 : loss : 0.092832, loss_ce: 0.012635
iteration 1864 : loss : 0.066594, loss_ce: 0.025119
iteration 1865 : loss : 0.070694, loss_ce: 0.014460
iteration 1866 : loss : 0.048842, loss_ce: 0.014210
iteration 1867 : loss : 0.045410, loss_ce: 0.013224
iteration 1868 : loss : 0.046197, loss_ce: 0.015519
iteration 1869 : loss : 0.100358, loss_ce: 0.016651
iteration 1870 : loss : 0.053842, loss_ce: 0.023110
iteration 1871 : loss : 0.075965, loss_ce: 0.018824
iteration 1872 : loss : 0.060944, loss_ce: 0.022135
iteration 1873 : loss : 0.118191, loss_ce: 0.018054
iteration 1874 : loss : 0.056644, loss_ce: 0.018553
iteration 1875 : loss : 0.053582, loss_ce: 0.014921
iteration 1876 : loss : 0.080770, loss_ce: 0.020049
iteration 1877 : loss : 0.061662, loss_ce: 0.020933
iteration 1878 : loss : 0.088599, loss_ce: 0.020234
iteration 1879 : loss : 0.043290, loss_ce: 0.014351
iteration 1880 : loss : 0.099728, loss_ce: 0.028573
iteration 1881 : loss : 0.044896, loss_ce: 0.017946
iteration 1882 : loss : 0.119769, loss_ce: 0.014587
iteration 1883 : loss : 0.054411, loss_ce: 0.018962
iteration 1884 : loss : 0.063155, loss_ce: 0.020690
iteration 1885 : loss : 0.053875, loss_ce: 0.018051
iteration 1886 : loss : 0.052026, loss_ce: 0.017934
iteration 1887 : loss : 0.079640, loss_ce: 0.019444
iteration 1888 : loss : 0.077852, loss_ce: 0.019485
iteration 1889 : loss : 0.078656, loss_ce: 0.018807
iteration 1890 : loss : 0.059699, loss_ce: 0.016657
iteration 1891 : loss : 0.063946, loss_ce: 0.021967
iteration 1892 : loss : 0.073726, loss_ce: 0.021203
iteration 1893 : loss : 0.060899, loss_ce: 0.018925
iteration 1894 : loss : 0.067056, loss_ce: 0.020039
iteration 1895 : loss : 0.057943, loss_ce: 0.020143
iteration 1896 : loss : 0.059204, loss_ce: 0.021444
iteration 1897 : loss : 0.059263, loss_ce: 0.019769
iteration 1898 : loss : 0.055920, loss_ce: 0.020605
iteration 1899 : loss : 0.083807, loss_ce: 0.020386
iteration 1900 : loss : 0.108487, loss_ce: 0.021378
iteration 1901 : loss : 0.139465, loss_ce: 0.022074
iteration 1902 : loss : 0.067700, loss_ce: 0.026671
iteration 1903 : loss : 0.071566, loss_ce: 0.017373
iteration 1904 : loss : 0.054640, loss_ce: 0.021319
iteration 1905 : loss : 0.067959, loss_ce: 0.016138
iteration 1906 : loss : 0.142749, loss_ce: 0.025597
iteration 1907 : loss : 0.055360, loss_ce: 0.020953
iteration 1908 : loss : 0.066447, loss_ce: 0.022854
iteration 1909 : loss : 0.086892, loss_ce: 0.018475
iteration 1910 : loss : 0.063193, loss_ce: 0.023597
iteration 1911 : loss : 0.101302, loss_ce: 0.017474
iteration 1912 : loss : 0.070748, loss_ce: 0.015754
iteration 1913 : loss : 0.055513, loss_ce: 0.017740
iteration 1914 : loss : 0.078211, loss_ce: 0.019221
iteration 1915 : loss : 0.062827, loss_ce: 0.022227
iteration 1916 : loss : 0.058063, loss_ce: 0.016746
iteration 1917 : loss : 0.055854, loss_ce: 0.012670
iteration 1918 : loss : 0.067795, loss_ce: 0.025663
iteration 1919 : loss : 0.054469, loss_ce: 0.014004
iteration 1920 : loss : 0.074161, loss_ce: 0.024224
iteration 1921 : loss : 0.110789, loss_ce: 0.008953
iteration 1922 : loss : 0.076977, loss_ce: 0.022691
iteration 1923 : loss : 0.061544, loss_ce: 0.017033
iteration 1924 : loss : 0.103723, loss_ce: 0.011479
iteration 1925 : loss : 0.065800, loss_ce: 0.025170
iteration 1926 : loss : 0.066894, loss_ce: 0.017729
iteration 1927 : loss : 0.072728, loss_ce: 0.019902
iteration 1928 : loss : 0.079109, loss_ce: 0.019346
iteration 1929 : loss : 0.058552, loss_ce: 0.017938
iteration 1930 : loss : 0.070720, loss_ce: 0.017124
iteration 1931 : loss : 0.107179, loss_ce: 0.013807
iteration 1932 : loss : 0.087864, loss_ce: 0.018461
iteration 1933 : loss : 0.083382, loss_ce: 0.027978
iteration 1934 : loss : 0.047410, loss_ce: 0.021900
iteration 1935 : loss : 0.072763, loss_ce: 0.022089
iteration 1936 : loss : 0.046052, loss_ce: 0.010320
iteration 1937 : loss : 0.090528, loss_ce: 0.020379
iteration 1938 : loss : 0.066814, loss_ce: 0.030132
iteration 1939 : loss : 0.057338, loss_ce: 0.020799
iteration 1940 : loss : 0.068922, loss_ce: 0.028538
iteration 1941 : loss : 0.077212, loss_ce: 0.023877
iteration 1942 : loss : 0.055942, loss_ce: 0.015201
iteration 1943 : loss : 0.061366, loss_ce: 0.026825
iteration 1944 : loss : 0.064339, loss_ce: 0.022267
iteration 1945 : loss : 0.057098, loss_ce: 0.023686
iteration 1946 : loss : 0.065220, loss_ce: 0.023468
iteration 1947 : loss : 0.048929, loss_ce: 0.019029
iteration 1948 : loss : 0.074117, loss_ce: 0.027198
iteration 1949 : loss : 0.080362, loss_ce: 0.022239
iteration 1950 : loss : 0.058259, loss_ce: 0.020439
iteration 1951 : loss : 0.055417, loss_ce: 0.023143
iteration 1952 : loss : 0.048867, loss_ce: 0.020407
iteration 1953 : loss : 0.269294, loss_ce: 0.027384
 10%|███▏                          | 21/200 [21:29<3:03:57, 61.66s/it]iteration 1954 : loss : 0.048636, loss_ce: 0.018700
iteration 1955 : loss : 0.056558, loss_ce: 0.021624
iteration 1956 : loss : 0.066500, loss_ce: 0.014196
iteration 1957 : loss : 0.109354, loss_ce: 0.017526
iteration 1958 : loss : 0.062161, loss_ce: 0.028098
iteration 1959 : loss : 0.071374, loss_ce: 0.030612
iteration 1960 : loss : 0.061549, loss_ce: 0.012294
iteration 1961 : loss : 0.049587, loss_ce: 0.019621
iteration 1962 : loss : 0.061492, loss_ce: 0.016732
iteration 1963 : loss : 0.057158, loss_ce: 0.027865
iteration 1964 : loss : 0.057665, loss_ce: 0.026856
iteration 1965 : loss : 0.060012, loss_ce: 0.023349
iteration 1966 : loss : 0.052296, loss_ce: 0.014037
iteration 1967 : loss : 0.057295, loss_ce: 0.017968
iteration 1968 : loss : 0.058312, loss_ce: 0.027495
iteration 1969 : loss : 0.074756, loss_ce: 0.026650
iteration 1970 : loss : 0.059083, loss_ce: 0.020133
iteration 1971 : loss : 0.069456, loss_ce: 0.020750
iteration 1972 : loss : 0.049268, loss_ce: 0.017341
iteration 1973 : loss : 0.048085, loss_ce: 0.016575
iteration 1974 : loss : 0.097447, loss_ce: 0.012483
iteration 1975 : loss : 0.060828, loss_ce: 0.024685
iteration 1976 : loss : 0.046941, loss_ce: 0.011182
iteration 1977 : loss : 0.066718, loss_ce: 0.018065
iteration 1978 : loss : 0.093470, loss_ce: 0.010407
iteration 1979 : loss : 0.056978, loss_ce: 0.013604
iteration 1980 : loss : 0.044624, loss_ce: 0.016084
iteration 1981 : loss : 0.068087, loss_ce: 0.018759
iteration 1982 : loss : 0.048853, loss_ce: 0.017909
iteration 1983 : loss : 0.059151, loss_ce: 0.021357
iteration 1984 : loss : 0.060808, loss_ce: 0.015559
iteration 1985 : loss : 0.074531, loss_ce: 0.023687
iteration 1986 : loss : 0.100206, loss_ce: 0.016823
iteration 1987 : loss : 0.051986, loss_ce: 0.019670
iteration 1988 : loss : 0.054910, loss_ce: 0.013867
iteration 1989 : loss : 0.056492, loss_ce: 0.019332
iteration 1990 : loss : 0.068340, loss_ce: 0.019680
iteration 1991 : loss : 0.054472, loss_ce: 0.016164
iteration 1992 : loss : 0.116702, loss_ce: 0.011100
iteration 1993 : loss : 0.058927, loss_ce: 0.027102
iteration 1994 : loss : 0.054971, loss_ce: 0.014366
iteration 1995 : loss : 0.076014, loss_ce: 0.019567
iteration 1996 : loss : 0.078471, loss_ce: 0.026544
iteration 1997 : loss : 0.117048, loss_ce: 0.023156
iteration 1998 : loss : 0.107337, loss_ce: 0.018742
iteration 1999 : loss : 0.084873, loss_ce: 0.019833
iteration 2000 : loss : 0.063337, loss_ce: 0.017377
iteration 2001 : loss : 0.077226, loss_ce: 0.025795
iteration 2002 : loss : 0.054944, loss_ce: 0.013513
iteration 2003 : loss : 0.056656, loss_ce: 0.019625
iteration 2004 : loss : 0.075475, loss_ce: 0.027573
iteration 2005 : loss : 0.069785, loss_ce: 0.017584
iteration 2006 : loss : 0.066032, loss_ce: 0.014912
iteration 2007 : loss : 0.077282, loss_ce: 0.028435
iteration 2008 : loss : 0.064133, loss_ce: 0.021010
iteration 2009 : loss : 0.046565, loss_ce: 0.015419
iteration 2010 : loss : 0.090915, loss_ce: 0.016485
iteration 2011 : loss : 0.054536, loss_ce: 0.018078
iteration 2012 : loss : 0.068924, loss_ce: 0.025082
iteration 2013 : loss : 0.064307, loss_ce: 0.023727
iteration 2014 : loss : 0.056201, loss_ce: 0.023367
iteration 2015 : loss : 0.041575, loss_ce: 0.015117
iteration 2016 : loss : 0.078440, loss_ce: 0.020850
iteration 2017 : loss : 0.052322, loss_ce: 0.014081
iteration 2018 : loss : 0.104009, loss_ce: 0.021289
iteration 2019 : loss : 0.062474, loss_ce: 0.013311
iteration 2020 : loss : 0.062036, loss_ce: 0.019960
iteration 2021 : loss : 0.069127, loss_ce: 0.016103
iteration 2022 : loss : 0.054618, loss_ce: 0.021191
iteration 2023 : loss : 0.103978, loss_ce: 0.017306
iteration 2024 : loss : 0.052207, loss_ce: 0.015780
iteration 2025 : loss : 0.051898, loss_ce: 0.014775
iteration 2026 : loss : 0.065241, loss_ce: 0.022015
iteration 2027 : loss : 0.043503, loss_ce: 0.012969
iteration 2028 : loss : 0.062787, loss_ce: 0.015557
iteration 2029 : loss : 0.057580, loss_ce: 0.027836
iteration 2030 : loss : 0.049276, loss_ce: 0.013414
iteration 2031 : loss : 0.065876, loss_ce: 0.013210
iteration 2032 : loss : 0.062647, loss_ce: 0.014525
iteration 2033 : loss : 0.104379, loss_ce: 0.018357
iteration 2034 : loss : 0.107727, loss_ce: 0.015397
iteration 2035 : loss : 0.050362, loss_ce: 0.019145
iteration 2036 : loss : 0.074637, loss_ce: 0.024748
iteration 2037 : loss : 0.065167, loss_ce: 0.018013
iteration 2038 : loss : 0.068231, loss_ce: 0.020179
iteration 2039 : loss : 0.049604, loss_ce: 0.019548
iteration 2040 : loss : 0.094952, loss_ce: 0.020131
iteration 2041 : loss : 0.087603, loss_ce: 0.008684
iteration 2042 : loss : 0.065333, loss_ce: 0.021614
iteration 2043 : loss : 0.058551, loss_ce: 0.016853
iteration 2044 : loss : 0.058261, loss_ce: 0.026595
iteration 2045 : loss : 0.092430, loss_ce: 0.007313
iteration 2046 : loss : 0.145058, loss_ce: 0.025264
 11%|███▎                          | 22/200 [22:31<3:02:59, 61.68s/it]iteration 2047 : loss : 0.108531, loss_ce: 0.022105
iteration 2048 : loss : 0.091842, loss_ce: 0.024605
iteration 2049 : loss : 0.063363, loss_ce: 0.019517
iteration 2050 : loss : 0.072396, loss_ce: 0.020390
iteration 2051 : loss : 0.072524, loss_ce: 0.039646
iteration 2052 : loss : 0.064216, loss_ce: 0.022730
iteration 2053 : loss : 0.127361, loss_ce: 0.019793
iteration 2054 : loss : 0.052012, loss_ce: 0.017229
iteration 2055 : loss : 0.066973, loss_ce: 0.016404
iteration 2056 : loss : 0.049648, loss_ce: 0.014298
iteration 2057 : loss : 0.132428, loss_ce: 0.021798
iteration 2058 : loss : 0.074271, loss_ce: 0.023285
iteration 2059 : loss : 0.089169, loss_ce: 0.025045
iteration 2060 : loss : 0.060394, loss_ce: 0.019649
iteration 2061 : loss : 0.083914, loss_ce: 0.035720
iteration 2062 : loss : 0.064976, loss_ce: 0.021383
iteration 2063 : loss : 0.136522, loss_ce: 0.028575
iteration 2064 : loss : 0.135234, loss_ce: 0.021099
iteration 2065 : loss : 0.065004, loss_ce: 0.026718
iteration 2066 : loss : 0.065052, loss_ce: 0.021037
iteration 2067 : loss : 0.088092, loss_ce: 0.016660
iteration 2068 : loss : 0.064320, loss_ce: 0.016372
iteration 2069 : loss : 0.057684, loss_ce: 0.022862
iteration 2070 : loss : 0.072603, loss_ce: 0.016335
iteration 2071 : loss : 0.057022, loss_ce: 0.017525
iteration 2072 : loss : 0.063498, loss_ce: 0.022812
iteration 2073 : loss : 0.068047, loss_ce: 0.027623
iteration 2074 : loss : 0.063427, loss_ce: 0.019326
iteration 2075 : loss : 0.053731, loss_ce: 0.020298
iteration 2076 : loss : 0.068134, loss_ce: 0.035847
iteration 2077 : loss : 0.060843, loss_ce: 0.028901
iteration 2078 : loss : 0.078592, loss_ce: 0.026753
iteration 2079 : loss : 0.065568, loss_ce: 0.017673
iteration 2080 : loss : 0.061986, loss_ce: 0.023628
iteration 2081 : loss : 0.065747, loss_ce: 0.023340
iteration 2082 : loss : 0.102581, loss_ce: 0.011915
iteration 2083 : loss : 0.082239, loss_ce: 0.020786
iteration 2084 : loss : 0.094220, loss_ce: 0.012639
iteration 2085 : loss : 0.052586, loss_ce: 0.017418
iteration 2086 : loss : 0.058116, loss_ce: 0.013490
iteration 2087 : loss : 0.063456, loss_ce: 0.026030
iteration 2088 : loss : 0.066101, loss_ce: 0.027482
iteration 2089 : loss : 0.063651, loss_ce: 0.024519
iteration 2090 : loss : 0.072159, loss_ce: 0.016076
iteration 2091 : loss : 0.088106, loss_ce: 0.009675
iteration 2092 : loss : 0.059351, loss_ce: 0.018143
iteration 2093 : loss : 0.051562, loss_ce: 0.016480
iteration 2094 : loss : 0.084034, loss_ce: 0.017441
iteration 2095 : loss : 0.074060, loss_ce: 0.025677
iteration 2096 : loss : 0.104830, loss_ce: 0.013723
iteration 2097 : loss : 0.066329, loss_ce: 0.014774
iteration 2098 : loss : 0.070260, loss_ce: 0.021064
iteration 2099 : loss : 0.071549, loss_ce: 0.017720
iteration 2100 : loss : 0.072299, loss_ce: 0.023422
iteration 2101 : loss : 0.061246, loss_ce: 0.012580
iteration 2102 : loss : 0.074996, loss_ce: 0.020477
iteration 2103 : loss : 0.088299, loss_ce: 0.012704
iteration 2104 : loss : 0.049213, loss_ce: 0.018794
iteration 2105 : loss : 0.050534, loss_ce: 0.016532
iteration 2106 : loss : 0.071415, loss_ce: 0.026577
iteration 2107 : loss : 0.057449, loss_ce: 0.015873
iteration 2108 : loss : 0.064871, loss_ce: 0.019888
iteration 2109 : loss : 0.076292, loss_ce: 0.021967
iteration 2110 : loss : 0.065990, loss_ce: 0.027124
iteration 2111 : loss : 0.072749, loss_ce: 0.012516
iteration 2112 : loss : 0.124667, loss_ce: 0.018631
iteration 2113 : loss : 0.058563, loss_ce: 0.025603
iteration 2114 : loss : 0.064594, loss_ce: 0.018580
iteration 2115 : loss : 0.070130, loss_ce: 0.019672
iteration 2116 : loss : 0.047043, loss_ce: 0.011900
iteration 2117 : loss : 0.076982, loss_ce: 0.023704
iteration 2118 : loss : 0.148209, loss_ce: 0.008861
iteration 2119 : loss : 0.082265, loss_ce: 0.022485
iteration 2120 : loss : 0.069590, loss_ce: 0.017328
iteration 2121 : loss : 0.050505, loss_ce: 0.016344
iteration 2122 : loss : 0.066196, loss_ce: 0.017682
iteration 2123 : loss : 0.068131, loss_ce: 0.024732
iteration 2124 : loss : 0.053533, loss_ce: 0.016076
iteration 2125 : loss : 0.092452, loss_ce: 0.020581
iteration 2126 : loss : 0.065738, loss_ce: 0.021799
iteration 2127 : loss : 0.066515, loss_ce: 0.017502
iteration 2128 : loss : 0.053777, loss_ce: 0.015056
iteration 2129 : loss : 0.097781, loss_ce: 0.020932
iteration 2130 : loss : 0.049710, loss_ce: 0.018732
iteration 2131 : loss : 0.053213, loss_ce: 0.024726
iteration 2132 : loss : 0.073834, loss_ce: 0.021080
iteration 2133 : loss : 0.070221, loss_ce: 0.016935
iteration 2134 : loss : 0.069203, loss_ce: 0.018630
iteration 2135 : loss : 0.094748, loss_ce: 0.013339
iteration 2136 : loss : 0.059443, loss_ce: 0.017342
iteration 2137 : loss : 0.047668, loss_ce: 0.018521
iteration 2138 : loss : 0.080880, loss_ce: 0.019131
iteration 2139 : loss : 0.252053, loss_ce: 0.031020
 12%|███▍                          | 23/200 [23:33<3:01:53, 61.66s/it]iteration 2140 : loss : 0.071672, loss_ce: 0.022976
iteration 2141 : loss : 0.092133, loss_ce: 0.030688
iteration 2142 : loss : 0.059298, loss_ce: 0.017814
iteration 2143 : loss : 0.062332, loss_ce: 0.027698
iteration 2144 : loss : 0.079323, loss_ce: 0.016310
iteration 2145 : loss : 0.066093, loss_ce: 0.026326
iteration 2146 : loss : 0.076586, loss_ce: 0.022548
iteration 2147 : loss : 0.051330, loss_ce: 0.020252
iteration 2148 : loss : 0.100324, loss_ce: 0.012370
iteration 2149 : loss : 0.064437, loss_ce: 0.023905
iteration 2150 : loss : 0.112800, loss_ce: 0.013920
iteration 2151 : loss : 0.049909, loss_ce: 0.014353
iteration 2152 : loss : 0.056140, loss_ce: 0.014050
iteration 2153 : loss : 0.071766, loss_ce: 0.023425
iteration 2154 : loss : 0.061073, loss_ce: 0.018247
iteration 2155 : loss : 0.075520, loss_ce: 0.032685
iteration 2156 : loss : 0.051326, loss_ce: 0.015318
iteration 2157 : loss : 0.053984, loss_ce: 0.017406
iteration 2158 : loss : 0.077425, loss_ce: 0.017909
iteration 2159 : loss : 0.059034, loss_ce: 0.024364
iteration 2160 : loss : 0.058632, loss_ce: 0.020886
iteration 2161 : loss : 0.049916, loss_ce: 0.018933
iteration 2162 : loss : 0.064498, loss_ce: 0.018431
iteration 2163 : loss : 0.054280, loss_ce: 0.015301
iteration 2164 : loss : 0.083324, loss_ce: 0.016523
iteration 2165 : loss : 0.098040, loss_ce: 0.010754
iteration 2166 : loss : 0.049797, loss_ce: 0.021770
iteration 2167 : loss : 0.057305, loss_ce: 0.028736
iteration 2168 : loss : 0.092176, loss_ce: 0.012088
iteration 2169 : loss : 0.056985, loss_ce: 0.015829
iteration 2170 : loss : 0.045668, loss_ce: 0.013869
iteration 2171 : loss : 0.057853, loss_ce: 0.013095
iteration 2172 : loss : 0.075025, loss_ce: 0.014313
iteration 2173 : loss : 0.059250, loss_ce: 0.007152
iteration 2174 : loss : 0.065163, loss_ce: 0.029200
iteration 2175 : loss : 0.067832, loss_ce: 0.014701
iteration 2176 : loss : 0.064504, loss_ce: 0.032118
iteration 2177 : loss : 0.047296, loss_ce: 0.021759
iteration 2178 : loss : 0.071571, loss_ce: 0.018554
iteration 2179 : loss : 0.065520, loss_ce: 0.016659
iteration 2180 : loss : 0.047792, loss_ce: 0.013314
iteration 2181 : loss : 0.106393, loss_ce: 0.017198
iteration 2182 : loss : 0.052434, loss_ce: 0.019229
iteration 2183 : loss : 0.061835, loss_ce: 0.018537
iteration 2184 : loss : 0.066872, loss_ce: 0.019558
iteration 2185 : loss : 0.071276, loss_ce: 0.016997
iteration 2186 : loss : 0.080196, loss_ce: 0.013668
iteration 2187 : loss : 0.054728, loss_ce: 0.019322
iteration 2188 : loss : 0.074772, loss_ce: 0.018776
iteration 2189 : loss : 0.057990, loss_ce: 0.014821
iteration 2190 : loss : 0.112878, loss_ce: 0.019104
iteration 2191 : loss : 0.051610, loss_ce: 0.019857
iteration 2192 : loss : 0.059739, loss_ce: 0.015360
iteration 2193 : loss : 0.071437, loss_ce: 0.022224
iteration 2194 : loss : 0.065893, loss_ce: 0.009637
iteration 2195 : loss : 0.052595, loss_ce: 0.012875
iteration 2196 : loss : 0.066729, loss_ce: 0.016648
iteration 2197 : loss : 0.052824, loss_ce: 0.013587
iteration 2198 : loss : 0.099154, loss_ce: 0.024523
iteration 2199 : loss : 0.087161, loss_ce: 0.024843
iteration 2200 : loss : 0.102929, loss_ce: 0.012816
iteration 2201 : loss : 0.053064, loss_ce: 0.019721
iteration 2202 : loss : 0.058990, loss_ce: 0.019135
iteration 2203 : loss : 0.050426, loss_ce: 0.017555
iteration 2204 : loss : 0.079965, loss_ce: 0.022348
iteration 2205 : loss : 0.068661, loss_ce: 0.021875
iteration 2206 : loss : 0.051842, loss_ce: 0.019868
iteration 2207 : loss : 0.043148, loss_ce: 0.016658
iteration 2208 : loss : 0.045269, loss_ce: 0.009888
iteration 2209 : loss : 0.097465, loss_ce: 0.012553
iteration 2210 : loss : 0.064503, loss_ce: 0.029413
iteration 2211 : loss : 0.090340, loss_ce: 0.023548
iteration 2212 : loss : 0.047787, loss_ce: 0.011223
iteration 2213 : loss : 0.056546, loss_ce: 0.022463
iteration 2214 : loss : 0.073530, loss_ce: 0.013468
iteration 2215 : loss : 0.057077, loss_ce: 0.020117
iteration 2216 : loss : 0.068243, loss_ce: 0.012102
iteration 2217 : loss : 0.062716, loss_ce: 0.024416
iteration 2218 : loss : 0.057267, loss_ce: 0.026144
iteration 2219 : loss : 0.099747, loss_ce: 0.023617
iteration 2220 : loss : 0.049603, loss_ce: 0.018014
iteration 2221 : loss : 0.047801, loss_ce: 0.016153
iteration 2222 : loss : 0.066396, loss_ce: 0.022337
iteration 2223 : loss : 0.106903, loss_ce: 0.013983
iteration 2224 : loss : 0.050560, loss_ce: 0.022010
iteration 2225 : loss : 0.059541, loss_ce: 0.013323
iteration 2226 : loss : 0.104166, loss_ce: 0.011444
iteration 2227 : loss : 0.039220, loss_ce: 0.015940
iteration 2228 : loss : 0.122158, loss_ce: 0.020121
iteration 2229 : loss : 0.058889, loss_ce: 0.022705
iteration 2230 : loss : 0.068571, loss_ce: 0.023267
iteration 2231 : loss : 0.096907, loss_ce: 0.016992
iteration 2232 : loss : 0.235466, loss_ce: 0.020286
 12%|███▌                          | 24/200 [24:34<3:00:49, 61.64s/it]iteration 2233 : loss : 0.113531, loss_ce: 0.012763
iteration 2234 : loss : 0.047596, loss_ce: 0.019372
iteration 2235 : loss : 0.047068, loss_ce: 0.016555
iteration 2236 : loss : 0.067487, loss_ce: 0.020610
iteration 2237 : loss : 0.102367, loss_ce: 0.011066
iteration 2238 : loss : 0.071045, loss_ce: 0.012840
iteration 2239 : loss : 0.054663, loss_ce: 0.010736
iteration 2240 : loss : 0.063382, loss_ce: 0.032704
iteration 2241 : loss : 0.056752, loss_ce: 0.018043
iteration 2242 : loss : 0.071448, loss_ce: 0.017223
iteration 2243 : loss : 0.074639, loss_ce: 0.021105
iteration 2244 : loss : 0.062400, loss_ce: 0.015516
iteration 2245 : loss : 0.073803, loss_ce: 0.021571
iteration 2246 : loss : 0.062316, loss_ce: 0.025226
iteration 2247 : loss : 0.097609, loss_ce: 0.013814
iteration 2248 : loss : 0.068133, loss_ce: 0.021939
iteration 2249 : loss : 0.044236, loss_ce: 0.017845
iteration 2250 : loss : 0.051533, loss_ce: 0.018910
iteration 2251 : loss : 0.044647, loss_ce: 0.017668
iteration 2252 : loss : 0.054783, loss_ce: 0.016135
iteration 2253 : loss : 0.075919, loss_ce: 0.017806
iteration 2254 : loss : 0.041636, loss_ce: 0.014680
iteration 2255 : loss : 0.095681, loss_ce: 0.011832
iteration 2256 : loss : 0.062761, loss_ce: 0.021095
iteration 2257 : loss : 0.041743, loss_ce: 0.015816
iteration 2258 : loss : 0.056411, loss_ce: 0.026695
iteration 2259 : loss : 0.049369, loss_ce: 0.022223
iteration 2260 : loss : 0.063293, loss_ce: 0.025912
iteration 2261 : loss : 0.076420, loss_ce: 0.016109
iteration 2262 : loss : 0.049761, loss_ce: 0.014444
iteration 2263 : loss : 0.046665, loss_ce: 0.026196
iteration 2264 : loss : 0.053925, loss_ce: 0.022371
iteration 2265 : loss : 0.053252, loss_ce: 0.020478
iteration 2266 : loss : 0.130325, loss_ce: 0.007006
iteration 2267 : loss : 0.061588, loss_ce: 0.015660
iteration 2268 : loss : 0.067385, loss_ce: 0.027076
iteration 2269 : loss : 0.063338, loss_ce: 0.019955
iteration 2270 : loss : 0.089177, loss_ce: 0.019449
iteration 2271 : loss : 0.062715, loss_ce: 0.022802
iteration 2272 : loss : 0.053207, loss_ce: 0.013269
iteration 2273 : loss : 0.077781, loss_ce: 0.024126
iteration 2274 : loss : 0.055566, loss_ce: 0.021453
iteration 2275 : loss : 0.070648, loss_ce: 0.019157
iteration 2276 : loss : 0.083508, loss_ce: 0.015805
iteration 2277 : loss : 0.057412, loss_ce: 0.020049
iteration 2278 : loss : 0.052379, loss_ce: 0.011959
iteration 2279 : loss : 0.043249, loss_ce: 0.013092
iteration 2280 : loss : 0.055031, loss_ce: 0.021900
iteration 2281 : loss : 0.066636, loss_ce: 0.012581
iteration 2282 : loss : 0.047999, loss_ce: 0.015523
iteration 2283 : loss : 0.051675, loss_ce: 0.017848
iteration 2284 : loss : 0.093704, loss_ce: 0.015667
iteration 2285 : loss : 0.061698, loss_ce: 0.024575
iteration 2286 : loss : 0.052444, loss_ce: 0.016119
iteration 2287 : loss : 0.071272, loss_ce: 0.021900
iteration 2288 : loss : 0.069645, loss_ce: 0.018413
iteration 2289 : loss : 0.055424, loss_ce: 0.015149
iteration 2290 : loss : 0.057462, loss_ce: 0.019513
iteration 2291 : loss : 0.070890, loss_ce: 0.026988
iteration 2292 : loss : 0.083008, loss_ce: 0.017736
iteration 2293 : loss : 0.055549, loss_ce: 0.018453
iteration 2294 : loss : 0.075603, loss_ce: 0.015337
iteration 2295 : loss : 0.063181, loss_ce: 0.021463
iteration 2296 : loss : 0.042410, loss_ce: 0.010130
iteration 2297 : loss : 0.087626, loss_ce: 0.013844
iteration 2298 : loss : 0.058681, loss_ce: 0.024708
iteration 2299 : loss : 0.049226, loss_ce: 0.012474
iteration 2300 : loss : 0.063532, loss_ce: 0.030856
iteration 2301 : loss : 0.068726, loss_ce: 0.025519
iteration 2302 : loss : 0.046639, loss_ce: 0.015179
iteration 2303 : loss : 0.054875, loss_ce: 0.017838
iteration 2304 : loss : 0.106591, loss_ce: 0.018987
iteration 2305 : loss : 0.055228, loss_ce: 0.020362
iteration 2306 : loss : 0.047733, loss_ce: 0.016402
iteration 2307 : loss : 0.039711, loss_ce: 0.012342
iteration 2308 : loss : 0.090092, loss_ce: 0.014014
iteration 2309 : loss : 0.053718, loss_ce: 0.009498
iteration 2310 : loss : 0.053905, loss_ce: 0.013448
iteration 2311 : loss : 0.121952, loss_ce: 0.010913
iteration 2312 : loss : 0.083750, loss_ce: 0.020095
iteration 2313 : loss : 0.046387, loss_ce: 0.012363
iteration 2314 : loss : 0.060119, loss_ce: 0.016432
iteration 2315 : loss : 0.053524, loss_ce: 0.023377
iteration 2316 : loss : 0.048751, loss_ce: 0.015069
iteration 2317 : loss : 0.086666, loss_ce: 0.016533
iteration 2318 : loss : 0.045219, loss_ce: 0.012947
iteration 2319 : loss : 0.054303, loss_ce: 0.021060
iteration 2320 : loss : 0.079423, loss_ce: 0.025562
iteration 2321 : loss : 0.057792, loss_ce: 0.015915
iteration 2322 : loss : 0.046222, loss_ce: 0.017001
iteration 2323 : loss : 0.048726, loss_ce: 0.017591
iteration 2324 : loss : 0.064759, loss_ce: 0.013615
iteration 2325 : loss : 0.138426, loss_ce: 0.039286
 12%|███▊                          | 25/200 [25:36<2:59:55, 61.69s/it]iteration 2326 : loss : 0.095396, loss_ce: 0.015345
iteration 2327 : loss : 0.067045, loss_ce: 0.013535
iteration 2328 : loss : 0.055759, loss_ce: 0.020219
iteration 2329 : loss : 0.097470, loss_ce: 0.018072
iteration 2330 : loss : 0.064047, loss_ce: 0.010187
iteration 2331 : loss : 0.047386, loss_ce: 0.017822
iteration 2332 : loss : 0.146501, loss_ce: 0.011319
iteration 2333 : loss : 0.063999, loss_ce: 0.020080
iteration 2334 : loss : 0.064772, loss_ce: 0.016656
iteration 2335 : loss : 0.069971, loss_ce: 0.032343
iteration 2336 : loss : 0.100987, loss_ce: 0.016997
iteration 2337 : loss : 0.083966, loss_ce: 0.023525
iteration 2338 : loss : 0.082333, loss_ce: 0.017382
iteration 2339 : loss : 0.052360, loss_ce: 0.016877
iteration 2340 : loss : 0.070570, loss_ce: 0.019098
iteration 2341 : loss : 0.055052, loss_ce: 0.020108
iteration 2342 : loss : 0.050656, loss_ce: 0.015206
iteration 2343 : loss : 0.072546, loss_ce: 0.018849
iteration 2344 : loss : 0.075177, loss_ce: 0.016038
iteration 2345 : loss : 0.072181, loss_ce: 0.016357
iteration 2346 : loss : 0.049706, loss_ce: 0.010551
iteration 2347 : loss : 0.051076, loss_ce: 0.018880
iteration 2348 : loss : 0.099069, loss_ce: 0.020592
iteration 2349 : loss : 0.091802, loss_ce: 0.033487
iteration 2350 : loss : 0.061113, loss_ce: 0.016913
iteration 2351 : loss : 0.079666, loss_ce: 0.010155
iteration 2352 : loss : 0.055356, loss_ce: 0.017729
iteration 2353 : loss : 0.053062, loss_ce: 0.019952
iteration 2354 : loss : 0.063452, loss_ce: 0.014079
iteration 2355 : loss : 0.066500, loss_ce: 0.019463
iteration 2356 : loss : 0.059620, loss_ce: 0.025172
iteration 2357 : loss : 0.054542, loss_ce: 0.024939
iteration 2358 : loss : 0.046227, loss_ce: 0.015791
iteration 2359 : loss : 0.060020, loss_ce: 0.014609
iteration 2360 : loss : 0.067840, loss_ce: 0.030736
iteration 2361 : loss : 0.063044, loss_ce: 0.026941
iteration 2362 : loss : 0.089605, loss_ce: 0.010101
iteration 2363 : loss : 0.057189, loss_ce: 0.012577
iteration 2364 : loss : 0.057085, loss_ce: 0.011952
iteration 2365 : loss : 0.069350, loss_ce: 0.017396
iteration 2366 : loss : 0.089871, loss_ce: 0.019044
iteration 2367 : loss : 0.069277, loss_ce: 0.024248
iteration 2368 : loss : 0.058234, loss_ce: 0.013098
iteration 2369 : loss : 0.053574, loss_ce: 0.018029
iteration 2370 : loss : 0.050983, loss_ce: 0.016983
iteration 2371 : loss : 0.052728, loss_ce: 0.019724
iteration 2372 : loss : 0.045251, loss_ce: 0.021698
iteration 2373 : loss : 0.066912, loss_ce: 0.017760
iteration 2374 : loss : 0.057211, loss_ce: 0.021122
iteration 2375 : loss : 0.058184, loss_ce: 0.013759
iteration 2376 : loss : 0.054247, loss_ce: 0.025030
iteration 2377 : loss : 0.094136, loss_ce: 0.013634
iteration 2378 : loss : 0.057815, loss_ce: 0.020442
iteration 2379 : loss : 0.058350, loss_ce: 0.026262
iteration 2380 : loss : 0.060396, loss_ce: 0.022386
iteration 2381 : loss : 0.057610, loss_ce: 0.017106
iteration 2382 : loss : 0.056432, loss_ce: 0.014587
iteration 2383 : loss : 0.054479, loss_ce: 0.025951
iteration 2384 : loss : 0.054055, loss_ce: 0.014557
iteration 2385 : loss : 0.054544, loss_ce: 0.024578
iteration 2386 : loss : 0.063957, loss_ce: 0.018438
iteration 2387 : loss : 0.060482, loss_ce: 0.025147
iteration 2388 : loss : 0.054051, loss_ce: 0.024638
iteration 2389 : loss : 0.045086, loss_ce: 0.018571
iteration 2390 : loss : 0.090921, loss_ce: 0.011053
iteration 2391 : loss : 0.062779, loss_ce: 0.014143
iteration 2392 : loss : 0.054813, loss_ce: 0.013514
iteration 2393 : loss : 0.051333, loss_ce: 0.014660
iteration 2394 : loss : 0.093497, loss_ce: 0.016998
iteration 2395 : loss : 0.051392, loss_ce: 0.016488
iteration 2396 : loss : 0.047301, loss_ce: 0.015674
iteration 2397 : loss : 0.042520, loss_ce: 0.017704
iteration 2398 : loss : 0.049374, loss_ce: 0.013549
iteration 2399 : loss : 0.042713, loss_ce: 0.014017
iteration 2400 : loss : 0.098983, loss_ce: 0.013273
iteration 2401 : loss : 0.052286, loss_ce: 0.026156
iteration 2402 : loss : 0.042967, loss_ce: 0.009564
iteration 2403 : loss : 0.060866, loss_ce: 0.017870
iteration 2404 : loss : 0.100724, loss_ce: 0.009576
iteration 2405 : loss : 0.060096, loss_ce: 0.016027
iteration 2406 : loss : 0.051836, loss_ce: 0.019269
iteration 2407 : loss : 0.043083, loss_ce: 0.016755
iteration 2408 : loss : 0.059477, loss_ce: 0.015072
iteration 2409 : loss : 0.064686, loss_ce: 0.024261
iteration 2410 : loss : 0.035686, loss_ce: 0.012203
iteration 2411 : loss : 0.047940, loss_ce: 0.018479
iteration 2412 : loss : 0.061301, loss_ce: 0.019297
iteration 2413 : loss : 0.090261, loss_ce: 0.012205
iteration 2414 : loss : 0.058161, loss_ce: 0.020666
iteration 2415 : loss : 0.081152, loss_ce: 0.013520
iteration 2416 : loss : 0.050788, loss_ce: 0.017921
iteration 2417 : loss : 0.043949, loss_ce: 0.010072
iteration 2418 : loss : 0.287949, loss_ce: 0.011415
 13%|███▉                          | 26/200 [26:38<2:58:55, 61.70s/it]iteration 2419 : loss : 0.045971, loss_ce: 0.012611
iteration 2420 : loss : 0.068085, loss_ce: 0.024516
iteration 2421 : loss : 0.101603, loss_ce: 0.013858
iteration 2422 : loss : 0.090724, loss_ce: 0.015436
iteration 2423 : loss : 0.049104, loss_ce: 0.017189
iteration 2424 : loss : 0.061789, loss_ce: 0.031704
iteration 2425 : loss : 0.060934, loss_ce: 0.016730
iteration 2426 : loss : 0.041165, loss_ce: 0.013635
iteration 2427 : loss : 0.059843, loss_ce: 0.023936
iteration 2428 : loss : 0.104873, loss_ce: 0.020964
iteration 2429 : loss : 0.049885, loss_ce: 0.019611
iteration 2430 : loss : 0.055342, loss_ce: 0.019698
iteration 2431 : loss : 0.076901, loss_ce: 0.023820
iteration 2432 : loss : 0.057089, loss_ce: 0.014751
iteration 2433 : loss : 0.066274, loss_ce: 0.016687
iteration 2434 : loss : 0.062630, loss_ce: 0.020749
iteration 2435 : loss : 0.063774, loss_ce: 0.028414
iteration 2436 : loss : 0.052033, loss_ce: 0.017887
iteration 2437 : loss : 0.070503, loss_ce: 0.025529
iteration 2438 : loss : 0.049319, loss_ce: 0.019165
iteration 2439 : loss : 0.094311, loss_ce: 0.012977
iteration 2440 : loss : 0.057864, loss_ce: 0.012433
iteration 2441 : loss : 0.100778, loss_ce: 0.018273
iteration 2442 : loss : 0.047986, loss_ce: 0.015446
iteration 2443 : loss : 0.081992, loss_ce: 0.011690
iteration 2444 : loss : 0.132371, loss_ce: 0.009664
iteration 2445 : loss : 0.060147, loss_ce: 0.019743
iteration 2446 : loss : 0.061594, loss_ce: 0.031988
iteration 2447 : loss : 0.060597, loss_ce: 0.018498
iteration 2448 : loss : 0.103689, loss_ce: 0.015747
iteration 2449 : loss : 0.074457, loss_ce: 0.018342
iteration 2450 : loss : 0.072510, loss_ce: 0.021676
iteration 2451 : loss : 0.061934, loss_ce: 0.022824
iteration 2452 : loss : 0.078427, loss_ce: 0.017852
iteration 2453 : loss : 0.071503, loss_ce: 0.030928
iteration 2454 : loss : 0.067204, loss_ce: 0.017657
iteration 2455 : loss : 0.063667, loss_ce: 0.031014
iteration 2456 : loss : 0.055618, loss_ce: 0.014593
iteration 2457 : loss : 0.053006, loss_ce: 0.025145
iteration 2458 : loss : 0.075901, loss_ce: 0.014770
iteration 2459 : loss : 0.065833, loss_ce: 0.018139
iteration 2460 : loss : 0.047020, loss_ce: 0.015208
iteration 2461 : loss : 0.049419, loss_ce: 0.015949
iteration 2462 : loss : 0.066617, loss_ce: 0.025206
iteration 2463 : loss : 0.080506, loss_ce: 0.023209
iteration 2464 : loss : 0.066256, loss_ce: 0.014868
iteration 2465 : loss : 0.068299, loss_ce: 0.010924
iteration 2466 : loss : 0.048894, loss_ce: 0.016749
iteration 2467 : loss : 0.055981, loss_ce: 0.024132
iteration 2468 : loss : 0.058159, loss_ce: 0.020885
iteration 2469 : loss : 0.061197, loss_ce: 0.021494
iteration 2470 : loss : 0.051193, loss_ce: 0.019090
iteration 2471 : loss : 0.054762, loss_ce: 0.018925
iteration 2472 : loss : 0.059411, loss_ce: 0.027201
iteration 2473 : loss : 0.048501, loss_ce: 0.011235
iteration 2474 : loss : 0.058073, loss_ce: 0.020447
iteration 2475 : loss : 0.051457, loss_ce: 0.014165
iteration 2476 : loss : 0.093281, loss_ce: 0.015415
iteration 2477 : loss : 0.107714, loss_ce: 0.017836
iteration 2478 : loss : 0.112430, loss_ce: 0.015098
iteration 2479 : loss : 0.098941, loss_ce: 0.021654
iteration 2480 : loss : 0.063733, loss_ce: 0.017226
iteration 2481 : loss : 0.090207, loss_ce: 0.017077
iteration 2482 : loss : 0.061966, loss_ce: 0.015992
iteration 2483 : loss : 0.078065, loss_ce: 0.012865
iteration 2484 : loss : 0.050287, loss_ce: 0.017287
iteration 2485 : loss : 0.054219, loss_ce: 0.017558
iteration 2486 : loss : 0.070307, loss_ce: 0.022659
iteration 2487 : loss : 0.096483, loss_ce: 0.008163
iteration 2488 : loss : 0.049111, loss_ce: 0.015179
iteration 2489 : loss : 0.152949, loss_ce: 0.007691
iteration 2490 : loss : 0.064262, loss_ce: 0.013455
iteration 2491 : loss : 0.062287, loss_ce: 0.016741
iteration 2492 : loss : 0.069361, loss_ce: 0.035449
iteration 2493 : loss : 0.062545, loss_ce: 0.020244
iteration 2494 : loss : 0.070604, loss_ce: 0.020291
iteration 2495 : loss : 0.066244, loss_ce: 0.011501
iteration 2496 : loss : 0.070430, loss_ce: 0.026000
iteration 2497 : loss : 0.059325, loss_ce: 0.018211
iteration 2498 : loss : 0.071603, loss_ce: 0.013740
iteration 2499 : loss : 0.076703, loss_ce: 0.015390
iteration 2500 : loss : 0.051353, loss_ce: 0.020351
iteration 2501 : loss : 0.066833, loss_ce: 0.020529
iteration 2502 : loss : 0.056754, loss_ce: 0.020848
iteration 2503 : loss : 0.095784, loss_ce: 0.021978
iteration 2504 : loss : 0.053492, loss_ce: 0.012658
iteration 2505 : loss : 0.064102, loss_ce: 0.021536
iteration 2506 : loss : 0.068068, loss_ce: 0.020925
iteration 2507 : loss : 0.063763, loss_ce: 0.019366
iteration 2508 : loss : 0.054011, loss_ce: 0.025789
iteration 2509 : loss : 0.083707, loss_ce: 0.013049
iteration 2510 : loss : 0.109437, loss_ce: 0.014738
iteration 2511 : loss : 0.052478, loss_ce: 0.020149
 14%|████                          | 27/200 [27:40<2:57:57, 61.72s/it]iteration 2512 : loss : 0.094274, loss_ce: 0.012851
iteration 2513 : loss : 0.046357, loss_ce: 0.023012
iteration 2514 : loss : 0.061608, loss_ce: 0.012774
iteration 2515 : loss : 0.054074, loss_ce: 0.017232
iteration 2516 : loss : 0.066211, loss_ce: 0.023209
iteration 2517 : loss : 0.146520, loss_ce: 0.021963
iteration 2518 : loss : 0.057686, loss_ce: 0.015576
iteration 2519 : loss : 0.057591, loss_ce: 0.021157
iteration 2520 : loss : 0.060640, loss_ce: 0.016452
iteration 2521 : loss : 0.043716, loss_ce: 0.015170
iteration 2522 : loss : 0.097381, loss_ce: 0.018672
iteration 2523 : loss : 0.041057, loss_ce: 0.017020
iteration 2524 : loss : 0.052848, loss_ce: 0.020674
iteration 2525 : loss : 0.044363, loss_ce: 0.009919
iteration 2526 : loss : 0.044884, loss_ce: 0.014756
iteration 2527 : loss : 0.055704, loss_ce: 0.024630
iteration 2528 : loss : 0.044714, loss_ce: 0.015147
iteration 2529 : loss : 0.052343, loss_ce: 0.013244
iteration 2530 : loss : 0.100813, loss_ce: 0.015876
iteration 2531 : loss : 0.069883, loss_ce: 0.019199
iteration 2532 : loss : 0.041289, loss_ce: 0.015770
iteration 2533 : loss : 0.045237, loss_ce: 0.014912
iteration 2534 : loss : 0.051364, loss_ce: 0.007169
iteration 2535 : loss : 0.078181, loss_ce: 0.017766
iteration 2536 : loss : 0.058860, loss_ce: 0.017279
iteration 2537 : loss : 0.056943, loss_ce: 0.020025
iteration 2538 : loss : 0.051304, loss_ce: 0.017217
iteration 2539 : loss : 0.072219, loss_ce: 0.021708
iteration 2540 : loss : 0.059062, loss_ce: 0.012596
iteration 2541 : loss : 0.046364, loss_ce: 0.015848
iteration 2542 : loss : 0.045783, loss_ce: 0.016368
iteration 2543 : loss : 0.048744, loss_ce: 0.014802
iteration 2544 : loss : 0.044539, loss_ce: 0.011979
iteration 2545 : loss : 0.099198, loss_ce: 0.009108
iteration 2546 : loss : 0.086773, loss_ce: 0.014372
iteration 2547 : loss : 0.040041, loss_ce: 0.016500
iteration 2548 : loss : 0.033594, loss_ce: 0.013488
iteration 2549 : loss : 0.057631, loss_ce: 0.017794
iteration 2550 : loss : 0.059181, loss_ce: 0.018029
iteration 2551 : loss : 0.048868, loss_ce: 0.021016
iteration 2552 : loss : 0.056005, loss_ce: 0.015210
iteration 2553 : loss : 0.051271, loss_ce: 0.023655
iteration 2554 : loss : 0.052690, loss_ce: 0.015987
iteration 2555 : loss : 0.055278, loss_ce: 0.016881
iteration 2556 : loss : 0.041216, loss_ce: 0.013045
iteration 2557 : loss : 0.046582, loss_ce: 0.018863
iteration 2558 : loss : 0.072982, loss_ce: 0.015644
iteration 2559 : loss : 0.052640, loss_ce: 0.018029
iteration 2560 : loss : 0.059047, loss_ce: 0.024122
iteration 2561 : loss : 0.049356, loss_ce: 0.019508
iteration 2562 : loss : 0.100181, loss_ce: 0.016798
iteration 2563 : loss : 0.046614, loss_ce: 0.022409
iteration 2564 : loss : 0.051455, loss_ce: 0.017689
iteration 2565 : loss : 0.049145, loss_ce: 0.015776
iteration 2566 : loss : 0.094279, loss_ce: 0.007944
iteration 2567 : loss : 0.043424, loss_ce: 0.013150
iteration 2568 : loss : 0.049529, loss_ce: 0.018340
iteration 2569 : loss : 0.056630, loss_ce: 0.020585
iteration 2570 : loss : 0.056272, loss_ce: 0.021500
iteration 2571 : loss : 0.057590, loss_ce: 0.010060
iteration 2572 : loss : 0.046307, loss_ce: 0.019518
iteration 2573 : loss : 0.039082, loss_ce: 0.010768
iteration 2574 : loss : 0.037678, loss_ce: 0.015729
iteration 2575 : loss : 0.069323, loss_ce: 0.016578
iteration 2576 : loss : 0.049670, loss_ce: 0.015214
iteration 2577 : loss : 0.046480, loss_ce: 0.014592
iteration 2578 : loss : 0.062601, loss_ce: 0.022513
iteration 2579 : loss : 0.107282, loss_ce: 0.009539
iteration 2580 : loss : 0.059099, loss_ce: 0.015395
iteration 2581 : loss : 0.055884, loss_ce: 0.022629
iteration 2582 : loss : 0.051367, loss_ce: 0.021316
iteration 2583 : loss : 0.054909, loss_ce: 0.019137
iteration 2584 : loss : 0.076365, loss_ce: 0.019720
iteration 2585 : loss : 0.049113, loss_ce: 0.015681
iteration 2586 : loss : 0.057190, loss_ce: 0.014232
iteration 2587 : loss : 0.044041, loss_ce: 0.020887
iteration 2588 : loss : 0.052810, loss_ce: 0.021624
iteration 2589 : loss : 0.059026, loss_ce: 0.021326
iteration 2590 : loss : 0.046492, loss_ce: 0.013888
iteration 2591 : loss : 0.046450, loss_ce: 0.013136
iteration 2592 : loss : 0.053569, loss_ce: 0.015750
iteration 2593 : loss : 0.097879, loss_ce: 0.013787
iteration 2594 : loss : 0.071312, loss_ce: 0.015305
iteration 2595 : loss : 0.050874, loss_ce: 0.009864
iteration 2596 : loss : 0.052005, loss_ce: 0.015489
iteration 2597 : loss : 0.099836, loss_ce: 0.015439
iteration 2598 : loss : 0.074991, loss_ce: 0.021042
iteration 2599 : loss : 0.053443, loss_ce: 0.018666
iteration 2600 : loss : 0.089834, loss_ce: 0.009700
iteration 2601 : loss : 0.072100, loss_ce: 0.025397
iteration 2602 : loss : 0.051750, loss_ce: 0.020062
iteration 2603 : loss : 0.047209, loss_ce: 0.015971
iteration 2604 : loss : 0.206174, loss_ce: 0.028421
 14%|████▏                         | 28/200 [28:41<2:56:47, 61.67s/it]iteration 2605 : loss : 0.040176, loss_ce: 0.014399
iteration 2606 : loss : 0.057937, loss_ce: 0.013801
iteration 2607 : loss : 0.046866, loss_ce: 0.020929
iteration 2608 : loss : 0.058436, loss_ce: 0.016822
iteration 2609 : loss : 0.099022, loss_ce: 0.026971
iteration 2610 : loss : 0.045540, loss_ce: 0.015971
iteration 2611 : loss : 0.086054, loss_ce: 0.019824
iteration 2612 : loss : 0.067339, loss_ce: 0.018825
iteration 2613 : loss : 0.043633, loss_ce: 0.012517
iteration 2614 : loss : 0.041364, loss_ce: 0.010492
iteration 2615 : loss : 0.047326, loss_ce: 0.021216
iteration 2616 : loss : 0.049503, loss_ce: 0.018156
iteration 2617 : loss : 0.070672, loss_ce: 0.026778
iteration 2618 : loss : 0.045360, loss_ce: 0.013612
iteration 2619 : loss : 0.053945, loss_ce: 0.014108
iteration 2620 : loss : 0.051710, loss_ce: 0.013018
iteration 2621 : loss : 0.050101, loss_ce: 0.014239
iteration 2622 : loss : 0.104170, loss_ce: 0.014526
iteration 2623 : loss : 0.058380, loss_ce: 0.013478
iteration 2624 : loss : 0.041832, loss_ce: 0.014991
iteration 2625 : loss : 0.069447, loss_ce: 0.025249
iteration 2626 : loss : 0.052838, loss_ce: 0.016860
iteration 2627 : loss : 0.049188, loss_ce: 0.014863
iteration 2628 : loss : 0.067365, loss_ce: 0.024016
iteration 2629 : loss : 0.051718, loss_ce: 0.020885
iteration 2630 : loss : 0.047200, loss_ce: 0.015200
iteration 2631 : loss : 0.054488, loss_ce: 0.023642
iteration 2632 : loss : 0.061832, loss_ce: 0.014730
iteration 2633 : loss : 0.048934, loss_ce: 0.010987
iteration 2634 : loss : 0.056950, loss_ce: 0.026917
iteration 2635 : loss : 0.056568, loss_ce: 0.017557
iteration 2636 : loss : 0.060562, loss_ce: 0.010847
iteration 2637 : loss : 0.068724, loss_ce: 0.019418
iteration 2638 : loss : 0.055068, loss_ce: 0.021069
iteration 2639 : loss : 0.056285, loss_ce: 0.013637
iteration 2640 : loss : 0.102329, loss_ce: 0.017872
iteration 2641 : loss : 0.058993, loss_ce: 0.016599
iteration 2642 : loss : 0.069229, loss_ce: 0.019099
iteration 2643 : loss : 0.053767, loss_ce: 0.023225
iteration 2644 : loss : 0.042095, loss_ce: 0.015488
iteration 2645 : loss : 0.062825, loss_ce: 0.017584
iteration 2646 : loss : 0.047210, loss_ce: 0.014000
iteration 2647 : loss : 0.046733, loss_ce: 0.021376
iteration 2648 : loss : 0.037814, loss_ce: 0.013669
iteration 2649 : loss : 0.050659, loss_ce: 0.015893
iteration 2650 : loss : 0.056326, loss_ce: 0.017863
iteration 2651 : loss : 0.055350, loss_ce: 0.027121
iteration 2652 : loss : 0.051894, loss_ce: 0.025332
iteration 2653 : loss : 0.074406, loss_ce: 0.017597
iteration 2654 : loss : 0.046365, loss_ce: 0.013392
iteration 2655 : loss : 0.072270, loss_ce: 0.014280
iteration 2656 : loss : 0.047154, loss_ce: 0.017811
iteration 2657 : loss : 0.050129, loss_ce: 0.017607
iteration 2658 : loss : 0.046497, loss_ce: 0.012280
iteration 2659 : loss : 0.067821, loss_ce: 0.017931
iteration 2660 : loss : 0.052840, loss_ce: 0.016077
iteration 2661 : loss : 0.076483, loss_ce: 0.008971
iteration 2662 : loss : 0.054339, loss_ce: 0.014694
iteration 2663 : loss : 0.079864, loss_ce: 0.014840
iteration 2664 : loss : 0.048305, loss_ce: 0.016401
iteration 2665 : loss : 0.059092, loss_ce: 0.018872
iteration 2666 : loss : 0.043383, loss_ce: 0.020126
iteration 2667 : loss : 0.066690, loss_ce: 0.014423
iteration 2668 : loss : 0.051258, loss_ce: 0.024731
iteration 2669 : loss : 0.042995, loss_ce: 0.020785
iteration 2670 : loss : 0.061113, loss_ce: 0.015307
iteration 2671 : loss : 0.095342, loss_ce: 0.013434
iteration 2672 : loss : 0.087947, loss_ce: 0.012818
iteration 2673 : loss : 0.084342, loss_ce: 0.017107
iteration 2674 : loss : 0.061804, loss_ce: 0.023758
iteration 2675 : loss : 0.043770, loss_ce: 0.011560
iteration 2676 : loss : 0.052181, loss_ce: 0.013820
iteration 2677 : loss : 0.101037, loss_ce: 0.006013
iteration 2678 : loss : 0.048125, loss_ce: 0.018953
iteration 2679 : loss : 0.061651, loss_ce: 0.015199
iteration 2680 : loss : 0.092275, loss_ce: 0.011978
iteration 2681 : loss : 0.065260, loss_ce: 0.016318
iteration 2682 : loss : 0.088896, loss_ce: 0.014961
iteration 2683 : loss : 0.053297, loss_ce: 0.016392
iteration 2684 : loss : 0.070009, loss_ce: 0.012700
iteration 2685 : loss : 0.049548, loss_ce: 0.008822
iteration 2686 : loss : 0.050932, loss_ce: 0.011494
iteration 2687 : loss : 0.058317, loss_ce: 0.016733
iteration 2688 : loss : 0.058455, loss_ce: 0.019700
iteration 2689 : loss : 0.060342, loss_ce: 0.022256
iteration 2690 : loss : 0.048427, loss_ce: 0.017952
iteration 2691 : loss : 0.065350, loss_ce: 0.021193
iteration 2692 : loss : 0.086943, loss_ce: 0.015117
iteration 2693 : loss : 0.051999, loss_ce: 0.019376
iteration 2694 : loss : 0.051813, loss_ce: 0.023437
iteration 2695 : loss : 0.064272, loss_ce: 0.018359
iteration 2696 : loss : 0.052750, loss_ce: 0.018933
iteration 2697 : loss : 0.104146, loss_ce: 0.042628
 14%|████▎                         | 29/200 [29:43<2:55:37, 61.62s/it]iteration 2698 : loss : 0.063361, loss_ce: 0.025085
iteration 2699 : loss : 0.073996, loss_ce: 0.020248
iteration 2700 : loss : 0.061935, loss_ce: 0.015580
iteration 2701 : loss : 0.051273, loss_ce: 0.019484
iteration 2702 : loss : 0.085995, loss_ce: 0.033813
iteration 2703 : loss : 0.076660, loss_ce: 0.019500
iteration 2704 : loss : 0.062027, loss_ce: 0.027857
iteration 2705 : loss : 0.055112, loss_ce: 0.018214
iteration 2706 : loss : 0.054159, loss_ce: 0.016200
iteration 2707 : loss : 0.056446, loss_ce: 0.022361
iteration 2708 : loss : 0.048741, loss_ce: 0.015617
iteration 2709 : loss : 0.051993, loss_ce: 0.010710
iteration 2710 : loss : 0.047262, loss_ce: 0.013357
iteration 2711 : loss : 0.046399, loss_ce: 0.013225
iteration 2712 : loss : 0.077472, loss_ce: 0.017919
iteration 2713 : loss : 0.045847, loss_ce: 0.013664
iteration 2714 : loss : 0.050244, loss_ce: 0.016802
iteration 2715 : loss : 0.073548, loss_ce: 0.028309
iteration 2716 : loss : 0.046545, loss_ce: 0.011971
iteration 2717 : loss : 0.038776, loss_ce: 0.013133
iteration 2718 : loss : 0.097758, loss_ce: 0.016334
iteration 2719 : loss : 0.055548, loss_ce: 0.024792
iteration 2720 : loss : 0.055628, loss_ce: 0.017743
iteration 2721 : loss : 0.057507, loss_ce: 0.020157
iteration 2722 : loss : 0.053779, loss_ce: 0.019100
iteration 2723 : loss : 0.049695, loss_ce: 0.021743
iteration 2724 : loss : 0.045537, loss_ce: 0.014943
iteration 2725 : loss : 0.048111, loss_ce: 0.017520
iteration 2726 : loss : 0.051124, loss_ce: 0.015927
iteration 2727 : loss : 0.094126, loss_ce: 0.013737
iteration 2728 : loss : 0.043291, loss_ce: 0.021391
iteration 2729 : loss : 0.041537, loss_ce: 0.017016
iteration 2730 : loss : 0.094250, loss_ce: 0.019286
iteration 2731 : loss : 0.057784, loss_ce: 0.017059
iteration 2732 : loss : 0.052549, loss_ce: 0.019003
iteration 2733 : loss : 0.062985, loss_ce: 0.013679
iteration 2734 : loss : 0.070086, loss_ce: 0.011729
iteration 2735 : loss : 0.069549, loss_ce: 0.017670
iteration 2736 : loss : 0.091083, loss_ce: 0.011152
iteration 2737 : loss : 0.093938, loss_ce: 0.011331
iteration 2738 : loss : 0.048660, loss_ce: 0.008925
iteration 2739 : loss : 0.054915, loss_ce: 0.020498
iteration 2740 : loss : 0.057779, loss_ce: 0.014628
iteration 2741 : loss : 0.040677, loss_ce: 0.014820
iteration 2742 : loss : 0.239953, loss_ce: 0.005776
iteration 2743 : loss : 0.048632, loss_ce: 0.017649
iteration 2744 : loss : 0.067686, loss_ce: 0.020348
iteration 2745 : loss : 0.047016, loss_ce: 0.021719
iteration 2746 : loss : 0.089744, loss_ce: 0.009939
iteration 2747 : loss : 0.054002, loss_ce: 0.012653
iteration 2748 : loss : 0.059481, loss_ce: 0.021419
iteration 2749 : loss : 0.063853, loss_ce: 0.014200
iteration 2750 : loss : 0.049703, loss_ce: 0.010749
iteration 2751 : loss : 0.042299, loss_ce: 0.010572
iteration 2752 : loss : 0.056147, loss_ce: 0.016424
iteration 2753 : loss : 0.064508, loss_ce: 0.022670
iteration 2754 : loss : 0.100134, loss_ce: 0.017371
iteration 2755 : loss : 0.040711, loss_ce: 0.011206
iteration 2756 : loss : 0.048664, loss_ce: 0.016330
iteration 2757 : loss : 0.055401, loss_ce: 0.014479
iteration 2758 : loss : 0.051997, loss_ce: 0.019384
iteration 2759 : loss : 0.067070, loss_ce: 0.012344
iteration 2760 : loss : 0.051202, loss_ce: 0.019350
iteration 2761 : loss : 0.098552, loss_ce: 0.022754
iteration 2762 : loss : 0.075426, loss_ce: 0.017435
iteration 2763 : loss : 0.039566, loss_ce: 0.014488
iteration 2764 : loss : 0.059118, loss_ce: 0.022318
iteration 2765 : loss : 0.047350, loss_ce: 0.022571
iteration 2766 : loss : 0.056014, loss_ce: 0.015355
iteration 2767 : loss : 0.063989, loss_ce: 0.018993
iteration 2768 : loss : 0.043577, loss_ce: 0.010257
iteration 2769 : loss : 0.050099, loss_ce: 0.010197
iteration 2770 : loss : 0.053457, loss_ce: 0.018023
iteration 2771 : loss : 0.046376, loss_ce: 0.016168
iteration 2772 : loss : 0.050989, loss_ce: 0.013843
iteration 2773 : loss : 0.056508, loss_ce: 0.015013
iteration 2774 : loss : 0.045769, loss_ce: 0.017601
iteration 2775 : loss : 0.049238, loss_ce: 0.022596
iteration 2776 : loss : 0.045329, loss_ce: 0.009923
iteration 2777 : loss : 0.048402, loss_ce: 0.022209
iteration 2778 : loss : 0.035324, loss_ce: 0.009033
iteration 2779 : loss : 0.062043, loss_ce: 0.022684
iteration 2780 : loss : 0.069052, loss_ce: 0.012239
iteration 2781 : loss : 0.045700, loss_ce: 0.019332
iteration 2782 : loss : 0.055803, loss_ce: 0.017089
iteration 2783 : loss : 0.043533, loss_ce: 0.011772
iteration 2784 : loss : 0.059955, loss_ce: 0.016734
iteration 2785 : loss : 0.051200, loss_ce: 0.013810
iteration 2786 : loss : 0.048244, loss_ce: 0.014532
iteration 2787 : loss : 0.089001, loss_ce: 0.010886
iteration 2788 : loss : 0.061158, loss_ce: 0.012358
iteration 2789 : loss : 0.046684, loss_ce: 0.023260
iteration 2790 : loss : 0.235917, loss_ce: 0.010987
 15%|████▌                         | 30/200 [30:44<2:54:35, 61.62s/it]iteration 2791 : loss : 0.044170, loss_ce: 0.020640
iteration 2792 : loss : 0.075080, loss_ce: 0.025922
iteration 2793 : loss : 0.055412, loss_ce: 0.022139
iteration 2794 : loss : 0.100178, loss_ce: 0.009128
iteration 2795 : loss : 0.055683, loss_ce: 0.021371
iteration 2796 : loss : 0.043407, loss_ce: 0.012970
iteration 2797 : loss : 0.058345, loss_ce: 0.024036
iteration 2798 : loss : 0.044194, loss_ce: 0.022250
iteration 2799 : loss : 0.087249, loss_ce: 0.010268
iteration 2800 : loss : 0.047610, loss_ce: 0.014138
iteration 2801 : loss : 0.037231, loss_ce: 0.016710
iteration 2802 : loss : 0.058469, loss_ce: 0.013867
iteration 2803 : loss : 0.056695, loss_ce: 0.013722
iteration 2804 : loss : 0.091938, loss_ce: 0.012278
iteration 2805 : loss : 0.043772, loss_ce: 0.018896
iteration 2806 : loss : 0.131675, loss_ce: 0.010461
iteration 2807 : loss : 0.043584, loss_ce: 0.018814
iteration 2808 : loss : 0.069285, loss_ce: 0.018639
iteration 2809 : loss : 0.041282, loss_ce: 0.015598
iteration 2810 : loss : 0.091252, loss_ce: 0.013993
iteration 2811 : loss : 0.041405, loss_ce: 0.014099
iteration 2812 : loss : 0.043365, loss_ce: 0.013016
iteration 2813 : loss : 0.044774, loss_ce: 0.019800
iteration 2814 : loss : 0.094060, loss_ce: 0.007394
iteration 2815 : loss : 0.090329, loss_ce: 0.011209
iteration 2816 : loss : 0.081716, loss_ce: 0.015817
iteration 2817 : loss : 0.037312, loss_ce: 0.009165
iteration 2818 : loss : 0.054392, loss_ce: 0.024548
iteration 2819 : loss : 0.049322, loss_ce: 0.017325
iteration 2820 : loss : 0.061914, loss_ce: 0.008123
iteration 2821 : loss : 0.052395, loss_ce: 0.011411
iteration 2822 : loss : 0.049077, loss_ce: 0.016726
iteration 2823 : loss : 0.065419, loss_ce: 0.011833
iteration 2824 : loss : 0.046445, loss_ce: 0.013288
iteration 2825 : loss : 0.041901, loss_ce: 0.011443
iteration 2826 : loss : 0.061840, loss_ce: 0.021604
iteration 2827 : loss : 0.057223, loss_ce: 0.010771
iteration 2828 : loss : 0.051011, loss_ce: 0.019599
iteration 2829 : loss : 0.051031, loss_ce: 0.011672
iteration 2830 : loss : 0.041892, loss_ce: 0.015450
iteration 2831 : loss : 0.062411, loss_ce: 0.025616
iteration 2832 : loss : 0.048039, loss_ce: 0.010776
iteration 2833 : loss : 0.048356, loss_ce: 0.024224
iteration 2834 : loss : 0.049309, loss_ce: 0.016322
iteration 2835 : loss : 0.048118, loss_ce: 0.015877
iteration 2836 : loss : 0.120058, loss_ce: 0.018752
iteration 2837 : loss : 0.035194, loss_ce: 0.012588
iteration 2838 : loss : 0.052139, loss_ce: 0.015202
iteration 2839 : loss : 0.054175, loss_ce: 0.015560
iteration 2840 : loss : 0.042102, loss_ce: 0.019233
iteration 2841 : loss : 0.050261, loss_ce: 0.013138
iteration 2842 : loss : 0.049958, loss_ce: 0.012924
iteration 2843 : loss : 0.052072, loss_ce: 0.019797
iteration 2844 : loss : 0.042911, loss_ce: 0.020580
iteration 2845 : loss : 0.039970, loss_ce: 0.014004
iteration 2846 : loss : 0.131880, loss_ce: 0.013117
iteration 2847 : loss : 0.048955, loss_ce: 0.015642
iteration 2848 : loss : 0.051285, loss_ce: 0.032855
iteration 2849 : loss : 0.049228, loss_ce: 0.012849
iteration 2850 : loss : 0.045500, loss_ce: 0.017717
iteration 2851 : loss : 0.080370, loss_ce: 0.013177
iteration 2852 : loss : 0.047352, loss_ce: 0.013169
iteration 2853 : loss : 0.069851, loss_ce: 0.019375
iteration 2854 : loss : 0.052509, loss_ce: 0.016113
iteration 2855 : loss : 0.100216, loss_ce: 0.011571
iteration 2856 : loss : 0.047834, loss_ce: 0.014497
iteration 2857 : loss : 0.052138, loss_ce: 0.014003
iteration 2858 : loss : 0.041497, loss_ce: 0.015727
iteration 2859 : loss : 0.050223, loss_ce: 0.011255
iteration 2860 : loss : 0.039759, loss_ce: 0.014899
iteration 2861 : loss : 0.037131, loss_ce: 0.016313
iteration 2862 : loss : 0.037133, loss_ce: 0.011645
iteration 2863 : loss : 0.040189, loss_ce: 0.018632
iteration 2864 : loss : 0.046828, loss_ce: 0.017860
iteration 2865 : loss : 0.059089, loss_ce: 0.012938
iteration 2866 : loss : 0.058165, loss_ce: 0.017820
iteration 2867 : loss : 0.091672, loss_ce: 0.015618
iteration 2868 : loss : 0.040502, loss_ce: 0.011022
iteration 2869 : loss : 0.039560, loss_ce: 0.012132
iteration 2870 : loss : 0.050933, loss_ce: 0.021380
iteration 2871 : loss : 0.058922, loss_ce: 0.018443
iteration 2872 : loss : 0.046498, loss_ce: 0.009932
iteration 2873 : loss : 0.046041, loss_ce: 0.012703
iteration 2874 : loss : 0.049055, loss_ce: 0.017011
iteration 2875 : loss : 0.050929, loss_ce: 0.015870
iteration 2876 : loss : 0.052460, loss_ce: 0.021091
iteration 2877 : loss : 0.080788, loss_ce: 0.009836
iteration 2878 : loss : 0.045827, loss_ce: 0.017452
iteration 2879 : loss : 0.054179, loss_ce: 0.017666
iteration 2880 : loss : 0.045194, loss_ce: 0.011490
iteration 2881 : loss : 0.062878, loss_ce: 0.013172
iteration 2882 : loss : 0.043462, loss_ce: 0.017152
iteration 2883 : loss : 0.348388, loss_ce: 0.006529
 16%|████▋                         | 31/200 [31:46<2:53:26, 61.58s/it]iteration 2884 : loss : 0.051126, loss_ce: 0.014876
iteration 2885 : loss : 0.052752, loss_ce: 0.017348
iteration 2886 : loss : 0.037890, loss_ce: 0.015672
iteration 2887 : loss : 0.094081, loss_ce: 0.009950
iteration 2888 : loss : 0.049536, loss_ce: 0.016192
iteration 2889 : loss : 0.048735, loss_ce: 0.016865
iteration 2890 : loss : 0.048614, loss_ce: 0.024539
iteration 2891 : loss : 0.051316, loss_ce: 0.014241
iteration 2892 : loss : 0.039297, loss_ce: 0.011134
iteration 2893 : loss : 0.052636, loss_ce: 0.018566
iteration 2894 : loss : 0.054735, loss_ce: 0.021624
iteration 2895 : loss : 0.041382, loss_ce: 0.014404
iteration 2896 : loss : 0.076409, loss_ce: 0.010469
iteration 2897 : loss : 0.046533, loss_ce: 0.016377
iteration 2898 : loss : 0.044223, loss_ce: 0.015095
iteration 2899 : loss : 0.059778, loss_ce: 0.012696
iteration 2900 : loss : 0.058971, loss_ce: 0.020634
iteration 2901 : loss : 0.053887, loss_ce: 0.013464
iteration 2902 : loss : 0.153888, loss_ce: 0.010021
iteration 2903 : loss : 0.092669, loss_ce: 0.010204
iteration 2904 : loss : 0.046298, loss_ce: 0.014501
iteration 2905 : loss : 0.054089, loss_ce: 0.015776
iteration 2906 : loss : 0.088985, loss_ce: 0.020394
iteration 2907 : loss : 0.060886, loss_ce: 0.013793
iteration 2908 : loss : 0.061299, loss_ce: 0.026454
iteration 2909 : loss : 0.048647, loss_ce: 0.013825
iteration 2910 : loss : 0.061578, loss_ce: 0.020916
iteration 2911 : loss : 0.055808, loss_ce: 0.020344
iteration 2912 : loss : 0.050915, loss_ce: 0.017923
iteration 2913 : loss : 0.077008, loss_ce: 0.018233
iteration 2914 : loss : 0.059142, loss_ce: 0.018452
iteration 2915 : loss : 0.103907, loss_ce: 0.017080
iteration 2916 : loss : 0.049135, loss_ce: 0.018119
iteration 2917 : loss : 0.052733, loss_ce: 0.020243
iteration 2918 : loss : 0.054376, loss_ce: 0.019113
iteration 2919 : loss : 0.043147, loss_ce: 0.011061
iteration 2920 : loss : 0.060979, loss_ce: 0.012015
iteration 2921 : loss : 0.056447, loss_ce: 0.013999
iteration 2922 : loss : 0.064775, loss_ce: 0.012989
iteration 2923 : loss : 0.066083, loss_ce: 0.021868
iteration 2924 : loss : 0.054684, loss_ce: 0.017090
iteration 2925 : loss : 0.047978, loss_ce: 0.012363
iteration 2926 : loss : 0.048795, loss_ce: 0.018249
iteration 2927 : loss : 0.038168, loss_ce: 0.012737
iteration 2928 : loss : 0.092724, loss_ce: 0.019196
iteration 2929 : loss : 0.069678, loss_ce: 0.016417
iteration 2930 : loss : 0.058353, loss_ce: 0.014023
iteration 2931 : loss : 0.052530, loss_ce: 0.026585
iteration 2932 : loss : 0.070303, loss_ce: 0.015146
iteration 2933 : loss : 0.055923, loss_ce: 0.025295
iteration 2934 : loss : 0.057987, loss_ce: 0.022043
iteration 2935 : loss : 0.091909, loss_ce: 0.010822
iteration 2936 : loss : 0.053441, loss_ce: 0.019689
iteration 2937 : loss : 0.047489, loss_ce: 0.017739
iteration 2938 : loss : 0.046964, loss_ce: 0.014906
iteration 2939 : loss : 0.072609, loss_ce: 0.015055
iteration 2940 : loss : 0.040418, loss_ce: 0.011353
iteration 2941 : loss : 0.043709, loss_ce: 0.014948
iteration 2942 : loss : 0.061205, loss_ce: 0.020330
iteration 2943 : loss : 0.046552, loss_ce: 0.010985
iteration 2944 : loss : 0.037967, loss_ce: 0.016420
iteration 2945 : loss : 0.064004, loss_ce: 0.019153
iteration 2946 : loss : 0.042439, loss_ce: 0.015756
iteration 2947 : loss : 0.045931, loss_ce: 0.014250
iteration 2948 : loss : 0.037244, loss_ce: 0.012781
iteration 2949 : loss : 0.044543, loss_ce: 0.016774
iteration 2950 : loss : 0.051506, loss_ce: 0.020998
iteration 2951 : loss : 0.052624, loss_ce: 0.012476
iteration 2952 : loss : 0.057096, loss_ce: 0.007742
iteration 2953 : loss : 0.041795, loss_ce: 0.020319
iteration 2954 : loss : 0.047014, loss_ce: 0.015318
iteration 2955 : loss : 0.051770, loss_ce: 0.015616
iteration 2956 : loss : 0.047475, loss_ce: 0.016660
iteration 2957 : loss : 0.054995, loss_ce: 0.018961
iteration 2958 : loss : 0.047933, loss_ce: 0.016871
iteration 2959 : loss : 0.041015, loss_ce: 0.015305
iteration 2960 : loss : 0.030227, loss_ce: 0.010895
iteration 2961 : loss : 0.046235, loss_ce: 0.011149
iteration 2962 : loss : 0.052186, loss_ce: 0.016224
iteration 2963 : loss : 0.036553, loss_ce: 0.014039
iteration 2964 : loss : 0.041410, loss_ce: 0.011407
iteration 2965 : loss : 0.053454, loss_ce: 0.016025
iteration 2966 : loss : 0.047894, loss_ce: 0.016092
iteration 2967 : loss : 0.036172, loss_ce: 0.010386
iteration 2968 : loss : 0.037198, loss_ce: 0.015662
iteration 2969 : loss : 0.043468, loss_ce: 0.012942
iteration 2970 : loss : 0.046065, loss_ce: 0.013881
iteration 2971 : loss : 0.045343, loss_ce: 0.011320
iteration 2972 : loss : 0.040911, loss_ce: 0.013405
iteration 2973 : loss : 0.064615, loss_ce: 0.020244
iteration 2974 : loss : 0.046110, loss_ce: 0.017229
iteration 2975 : loss : 0.041816, loss_ce: 0.014653
iteration 2976 : loss : 0.238553, loss_ce: 0.014189
 16%|████▊                         | 32/200 [32:47<2:52:28, 61.60s/it]iteration 2977 : loss : 0.052315, loss_ce: 0.012614
iteration 2978 : loss : 0.065253, loss_ce: 0.011883
iteration 2979 : loss : 0.037435, loss_ce: 0.011261
iteration 2980 : loss : 0.039143, loss_ce: 0.011001
iteration 2981 : loss : 0.044361, loss_ce: 0.021928
iteration 2982 : loss : 0.038003, loss_ce: 0.016972
iteration 2983 : loss : 0.042187, loss_ce: 0.012831
iteration 2984 : loss : 0.044599, loss_ce: 0.010308
iteration 2985 : loss : 0.051814, loss_ce: 0.014578
iteration 2986 : loss : 0.036304, loss_ce: 0.011892
iteration 2987 : loss : 0.064613, loss_ce: 0.014747
iteration 2988 : loss : 0.051362, loss_ce: 0.012343
iteration 2989 : loss : 0.048287, loss_ce: 0.011305
iteration 2990 : loss : 0.038202, loss_ce: 0.012262
iteration 2991 : loss : 0.098226, loss_ce: 0.014480
iteration 2992 : loss : 0.042206, loss_ce: 0.015625
iteration 2993 : loss : 0.052809, loss_ce: 0.022317
iteration 2994 : loss : 0.045928, loss_ce: 0.019786
iteration 2995 : loss : 0.039765, loss_ce: 0.012669
iteration 2996 : loss : 0.085651, loss_ce: 0.012619
iteration 2997 : loss : 0.040002, loss_ce: 0.014162
iteration 2998 : loss : 0.044233, loss_ce: 0.016543
iteration 2999 : loss : 0.051454, loss_ce: 0.011925
iteration 3000 : loss : 0.041445, loss_ce: 0.016466
iteration 3001 : loss : 0.039659, loss_ce: 0.012459
iteration 3002 : loss : 0.043378, loss_ce: 0.015251
iteration 3003 : loss : 0.041967, loss_ce: 0.015697
iteration 3004 : loss : 0.054143, loss_ce: 0.014450
iteration 3005 : loss : 0.061028, loss_ce: 0.014794
iteration 3006 : loss : 0.094709, loss_ce: 0.008402
iteration 3007 : loss : 0.043566, loss_ce: 0.017710
iteration 3008 : loss : 0.046060, loss_ce: 0.022863
iteration 3009 : loss : 0.045966, loss_ce: 0.012981
iteration 3010 : loss : 0.045057, loss_ce: 0.017919
iteration 3011 : loss : 0.087686, loss_ce: 0.012546
iteration 3012 : loss : 0.041580, loss_ce: 0.016076
iteration 3013 : loss : 0.039511, loss_ce: 0.017198
iteration 3014 : loss : 0.041575, loss_ce: 0.020803
iteration 3015 : loss : 0.045487, loss_ce: 0.017108
iteration 3016 : loss : 0.052017, loss_ce: 0.020378
iteration 3017 : loss : 0.039411, loss_ce: 0.011797
iteration 3018 : loss : 0.073490, loss_ce: 0.015769
iteration 3019 : loss : 0.051253, loss_ce: 0.015827
iteration 3020 : loss : 0.055505, loss_ce: 0.019742
iteration 3021 : loss : 0.046510, loss_ce: 0.012187
iteration 3022 : loss : 0.060258, loss_ce: 0.019582
iteration 3023 : loss : 0.085426, loss_ce: 0.007132
iteration 3024 : loss : 0.039165, loss_ce: 0.010264
iteration 3025 : loss : 0.051513, loss_ce: 0.025217
iteration 3026 : loss : 0.134490, loss_ce: 0.010535
iteration 3027 : loss : 0.070634, loss_ce: 0.018322
iteration 3028 : loss : 0.053860, loss_ce: 0.014767
iteration 3029 : loss : 0.043582, loss_ce: 0.009755
iteration 3030 : loss : 0.042561, loss_ce: 0.010696
iteration 3031 : loss : 0.057463, loss_ce: 0.018214
iteration 3032 : loss : 0.046064, loss_ce: 0.018980
iteration 3033 : loss : 0.090197, loss_ce: 0.010220
iteration 3034 : loss : 0.066369, loss_ce: 0.011923
iteration 3035 : loss : 0.043226, loss_ce: 0.018063
iteration 3036 : loss : 0.048461, loss_ce: 0.013223
iteration 3037 : loss : 0.050865, loss_ce: 0.012050
iteration 3038 : loss : 0.044047, loss_ce: 0.012307
iteration 3039 : loss : 0.068209, loss_ce: 0.016638
iteration 3040 : loss : 0.045490, loss_ce: 0.010686
iteration 3041 : loss : 0.044873, loss_ce: 0.018927
iteration 3042 : loss : 0.091110, loss_ce: 0.008992
iteration 3043 : loss : 0.035823, loss_ce: 0.012567
iteration 3044 : loss : 0.040554, loss_ce: 0.010900
iteration 3045 : loss : 0.043978, loss_ce: 0.013731
iteration 3046 : loss : 0.089460, loss_ce: 0.013435
iteration 3047 : loss : 0.052800, loss_ce: 0.016536
iteration 3048 : loss : 0.054920, loss_ce: 0.016029
iteration 3049 : loss : 0.064002, loss_ce: 0.012703
iteration 3050 : loss : 0.051444, loss_ce: 0.012158
iteration 3051 : loss : 0.120279, loss_ce: 0.012613
iteration 3052 : loss : 0.041386, loss_ce: 0.013737
iteration 3053 : loss : 0.045132, loss_ce: 0.018058
iteration 3054 : loss : 0.089478, loss_ce: 0.015941
iteration 3055 : loss : 0.088705, loss_ce: 0.011493
iteration 3056 : loss : 0.053762, loss_ce: 0.016458
iteration 3057 : loss : 0.038731, loss_ce: 0.020368
iteration 3058 : loss : 0.062864, loss_ce: 0.014407
iteration 3059 : loss : 0.050149, loss_ce: 0.013972
iteration 3060 : loss : 0.043224, loss_ce: 0.024985
iteration 3061 : loss : 0.041767, loss_ce: 0.016272
iteration 3062 : loss : 0.048003, loss_ce: 0.012695
iteration 3063 : loss : 0.039912, loss_ce: 0.013248
iteration 3064 : loss : 0.045773, loss_ce: 0.015379
iteration 3065 : loss : 0.070175, loss_ce: 0.016873
iteration 3066 : loss : 0.044729, loss_ce: 0.014510
iteration 3067 : loss : 0.045915, loss_ce: 0.014352
iteration 3068 : loss : 0.081598, loss_ce: 0.010230
iteration 3069 : loss : 0.339195, loss_ce: 0.003047
 16%|████▉                         | 33/200 [33:49<2:51:25, 61.59s/it]iteration 3070 : loss : 0.031389, loss_ce: 0.010179
iteration 3071 : loss : 0.047528, loss_ce: 0.015540
iteration 3072 : loss : 0.045599, loss_ce: 0.015595
iteration 3073 : loss : 0.039826, loss_ce: 0.012696
iteration 3074 : loss : 0.045209, loss_ce: 0.019254
iteration 3075 : loss : 0.087922, loss_ce: 0.008448
iteration 3076 : loss : 0.042865, loss_ce: 0.014707
iteration 3077 : loss : 0.034914, loss_ce: 0.013671
iteration 3078 : loss : 0.042199, loss_ce: 0.019227
iteration 3079 : loss : 0.055602, loss_ce: 0.014180
iteration 3080 : loss : 0.038806, loss_ce: 0.011762
iteration 3081 : loss : 0.050365, loss_ce: 0.020550
iteration 3082 : loss : 0.044540, loss_ce: 0.014085
iteration 3083 : loss : 0.054121, loss_ce: 0.012259
iteration 3084 : loss : 0.054166, loss_ce: 0.015709
iteration 3085 : loss : 0.045323, loss_ce: 0.013057
iteration 3086 : loss : 0.035423, loss_ce: 0.013402
iteration 3087 : loss : 0.043725, loss_ce: 0.020235
iteration 3088 : loss : 0.076204, loss_ce: 0.013032
iteration 3089 : loss : 0.040246, loss_ce: 0.008433
iteration 3090 : loss : 0.045511, loss_ce: 0.012833
iteration 3091 : loss : 0.047050, loss_ce: 0.017047
iteration 3092 : loss : 0.043951, loss_ce: 0.018307
iteration 3093 : loss : 0.042469, loss_ce: 0.016908
iteration 3094 : loss : 0.043765, loss_ce: 0.019341
iteration 3095 : loss : 0.088654, loss_ce: 0.013052
iteration 3096 : loss : 0.040559, loss_ce: 0.014393
iteration 3097 : loss : 0.035862, loss_ce: 0.013743
iteration 3098 : loss : 0.079705, loss_ce: 0.007492
iteration 3099 : loss : 0.047294, loss_ce: 0.016906
iteration 3100 : loss : 0.070978, loss_ce: 0.023037
iteration 3101 : loss : 0.097411, loss_ce: 0.014353
iteration 3102 : loss : 0.027730, loss_ce: 0.008647
iteration 3103 : loss : 0.049211, loss_ce: 0.019288
iteration 3104 : loss : 0.046448, loss_ce: 0.021631
iteration 3105 : loss : 0.037688, loss_ce: 0.009876
iteration 3106 : loss : 0.043127, loss_ce: 0.012313
iteration 3107 : loss : 0.046657, loss_ce: 0.018503
iteration 3108 : loss : 0.040093, loss_ce: 0.013357
iteration 3109 : loss : 0.040633, loss_ce: 0.016300
iteration 3110 : loss : 0.048189, loss_ce: 0.018116
iteration 3111 : loss : 0.090433, loss_ce: 0.009991
iteration 3112 : loss : 0.049224, loss_ce: 0.016048
iteration 3113 : loss : 0.047689, loss_ce: 0.015237
iteration 3114 : loss : 0.036490, loss_ce: 0.010858
iteration 3115 : loss : 0.086021, loss_ce: 0.015251
iteration 3116 : loss : 0.030036, loss_ce: 0.009883
iteration 3117 : loss : 0.030737, loss_ce: 0.011775
iteration 3118 : loss : 0.038552, loss_ce: 0.013631
iteration 3119 : loss : 0.037620, loss_ce: 0.011657
iteration 3120 : loss : 0.038256, loss_ce: 0.009957
iteration 3121 : loss : 0.050637, loss_ce: 0.012475
iteration 3122 : loss : 0.037847, loss_ce: 0.008218
iteration 3123 : loss : 0.079192, loss_ce: 0.015552
iteration 3124 : loss : 0.034005, loss_ce: 0.011220
iteration 3125 : loss : 0.065181, loss_ce: 0.011981
iteration 3126 : loss : 0.041227, loss_ce: 0.013567
iteration 3127 : loss : 0.043868, loss_ce: 0.016785
iteration 3128 : loss : 0.058762, loss_ce: 0.017382
iteration 3129 : loss : 0.040110, loss_ce: 0.016587
iteration 3130 : loss : 0.038675, loss_ce: 0.011054
iteration 3131 : loss : 0.052260, loss_ce: 0.021742
iteration 3132 : loss : 0.060430, loss_ce: 0.015958
iteration 3133 : loss : 0.046519, loss_ce: 0.016390
iteration 3134 : loss : 0.041516, loss_ce: 0.018263
iteration 3135 : loss : 0.049723, loss_ce: 0.011446
iteration 3136 : loss : 0.040087, loss_ce: 0.015539
iteration 3137 : loss : 0.064469, loss_ce: 0.010812
iteration 3138 : loss : 0.045492, loss_ce: 0.012374
iteration 3139 : loss : 0.034001, loss_ce: 0.013638
iteration 3140 : loss : 0.047057, loss_ce: 0.018151
iteration 3141 : loss : 0.045691, loss_ce: 0.017705
iteration 3142 : loss : 0.048679, loss_ce: 0.011011
iteration 3143 : loss : 0.046281, loss_ce: 0.022699
iteration 3144 : loss : 0.110859, loss_ce: 0.007077
iteration 3145 : loss : 0.084538, loss_ce: 0.010070
iteration 3146 : loss : 0.042550, loss_ce: 0.014067
iteration 3147 : loss : 0.051361, loss_ce: 0.013343
iteration 3148 : loss : 0.092281, loss_ce: 0.011217
iteration 3149 : loss : 0.049200, loss_ce: 0.016452
iteration 3150 : loss : 0.037462, loss_ce: 0.014252
iteration 3151 : loss : 0.048890, loss_ce: 0.021576
iteration 3152 : loss : 0.043524, loss_ce: 0.006960
iteration 3153 : loss : 0.058366, loss_ce: 0.013803
iteration 3154 : loss : 0.058539, loss_ce: 0.007498
iteration 3155 : loss : 0.066150, loss_ce: 0.013189
iteration 3156 : loss : 0.047315, loss_ce: 0.015312
iteration 3157 : loss : 0.043090, loss_ce: 0.017116
iteration 3158 : loss : 0.048064, loss_ce: 0.013725
iteration 3159 : loss : 0.088909, loss_ce: 0.012183
iteration 3160 : loss : 0.043702, loss_ce: 0.013879
iteration 3161 : loss : 0.031696, loss_ce: 0.010665
iteration 3162 : loss : 0.256295, loss_ce: 0.033829
 17%|█████                         | 34/200 [34:51<2:50:31, 61.64s/it]iteration 3163 : loss : 0.041018, loss_ce: 0.012910
iteration 3164 : loss : 0.038925, loss_ce: 0.017688
iteration 3165 : loss : 0.039343, loss_ce: 0.014526
iteration 3166 : loss : 0.047619, loss_ce: 0.013749
iteration 3167 : loss : 0.039400, loss_ce: 0.012506
iteration 3168 : loss : 0.043930, loss_ce: 0.015221
iteration 3169 : loss : 0.039197, loss_ce: 0.014902
iteration 3170 : loss : 0.061215, loss_ce: 0.011790
iteration 3171 : loss : 0.039194, loss_ce: 0.010654
iteration 3172 : loss : 0.033999, loss_ce: 0.010347
iteration 3173 : loss : 0.033509, loss_ce: 0.010456
iteration 3174 : loss : 0.038107, loss_ce: 0.013471
iteration 3175 : loss : 0.047903, loss_ce: 0.008266
iteration 3176 : loss : 0.055206, loss_ce: 0.015111
iteration 3177 : loss : 0.046969, loss_ce: 0.013730
iteration 3178 : loss : 0.054489, loss_ce: 0.015079
iteration 3179 : loss : 0.041606, loss_ce: 0.013489
iteration 3180 : loss : 0.051853, loss_ce: 0.015824
iteration 3181 : loss : 0.040186, loss_ce: 0.012238
iteration 3182 : loss : 0.039041, loss_ce: 0.008249
iteration 3183 : loss : 0.045380, loss_ce: 0.014407
iteration 3184 : loss : 0.039527, loss_ce: 0.013826
iteration 3185 : loss : 0.050760, loss_ce: 0.014760
iteration 3186 : loss : 0.038602, loss_ce: 0.016384
iteration 3187 : loss : 0.036350, loss_ce: 0.013368
iteration 3188 : loss : 0.036180, loss_ce: 0.014517
iteration 3189 : loss : 0.044852, loss_ce: 0.016324
iteration 3190 : loss : 0.047718, loss_ce: 0.025236
iteration 3191 : loss : 0.041993, loss_ce: 0.020565
iteration 3192 : loss : 0.044821, loss_ce: 0.019247
iteration 3193 : loss : 0.054272, loss_ce: 0.013879
iteration 3194 : loss : 0.034604, loss_ce: 0.011647
iteration 3195 : loss : 0.039029, loss_ce: 0.012779
iteration 3196 : loss : 0.043202, loss_ce: 0.013106
iteration 3197 : loss : 0.033452, loss_ce: 0.010224
iteration 3198 : loss : 0.046946, loss_ce: 0.016007
iteration 3199 : loss : 0.060050, loss_ce: 0.018644
iteration 3200 : loss : 0.041636, loss_ce: 0.019478
iteration 3201 : loss : 0.059810, loss_ce: 0.017236
iteration 3202 : loss : 0.039779, loss_ce: 0.011918
iteration 3203 : loss : 0.045665, loss_ce: 0.013120
iteration 3204 : loss : 0.038786, loss_ce: 0.019180
iteration 3205 : loss : 0.046969, loss_ce: 0.014022
iteration 3206 : loss : 0.040791, loss_ce: 0.021515
iteration 3207 : loss : 0.052284, loss_ce: 0.010541
iteration 3208 : loss : 0.033778, loss_ce: 0.007100
iteration 3209 : loss : 0.034977, loss_ce: 0.012429
iteration 3210 : loss : 0.030861, loss_ce: 0.009755
iteration 3211 : loss : 0.085034, loss_ce: 0.012298
iteration 3212 : loss : 0.036021, loss_ce: 0.010591
iteration 3213 : loss : 0.045255, loss_ce: 0.013524
iteration 3214 : loss : 0.048391, loss_ce: 0.012286
iteration 3215 : loss : 0.079392, loss_ce: 0.016257
iteration 3216 : loss : 0.040613, loss_ce: 0.014513
iteration 3217 : loss : 0.030643, loss_ce: 0.010444
iteration 3218 : loss : 0.091671, loss_ce: 0.016380
iteration 3219 : loss : 0.049102, loss_ce: 0.018772
iteration 3220 : loss : 0.064941, loss_ce: 0.010105
iteration 3221 : loss : 0.048405, loss_ce: 0.008544
iteration 3222 : loss : 0.055923, loss_ce: 0.008240
iteration 3223 : loss : 0.046361, loss_ce: 0.012776
iteration 3224 : loss : 0.042494, loss_ce: 0.013086
iteration 3225 : loss : 0.045383, loss_ce: 0.013646
iteration 3226 : loss : 0.055397, loss_ce: 0.023150
iteration 3227 : loss : 0.065177, loss_ce: 0.023368
iteration 3228 : loss : 0.061477, loss_ce: 0.011763
iteration 3229 : loss : 0.050718, loss_ce: 0.019103
iteration 3230 : loss : 0.099803, loss_ce: 0.009904
iteration 3231 : loss : 0.040847, loss_ce: 0.014021
iteration 3232 : loss : 0.037923, loss_ce: 0.010329
iteration 3233 : loss : 0.046182, loss_ce: 0.012758
iteration 3234 : loss : 0.055473, loss_ce: 0.015585
iteration 3235 : loss : 0.054569, loss_ce: 0.017470
iteration 3236 : loss : 0.041337, loss_ce: 0.019731
iteration 3237 : loss : 0.053177, loss_ce: 0.010547
iteration 3238 : loss : 0.042689, loss_ce: 0.017200
iteration 3239 : loss : 0.044900, loss_ce: 0.020020
iteration 3240 : loss : 0.046429, loss_ce: 0.020337
iteration 3241 : loss : 0.036103, loss_ce: 0.014465
iteration 3242 : loss : 0.087592, loss_ce: 0.009262
iteration 3243 : loss : 0.056022, loss_ce: 0.019374
iteration 3244 : loss : 0.036817, loss_ce: 0.014402
iteration 3245 : loss : 0.088411, loss_ce: 0.009130
iteration 3246 : loss : 0.049066, loss_ce: 0.017821
iteration 3247 : loss : 0.038175, loss_ce: 0.010975
iteration 3248 : loss : 0.061563, loss_ce: 0.011588
iteration 3249 : loss : 0.045291, loss_ce: 0.018488
iteration 3250 : loss : 0.046526, loss_ce: 0.008767
iteration 3251 : loss : 0.043452, loss_ce: 0.014639
iteration 3252 : loss : 0.040244, loss_ce: 0.016166
iteration 3253 : loss : 0.048395, loss_ce: 0.012031
iteration 3254 : loss : 0.049343, loss_ce: 0.010747
iteration 3255 : loss : 0.236728, loss_ce: 0.011668
 18%|█████▎                        | 35/200 [35:52<2:49:28, 61.63s/it]iteration 3256 : loss : 0.031560, loss_ce: 0.009790
iteration 3257 : loss : 0.134738, loss_ce: 0.009583
iteration 3258 : loss : 0.046734, loss_ce: 0.015898
iteration 3259 : loss : 0.092338, loss_ce: 0.009241
iteration 3260 : loss : 0.048245, loss_ce: 0.012907
iteration 3261 : loss : 0.052802, loss_ce: 0.016346
iteration 3262 : loss : 0.065951, loss_ce: 0.017312
iteration 3263 : loss : 0.035602, loss_ce: 0.010924
iteration 3264 : loss : 0.042421, loss_ce: 0.011869
iteration 3265 : loss : 0.043393, loss_ce: 0.017026
iteration 3266 : loss : 0.037594, loss_ce: 0.010429
iteration 3267 : loss : 0.035776, loss_ce: 0.009432
iteration 3268 : loss : 0.051380, loss_ce: 0.013508
iteration 3269 : loss : 0.036607, loss_ce: 0.012148
iteration 3270 : loss : 0.040692, loss_ce: 0.016357
iteration 3271 : loss : 0.042462, loss_ce: 0.009768
iteration 3272 : loss : 0.056635, loss_ce: 0.016785
iteration 3273 : loss : 0.043578, loss_ce: 0.017248
iteration 3274 : loss : 0.038437, loss_ce: 0.015975
iteration 3275 : loss : 0.035884, loss_ce: 0.013174
iteration 3276 : loss : 0.036297, loss_ce: 0.014443
iteration 3277 : loss : 0.043841, loss_ce: 0.013889
iteration 3278 : loss : 0.050463, loss_ce: 0.017842
iteration 3279 : loss : 0.047625, loss_ce: 0.014546
iteration 3280 : loss : 0.053944, loss_ce: 0.017871
iteration 3281 : loss : 0.033584, loss_ce: 0.012218
iteration 3282 : loss : 0.052030, loss_ce: 0.015650
iteration 3283 : loss : 0.043431, loss_ce: 0.016436
iteration 3284 : loss : 0.040475, loss_ce: 0.007200
iteration 3285 : loss : 0.039752, loss_ce: 0.013979
iteration 3286 : loss : 0.043613, loss_ce: 0.014756
iteration 3287 : loss : 0.039231, loss_ce: 0.016389
iteration 3288 : loss : 0.052421, loss_ce: 0.013032
iteration 3289 : loss : 0.045762, loss_ce: 0.016765
iteration 3290 : loss : 0.046262, loss_ce: 0.008515
iteration 3291 : loss : 0.047195, loss_ce: 0.017979
iteration 3292 : loss : 0.032791, loss_ce: 0.010439
iteration 3293 : loss : 0.074757, loss_ce: 0.010999
iteration 3294 : loss : 0.054324, loss_ce: 0.019304
iteration 3295 : loss : 0.034750, loss_ce: 0.012275
iteration 3296 : loss : 0.044459, loss_ce: 0.014999
iteration 3297 : loss : 0.040215, loss_ce: 0.007807
iteration 3298 : loss : 0.048201, loss_ce: 0.013589
iteration 3299 : loss : 0.034035, loss_ce: 0.016021
iteration 3300 : loss : 0.043265, loss_ce: 0.014572
iteration 3301 : loss : 0.042692, loss_ce: 0.013050
iteration 3302 : loss : 0.046485, loss_ce: 0.022489
iteration 3303 : loss : 0.086176, loss_ce: 0.009907
iteration 3304 : loss : 0.075266, loss_ce: 0.016921
iteration 3305 : loss : 0.036581, loss_ce: 0.013756
iteration 3306 : loss : 0.050783, loss_ce: 0.017458
iteration 3307 : loss : 0.038462, loss_ce: 0.015565
iteration 3308 : loss : 0.033158, loss_ce: 0.010900
iteration 3309 : loss : 0.047253, loss_ce: 0.011759
iteration 3310 : loss : 0.037463, loss_ce: 0.014075
iteration 3311 : loss : 0.032040, loss_ce: 0.008989
iteration 3312 : loss : 0.032766, loss_ce: 0.007747
iteration 3313 : loss : 0.052902, loss_ce: 0.013486
iteration 3314 : loss : 0.048942, loss_ce: 0.018271
iteration 3315 : loss : 0.052489, loss_ce: 0.019038
iteration 3316 : loss : 0.182946, loss_ce: 0.005223
iteration 3317 : loss : 0.091217, loss_ce: 0.013182
iteration 3318 : loss : 0.048695, loss_ce: 0.012886
iteration 3319 : loss : 0.051827, loss_ce: 0.025593
iteration 3320 : loss : 0.049794, loss_ce: 0.024311
iteration 3321 : loss : 0.054654, loss_ce: 0.017077
iteration 3322 : loss : 0.038565, loss_ce: 0.020748
iteration 3323 : loss : 0.042670, loss_ce: 0.012205
iteration 3324 : loss : 0.046990, loss_ce: 0.013759
iteration 3325 : loss : 0.039248, loss_ce: 0.015531
iteration 3326 : loss : 0.040040, loss_ce: 0.016641
iteration 3327 : loss : 0.064413, loss_ce: 0.015764
iteration 3328 : loss : 0.035283, loss_ce: 0.014034
iteration 3329 : loss : 0.043357, loss_ce: 0.012766
iteration 3330 : loss : 0.045468, loss_ce: 0.010768
iteration 3331 : loss : 0.042778, loss_ce: 0.007339
iteration 3332 : loss : 0.042932, loss_ce: 0.020444
iteration 3333 : loss : 0.046942, loss_ce: 0.012433
iteration 3334 : loss : 0.054505, loss_ce: 0.018276
iteration 3335 : loss : 0.040313, loss_ce: 0.016180
iteration 3336 : loss : 0.034837, loss_ce: 0.010512
iteration 3337 : loss : 0.043909, loss_ce: 0.015529
iteration 3338 : loss : 0.134819, loss_ce: 0.003651
iteration 3339 : loss : 0.047998, loss_ce: 0.015109
iteration 3340 : loss : 0.067322, loss_ce: 0.011746
iteration 3341 : loss : 0.039404, loss_ce: 0.018900
iteration 3342 : loss : 0.039648, loss_ce: 0.016688
iteration 3343 : loss : 0.057222, loss_ce: 0.016913
iteration 3344 : loss : 0.038427, loss_ce: 0.013800
iteration 3345 : loss : 0.087768, loss_ce: 0.005781
iteration 3346 : loss : 0.039162, loss_ce: 0.007474
iteration 3347 : loss : 0.034834, loss_ce: 0.013987
iteration 3348 : loss : 0.251542, loss_ce: 0.037505
 18%|█████▍                        | 36/200 [36:54<2:48:27, 61.63s/it]iteration 3349 : loss : 0.037512, loss_ce: 0.011777
iteration 3350 : loss : 0.041085, loss_ce: 0.015978
iteration 3351 : loss : 0.041327, loss_ce: 0.014224
iteration 3352 : loss : 0.039437, loss_ce: 0.021101
iteration 3353 : loss : 0.063887, loss_ce: 0.015399
iteration 3354 : loss : 0.056617, loss_ce: 0.026014
iteration 3355 : loss : 0.048643, loss_ce: 0.012999
iteration 3356 : loss : 0.032075, loss_ce: 0.010472
iteration 3357 : loss : 0.093207, loss_ce: 0.012280
iteration 3358 : loss : 0.049247, loss_ce: 0.017372
iteration 3359 : loss : 0.049036, loss_ce: 0.017156
iteration 3360 : loss : 0.040946, loss_ce: 0.010588
iteration 3361 : loss : 0.085377, loss_ce: 0.009479
iteration 3362 : loss : 0.041451, loss_ce: 0.013754
iteration 3363 : loss : 0.036253, loss_ce: 0.011383
iteration 3364 : loss : 0.089635, loss_ce: 0.013795
iteration 3365 : loss : 0.047165, loss_ce: 0.013250
iteration 3366 : loss : 0.048803, loss_ce: 0.012686
iteration 3367 : loss : 0.038558, loss_ce: 0.010259
iteration 3368 : loss : 0.038134, loss_ce: 0.011243
iteration 3369 : loss : 0.088736, loss_ce: 0.010297
iteration 3370 : loss : 0.040022, loss_ce: 0.011552
iteration 3371 : loss : 0.045847, loss_ce: 0.012325
iteration 3372 : loss : 0.041194, loss_ce: 0.013899
iteration 3373 : loss : 0.036063, loss_ce: 0.016511
iteration 3374 : loss : 0.040368, loss_ce: 0.015591
iteration 3375 : loss : 0.045652, loss_ce: 0.021682
iteration 3376 : loss : 0.043997, loss_ce: 0.013848
iteration 3377 : loss : 0.038965, loss_ce: 0.008288
iteration 3378 : loss : 0.086340, loss_ce: 0.007367
iteration 3379 : loss : 0.036151, loss_ce: 0.013620
iteration 3380 : loss : 0.040026, loss_ce: 0.009652
iteration 3381 : loss : 0.061160, loss_ce: 0.014819
iteration 3382 : loss : 0.129827, loss_ce: 0.006607
iteration 3383 : loss : 0.047370, loss_ce: 0.019615
iteration 3384 : loss : 0.041856, loss_ce: 0.018102
iteration 3385 : loss : 0.042665, loss_ce: 0.016265
iteration 3386 : loss : 0.054082, loss_ce: 0.017909
iteration 3387 : loss : 0.090700, loss_ce: 0.014457
iteration 3388 : loss : 0.045690, loss_ce: 0.016111
iteration 3389 : loss : 0.034946, loss_ce: 0.005682
iteration 3390 : loss : 0.044466, loss_ce: 0.017592
iteration 3391 : loss : 0.038802, loss_ce: 0.017782
iteration 3392 : loss : 0.046443, loss_ce: 0.019632
iteration 3393 : loss : 0.053135, loss_ce: 0.019453
iteration 3394 : loss : 0.045988, loss_ce: 0.019220
iteration 3395 : loss : 0.035155, loss_ce: 0.014303
iteration 3396 : loss : 0.041580, loss_ce: 0.016121
iteration 3397 : loss : 0.060623, loss_ce: 0.016999
iteration 3398 : loss : 0.040670, loss_ce: 0.012088
iteration 3399 : loss : 0.038796, loss_ce: 0.015944
iteration 3400 : loss : 0.047844, loss_ce: 0.017567
iteration 3401 : loss : 0.039827, loss_ce: 0.016354
iteration 3402 : loss : 0.040661, loss_ce: 0.011801
iteration 3403 : loss : 0.040497, loss_ce: 0.015192
iteration 3404 : loss : 0.041784, loss_ce: 0.021458
iteration 3405 : loss : 0.092193, loss_ce: 0.012755
iteration 3406 : loss : 0.044672, loss_ce: 0.009321
iteration 3407 : loss : 0.044932, loss_ce: 0.012998
iteration 3408 : loss : 0.058047, loss_ce: 0.020230
iteration 3409 : loss : 0.051360, loss_ce: 0.021110
iteration 3410 : loss : 0.042195, loss_ce: 0.012530
iteration 3411 : loss : 0.033219, loss_ce: 0.013525
iteration 3412 : loss : 0.039988, loss_ce: 0.010690
iteration 3413 : loss : 0.034985, loss_ce: 0.012405
iteration 3414 : loss : 0.043684, loss_ce: 0.008914
iteration 3415 : loss : 0.045940, loss_ce: 0.018631
iteration 3416 : loss : 0.041031, loss_ce: 0.017677
iteration 3417 : loss : 0.034594, loss_ce: 0.015182
iteration 3418 : loss : 0.062215, loss_ce: 0.012861
iteration 3419 : loss : 0.097545, loss_ce: 0.009917
iteration 3420 : loss : 0.040602, loss_ce: 0.018198
iteration 3421 : loss : 0.038399, loss_ce: 0.013444
iteration 3422 : loss : 0.033893, loss_ce: 0.011032
iteration 3423 : loss : 0.054423, loss_ce: 0.017937
iteration 3424 : loss : 0.045492, loss_ce: 0.014202
iteration 3425 : loss : 0.048673, loss_ce: 0.014156
iteration 3426 : loss : 0.068059, loss_ce: 0.010720
iteration 3427 : loss : 0.040718, loss_ce: 0.012857
iteration 3428 : loss : 0.040375, loss_ce: 0.013203
iteration 3429 : loss : 0.045751, loss_ce: 0.018472
iteration 3430 : loss : 0.055424, loss_ce: 0.019440
iteration 3431 : loss : 0.088302, loss_ce: 0.010489
iteration 3432 : loss : 0.046395, loss_ce: 0.015666
iteration 3433 : loss : 0.040798, loss_ce: 0.017548
iteration 3434 : loss : 0.048676, loss_ce: 0.019475
iteration 3435 : loss : 0.043223, loss_ce: 0.012207
iteration 3436 : loss : 0.041470, loss_ce: 0.010358
iteration 3437 : loss : 0.044442, loss_ce: 0.014927
iteration 3438 : loss : 0.052574, loss_ce: 0.024325
iteration 3439 : loss : 0.043194, loss_ce: 0.016818
iteration 3440 : loss : 0.044382, loss_ce: 0.017050
iteration 3441 : loss : 0.122355, loss_ce: 0.014741
 18%|█████▌                        | 37/200 [37:56<2:47:24, 61.62s/it]iteration 3442 : loss : 0.108404, loss_ce: 0.009555
iteration 3443 : loss : 0.055191, loss_ce: 0.014673
iteration 3444 : loss : 0.041657, loss_ce: 0.021045
iteration 3445 : loss : 0.094931, loss_ce: 0.014428
iteration 3446 : loss : 0.052206, loss_ce: 0.020668
iteration 3447 : loss : 0.048553, loss_ce: 0.017350
iteration 3448 : loss : 0.048666, loss_ce: 0.012526
iteration 3449 : loss : 0.090669, loss_ce: 0.014703
iteration 3450 : loss : 0.042877, loss_ce: 0.016458
iteration 3451 : loss : 0.038136, loss_ce: 0.010686
iteration 3452 : loss : 0.040604, loss_ce: 0.014161
iteration 3453 : loss : 0.048149, loss_ce: 0.021978
iteration 3454 : loss : 0.037614, loss_ce: 0.014827
iteration 3455 : loss : 0.033781, loss_ce: 0.009563
iteration 3456 : loss : 0.038761, loss_ce: 0.015979
iteration 3457 : loss : 0.048171, loss_ce: 0.019345
iteration 3458 : loss : 0.042171, loss_ce: 0.017351
iteration 3459 : loss : 0.054215, loss_ce: 0.011917
iteration 3460 : loss : 0.039657, loss_ce: 0.011794
iteration 3461 : loss : 0.043786, loss_ce: 0.012994
iteration 3462 : loss : 0.096685, loss_ce: 0.014106
iteration 3463 : loss : 0.039479, loss_ce: 0.005526
iteration 3464 : loss : 0.041582, loss_ce: 0.013364
iteration 3465 : loss : 0.044992, loss_ce: 0.022542
iteration 3466 : loss : 0.056988, loss_ce: 0.019417
iteration 3467 : loss : 0.038634, loss_ce: 0.014304
iteration 3468 : loss : 0.044068, loss_ce: 0.012809
iteration 3469 : loss : 0.035119, loss_ce: 0.015572
iteration 3470 : loss : 0.047553, loss_ce: 0.017924
iteration 3471 : loss : 0.047465, loss_ce: 0.008865
iteration 3472 : loss : 0.053237, loss_ce: 0.032364
iteration 3473 : loss : 0.043881, loss_ce: 0.015348
iteration 3474 : loss : 0.037828, loss_ce: 0.013321
iteration 3475 : loss : 0.054204, loss_ce: 0.019056
iteration 3476 : loss : 0.048122, loss_ce: 0.016677
iteration 3477 : loss : 0.050120, loss_ce: 0.017719
iteration 3478 : loss : 0.038550, loss_ce: 0.014972
iteration 3479 : loss : 0.040217, loss_ce: 0.010741
iteration 3480 : loss : 0.050190, loss_ce: 0.012351
iteration 3481 : loss : 0.046297, loss_ce: 0.007587
iteration 3482 : loss : 0.038682, loss_ce: 0.012528
iteration 3483 : loss : 0.047437, loss_ce: 0.016309
iteration 3484 : loss : 0.054134, loss_ce: 0.021896
iteration 3485 : loss : 0.032247, loss_ce: 0.008312
iteration 3486 : loss : 0.047425, loss_ce: 0.015528
iteration 3487 : loss : 0.083106, loss_ce: 0.006543
iteration 3488 : loss : 0.097851, loss_ce: 0.006976
iteration 3489 : loss : 0.051313, loss_ce: 0.009566
iteration 3490 : loss : 0.040449, loss_ce: 0.015574
iteration 3491 : loss : 0.043770, loss_ce: 0.012277
iteration 3492 : loss : 0.046705, loss_ce: 0.007435
iteration 3493 : loss : 0.040021, loss_ce: 0.015215
iteration 3494 : loss : 0.041941, loss_ce: 0.014797
iteration 3495 : loss : 0.041746, loss_ce: 0.013376
iteration 3496 : loss : 0.047162, loss_ce: 0.011153
iteration 3497 : loss : 0.046408, loss_ce: 0.016581
iteration 3498 : loss : 0.057296, loss_ce: 0.013522
iteration 3499 : loss : 0.059853, loss_ce: 0.015197
iteration 3500 : loss : 0.123148, loss_ce: 0.008240
iteration 3501 : loss : 0.027888, loss_ce: 0.008514
iteration 3502 : loss : 0.090307, loss_ce: 0.009889
iteration 3503 : loss : 0.044084, loss_ce: 0.016974
iteration 3504 : loss : 0.037687, loss_ce: 0.009426
iteration 3505 : loss : 0.039752, loss_ce: 0.014110
iteration 3506 : loss : 0.049758, loss_ce: 0.017157
iteration 3507 : loss : 0.041365, loss_ce: 0.008314
iteration 3508 : loss : 0.048985, loss_ce: 0.022209
iteration 3509 : loss : 0.041905, loss_ce: 0.012792
iteration 3510 : loss : 0.041978, loss_ce: 0.013612
iteration 3511 : loss : 0.045598, loss_ce: 0.012987
iteration 3512 : loss : 0.040589, loss_ce: 0.015071
iteration 3513 : loss : 0.039914, loss_ce: 0.016535
iteration 3514 : loss : 0.045767, loss_ce: 0.013385
iteration 3515 : loss : 0.094618, loss_ce: 0.011539
iteration 3516 : loss : 0.037501, loss_ce: 0.014674
iteration 3517 : loss : 0.105499, loss_ce: 0.009081
iteration 3518 : loss : 0.050952, loss_ce: 0.013320
iteration 3519 : loss : 0.090155, loss_ce: 0.019262
iteration 3520 : loss : 0.071391, loss_ce: 0.010582
iteration 3521 : loss : 0.039907, loss_ce: 0.012215
iteration 3522 : loss : 0.048818, loss_ce: 0.020386
iteration 3523 : loss : 0.051438, loss_ce: 0.023890
iteration 3524 : loss : 0.054963, loss_ce: 0.017189
iteration 3525 : loss : 0.051039, loss_ce: 0.014743
iteration 3526 : loss : 0.039029, loss_ce: 0.019159
iteration 3527 : loss : 0.037132, loss_ce: 0.014268
iteration 3528 : loss : 0.037343, loss_ce: 0.017948
iteration 3529 : loss : 0.034662, loss_ce: 0.012150
iteration 3530 : loss : 0.047216, loss_ce: 0.022773
iteration 3531 : loss : 0.041602, loss_ce: 0.014988
iteration 3532 : loss : 0.058744, loss_ce: 0.014666
iteration 3533 : loss : 0.041101, loss_ce: 0.013430
iteration 3534 : loss : 0.240003, loss_ce: 0.013174
 19%|█████▋                        | 38/200 [38:57<2:46:25, 61.64s/it]iteration 3535 : loss : 0.037884, loss_ce: 0.010380
iteration 3536 : loss : 0.056354, loss_ce: 0.016579
iteration 3537 : loss : 0.047257, loss_ce: 0.020225
iteration 3538 : loss : 0.040116, loss_ce: 0.013543
iteration 3539 : loss : 0.100149, loss_ce: 0.011982
iteration 3540 : loss : 0.043286, loss_ce: 0.014244
iteration 3541 : loss : 0.036811, loss_ce: 0.010497
iteration 3542 : loss : 0.046491, loss_ce: 0.016102
iteration 3543 : loss : 0.041891, loss_ce: 0.017116
iteration 3544 : loss : 0.037427, loss_ce: 0.011544
iteration 3545 : loss : 0.087246, loss_ce: 0.008751
iteration 3546 : loss : 0.059967, loss_ce: 0.015183
iteration 3547 : loss : 0.047989, loss_ce: 0.023625
iteration 3548 : loss : 0.039418, loss_ce: 0.016282
iteration 3549 : loss : 0.042136, loss_ce: 0.017393
iteration 3550 : loss : 0.034126, loss_ce: 0.011271
iteration 3551 : loss : 0.052270, loss_ce: 0.020760
iteration 3552 : loss : 0.039726, loss_ce: 0.016200
iteration 3553 : loss : 0.040388, loss_ce: 0.017158
iteration 3554 : loss : 0.035237, loss_ce: 0.008467
iteration 3555 : loss : 0.061500, loss_ce: 0.010290
iteration 3556 : loss : 0.044615, loss_ce: 0.010587
iteration 3557 : loss : 0.099667, loss_ce: 0.009460
iteration 3558 : loss : 0.040022, loss_ce: 0.015827
iteration 3559 : loss : 0.055417, loss_ce: 0.015294
iteration 3560 : loss : 0.030909, loss_ce: 0.013414
iteration 3561 : loss : 0.041190, loss_ce: 0.013381
iteration 3562 : loss : 0.051293, loss_ce: 0.023143
iteration 3563 : loss : 0.039596, loss_ce: 0.016091
iteration 3564 : loss : 0.051766, loss_ce: 0.013425
iteration 3565 : loss : 0.091139, loss_ce: 0.008067
iteration 3566 : loss : 0.044937, loss_ce: 0.014401
iteration 3567 : loss : 0.091719, loss_ce: 0.009959
iteration 3568 : loss : 0.078411, loss_ce: 0.014740
iteration 3569 : loss : 0.057235, loss_ce: 0.016366
iteration 3570 : loss : 0.065178, loss_ce: 0.016909
iteration 3571 : loss : 0.046597, loss_ce: 0.018302
iteration 3572 : loss : 0.045812, loss_ce: 0.012771
iteration 3573 : loss : 0.049858, loss_ce: 0.026041
iteration 3574 : loss : 0.037431, loss_ce: 0.011292
iteration 3575 : loss : 0.065960, loss_ce: 0.020189
iteration 3576 : loss : 0.061878, loss_ce: 0.017389
iteration 3577 : loss : 0.051591, loss_ce: 0.016815
iteration 3578 : loss : 0.104052, loss_ce: 0.007461
iteration 3579 : loss : 0.058105, loss_ce: 0.006039
iteration 3580 : loss : 0.086361, loss_ce: 0.010912
iteration 3581 : loss : 0.043628, loss_ce: 0.015077
iteration 3582 : loss : 0.040222, loss_ce: 0.013497
iteration 3583 : loss : 0.037815, loss_ce: 0.017598
iteration 3584 : loss : 0.048618, loss_ce: 0.016071
iteration 3585 : loss : 0.050444, loss_ce: 0.019832
iteration 3586 : loss : 0.038404, loss_ce: 0.009960
iteration 3587 : loss : 0.042753, loss_ce: 0.014465
iteration 3588 : loss : 0.042792, loss_ce: 0.014011
iteration 3589 : loss : 0.035313, loss_ce: 0.010699
iteration 3590 : loss : 0.049103, loss_ce: 0.014454
iteration 3591 : loss : 0.055436, loss_ce: 0.013111
iteration 3592 : loss : 0.109207, loss_ce: 0.008242
iteration 3593 : loss : 0.093203, loss_ce: 0.014475
iteration 3594 : loss : 0.042310, loss_ce: 0.019135
iteration 3595 : loss : 0.042873, loss_ce: 0.013902
iteration 3596 : loss : 0.049006, loss_ce: 0.019483
iteration 3597 : loss : 0.067227, loss_ce: 0.017571
iteration 3598 : loss : 0.057343, loss_ce: 0.023966
iteration 3599 : loss : 0.051266, loss_ce: 0.016575
iteration 3600 : loss : 0.055748, loss_ce: 0.018351
iteration 3601 : loss : 0.043656, loss_ce: 0.015354
iteration 3602 : loss : 0.064292, loss_ce: 0.014522
iteration 3603 : loss : 0.040593, loss_ce: 0.009226
iteration 3604 : loss : 0.043387, loss_ce: 0.013917
iteration 3605 : loss : 0.034617, loss_ce: 0.007405
iteration 3606 : loss : 0.041807, loss_ce: 0.018115
iteration 3607 : loss : 0.040159, loss_ce: 0.017051
iteration 3608 : loss : 0.039702, loss_ce: 0.009092
iteration 3609 : loss : 0.044387, loss_ce: 0.016888
iteration 3610 : loss : 0.047362, loss_ce: 0.015775
iteration 3611 : loss : 0.039268, loss_ce: 0.012883
iteration 3612 : loss : 0.037116, loss_ce: 0.013159
iteration 3613 : loss : 0.043107, loss_ce: 0.013386
iteration 3614 : loss : 0.046736, loss_ce: 0.013994
iteration 3615 : loss : 0.045377, loss_ce: 0.009954
iteration 3616 : loss : 0.052097, loss_ce: 0.015032
iteration 3617 : loss : 0.087994, loss_ce: 0.013539
iteration 3618 : loss : 0.054645, loss_ce: 0.013317
iteration 3619 : loss : 0.034881, loss_ce: 0.013155
iteration 3620 : loss : 0.051564, loss_ce: 0.010994
iteration 3621 : loss : 0.050055, loss_ce: 0.015495
iteration 3622 : loss : 0.033616, loss_ce: 0.012956
iteration 3623 : loss : 0.050537, loss_ce: 0.015856
iteration 3624 : loss : 0.053885, loss_ce: 0.019003
iteration 3625 : loss : 0.053171, loss_ce: 0.015772
iteration 3626 : loss : 0.044860, loss_ce: 0.017366
iteration 3627 : loss : 0.445410, loss_ce: 0.002078
 20%|█████▊                        | 39/200 [39:59<2:45:22, 61.63s/it]iteration 3628 : loss : 0.038238, loss_ce: 0.012386
iteration 3629 : loss : 0.091789, loss_ce: 0.010256
iteration 3630 : loss : 0.041234, loss_ce: 0.016482
iteration 3631 : loss : 0.047584, loss_ce: 0.012830
iteration 3632 : loss : 0.045408, loss_ce: 0.018808
iteration 3633 : loss : 0.047807, loss_ce: 0.016718
iteration 3634 : loss : 0.054746, loss_ce: 0.018023
iteration 3635 : loss : 0.052703, loss_ce: 0.013731
iteration 3636 : loss : 0.036303, loss_ce: 0.013606
iteration 3637 : loss : 0.044457, loss_ce: 0.020473
iteration 3638 : loss : 0.045495, loss_ce: 0.017808
iteration 3639 : loss : 0.049382, loss_ce: 0.018622
iteration 3640 : loss : 0.089014, loss_ce: 0.010869
iteration 3641 : loss : 0.027657, loss_ce: 0.010171
iteration 3642 : loss : 0.045509, loss_ce: 0.008556
iteration 3643 : loss : 0.040073, loss_ce: 0.019689
iteration 3644 : loss : 0.040268, loss_ce: 0.015438
iteration 3645 : loss : 0.044369, loss_ce: 0.017004
iteration 3646 : loss : 0.040283, loss_ce: 0.009030
iteration 3647 : loss : 0.033894, loss_ce: 0.010676
iteration 3648 : loss : 0.035898, loss_ce: 0.007277
iteration 3649 : loss : 0.043299, loss_ce: 0.012706
iteration 3650 : loss : 0.039361, loss_ce: 0.012801
iteration 3651 : loss : 0.037107, loss_ce: 0.014403
iteration 3652 : loss : 0.083522, loss_ce: 0.007056
iteration 3653 : loss : 0.041496, loss_ce: 0.009362
iteration 3654 : loss : 0.038024, loss_ce: 0.015638
iteration 3655 : loss : 0.084279, loss_ce: 0.007885
iteration 3656 : loss : 0.040601, loss_ce: 0.008988
iteration 3657 : loss : 0.046851, loss_ce: 0.011860
iteration 3658 : loss : 0.037625, loss_ce: 0.012371
iteration 3659 : loss : 0.042090, loss_ce: 0.016724
iteration 3660 : loss : 0.038559, loss_ce: 0.011299
iteration 3661 : loss : 0.060669, loss_ce: 0.010252
iteration 3662 : loss : 0.034785, loss_ce: 0.012227
iteration 3663 : loss : 0.088359, loss_ce: 0.010013
iteration 3664 : loss : 0.038174, loss_ce: 0.014492
iteration 3665 : loss : 0.068163, loss_ce: 0.013588
iteration 3666 : loss : 0.068846, loss_ce: 0.013581
iteration 3667 : loss : 0.041504, loss_ce: 0.021212
iteration 3668 : loss : 0.040272, loss_ce: 0.013927
iteration 3669 : loss : 0.033919, loss_ce: 0.015604
iteration 3670 : loss : 0.054112, loss_ce: 0.019906
iteration 3671 : loss : 0.042582, loss_ce: 0.011638
iteration 3672 : loss : 0.049909, loss_ce: 0.007186
iteration 3673 : loss : 0.092271, loss_ce: 0.014116
iteration 3674 : loss : 0.045379, loss_ce: 0.014174
iteration 3675 : loss : 0.052792, loss_ce: 0.015740
iteration 3676 : loss : 0.038813, loss_ce: 0.014567
iteration 3677 : loss : 0.042080, loss_ce: 0.017278
iteration 3678 : loss : 0.052969, loss_ce: 0.018611
iteration 3679 : loss : 0.045910, loss_ce: 0.016412
iteration 3680 : loss : 0.042563, loss_ce: 0.011639
iteration 3681 : loss : 0.051046, loss_ce: 0.018079
iteration 3682 : loss : 0.053046, loss_ce: 0.013821
iteration 3683 : loss : 0.039472, loss_ce: 0.013564
iteration 3684 : loss : 0.038318, loss_ce: 0.014712
iteration 3685 : loss : 0.213836, loss_ce: 0.004212
iteration 3686 : loss : 0.060483, loss_ce: 0.016577
iteration 3687 : loss : 0.036726, loss_ce: 0.009643
iteration 3688 : loss : 0.041268, loss_ce: 0.014692
iteration 3689 : loss : 0.039409, loss_ce: 0.017309
iteration 3690 : loss : 0.045666, loss_ce: 0.013932
iteration 3691 : loss : 0.042088, loss_ce: 0.015625
iteration 3692 : loss : 0.044813, loss_ce: 0.014793
iteration 3693 : loss : 0.046674, loss_ce: 0.013244
iteration 3694 : loss : 0.044831, loss_ce: 0.017681
iteration 3695 : loss : 0.041773, loss_ce: 0.012474
iteration 3696 : loss : 0.043177, loss_ce: 0.013842
iteration 3697 : loss : 0.042273, loss_ce: 0.013192
iteration 3698 : loss : 0.032597, loss_ce: 0.012484
iteration 3699 : loss : 0.052986, loss_ce: 0.011615
iteration 3700 : loss : 0.037600, loss_ce: 0.014296
iteration 3701 : loss : 0.048871, loss_ce: 0.014242
iteration 3702 : loss : 0.135258, loss_ce: 0.009706
iteration 3703 : loss : 0.085300, loss_ce: 0.012055
iteration 3704 : loss : 0.049623, loss_ce: 0.014287
iteration 3705 : loss : 0.043036, loss_ce: 0.019023
iteration 3706 : loss : 0.048084, loss_ce: 0.012965
iteration 3707 : loss : 0.045471, loss_ce: 0.011792
iteration 3708 : loss : 0.058248, loss_ce: 0.010350
iteration 3709 : loss : 0.046106, loss_ce: 0.013935
iteration 3710 : loss : 0.039199, loss_ce: 0.012107
iteration 3711 : loss : 0.083468, loss_ce: 0.008173
iteration 3712 : loss : 0.045965, loss_ce: 0.021039
iteration 3713 : loss : 0.035120, loss_ce: 0.013105
iteration 3714 : loss : 0.039135, loss_ce: 0.008472
iteration 3715 : loss : 0.044729, loss_ce: 0.018787
iteration 3716 : loss : 0.036888, loss_ce: 0.012564
iteration 3717 : loss : 0.042664, loss_ce: 0.013257
iteration 3718 : loss : 0.042486, loss_ce: 0.021025
iteration 3719 : loss : 0.031200, loss_ce: 0.009494
iteration 3720 : loss : 0.290635, loss_ce: 0.008592
 20%|██████                        | 40/200 [41:01<2:44:21, 61.63s/it]iteration 3721 : loss : 0.051719, loss_ce: 0.011292
iteration 3722 : loss : 0.036040, loss_ce: 0.014001
iteration 3723 : loss : 0.038584, loss_ce: 0.015377
iteration 3724 : loss : 0.039328, loss_ce: 0.016319
iteration 3725 : loss : 0.033048, loss_ce: 0.010765
iteration 3726 : loss : 0.037486, loss_ce: 0.015086
iteration 3727 : loss : 0.048408, loss_ce: 0.017070
iteration 3728 : loss : 0.054471, loss_ce: 0.009302
iteration 3729 : loss : 0.032741, loss_ce: 0.008915
iteration 3730 : loss : 0.040741, loss_ce: 0.011428
iteration 3731 : loss : 0.088590, loss_ce: 0.013910
iteration 3732 : loss : 0.049352, loss_ce: 0.015857
iteration 3733 : loss : 0.041092, loss_ce: 0.011686
iteration 3734 : loss : 0.035414, loss_ce: 0.014765
iteration 3735 : loss : 0.041220, loss_ce: 0.017938
iteration 3736 : loss : 0.045786, loss_ce: 0.014889
iteration 3737 : loss : 0.051309, loss_ce: 0.018920
iteration 3738 : loss : 0.092968, loss_ce: 0.016255
iteration 3739 : loss : 0.042060, loss_ce: 0.013926
iteration 3740 : loss : 0.038848, loss_ce: 0.008259
iteration 3741 : loss : 0.035184, loss_ce: 0.013972
iteration 3742 : loss : 0.039518, loss_ce: 0.016113
iteration 3743 : loss : 0.047184, loss_ce: 0.017541
iteration 3744 : loss : 0.047001, loss_ce: 0.021415
iteration 3745 : loss : 0.038353, loss_ce: 0.012471
iteration 3746 : loss : 0.051588, loss_ce: 0.013806
iteration 3747 : loss : 0.036836, loss_ce: 0.016407
iteration 3748 : loss : 0.056489, loss_ce: 0.010630
iteration 3749 : loss : 0.035063, loss_ce: 0.014574
iteration 3750 : loss : 0.047804, loss_ce: 0.020359
iteration 3751 : loss : 0.084152, loss_ce: 0.006758
iteration 3752 : loss : 0.037898, loss_ce: 0.012096
iteration 3753 : loss : 0.058770, loss_ce: 0.007334
iteration 3754 : loss : 0.035613, loss_ce: 0.010143
iteration 3755 : loss : 0.039798, loss_ce: 0.010357
iteration 3756 : loss : 0.047858, loss_ce: 0.021810
iteration 3757 : loss : 0.032344, loss_ce: 0.007390
iteration 3758 : loss : 0.050064, loss_ce: 0.017072
iteration 3759 : loss : 0.046057, loss_ce: 0.021994
iteration 3760 : loss : 0.038224, loss_ce: 0.013935
iteration 3761 : loss : 0.089625, loss_ce: 0.015469
iteration 3762 : loss : 0.038823, loss_ce: 0.010752
iteration 3763 : loss : 0.039159, loss_ce: 0.011814
iteration 3764 : loss : 0.054997, loss_ce: 0.009585
iteration 3765 : loss : 0.034844, loss_ce: 0.013837
iteration 3766 : loss : 0.054004, loss_ce: 0.017064
iteration 3767 : loss : 0.041749, loss_ce: 0.015418
iteration 3768 : loss : 0.031259, loss_ce: 0.015552
iteration 3769 : loss : 0.051778, loss_ce: 0.012543
iteration 3770 : loss : 0.034138, loss_ce: 0.007179
iteration 3771 : loss : 0.036473, loss_ce: 0.015936
iteration 3772 : loss : 0.037157, loss_ce: 0.009271
iteration 3773 : loss : 0.105869, loss_ce: 0.006117
iteration 3774 : loss : 0.053431, loss_ce: 0.016006
iteration 3775 : loss : 0.037025, loss_ce: 0.014289
iteration 3776 : loss : 0.045810, loss_ce: 0.010836
iteration 3777 : loss : 0.041113, loss_ce: 0.008507
iteration 3778 : loss : 0.057050, loss_ce: 0.014376
iteration 3779 : loss : 0.040642, loss_ce: 0.015259
iteration 3780 : loss : 0.059246, loss_ce: 0.011553
iteration 3781 : loss : 0.092634, loss_ce: 0.013357
iteration 3782 : loss : 0.041854, loss_ce: 0.019490
iteration 3783 : loss : 0.033853, loss_ce: 0.007527
iteration 3784 : loss : 0.133727, loss_ce: 0.004625
iteration 3785 : loss : 0.090667, loss_ce: 0.011160
iteration 3786 : loss : 0.043336, loss_ce: 0.012527
iteration 3787 : loss : 0.048917, loss_ce: 0.018147
iteration 3788 : loss : 0.042174, loss_ce: 0.016394
iteration 3789 : loss : 0.044896, loss_ce: 0.019991
iteration 3790 : loss : 0.035957, loss_ce: 0.011144
iteration 3791 : loss : 0.039357, loss_ce: 0.012500
iteration 3792 : loss : 0.078334, loss_ce: 0.019289
iteration 3793 : loss : 0.088955, loss_ce: 0.005891
iteration 3794 : loss : 0.037259, loss_ce: 0.009973
iteration 3795 : loss : 0.046165, loss_ce: 0.011569
iteration 3796 : loss : 0.043317, loss_ce: 0.015801
iteration 3797 : loss : 0.044307, loss_ce: 0.014517
iteration 3798 : loss : 0.049109, loss_ce: 0.018960
iteration 3799 : loss : 0.042091, loss_ce: 0.010858
iteration 3800 : loss : 0.040028, loss_ce: 0.016746
iteration 3801 : loss : 0.050833, loss_ce: 0.015166
iteration 3802 : loss : 0.062670, loss_ce: 0.016727
iteration 3803 : loss : 0.042294, loss_ce: 0.011095
iteration 3804 : loss : 0.040999, loss_ce: 0.011164
iteration 3805 : loss : 0.055221, loss_ce: 0.025959
iteration 3806 : loss : 0.038100, loss_ce: 0.010236
iteration 3807 : loss : 0.051326, loss_ce: 0.011761
iteration 3808 : loss : 0.046903, loss_ce: 0.008457
iteration 3809 : loss : 0.038939, loss_ce: 0.018011
iteration 3810 : loss : 0.036828, loss_ce: 0.015085
iteration 3811 : loss : 0.035029, loss_ce: 0.009572
iteration 3812 : loss : 0.100380, loss_ce: 0.007892
iteration 3813 : loss : 0.448706, loss_ce: 0.008885
 20%|██████▏                       | 41/200 [42:02<2:43:20, 61.64s/it]iteration 3814 : loss : 0.091506, loss_ce: 0.013912
iteration 3815 : loss : 0.046456, loss_ce: 0.010982
iteration 3816 : loss : 0.045309, loss_ce: 0.016734
iteration 3817 : loss : 0.061210, loss_ce: 0.014393
iteration 3818 : loss : 0.058216, loss_ce: 0.014393
iteration 3819 : loss : 0.040163, loss_ce: 0.016858
iteration 3820 : loss : 0.042520, loss_ce: 0.011254
iteration 3821 : loss : 0.043049, loss_ce: 0.018117
iteration 3822 : loss : 0.090028, loss_ce: 0.013278
iteration 3823 : loss : 0.044588, loss_ce: 0.012465
iteration 3824 : loss : 0.097616, loss_ce: 0.010597
iteration 3825 : loss : 0.047425, loss_ce: 0.015708
iteration 3826 : loss : 0.090680, loss_ce: 0.009684
iteration 3827 : loss : 0.050979, loss_ce: 0.011948
iteration 3828 : loss : 0.048216, loss_ce: 0.012130
iteration 3829 : loss : 0.038658, loss_ce: 0.007694
iteration 3830 : loss : 0.044962, loss_ce: 0.014733
iteration 3831 : loss : 0.046077, loss_ce: 0.015666
iteration 3832 : loss : 0.034682, loss_ce: 0.013742
iteration 3833 : loss : 0.037608, loss_ce: 0.012023
iteration 3834 : loss : 0.041747, loss_ce: 0.016617
iteration 3835 : loss : 0.044121, loss_ce: 0.012376
iteration 3836 : loss : 0.046480, loss_ce: 0.024117
iteration 3837 : loss : 0.039548, loss_ce: 0.014687
iteration 3838 : loss : 0.044681, loss_ce: 0.009008
iteration 3839 : loss : 0.044185, loss_ce: 0.011386
iteration 3840 : loss : 0.038166, loss_ce: 0.017605
iteration 3841 : loss : 0.048499, loss_ce: 0.016858
iteration 3842 : loss : 0.048295, loss_ce: 0.012714
iteration 3843 : loss : 0.049439, loss_ce: 0.014084
iteration 3844 : loss : 0.042753, loss_ce: 0.012638
iteration 3845 : loss : 0.047888, loss_ce: 0.012365
iteration 3846 : loss : 0.045536, loss_ce: 0.010649
iteration 3847 : loss : 0.027573, loss_ce: 0.006715
iteration 3848 : loss : 0.042096, loss_ce: 0.012028
iteration 3849 : loss : 0.047363, loss_ce: 0.012869
iteration 3850 : loss : 0.045918, loss_ce: 0.014735
iteration 3851 : loss : 0.057167, loss_ce: 0.019630
iteration 3852 : loss : 0.044330, loss_ce: 0.018928
iteration 3853 : loss : 0.070462, loss_ce: 0.013685
iteration 3854 : loss : 0.039345, loss_ce: 0.012181
iteration 3855 : loss : 0.040601, loss_ce: 0.012360
iteration 3856 : loss : 0.045630, loss_ce: 0.013987
iteration 3857 : loss : 0.046382, loss_ce: 0.011846
iteration 3858 : loss : 0.047747, loss_ce: 0.016891
iteration 3859 : loss : 0.044458, loss_ce: 0.012108
iteration 3860 : loss : 0.037356, loss_ce: 0.014335
iteration 3861 : loss : 0.030221, loss_ce: 0.013464
iteration 3862 : loss : 0.044320, loss_ce: 0.016456
iteration 3863 : loss : 0.086366, loss_ce: 0.014599
iteration 3864 : loss : 0.037873, loss_ce: 0.016555
iteration 3865 : loss : 0.052561, loss_ce: 0.013552
iteration 3866 : loss : 0.039461, loss_ce: 0.008992
iteration 3867 : loss : 0.046996, loss_ce: 0.015569
iteration 3868 : loss : 0.035948, loss_ce: 0.017038
iteration 3869 : loss : 0.039407, loss_ce: 0.012982
iteration 3870 : loss : 0.031996, loss_ce: 0.011137
iteration 3871 : loss : 0.041432, loss_ce: 0.013353
iteration 3872 : loss : 0.077950, loss_ce: 0.014729
iteration 3873 : loss : 0.040180, loss_ce: 0.009061
iteration 3874 : loss : 0.097017, loss_ce: 0.014535
iteration 3875 : loss : 0.035750, loss_ce: 0.014386
iteration 3876 : loss : 0.041125, loss_ce: 0.015069
iteration 3877 : loss : 0.037740, loss_ce: 0.009892
iteration 3878 : loss : 0.041835, loss_ce: 0.021495
iteration 3879 : loss : 0.043101, loss_ce: 0.012583
iteration 3880 : loss : 0.050961, loss_ce: 0.013567
iteration 3881 : loss : 0.037851, loss_ce: 0.017703
iteration 3882 : loss : 0.044483, loss_ce: 0.013064
iteration 3883 : loss : 0.088518, loss_ce: 0.010809
iteration 3884 : loss : 0.035869, loss_ce: 0.016144
iteration 3885 : loss : 0.040943, loss_ce: 0.018926
iteration 3886 : loss : 0.040774, loss_ce: 0.015551
iteration 3887 : loss : 0.043504, loss_ce: 0.009710
iteration 3888 : loss : 0.033617, loss_ce: 0.010651
iteration 3889 : loss : 0.044048, loss_ce: 0.020243
iteration 3890 : loss : 0.038825, loss_ce: 0.013971
iteration 3891 : loss : 0.041165, loss_ce: 0.012113
iteration 3892 : loss : 0.040505, loss_ce: 0.018066
iteration 3893 : loss : 0.062965, loss_ce: 0.007928
iteration 3894 : loss : 0.046002, loss_ce: 0.018033
iteration 3895 : loss : 0.038592, loss_ce: 0.011669
iteration 3896 : loss : 0.042267, loss_ce: 0.013234
iteration 3897 : loss : 0.035687, loss_ce: 0.010257
iteration 3898 : loss : 0.040490, loss_ce: 0.013023
iteration 3899 : loss : 0.047359, loss_ce: 0.013351
iteration 3900 : loss : 0.041835, loss_ce: 0.008116
iteration 3901 : loss : 0.041620, loss_ce: 0.014532
iteration 3902 : loss : 0.065745, loss_ce: 0.010268
iteration 3903 : loss : 0.034598, loss_ce: 0.010029
iteration 3904 : loss : 0.041980, loss_ce: 0.011817
iteration 3905 : loss : 0.038252, loss_ce: 0.018077
iteration 3906 : loss : 0.050956, loss_ce: 0.018110
 21%|██████▎                       | 42/200 [43:04<2:42:17, 61.63s/it]iteration 3907 : loss : 0.042837, loss_ce: 0.012521
iteration 3908 : loss : 0.041191, loss_ce: 0.012391
iteration 3909 : loss : 0.039954, loss_ce: 0.015061
iteration 3910 : loss : 0.038918, loss_ce: 0.013065
iteration 3911 : loss : 0.043548, loss_ce: 0.018180
iteration 3912 : loss : 0.088093, loss_ce: 0.013205
iteration 3913 : loss : 0.035896, loss_ce: 0.012104
iteration 3914 : loss : 0.040863, loss_ce: 0.016805
iteration 3915 : loss : 0.037537, loss_ce: 0.018372
iteration 3916 : loss : 0.042346, loss_ce: 0.009521
iteration 3917 : loss : 0.025427, loss_ce: 0.006325
iteration 3918 : loss : 0.039814, loss_ce: 0.010444
iteration 3919 : loss : 0.090216, loss_ce: 0.010645
iteration 3920 : loss : 0.040563, loss_ce: 0.015300
iteration 3921 : loss : 0.051266, loss_ce: 0.014219
iteration 3922 : loss : 0.036308, loss_ce: 0.013756
iteration 3923 : loss : 0.041358, loss_ce: 0.012816
iteration 3924 : loss : 0.038175, loss_ce: 0.010115
iteration 3925 : loss : 0.032659, loss_ce: 0.011568
iteration 3926 : loss : 0.036673, loss_ce: 0.012269
iteration 3927 : loss : 0.092028, loss_ce: 0.007761
iteration 3928 : loss : 0.029087, loss_ce: 0.010060
iteration 3929 : loss : 0.036125, loss_ce: 0.012329
iteration 3930 : loss : 0.042408, loss_ce: 0.009469
iteration 3931 : loss : 0.085315, loss_ce: 0.009452
iteration 3932 : loss : 0.036473, loss_ce: 0.016316
iteration 3933 : loss : 0.041883, loss_ce: 0.011529
iteration 3934 : loss : 0.036025, loss_ce: 0.008631
iteration 3935 : loss : 0.038046, loss_ce: 0.012197
iteration 3936 : loss : 0.041820, loss_ce: 0.016208
iteration 3937 : loss : 0.030258, loss_ce: 0.014738
iteration 3938 : loss : 0.032559, loss_ce: 0.008328
iteration 3939 : loss : 0.101562, loss_ce: 0.007479
iteration 3940 : loss : 0.031267, loss_ce: 0.007806
iteration 3941 : loss : 0.043017, loss_ce: 0.019378
iteration 3942 : loss : 0.083601, loss_ce: 0.005091
iteration 3943 : loss : 0.048481, loss_ce: 0.008504
iteration 3944 : loss : 0.045056, loss_ce: 0.014330
iteration 3945 : loss : 0.061348, loss_ce: 0.015204
iteration 3946 : loss : 0.056397, loss_ce: 0.014831
iteration 3947 : loss : 0.038903, loss_ce: 0.014409
iteration 3948 : loss : 0.033290, loss_ce: 0.009239
iteration 3949 : loss : 0.051969, loss_ce: 0.014234
iteration 3950 : loss : 0.033011, loss_ce: 0.009976
iteration 3951 : loss : 0.037030, loss_ce: 0.017556
iteration 3952 : loss : 0.039628, loss_ce: 0.011692
iteration 3953 : loss : 0.041315, loss_ce: 0.014278
iteration 3954 : loss : 0.033545, loss_ce: 0.015758
iteration 3955 : loss : 0.094309, loss_ce: 0.007634
iteration 3956 : loss : 0.043735, loss_ce: 0.015844
iteration 3957 : loss : 0.048554, loss_ce: 0.012988
iteration 3958 : loss : 0.035749, loss_ce: 0.014841
iteration 3959 : loss : 0.051803, loss_ce: 0.013186
iteration 3960 : loss : 0.042983, loss_ce: 0.022407
iteration 3961 : loss : 0.038409, loss_ce: 0.017576
iteration 3962 : loss : 0.107763, loss_ce: 0.016278
iteration 3963 : loss : 0.090152, loss_ce: 0.016750
iteration 3964 : loss : 0.037286, loss_ce: 0.009481
iteration 3965 : loss : 0.038430, loss_ce: 0.014548
iteration 3966 : loss : 0.087943, loss_ce: 0.014835
iteration 3967 : loss : 0.046455, loss_ce: 0.014358
iteration 3968 : loss : 0.040669, loss_ce: 0.014553
iteration 3969 : loss : 0.040926, loss_ce: 0.012793
iteration 3970 : loss : 0.042411, loss_ce: 0.009119
iteration 3971 : loss : 0.030711, loss_ce: 0.010607
iteration 3972 : loss : 0.038841, loss_ce: 0.013609
iteration 3973 : loss : 0.041864, loss_ce: 0.006603
iteration 3974 : loss : 0.034995, loss_ce: 0.012660
iteration 3975 : loss : 0.033374, loss_ce: 0.009736
iteration 3976 : loss : 0.033651, loss_ce: 0.010849
iteration 3977 : loss : 0.032398, loss_ce: 0.010262
iteration 3978 : loss : 0.069361, loss_ce: 0.006218
iteration 3979 : loss : 0.044214, loss_ce: 0.015355
iteration 3980 : loss : 0.049804, loss_ce: 0.013271
iteration 3981 : loss : 0.046395, loss_ce: 0.018279
iteration 3982 : loss : 0.033964, loss_ce: 0.016633
iteration 3983 : loss : 0.041961, loss_ce: 0.017171
iteration 3984 : loss : 0.043375, loss_ce: 0.019328
iteration 3985 : loss : 0.085868, loss_ce: 0.010036
iteration 3986 : loss : 0.039882, loss_ce: 0.015324
iteration 3987 : loss : 0.040434, loss_ce: 0.018570
iteration 3988 : loss : 0.040879, loss_ce: 0.011367
iteration 3989 : loss : 0.046486, loss_ce: 0.015018
iteration 3990 : loss : 0.036583, loss_ce: 0.015492
iteration 3991 : loss : 0.045871, loss_ce: 0.019013
iteration 3992 : loss : 0.034565, loss_ce: 0.012311
iteration 3993 : loss : 0.046084, loss_ce: 0.015859
iteration 3994 : loss : 0.038771, loss_ce: 0.008713
iteration 3995 : loss : 0.045333, loss_ce: 0.013423
iteration 3996 : loss : 0.087208, loss_ce: 0.010948
iteration 3997 : loss : 0.036342, loss_ce: 0.011982
iteration 3998 : loss : 0.034843, loss_ce: 0.011842
iteration 3999 : loss : 0.215174, loss_ce: 0.015616
 22%|██████▍                       | 43/200 [44:05<2:41:14, 61.62s/it]iteration 4000 : loss : 0.032415, loss_ce: 0.005742
iteration 4001 : loss : 0.036051, loss_ce: 0.013757
iteration 4002 : loss : 0.051746, loss_ce: 0.020965
iteration 4003 : loss : 0.043533, loss_ce: 0.017143
iteration 4004 : loss : 0.028710, loss_ce: 0.009940
iteration 4005 : loss : 0.033067, loss_ce: 0.012798
iteration 4006 : loss : 0.094509, loss_ce: 0.007707
iteration 4007 : loss : 0.047149, loss_ce: 0.016089
iteration 4008 : loss : 0.046919, loss_ce: 0.010622
iteration 4009 : loss : 0.040278, loss_ce: 0.017697
iteration 4010 : loss : 0.083065, loss_ce: 0.014215
iteration 4011 : loss : 0.070480, loss_ce: 0.012862
iteration 4012 : loss : 0.039687, loss_ce: 0.008863
iteration 4013 : loss : 0.039471, loss_ce: 0.020244
iteration 4014 : loss : 0.039262, loss_ce: 0.017883
iteration 4015 : loss : 0.034758, loss_ce: 0.008980
iteration 4016 : loss : 0.070725, loss_ce: 0.010324
iteration 4017 : loss : 0.037531, loss_ce: 0.014274
iteration 4018 : loss : 0.046657, loss_ce: 0.020540
iteration 4019 : loss : 0.039523, loss_ce: 0.010325
iteration 4020 : loss : 0.037751, loss_ce: 0.013837
iteration 4021 : loss : 0.084352, loss_ce: 0.010409
iteration 4022 : loss : 0.049174, loss_ce: 0.020415
iteration 4023 : loss : 0.029392, loss_ce: 0.011617
iteration 4024 : loss : 0.031518, loss_ce: 0.009725
iteration 4025 : loss : 0.045494, loss_ce: 0.016594
iteration 4026 : loss : 0.035999, loss_ce: 0.007395
iteration 4027 : loss : 0.043246, loss_ce: 0.011270
iteration 4028 : loss : 0.047928, loss_ce: 0.013414
iteration 4029 : loss : 0.035021, loss_ce: 0.011503
iteration 4030 : loss : 0.034121, loss_ce: 0.014410
iteration 4031 : loss : 0.075624, loss_ce: 0.004819
iteration 4032 : loss : 0.035927, loss_ce: 0.010643
iteration 4033 : loss : 0.036321, loss_ce: 0.012714
iteration 4034 : loss : 0.044742, loss_ce: 0.017857
iteration 4035 : loss : 0.055649, loss_ce: 0.016416
iteration 4036 : loss : 0.038598, loss_ce: 0.017034
iteration 4037 : loss : 0.032810, loss_ce: 0.008138
iteration 4038 : loss : 0.092462, loss_ce: 0.009279
iteration 4039 : loss : 0.037612, loss_ce: 0.012091
iteration 4040 : loss : 0.040028, loss_ce: 0.012193
iteration 4041 : loss : 0.035452, loss_ce: 0.012128
iteration 4042 : loss : 0.087977, loss_ce: 0.012702
iteration 4043 : loss : 0.034717, loss_ce: 0.011412
iteration 4044 : loss : 0.036385, loss_ce: 0.009754
iteration 4045 : loss : 0.039678, loss_ce: 0.015905
iteration 4046 : loss : 0.037549, loss_ce: 0.010137
iteration 4047 : loss : 0.035154, loss_ce: 0.009646
iteration 4048 : loss : 0.042509, loss_ce: 0.018372
iteration 4049 : loss : 0.037844, loss_ce: 0.017410
iteration 4050 : loss : 0.033378, loss_ce: 0.012128
iteration 4051 : loss : 0.040496, loss_ce: 0.012018
iteration 4052 : loss : 0.079175, loss_ce: 0.008123
iteration 4053 : loss : 0.039113, loss_ce: 0.012850
iteration 4054 : loss : 0.038899, loss_ce: 0.013781
iteration 4055 : loss : 0.046574, loss_ce: 0.008908
iteration 4056 : loss : 0.037514, loss_ce: 0.011499
iteration 4057 : loss : 0.032671, loss_ce: 0.009683
iteration 4058 : loss : 0.039419, loss_ce: 0.014367
iteration 4059 : loss : 0.041246, loss_ce: 0.015241
iteration 4060 : loss : 0.032732, loss_ce: 0.012482
iteration 4061 : loss : 0.036483, loss_ce: 0.016531
iteration 4062 : loss : 0.050123, loss_ce: 0.016384
iteration 4063 : loss : 0.039127, loss_ce: 0.014322
iteration 4064 : loss : 0.037706, loss_ce: 0.009127
iteration 4065 : loss : 0.039656, loss_ce: 0.013130
iteration 4066 : loss : 0.045834, loss_ce: 0.016029
iteration 4067 : loss : 0.054482, loss_ce: 0.014247
iteration 4068 : loss : 0.088511, loss_ce: 0.010481
iteration 4069 : loss : 0.043311, loss_ce: 0.010360
iteration 4070 : loss : 0.039748, loss_ce: 0.012509
iteration 4071 : loss : 0.032291, loss_ce: 0.011401
iteration 4072 : loss : 0.054905, loss_ce: 0.017346
iteration 4073 : loss : 0.041444, loss_ce: 0.015023
iteration 4074 : loss : 0.037145, loss_ce: 0.010801
iteration 4075 : loss : 0.038900, loss_ce: 0.010898
iteration 4076 : loss : 0.042533, loss_ce: 0.017822
iteration 4077 : loss : 0.044920, loss_ce: 0.013750
iteration 4078 : loss : 0.038403, loss_ce: 0.011935
iteration 4079 : loss : 0.041845, loss_ce: 0.011896
iteration 4080 : loss : 0.030081, loss_ce: 0.010587
iteration 4081 : loss : 0.044725, loss_ce: 0.007825
iteration 4082 : loss : 0.044899, loss_ce: 0.016864
iteration 4083 : loss : 0.033791, loss_ce: 0.006156
iteration 4084 : loss : 0.036720, loss_ce: 0.016172
iteration 4085 : loss : 0.038514, loss_ce: 0.012613
iteration 4086 : loss : 0.052593, loss_ce: 0.017815
iteration 4087 : loss : 0.039570, loss_ce: 0.010730
iteration 4088 : loss : 0.032120, loss_ce: 0.011169
iteration 4089 : loss : 0.086700, loss_ce: 0.012743
iteration 4090 : loss : 0.027941, loss_ce: 0.010674
iteration 4091 : loss : 0.084702, loss_ce: 0.008447
iteration 4092 : loss : 0.097519, loss_ce: 0.014604
 22%|██████▌                       | 44/200 [45:07<2:40:22, 61.68s/it]iteration 4093 : loss : 0.082323, loss_ce: 0.006935
iteration 4094 : loss : 0.037372, loss_ce: 0.014662
iteration 4095 : loss : 0.032396, loss_ce: 0.012210
iteration 4096 : loss : 0.040171, loss_ce: 0.012213
iteration 4097 : loss : 0.035446, loss_ce: 0.007578
iteration 4098 : loss : 0.083489, loss_ce: 0.008247
iteration 4099 : loss : 0.048590, loss_ce: 0.010320
iteration 4100 : loss : 0.033493, loss_ce: 0.013045
iteration 4101 : loss : 0.038915, loss_ce: 0.010977
iteration 4102 : loss : 0.038732, loss_ce: 0.012173
iteration 4103 : loss : 0.033387, loss_ce: 0.008840
iteration 4104 : loss : 0.085235, loss_ce: 0.010026
iteration 4105 : loss : 0.027543, loss_ce: 0.007278
iteration 4106 : loss : 0.087500, loss_ce: 0.014523
iteration 4107 : loss : 0.045364, loss_ce: 0.018084
iteration 4108 : loss : 0.036880, loss_ce: 0.010961
iteration 4109 : loss : 0.067575, loss_ce: 0.009657
iteration 4110 : loss : 0.032826, loss_ce: 0.009791
iteration 4111 : loss : 0.039492, loss_ce: 0.010508
iteration 4112 : loss : 0.029406, loss_ce: 0.010963
iteration 4113 : loss : 0.049340, loss_ce: 0.010314
iteration 4114 : loss : 0.030288, loss_ce: 0.009929
iteration 4115 : loss : 0.050370, loss_ce: 0.013636
iteration 4116 : loss : 0.035620, loss_ce: 0.007034
iteration 4117 : loss : 0.088577, loss_ce: 0.016216
iteration 4118 : loss : 0.039144, loss_ce: 0.014103
iteration 4119 : loss : 0.031625, loss_ce: 0.010702
iteration 4120 : loss : 0.045661, loss_ce: 0.013451
iteration 4121 : loss : 0.041513, loss_ce: 0.012251
iteration 4122 : loss : 0.088534, loss_ce: 0.019335
iteration 4123 : loss : 0.036493, loss_ce: 0.016654
iteration 4124 : loss : 0.030761, loss_ce: 0.011448
iteration 4125 : loss : 0.029307, loss_ce: 0.012066
iteration 4126 : loss : 0.035117, loss_ce: 0.014159
iteration 4127 : loss : 0.040169, loss_ce: 0.012025
iteration 4128 : loss : 0.032191, loss_ce: 0.011803
iteration 4129 : loss : 0.032013, loss_ce: 0.010362
iteration 4130 : loss : 0.039989, loss_ce: 0.012194
iteration 4131 : loss : 0.060691, loss_ce: 0.012614
iteration 4132 : loss : 0.031984, loss_ce: 0.012744
iteration 4133 : loss : 0.037792, loss_ce: 0.014841
iteration 4134 : loss : 0.031903, loss_ce: 0.011878
iteration 4135 : loss : 0.039852, loss_ce: 0.013335
iteration 4136 : loss : 0.068851, loss_ce: 0.007995
iteration 4137 : loss : 0.040173, loss_ce: 0.013809
iteration 4138 : loss : 0.038977, loss_ce: 0.016953
iteration 4139 : loss : 0.038908, loss_ce: 0.014860
iteration 4140 : loss : 0.040700, loss_ce: 0.017408
iteration 4141 : loss : 0.043710, loss_ce: 0.015503
iteration 4142 : loss : 0.043258, loss_ce: 0.011427
iteration 4143 : loss : 0.062033, loss_ce: 0.011944
iteration 4144 : loss : 0.037359, loss_ce: 0.009529
iteration 4145 : loss : 0.044029, loss_ce: 0.009977
iteration 4146 : loss : 0.049514, loss_ce: 0.012839
iteration 4147 : loss : 0.060260, loss_ce: 0.014741
iteration 4148 : loss : 0.082788, loss_ce: 0.009515
iteration 4149 : loss : 0.034203, loss_ce: 0.009717
iteration 4150 : loss : 0.086078, loss_ce: 0.010716
iteration 4151 : loss : 0.048182, loss_ce: 0.008665
iteration 4152 : loss : 0.040588, loss_ce: 0.020671
iteration 4153 : loss : 0.039147, loss_ce: 0.020186
iteration 4154 : loss : 0.033954, loss_ce: 0.014759
iteration 4155 : loss : 0.042186, loss_ce: 0.015414
iteration 4156 : loss : 0.081669, loss_ce: 0.011576
iteration 4157 : loss : 0.052781, loss_ce: 0.014635
iteration 4158 : loss : 0.047029, loss_ce: 0.011920
iteration 4159 : loss : 0.041457, loss_ce: 0.013140
iteration 4160 : loss : 0.041890, loss_ce: 0.010682
iteration 4161 : loss : 0.036689, loss_ce: 0.014071
iteration 4162 : loss : 0.036601, loss_ce: 0.013838
iteration 4163 : loss : 0.050226, loss_ce: 0.009992
iteration 4164 : loss : 0.046580, loss_ce: 0.020794
iteration 4165 : loss : 0.037697, loss_ce: 0.013799
iteration 4166 : loss : 0.082390, loss_ce: 0.009358
iteration 4167 : loss : 0.039565, loss_ce: 0.017803
iteration 4168 : loss : 0.032719, loss_ce: 0.005428
iteration 4169 : loss : 0.088330, loss_ce: 0.012387
iteration 4170 : loss : 0.032339, loss_ce: 0.010913
iteration 4171 : loss : 0.087235, loss_ce: 0.012782
iteration 4172 : loss : 0.046420, loss_ce: 0.009554
iteration 4173 : loss : 0.032102, loss_ce: 0.008142
iteration 4174 : loss : 0.035155, loss_ce: 0.007696
iteration 4175 : loss : 0.039885, loss_ce: 0.013016
iteration 4176 : loss : 0.041506, loss_ce: 0.009201
iteration 4177 : loss : 0.047349, loss_ce: 0.016981
iteration 4178 : loss : 0.048462, loss_ce: 0.017674
iteration 4179 : loss : 0.033692, loss_ce: 0.009634
iteration 4180 : loss : 0.033608, loss_ce: 0.015448
iteration 4181 : loss : 0.044760, loss_ce: 0.022310
iteration 4182 : loss : 0.036030, loss_ce: 0.012522
iteration 4183 : loss : 0.032548, loss_ce: 0.012749
iteration 4184 : loss : 0.036655, loss_ce: 0.011642
iteration 4185 : loss : 0.206725, loss_ce: 0.027438
 22%|██████▊                       | 45/200 [46:09<2:39:19, 61.67s/it]iteration 4186 : loss : 0.028242, loss_ce: 0.009167
iteration 4187 : loss : 0.039492, loss_ce: 0.014524
iteration 4188 : loss : 0.035062, loss_ce: 0.009738
iteration 4189 : loss : 0.047098, loss_ce: 0.010701
iteration 4190 : loss : 0.036997, loss_ce: 0.014620
iteration 4191 : loss : 0.085564, loss_ce: 0.010082
iteration 4192 : loss : 0.041774, loss_ce: 0.018360
iteration 4193 : loss : 0.036183, loss_ce: 0.012184
iteration 4194 : loss : 0.040567, loss_ce: 0.012721
iteration 4195 : loss : 0.087549, loss_ce: 0.008736
iteration 4196 : loss : 0.027016, loss_ce: 0.010944
iteration 4197 : loss : 0.045239, loss_ce: 0.012766
iteration 4198 : loss : 0.081450, loss_ce: 0.009696
iteration 4199 : loss : 0.039810, loss_ce: 0.013986
iteration 4200 : loss : 0.038809, loss_ce: 0.015419
iteration 4201 : loss : 0.068794, loss_ce: 0.008066
iteration 4202 : loss : 0.043669, loss_ce: 0.013462
iteration 4203 : loss : 0.053459, loss_ce: 0.012734
iteration 4204 : loss : 0.037050, loss_ce: 0.013704
iteration 4205 : loss : 0.028155, loss_ce: 0.008226
iteration 4206 : loss : 0.086396, loss_ce: 0.008012
iteration 4207 : loss : 0.031303, loss_ce: 0.009435
iteration 4208 : loss : 0.125497, loss_ce: 0.006175
iteration 4209 : loss : 0.041921, loss_ce: 0.011382
iteration 4210 : loss : 0.042917, loss_ce: 0.019154
iteration 4211 : loss : 0.024135, loss_ce: 0.008039
iteration 4212 : loss : 0.050542, loss_ce: 0.010163
iteration 4213 : loss : 0.058541, loss_ce: 0.008310
iteration 4214 : loss : 0.039447, loss_ce: 0.010151
iteration 4215 : loss : 0.032861, loss_ce: 0.011580
iteration 4216 : loss : 0.034201, loss_ce: 0.014492
iteration 4217 : loss : 0.043315, loss_ce: 0.012269
iteration 4218 : loss : 0.031730, loss_ce: 0.011993
iteration 4219 : loss : 0.039585, loss_ce: 0.010891
iteration 4220 : loss : 0.055303, loss_ce: 0.016497
iteration 4221 : loss : 0.034356, loss_ce: 0.010932
iteration 4222 : loss : 0.033794, loss_ce: 0.013327
iteration 4223 : loss : 0.037904, loss_ce: 0.010936
iteration 4224 : loss : 0.040904, loss_ce: 0.010643
iteration 4225 : loss : 0.044127, loss_ce: 0.015418
iteration 4226 : loss : 0.052123, loss_ce: 0.019396
iteration 4227 : loss : 0.043913, loss_ce: 0.008936
iteration 4228 : loss : 0.034428, loss_ce: 0.012218
iteration 4229 : loss : 0.043801, loss_ce: 0.011449
iteration 4230 : loss : 0.033080, loss_ce: 0.010536
iteration 4231 : loss : 0.038500, loss_ce: 0.015572
iteration 4232 : loss : 0.046122, loss_ce: 0.015322
iteration 4233 : loss : 0.036313, loss_ce: 0.012809
iteration 4234 : loss : 0.046505, loss_ce: 0.009283
iteration 4235 : loss : 0.038802, loss_ce: 0.013177
iteration 4236 : loss : 0.047880, loss_ce: 0.010701
iteration 4237 : loss : 0.037601, loss_ce: 0.017992
iteration 4238 : loss : 0.053365, loss_ce: 0.011343
iteration 4239 : loss : 0.026451, loss_ce: 0.011001
iteration 4240 : loss : 0.037149, loss_ce: 0.014764
iteration 4241 : loss : 0.036698, loss_ce: 0.012652
iteration 4242 : loss : 0.038114, loss_ce: 0.012104
iteration 4243 : loss : 0.036059, loss_ce: 0.013980
iteration 4244 : loss : 0.093249, loss_ce: 0.010240
iteration 4245 : loss : 0.083408, loss_ce: 0.007674
iteration 4246 : loss : 0.035323, loss_ce: 0.012694
iteration 4247 : loss : 0.040162, loss_ce: 0.010228
iteration 4248 : loss : 0.041145, loss_ce: 0.012810
iteration 4249 : loss : 0.039728, loss_ce: 0.016396
iteration 4250 : loss : 0.034533, loss_ce: 0.012030
iteration 4251 : loss : 0.035984, loss_ce: 0.011988
iteration 4252 : loss : 0.032747, loss_ce: 0.012071
iteration 4253 : loss : 0.038489, loss_ce: 0.013698
iteration 4254 : loss : 0.035406, loss_ce: 0.012980
iteration 4255 : loss : 0.028915, loss_ce: 0.011709
iteration 4256 : loss : 0.032960, loss_ce: 0.013797
iteration 4257 : loss : 0.034990, loss_ce: 0.015520
iteration 4258 : loss : 0.043795, loss_ce: 0.009132
iteration 4259 : loss : 0.039851, loss_ce: 0.011749
iteration 4260 : loss : 0.029530, loss_ce: 0.011729
iteration 4261 : loss : 0.029911, loss_ce: 0.008900
iteration 4262 : loss : 0.029965, loss_ce: 0.013459
iteration 4263 : loss : 0.089621, loss_ce: 0.008468
iteration 4264 : loss : 0.037535, loss_ce: 0.015919
iteration 4265 : loss : 0.036471, loss_ce: 0.008858
iteration 4266 : loss : 0.032767, loss_ce: 0.011209
iteration 4267 : loss : 0.037510, loss_ce: 0.013762
iteration 4268 : loss : 0.036391, loss_ce: 0.009458
iteration 4269 : loss : 0.039183, loss_ce: 0.022526
iteration 4270 : loss : 0.029997, loss_ce: 0.012027
iteration 4271 : loss : 0.038352, loss_ce: 0.013622
iteration 4272 : loss : 0.038628, loss_ce: 0.013910
iteration 4273 : loss : 0.041529, loss_ce: 0.013482
iteration 4274 : loss : 0.032313, loss_ce: 0.012103
iteration 4275 : loss : 0.038051, loss_ce: 0.015888
iteration 4276 : loss : 0.033776, loss_ce: 0.012433
iteration 4277 : loss : 0.084609, loss_ce: 0.012654
iteration 4278 : loss : 0.143275, loss_ce: 0.016321
 23%|██████▉                       | 46/200 [47:10<2:38:13, 61.65s/it]iteration 4279 : loss : 0.050961, loss_ce: 0.012959
iteration 4280 : loss : 0.032435, loss_ce: 0.009196
iteration 4281 : loss : 0.036995, loss_ce: 0.012434
iteration 4282 : loss : 0.030336, loss_ce: 0.013192
iteration 4283 : loss : 0.090202, loss_ce: 0.006685
iteration 4284 : loss : 0.041669, loss_ce: 0.010454
iteration 4285 : loss : 0.024402, loss_ce: 0.006115
iteration 4286 : loss : 0.040171, loss_ce: 0.017153
iteration 4287 : loss : 0.039914, loss_ce: 0.015265
iteration 4288 : loss : 0.044437, loss_ce: 0.011295
iteration 4289 : loss : 0.033320, loss_ce: 0.010809
iteration 4290 : loss : 0.042114, loss_ce: 0.007522
iteration 4291 : loss : 0.040188, loss_ce: 0.008181
iteration 4292 : loss : 0.035500, loss_ce: 0.017919
iteration 4293 : loss : 0.076965, loss_ce: 0.014552
iteration 4294 : loss : 0.039439, loss_ce: 0.013768
iteration 4295 : loss : 0.032697, loss_ce: 0.008564
iteration 4296 : loss : 0.037901, loss_ce: 0.013208
iteration 4297 : loss : 0.033996, loss_ce: 0.012576
iteration 4298 : loss : 0.033345, loss_ce: 0.008300
iteration 4299 : loss : 0.039938, loss_ce: 0.009976
iteration 4300 : loss : 0.046720, loss_ce: 0.012123
iteration 4301 : loss : 0.030377, loss_ce: 0.010131
iteration 4302 : loss : 0.033281, loss_ce: 0.010496
iteration 4303 : loss : 0.089695, loss_ce: 0.011938
iteration 4304 : loss : 0.083465, loss_ce: 0.008153
iteration 4305 : loss : 0.028083, loss_ce: 0.009994
iteration 4306 : loss : 0.040246, loss_ce: 0.018892
iteration 4307 : loss : 0.032498, loss_ce: 0.009027
iteration 4308 : loss : 0.027263, loss_ce: 0.007066
iteration 4309 : loss : 0.033016, loss_ce: 0.010338
iteration 4310 : loss : 0.033508, loss_ce: 0.009357
iteration 4311 : loss : 0.084538, loss_ce: 0.011265
iteration 4312 : loss : 0.034370, loss_ce: 0.010436
iteration 4313 : loss : 0.040700, loss_ce: 0.020599
iteration 4314 : loss : 0.081770, loss_ce: 0.013812
iteration 4315 : loss : 0.040363, loss_ce: 0.014338
iteration 4316 : loss : 0.039802, loss_ce: 0.013086
iteration 4317 : loss : 0.036577, loss_ce: 0.010079
iteration 4318 : loss : 0.035312, loss_ce: 0.010419
iteration 4319 : loss : 0.028772, loss_ce: 0.012646
iteration 4320 : loss : 0.057808, loss_ce: 0.008139
iteration 4321 : loss : 0.056657, loss_ce: 0.004657
iteration 4322 : loss : 0.032451, loss_ce: 0.015423
iteration 4323 : loss : 0.041278, loss_ce: 0.012208
iteration 4324 : loss : 0.038241, loss_ce: 0.012867
iteration 4325 : loss : 0.038468, loss_ce: 0.013835
iteration 4326 : loss : 0.035424, loss_ce: 0.015707
iteration 4327 : loss : 0.034745, loss_ce: 0.009191
iteration 4328 : loss : 0.037402, loss_ce: 0.015188
iteration 4329 : loss : 0.032733, loss_ce: 0.009589
iteration 4330 : loss : 0.045250, loss_ce: 0.012223
iteration 4331 : loss : 0.086808, loss_ce: 0.009293
iteration 4332 : loss : 0.043214, loss_ce: 0.022963
iteration 4333 : loss : 0.028826, loss_ce: 0.011318
iteration 4334 : loss : 0.042225, loss_ce: 0.007574
iteration 4335 : loss : 0.043764, loss_ce: 0.009400
iteration 4336 : loss : 0.038519, loss_ce: 0.020024
iteration 4337 : loss : 0.045623, loss_ce: 0.027001
iteration 4338 : loss : 0.044856, loss_ce: 0.014096
iteration 4339 : loss : 0.035472, loss_ce: 0.009743
iteration 4340 : loss : 0.035007, loss_ce: 0.013974
iteration 4341 : loss : 0.032769, loss_ce: 0.012112
iteration 4342 : loss : 0.035424, loss_ce: 0.013765
iteration 4343 : loss : 0.095499, loss_ce: 0.010502
iteration 4344 : loss : 0.050246, loss_ce: 0.012704
iteration 4345 : loss : 0.091269, loss_ce: 0.016168
iteration 4346 : loss : 0.031259, loss_ce: 0.008476
iteration 4347 : loss : 0.037967, loss_ce: 0.020623
iteration 4348 : loss : 0.036540, loss_ce: 0.015329
iteration 4349 : loss : 0.037581, loss_ce: 0.013099
iteration 4350 : loss : 0.032033, loss_ce: 0.010268
iteration 4351 : loss : 0.091662, loss_ce: 0.011342
iteration 4352 : loss : 0.037375, loss_ce: 0.010475
iteration 4353 : loss : 0.037793, loss_ce: 0.014397
iteration 4354 : loss : 0.038011, loss_ce: 0.012721
iteration 4355 : loss : 0.040292, loss_ce: 0.018823
iteration 4356 : loss : 0.033445, loss_ce: 0.015020
iteration 4357 : loss : 0.035016, loss_ce: 0.008599
iteration 4358 : loss : 0.043513, loss_ce: 0.003967
iteration 4359 : loss : 0.042637, loss_ce: 0.010957
iteration 4360 : loss : 0.035709, loss_ce: 0.013667
iteration 4361 : loss : 0.035880, loss_ce: 0.014116
iteration 4362 : loss : 0.041256, loss_ce: 0.008989
iteration 4363 : loss : 0.034964, loss_ce: 0.016914
iteration 4364 : loss : 0.048355, loss_ce: 0.006992
iteration 4365 : loss : 0.107777, loss_ce: 0.003541
iteration 4366 : loss : 0.085697, loss_ce: 0.013575
iteration 4367 : loss : 0.036267, loss_ce: 0.009965
iteration 4368 : loss : 0.037446, loss_ce: 0.011099
iteration 4369 : loss : 0.041275, loss_ce: 0.009734
iteration 4370 : loss : 0.040249, loss_ce: 0.011596
iteration 4371 : loss : 0.087273, loss_ce: 0.022869
 24%|███████                       | 47/200 [48:12<2:37:21, 61.71s/it]iteration 4372 : loss : 0.040263, loss_ce: 0.015129
iteration 4373 : loss : 0.038995, loss_ce: 0.013656
iteration 4374 : loss : 0.038505, loss_ce: 0.006459
iteration 4375 : loss : 0.039549, loss_ce: 0.012067
iteration 4376 : loss : 0.038227, loss_ce: 0.012017
iteration 4377 : loss : 0.042230, loss_ce: 0.014326
iteration 4378 : loss : 0.037877, loss_ce: 0.014095
iteration 4379 : loss : 0.046816, loss_ce: 0.017641
iteration 4380 : loss : 0.035524, loss_ce: 0.014685
iteration 4381 : loss : 0.042564, loss_ce: 0.014112
iteration 4382 : loss : 0.042210, loss_ce: 0.007799
iteration 4383 : loss : 0.037009, loss_ce: 0.011407
iteration 4384 : loss : 0.033594, loss_ce: 0.013010
iteration 4385 : loss : 0.033175, loss_ce: 0.006979
iteration 4386 : loss : 0.032713, loss_ce: 0.011514
iteration 4387 : loss : 0.032568, loss_ce: 0.011961
iteration 4388 : loss : 0.039065, loss_ce: 0.012567
iteration 4389 : loss : 0.037849, loss_ce: 0.013817
iteration 4390 : loss : 0.034040, loss_ce: 0.019108
iteration 4391 : loss : 0.029602, loss_ce: 0.009191
iteration 4392 : loss : 0.035691, loss_ce: 0.015432
iteration 4393 : loss : 0.037698, loss_ce: 0.010083
iteration 4394 : loss : 0.044492, loss_ce: 0.012767
iteration 4395 : loss : 0.032408, loss_ce: 0.010982
iteration 4396 : loss : 0.033545, loss_ce: 0.013155
iteration 4397 : loss : 0.034376, loss_ce: 0.011155
iteration 4398 : loss : 0.134905, loss_ce: 0.009712
iteration 4399 : loss : 0.038927, loss_ce: 0.013996
iteration 4400 : loss : 0.028001, loss_ce: 0.007201
iteration 4401 : loss : 0.031831, loss_ce: 0.015578
iteration 4402 : loss : 0.036540, loss_ce: 0.008655
iteration 4403 : loss : 0.035076, loss_ce: 0.011271
iteration 4404 : loss : 0.028660, loss_ce: 0.009999
iteration 4405 : loss : 0.029948, loss_ce: 0.008350
iteration 4406 : loss : 0.083034, loss_ce: 0.007115
iteration 4407 : loss : 0.085711, loss_ce: 0.008711
iteration 4408 : loss : 0.037830, loss_ce: 0.011039
iteration 4409 : loss : 0.028433, loss_ce: 0.005145
iteration 4410 : loss : 0.088898, loss_ce: 0.013146
iteration 4411 : loss : 0.033092, loss_ce: 0.012643
iteration 4412 : loss : 0.038184, loss_ce: 0.013771
iteration 4413 : loss : 0.031969, loss_ce: 0.012976
iteration 4414 : loss : 0.034007, loss_ce: 0.011143
iteration 4415 : loss : 0.032653, loss_ce: 0.011767
iteration 4416 : loss : 0.032895, loss_ce: 0.009750
iteration 4417 : loss : 0.036705, loss_ce: 0.018092
iteration 4418 : loss : 0.034603, loss_ce: 0.012546
iteration 4419 : loss : 0.032770, loss_ce: 0.013014
iteration 4420 : loss : 0.034630, loss_ce: 0.010423
iteration 4421 : loss : 0.039511, loss_ce: 0.007992
iteration 4422 : loss : 0.034606, loss_ce: 0.007977
iteration 4423 : loss : 0.032690, loss_ce: 0.008538
iteration 4424 : loss : 0.075137, loss_ce: 0.006623
iteration 4425 : loss : 0.044813, loss_ce: 0.011666
iteration 4426 : loss : 0.079614, loss_ce: 0.004418
iteration 4427 : loss : 0.033351, loss_ce: 0.010625
iteration 4428 : loss : 0.042827, loss_ce: 0.017527
iteration 4429 : loss : 0.035647, loss_ce: 0.016474
iteration 4430 : loss : 0.033934, loss_ce: 0.011572
iteration 4431 : loss : 0.036495, loss_ce: 0.008965
iteration 4432 : loss : 0.076677, loss_ce: 0.006028
iteration 4433 : loss : 0.037334, loss_ce: 0.012814
iteration 4434 : loss : 0.032729, loss_ce: 0.012366
iteration 4435 : loss : 0.041579, loss_ce: 0.014823
iteration 4436 : loss : 0.043165, loss_ce: 0.018402
iteration 4437 : loss : 0.039013, loss_ce: 0.011338
iteration 4438 : loss : 0.035470, loss_ce: 0.014269
iteration 4439 : loss : 0.038677, loss_ce: 0.014382
iteration 4440 : loss : 0.026683, loss_ce: 0.011933
iteration 4441 : loss : 0.051486, loss_ce: 0.009375
iteration 4442 : loss : 0.034243, loss_ce: 0.012738
iteration 4443 : loss : 0.034953, loss_ce: 0.008760
iteration 4444 : loss : 0.044444, loss_ce: 0.018367
iteration 4445 : loss : 0.032327, loss_ce: 0.012436
iteration 4446 : loss : 0.038333, loss_ce: 0.011376
iteration 4447 : loss : 0.128443, loss_ce: 0.003964
iteration 4448 : loss : 0.142810, loss_ce: 0.006173
iteration 4449 : loss : 0.038606, loss_ce: 0.013394
iteration 4450 : loss : 0.031727, loss_ce: 0.012816
iteration 4451 : loss : 0.082109, loss_ce: 0.013151
iteration 4452 : loss : 0.031910, loss_ce: 0.011585
iteration 4453 : loss : 0.035621, loss_ce: 0.023606
iteration 4454 : loss : 0.040381, loss_ce: 0.019076
iteration 4455 : loss : 0.029216, loss_ce: 0.010507
iteration 4456 : loss : 0.040045, loss_ce: 0.020525
iteration 4457 : loss : 0.034546, loss_ce: 0.007636
iteration 4458 : loss : 0.042874, loss_ce: 0.010089
iteration 4459 : loss : 0.048071, loss_ce: 0.013301
iteration 4460 : loss : 0.037649, loss_ce: 0.011769
iteration 4461 : loss : 0.038203, loss_ce: 0.016836
iteration 4462 : loss : 0.039099, loss_ce: 0.013492
iteration 4463 : loss : 0.030673, loss_ce: 0.010789
iteration 4464 : loss : 0.098230, loss_ce: 0.024482
 24%|███████▏                      | 48/200 [49:14<2:36:14, 61.67s/it]iteration 4465 : loss : 0.026371, loss_ce: 0.009879
iteration 4466 : loss : 0.034480, loss_ce: 0.011213
iteration 4467 : loss : 0.034515, loss_ce: 0.005800
iteration 4468 : loss : 0.029445, loss_ce: 0.011590
iteration 4469 : loss : 0.036866, loss_ce: 0.017072
iteration 4470 : loss : 0.041407, loss_ce: 0.014040
iteration 4471 : loss : 0.044998, loss_ce: 0.008882
iteration 4472 : loss : 0.033499, loss_ce: 0.014444
iteration 4473 : loss : 0.035271, loss_ce: 0.013280
iteration 4474 : loss : 0.032319, loss_ce: 0.013543
iteration 4475 : loss : 0.038736, loss_ce: 0.014548
iteration 4476 : loss : 0.033364, loss_ce: 0.015270
iteration 4477 : loss : 0.029143, loss_ce: 0.012753
iteration 4478 : loss : 0.037856, loss_ce: 0.010051
iteration 4479 : loss : 0.034379, loss_ce: 0.014644
iteration 4480 : loss : 0.035174, loss_ce: 0.013120
iteration 4481 : loss : 0.041075, loss_ce: 0.017657
iteration 4482 : loss : 0.029830, loss_ce: 0.008820
iteration 4483 : loss : 0.061908, loss_ce: 0.007319
iteration 4484 : loss : 0.037371, loss_ce: 0.014263
iteration 4485 : loss : 0.041564, loss_ce: 0.009166
iteration 4486 : loss : 0.050390, loss_ce: 0.013153
iteration 4487 : loss : 0.029911, loss_ce: 0.011718
iteration 4488 : loss : 0.089941, loss_ce: 0.010647
iteration 4489 : loss : 0.038121, loss_ce: 0.012574
iteration 4490 : loss : 0.046311, loss_ce: 0.012756
iteration 4491 : loss : 0.039608, loss_ce: 0.011480
iteration 4492 : loss : 0.042080, loss_ce: 0.013780
iteration 4493 : loss : 0.039217, loss_ce: 0.009044
iteration 4494 : loss : 0.036011, loss_ce: 0.016326
iteration 4495 : loss : 0.048876, loss_ce: 0.011958
iteration 4496 : loss : 0.041342, loss_ce: 0.015741
iteration 4497 : loss : 0.038451, loss_ce: 0.013105
iteration 4498 : loss : 0.029770, loss_ce: 0.008933
iteration 4499 : loss : 0.044139, loss_ce: 0.014423
iteration 4500 : loss : 0.032118, loss_ce: 0.009456
iteration 4501 : loss : 0.043053, loss_ce: 0.013195
iteration 4502 : loss : 0.030167, loss_ce: 0.006872
iteration 4503 : loss : 0.035364, loss_ce: 0.013512
iteration 4504 : loss : 0.036226, loss_ce: 0.010167
iteration 4505 : loss : 0.041606, loss_ce: 0.017469
iteration 4506 : loss : 0.028048, loss_ce: 0.009266
iteration 4507 : loss : 0.034522, loss_ce: 0.011773
iteration 4508 : loss : 0.049353, loss_ce: 0.014060
iteration 4509 : loss : 0.050454, loss_ce: 0.013463
iteration 4510 : loss : 0.031955, loss_ce: 0.009984
iteration 4511 : loss : 0.036322, loss_ce: 0.006224
iteration 4512 : loss : 0.030347, loss_ce: 0.007077
iteration 4513 : loss : 0.033649, loss_ce: 0.011878
iteration 4514 : loss : 0.035410, loss_ce: 0.015640
iteration 4515 : loss : 0.041313, loss_ce: 0.009669
iteration 4516 : loss : 0.042217, loss_ce: 0.013711
iteration 4517 : loss : 0.053288, loss_ce: 0.011872
iteration 4518 : loss : 0.033151, loss_ce: 0.007127
iteration 4519 : loss : 0.028882, loss_ce: 0.008802
iteration 4520 : loss : 0.035082, loss_ce: 0.013077
iteration 4521 : loss : 0.084475, loss_ce: 0.010661
iteration 4522 : loss : 0.036099, loss_ce: 0.014148
iteration 4523 : loss : 0.046120, loss_ce: 0.010022
iteration 4524 : loss : 0.030606, loss_ce: 0.008421
iteration 4525 : loss : 0.034881, loss_ce: 0.011937
iteration 4526 : loss : 0.044763, loss_ce: 0.015511
iteration 4527 : loss : 0.089316, loss_ce: 0.007922
iteration 4528 : loss : 0.034168, loss_ce: 0.016078
iteration 4529 : loss : 0.045195, loss_ce: 0.008247
iteration 4530 : loss : 0.038585, loss_ce: 0.020551
iteration 4531 : loss : 0.040094, loss_ce: 0.011054
iteration 4532 : loss : 0.052718, loss_ce: 0.010781
iteration 4533 : loss : 0.038796, loss_ce: 0.017124
iteration 4534 : loss : 0.041007, loss_ce: 0.021777
iteration 4535 : loss : 0.032590, loss_ce: 0.012226
iteration 4536 : loss : 0.033509, loss_ce: 0.009638
iteration 4537 : loss : 0.037194, loss_ce: 0.016061
iteration 4538 : loss : 0.037679, loss_ce: 0.009796
iteration 4539 : loss : 0.042323, loss_ce: 0.016484
iteration 4540 : loss : 0.029050, loss_ce: 0.013119
iteration 4541 : loss : 0.045821, loss_ce: 0.011348
iteration 4542 : loss : 0.040549, loss_ce: 0.019850
iteration 4543 : loss : 0.037574, loss_ce: 0.009838
iteration 4544 : loss : 0.032486, loss_ce: 0.014500
iteration 4545 : loss : 0.030081, loss_ce: 0.006618
iteration 4546 : loss : 0.037990, loss_ce: 0.009627
iteration 4547 : loss : 0.086182, loss_ce: 0.007303
iteration 4548 : loss : 0.035133, loss_ce: 0.006435
iteration 4549 : loss : 0.037343, loss_ce: 0.014387
iteration 4550 : loss : 0.035579, loss_ce: 0.014707
iteration 4551 : loss : 0.035586, loss_ce: 0.010668
iteration 4552 : loss : 0.042114, loss_ce: 0.010247
iteration 4553 : loss : 0.042067, loss_ce: 0.009652
iteration 4554 : loss : 0.082460, loss_ce: 0.007241
iteration 4555 : loss : 0.027352, loss_ce: 0.010975
iteration 4556 : loss : 0.045824, loss_ce: 0.017406
iteration 4557 : loss : 0.295340, loss_ce: 0.011966
 24%|███████▎                      | 49/200 [50:15<2:35:09, 61.65s/it]iteration 4558 : loss : 0.039850, loss_ce: 0.018943
iteration 4559 : loss : 0.050024, loss_ce: 0.010226
iteration 4560 : loss : 0.039529, loss_ce: 0.018377
iteration 4561 : loss : 0.035798, loss_ce: 0.018263
iteration 4562 : loss : 0.034434, loss_ce: 0.007906
iteration 4563 : loss : 0.035059, loss_ce: 0.012738
iteration 4564 : loss : 0.030276, loss_ce: 0.008384
iteration 4565 : loss : 0.034845, loss_ce: 0.011294
iteration 4566 : loss : 0.033944, loss_ce: 0.008149
iteration 4567 : loss : 0.030573, loss_ce: 0.011599
iteration 4568 : loss : 0.031026, loss_ce: 0.012658
iteration 4569 : loss : 0.035281, loss_ce: 0.010886
iteration 4570 : loss : 0.057752, loss_ce: 0.014691
iteration 4571 : loss : 0.032473, loss_ce: 0.009618
iteration 4572 : loss : 0.038331, loss_ce: 0.015832
iteration 4573 : loss : 0.035398, loss_ce: 0.013286
iteration 4574 : loss : 0.032257, loss_ce: 0.013046
iteration 4575 : loss : 0.025591, loss_ce: 0.008560
iteration 4576 : loss : 0.039567, loss_ce: 0.013158
iteration 4577 : loss : 0.031820, loss_ce: 0.012022
iteration 4578 : loss : 0.034411, loss_ce: 0.010431
iteration 4579 : loss : 0.033648, loss_ce: 0.015674
iteration 4580 : loss : 0.037168, loss_ce: 0.013261
iteration 4581 : loss : 0.034612, loss_ce: 0.016137
iteration 4582 : loss : 0.022645, loss_ce: 0.006188
iteration 4583 : loss : 0.032356, loss_ce: 0.010504
iteration 4584 : loss : 0.050502, loss_ce: 0.007090
iteration 4585 : loss : 0.037052, loss_ce: 0.016479
iteration 4586 : loss : 0.026180, loss_ce: 0.006259
iteration 4587 : loss : 0.026102, loss_ce: 0.009133
iteration 4588 : loss : 0.033475, loss_ce: 0.009780
iteration 4589 : loss : 0.031110, loss_ce: 0.010222
iteration 4590 : loss : 0.026146, loss_ce: 0.008830
iteration 4591 : loss : 0.034705, loss_ce: 0.010276
iteration 4592 : loss : 0.031366, loss_ce: 0.008938
iteration 4593 : loss : 0.035932, loss_ce: 0.018476
iteration 4594 : loss : 0.038220, loss_ce: 0.010569
iteration 4595 : loss : 0.028094, loss_ce: 0.006887
iteration 4596 : loss : 0.048326, loss_ce: 0.010351
iteration 4597 : loss : 0.028210, loss_ce: 0.014176
iteration 4598 : loss : 0.040971, loss_ce: 0.015835
iteration 4599 : loss : 0.037297, loss_ce: 0.014539
iteration 4600 : loss : 0.042564, loss_ce: 0.018145
iteration 4601 : loss : 0.033553, loss_ce: 0.011962
iteration 4602 : loss : 0.083980, loss_ce: 0.004967
iteration 4603 : loss : 0.043238, loss_ce: 0.012370
iteration 4604 : loss : 0.033063, loss_ce: 0.013839
iteration 4605 : loss : 0.039406, loss_ce: 0.015910
iteration 4606 : loss : 0.080303, loss_ce: 0.006293
iteration 4607 : loss : 0.034043, loss_ce: 0.010811
iteration 4608 : loss : 0.029873, loss_ce: 0.013335
iteration 4609 : loss : 0.082386, loss_ce: 0.012037
iteration 4610 : loss : 0.036215, loss_ce: 0.012454
iteration 4611 : loss : 0.029759, loss_ce: 0.009873
iteration 4612 : loss : 0.042186, loss_ce: 0.010699
iteration 4613 : loss : 0.027429, loss_ce: 0.009058
iteration 4614 : loss : 0.037519, loss_ce: 0.014742
iteration 4615 : loss : 0.125053, loss_ce: 0.004639
iteration 4616 : loss : 0.080375, loss_ce: 0.004964
iteration 4617 : loss : 0.037375, loss_ce: 0.021414
iteration 4618 : loss : 0.029788, loss_ce: 0.010268
iteration 4619 : loss : 0.076863, loss_ce: 0.011581
iteration 4620 : loss : 0.047001, loss_ce: 0.010248
iteration 4621 : loss : 0.139076, loss_ce: 0.012513
iteration 4622 : loss : 0.042309, loss_ce: 0.011411
iteration 4623 : loss : 0.034294, loss_ce: 0.009376
iteration 4624 : loss : 0.032342, loss_ce: 0.012235
iteration 4625 : loss : 0.032358, loss_ce: 0.010662
iteration 4626 : loss : 0.036285, loss_ce: 0.010782
iteration 4627 : loss : 0.075533, loss_ce: 0.008972
iteration 4628 : loss : 0.028251, loss_ce: 0.004447
iteration 4629 : loss : 0.075001, loss_ce: 0.011856
iteration 4630 : loss : 0.086128, loss_ce: 0.008319
iteration 4631 : loss : 0.040158, loss_ce: 0.016642
iteration 4632 : loss : 0.026440, loss_ce: 0.009800
iteration 4633 : loss : 0.034418, loss_ce: 0.009429
iteration 4634 : loss : 0.033304, loss_ce: 0.015031
iteration 4635 : loss : 0.054695, loss_ce: 0.015397
iteration 4636 : loss : 0.066002, loss_ce: 0.007210
iteration 4637 : loss : 0.034759, loss_ce: 0.011027
iteration 4638 : loss : 0.085802, loss_ce: 0.013864
iteration 4639 : loss : 0.041661, loss_ce: 0.011866
iteration 4640 : loss : 0.094738, loss_ce: 0.010434
iteration 4641 : loss : 0.036769, loss_ce: 0.012937
iteration 4642 : loss : 0.049893, loss_ce: 0.011466
iteration 4643 : loss : 0.032514, loss_ce: 0.011543
iteration 4644 : loss : 0.040355, loss_ce: 0.014761
iteration 4645 : loss : 0.051910, loss_ce: 0.009901
iteration 4646 : loss : 0.048713, loss_ce: 0.014978
iteration 4647 : loss : 0.043311, loss_ce: 0.017369
iteration 4648 : loss : 0.039531, loss_ce: 0.017386
iteration 4649 : loss : 0.043669, loss_ce: 0.015322
iteration 4650 : loss : 0.136394, loss_ce: 0.010695
 25%|███████▌                      | 50/200 [51:17<2:34:02, 61.61s/it]iteration 4651 : loss : 0.042918, loss_ce: 0.013544
iteration 4652 : loss : 0.049819, loss_ce: 0.022502
iteration 4653 : loss : 0.037618, loss_ce: 0.017037
iteration 4654 : loss : 0.033538, loss_ce: 0.011840
iteration 4655 : loss : 0.049714, loss_ce: 0.009163
iteration 4656 : loss : 0.034503, loss_ce: 0.010561
iteration 4657 : loss : 0.034336, loss_ce: 0.011217
iteration 4658 : loss : 0.042313, loss_ce: 0.011743
iteration 4659 : loss : 0.036217, loss_ce: 0.010466
iteration 4660 : loss : 0.034518, loss_ce: 0.006569
iteration 4661 : loss : 0.033442, loss_ce: 0.008744
iteration 4662 : loss : 0.036952, loss_ce: 0.016312
iteration 4663 : loss : 0.053603, loss_ce: 0.011211
iteration 4664 : loss : 0.036093, loss_ce: 0.008568
iteration 4665 : loss : 0.097412, loss_ce: 0.017350
iteration 4666 : loss : 0.029537, loss_ce: 0.010554
iteration 4667 : loss : 0.051315, loss_ce: 0.014431
iteration 4668 : loss : 0.045912, loss_ce: 0.012187
iteration 4669 : loss : 0.083760, loss_ce: 0.007994
iteration 4670 : loss : 0.035382, loss_ce: 0.009165
iteration 4671 : loss : 0.039967, loss_ce: 0.014180
iteration 4672 : loss : 0.075387, loss_ce: 0.010421
iteration 4673 : loss : 0.039747, loss_ce: 0.015005
iteration 4674 : loss : 0.035371, loss_ce: 0.012403
iteration 4675 : loss : 0.037526, loss_ce: 0.011784
iteration 4676 : loss : 0.045715, loss_ce: 0.015181
iteration 4677 : loss : 0.030542, loss_ce: 0.009958
iteration 4678 : loss : 0.039289, loss_ce: 0.014081
iteration 4679 : loss : 0.042794, loss_ce: 0.009367
iteration 4680 : loss : 0.043076, loss_ce: 0.006896
iteration 4681 : loss : 0.045721, loss_ce: 0.010572
iteration 4682 : loss : 0.036350, loss_ce: 0.009946
iteration 4683 : loss : 0.032608, loss_ce: 0.011795
iteration 4684 : loss : 0.030532, loss_ce: 0.008977
iteration 4685 : loss : 0.058866, loss_ce: 0.016690
iteration 4686 : loss : 0.039947, loss_ce: 0.012080
iteration 4687 : loss : 0.054222, loss_ce: 0.017984
iteration 4688 : loss : 0.043666, loss_ce: 0.009702
iteration 4689 : loss : 0.036368, loss_ce: 0.016337
iteration 4690 : loss : 0.037563, loss_ce: 0.014561
iteration 4691 : loss : 0.045115, loss_ce: 0.011345
iteration 4692 : loss : 0.034551, loss_ce: 0.008818
iteration 4693 : loss : 0.034565, loss_ce: 0.008773
iteration 4694 : loss : 0.042073, loss_ce: 0.015011
iteration 4695 : loss : 0.033946, loss_ce: 0.016801
iteration 4696 : loss : 0.046481, loss_ce: 0.016133
iteration 4697 : loss : 0.041228, loss_ce: 0.010372
iteration 4698 : loss : 0.030911, loss_ce: 0.012522
iteration 4699 : loss : 0.026535, loss_ce: 0.006139
iteration 4700 : loss : 0.087115, loss_ce: 0.009461
iteration 4701 : loss : 0.053656, loss_ce: 0.017415
iteration 4702 : loss : 0.034670, loss_ce: 0.011470
iteration 4703 : loss : 0.036351, loss_ce: 0.010375
iteration 4704 : loss : 0.035236, loss_ce: 0.011434
iteration 4705 : loss : 0.046670, loss_ce: 0.009960
iteration 4706 : loss : 0.033178, loss_ce: 0.015642
iteration 4707 : loss : 0.036786, loss_ce: 0.016957
iteration 4708 : loss : 0.029720, loss_ce: 0.011349
iteration 4709 : loss : 0.035837, loss_ce: 0.016294
iteration 4710 : loss : 0.032368, loss_ce: 0.012893
iteration 4711 : loss : 0.034174, loss_ce: 0.009340
iteration 4712 : loss : 0.040875, loss_ce: 0.019162
iteration 4713 : loss : 0.057725, loss_ce: 0.014024
iteration 4714 : loss : 0.039834, loss_ce: 0.013272
iteration 4715 : loss : 0.044631, loss_ce: 0.014373
iteration 4716 : loss : 0.032328, loss_ce: 0.011555
iteration 4717 : loss : 0.047345, loss_ce: 0.012756
iteration 4718 : loss : 0.032794, loss_ce: 0.010587
iteration 4719 : loss : 0.042593, loss_ce: 0.016340
iteration 4720 : loss : 0.045081, loss_ce: 0.010156
iteration 4721 : loss : 0.038328, loss_ce: 0.017937
iteration 4722 : loss : 0.035951, loss_ce: 0.013476
iteration 4723 : loss : 0.029650, loss_ce: 0.010499
iteration 4724 : loss : 0.035455, loss_ce: 0.011727
iteration 4725 : loss : 0.050288, loss_ce: 0.005611
iteration 4726 : loss : 0.032007, loss_ce: 0.009871
iteration 4727 : loss : 0.031273, loss_ce: 0.012079
iteration 4728 : loss : 0.039873, loss_ce: 0.013607
iteration 4729 : loss : 0.080165, loss_ce: 0.007152
iteration 4730 : loss : 0.032838, loss_ce: 0.007805
iteration 4731 : loss : 0.041106, loss_ce: 0.019237
iteration 4732 : loss : 0.054642, loss_ce: 0.013844
iteration 4733 : loss : 0.039339, loss_ce: 0.019150
iteration 4734 : loss : 0.081693, loss_ce: 0.007638
iteration 4735 : loss : 0.038355, loss_ce: 0.010298
iteration 4736 : loss : 0.032682, loss_ce: 0.012238
iteration 4737 : loss : 0.035910, loss_ce: 0.019442
iteration 4738 : loss : 0.030176, loss_ce: 0.009220
iteration 4739 : loss : 0.039179, loss_ce: 0.010588
iteration 4740 : loss : 0.032030, loss_ce: 0.009928
iteration 4741 : loss : 0.080615, loss_ce: 0.006045
iteration 4742 : loss : 0.082439, loss_ce: 0.007293
iteration 4743 : loss : 0.236948, loss_ce: 0.013498
 26%|███████▋                      | 51/200 [52:19<2:32:59, 61.61s/it]iteration 4744 : loss : 0.037883, loss_ce: 0.010721
iteration 4745 : loss : 0.048833, loss_ce: 0.010007
iteration 4746 : loss : 0.035396, loss_ce: 0.013178
iteration 4747 : loss : 0.036973, loss_ce: 0.009606
iteration 4748 : loss : 0.081569, loss_ce: 0.009882
iteration 4749 : loss : 0.079338, loss_ce: 0.007494
iteration 4750 : loss : 0.031213, loss_ce: 0.008057
iteration 4751 : loss : 0.034408, loss_ce: 0.013509
iteration 4752 : loss : 0.030562, loss_ce: 0.009387
iteration 4753 : loss : 0.037077, loss_ce: 0.013589
iteration 4754 : loss : 0.037919, loss_ce: 0.013232
iteration 4755 : loss : 0.030829, loss_ce: 0.011288
iteration 4756 : loss : 0.040111, loss_ce: 0.010713
iteration 4757 : loss : 0.043042, loss_ce: 0.009571
iteration 4758 : loss : 0.034973, loss_ce: 0.014851
iteration 4759 : loss : 0.039269, loss_ce: 0.016047
iteration 4760 : loss : 0.040971, loss_ce: 0.010921
iteration 4761 : loss : 0.034987, loss_ce: 0.015471
iteration 4762 : loss : 0.032973, loss_ce: 0.010356
iteration 4763 : loss : 0.026914, loss_ce: 0.012140
iteration 4764 : loss : 0.037774, loss_ce: 0.009323
iteration 4765 : loss : 0.037347, loss_ce: 0.017415
iteration 4766 : loss : 0.041775, loss_ce: 0.014527
iteration 4767 : loss : 0.036178, loss_ce: 0.011953
iteration 4768 : loss : 0.031369, loss_ce: 0.013471
iteration 4769 : loss : 0.031238, loss_ce: 0.014141
iteration 4770 : loss : 0.036031, loss_ce: 0.010440
iteration 4771 : loss : 0.088704, loss_ce: 0.009179
iteration 4772 : loss : 0.033626, loss_ce: 0.012845
iteration 4773 : loss : 0.031507, loss_ce: 0.015342
iteration 4774 : loss : 0.038704, loss_ce: 0.012067
iteration 4775 : loss : 0.037860, loss_ce: 0.017605
iteration 4776 : loss : 0.028127, loss_ce: 0.012001
iteration 4777 : loss : 0.030038, loss_ce: 0.009096
iteration 4778 : loss : 0.036665, loss_ce: 0.013699
iteration 4779 : loss : 0.038953, loss_ce: 0.009783
iteration 4780 : loss : 0.036415, loss_ce: 0.015657
iteration 4781 : loss : 0.034934, loss_ce: 0.014347
iteration 4782 : loss : 0.039483, loss_ce: 0.011888
iteration 4783 : loss : 0.035888, loss_ce: 0.013349
iteration 4784 : loss : 0.037679, loss_ce: 0.014998
iteration 4785 : loss : 0.037935, loss_ce: 0.010434
iteration 4786 : loss : 0.041826, loss_ce: 0.011751
iteration 4787 : loss : 0.032586, loss_ce: 0.010745
iteration 4788 : loss : 0.028303, loss_ce: 0.009384
iteration 4789 : loss : 0.046311, loss_ce: 0.011404
iteration 4790 : loss : 0.034869, loss_ce: 0.012348
iteration 4791 : loss : 0.047113, loss_ce: 0.008926
iteration 4792 : loss : 0.034773, loss_ce: 0.012249
iteration 4793 : loss : 0.034368, loss_ce: 0.014737
iteration 4794 : loss : 0.038862, loss_ce: 0.009952
iteration 4795 : loss : 0.033919, loss_ce: 0.010036
iteration 4796 : loss : 0.034723, loss_ce: 0.012666
iteration 4797 : loss : 0.034716, loss_ce: 0.006868
iteration 4798 : loss : 0.029010, loss_ce: 0.011525
iteration 4799 : loss : 0.039768, loss_ce: 0.010797
iteration 4800 : loss : 0.032173, loss_ce: 0.010528
iteration 4801 : loss : 0.038751, loss_ce: 0.010280
iteration 4802 : loss : 0.036524, loss_ce: 0.011579
iteration 4803 : loss : 0.031098, loss_ce: 0.011495
iteration 4804 : loss : 0.036305, loss_ce: 0.011717
iteration 4805 : loss : 0.038880, loss_ce: 0.006118
iteration 4806 : loss : 0.091268, loss_ce: 0.008365
iteration 4807 : loss : 0.040684, loss_ce: 0.013300
iteration 4808 : loss : 0.043105, loss_ce: 0.010913
iteration 4809 : loss : 0.040957, loss_ce: 0.007401
iteration 4810 : loss : 0.034817, loss_ce: 0.013556
iteration 4811 : loss : 0.033684, loss_ce: 0.010403
iteration 4812 : loss : 0.039193, loss_ce: 0.014112
iteration 4813 : loss : 0.083262, loss_ce: 0.009094
iteration 4814 : loss : 0.041566, loss_ce: 0.006900
iteration 4815 : loss : 0.087583, loss_ce: 0.011205
iteration 4816 : loss : 0.031775, loss_ce: 0.010969
iteration 4817 : loss : 0.030602, loss_ce: 0.012132
iteration 4818 : loss : 0.041174, loss_ce: 0.011864
iteration 4819 : loss : 0.026442, loss_ce: 0.011136
iteration 4820 : loss : 0.046052, loss_ce: 0.017139
iteration 4821 : loss : 0.040570, loss_ce: 0.013564
iteration 4822 : loss : 0.037148, loss_ce: 0.014781
iteration 4823 : loss : 0.033831, loss_ce: 0.011619
iteration 4824 : loss : 0.083555, loss_ce: 0.006066
iteration 4825 : loss : 0.040294, loss_ce: 0.008559
iteration 4826 : loss : 0.035905, loss_ce: 0.006780
iteration 4827 : loss : 0.036674, loss_ce: 0.011651
iteration 4828 : loss : 0.085049, loss_ce: 0.008664
iteration 4829 : loss : 0.035291, loss_ce: 0.014506
iteration 4830 : loss : 0.057311, loss_ce: 0.009228
iteration 4831 : loss : 0.030608, loss_ce: 0.011361
iteration 4832 : loss : 0.029206, loss_ce: 0.010240
iteration 4833 : loss : 0.038798, loss_ce: 0.012321
iteration 4834 : loss : 0.036398, loss_ce: 0.013290
iteration 4835 : loss : 0.082573, loss_ce: 0.015746
iteration 4836 : loss : 0.203449, loss_ce: 0.042429
 26%|███████▊                      | 52/200 [53:20<2:31:55, 61.59s/it]iteration 4837 : loss : 0.039413, loss_ce: 0.011791
iteration 4838 : loss : 0.049050, loss_ce: 0.014447
iteration 4839 : loss : 0.073510, loss_ce: 0.011892
iteration 4840 : loss : 0.035708, loss_ce: 0.016499
iteration 4841 : loss : 0.041670, loss_ce: 0.019586
iteration 4842 : loss : 0.087139, loss_ce: 0.008780
iteration 4843 : loss : 0.040250, loss_ce: 0.016779
iteration 4844 : loss : 0.050836, loss_ce: 0.010252
iteration 4845 : loss : 0.046368, loss_ce: 0.016629
iteration 4846 : loss : 0.047105, loss_ce: 0.010310
iteration 4847 : loss : 0.039947, loss_ce: 0.009116
iteration 4848 : loss : 0.041024, loss_ce: 0.009583
iteration 4849 : loss : 0.089661, loss_ce: 0.013615
iteration 4850 : loss : 0.067477, loss_ce: 0.009606
iteration 4851 : loss : 0.035440, loss_ce: 0.010795
iteration 4852 : loss : 0.043592, loss_ce: 0.018090
iteration 4853 : loss : 0.047156, loss_ce: 0.019171
iteration 4854 : loss : 0.079573, loss_ce: 0.010239
iteration 4855 : loss : 0.030051, loss_ce: 0.007794
iteration 4856 : loss : 0.041202, loss_ce: 0.013261
iteration 4857 : loss : 0.034542, loss_ce: 0.007121
iteration 4858 : loss : 0.033536, loss_ce: 0.015314
iteration 4859 : loss : 0.087659, loss_ce: 0.013136
iteration 4860 : loss : 0.049003, loss_ce: 0.012090
iteration 4861 : loss : 0.041149, loss_ce: 0.011967
iteration 4862 : loss : 0.030928, loss_ce: 0.012547
iteration 4863 : loss : 0.042006, loss_ce: 0.015364
iteration 4864 : loss : 0.040489, loss_ce: 0.014178
iteration 4865 : loss : 0.035579, loss_ce: 0.008702
iteration 4866 : loss : 0.034581, loss_ce: 0.010522
iteration 4867 : loss : 0.034247, loss_ce: 0.011188
iteration 4868 : loss : 0.089112, loss_ce: 0.008385
iteration 4869 : loss : 0.039845, loss_ce: 0.011994
iteration 4870 : loss : 0.038016, loss_ce: 0.013913
iteration 4871 : loss : 0.039512, loss_ce: 0.012910
iteration 4872 : loss : 0.033412, loss_ce: 0.011477
iteration 4873 : loss : 0.033674, loss_ce: 0.015131
iteration 4874 : loss : 0.042200, loss_ce: 0.012417
iteration 4875 : loss : 0.042556, loss_ce: 0.008798
iteration 4876 : loss : 0.029638, loss_ce: 0.012204
iteration 4877 : loss : 0.042760, loss_ce: 0.010510
iteration 4878 : loss : 0.078476, loss_ce: 0.006531
iteration 4879 : loss : 0.079365, loss_ce: 0.010731
iteration 4880 : loss : 0.031946, loss_ce: 0.007493
iteration 4881 : loss : 0.033419, loss_ce: 0.012655
iteration 4882 : loss : 0.040868, loss_ce: 0.013099
iteration 4883 : loss : 0.033514, loss_ce: 0.014145
iteration 4884 : loss : 0.028246, loss_ce: 0.006976
iteration 4885 : loss : 0.041165, loss_ce: 0.017647
iteration 4886 : loss : 0.048307, loss_ce: 0.012147
iteration 4887 : loss : 0.042139, loss_ce: 0.007927
iteration 4888 : loss : 0.039383, loss_ce: 0.012346
iteration 4889 : loss : 0.030587, loss_ce: 0.011800
iteration 4890 : loss : 0.032666, loss_ce: 0.013312
iteration 4891 : loss : 0.032627, loss_ce: 0.008468
iteration 4892 : loss : 0.085883, loss_ce: 0.013475
iteration 4893 : loss : 0.035734, loss_ce: 0.015229
iteration 4894 : loss : 0.036823, loss_ce: 0.013882
iteration 4895 : loss : 0.033640, loss_ce: 0.009017
iteration 4896 : loss : 0.036547, loss_ce: 0.014052
iteration 4897 : loss : 0.030318, loss_ce: 0.010502
iteration 4898 : loss : 0.035405, loss_ce: 0.014164
iteration 4899 : loss : 0.039115, loss_ce: 0.017751
iteration 4900 : loss : 0.048025, loss_ce: 0.010491
iteration 4901 : loss : 0.028655, loss_ce: 0.007524
iteration 4902 : loss : 0.035252, loss_ce: 0.010557
iteration 4903 : loss : 0.035366, loss_ce: 0.014207
iteration 4904 : loss : 0.041179, loss_ce: 0.013243
iteration 4905 : loss : 0.036712, loss_ce: 0.009324
iteration 4906 : loss : 0.028787, loss_ce: 0.011755
iteration 4907 : loss : 0.079063, loss_ce: 0.007595
iteration 4908 : loss : 0.035394, loss_ce: 0.012029
iteration 4909 : loss : 0.034700, loss_ce: 0.017810
iteration 4910 : loss : 0.029720, loss_ce: 0.010457
iteration 4911 : loss : 0.037022, loss_ce: 0.010729
iteration 4912 : loss : 0.037203, loss_ce: 0.013158
iteration 4913 : loss : 0.038810, loss_ce: 0.012779
iteration 4914 : loss : 0.031050, loss_ce: 0.009172
iteration 4915 : loss : 0.032344, loss_ce: 0.013704
iteration 4916 : loss : 0.036572, loss_ce: 0.013611
iteration 4917 : loss : 0.033716, loss_ce: 0.011230
iteration 4918 : loss : 0.043594, loss_ce: 0.011383
iteration 4919 : loss : 0.090583, loss_ce: 0.008210
iteration 4920 : loss : 0.082511, loss_ce: 0.010488
iteration 4921 : loss : 0.028212, loss_ce: 0.010319
iteration 4922 : loss : 0.033252, loss_ce: 0.014241
iteration 4923 : loss : 0.033731, loss_ce: 0.012473
iteration 4924 : loss : 0.026740, loss_ce: 0.009728
iteration 4925 : loss : 0.036259, loss_ce: 0.014546
iteration 4926 : loss : 0.030093, loss_ce: 0.011465
iteration 4927 : loss : 0.035926, loss_ce: 0.012256
iteration 4928 : loss : 0.026964, loss_ce: 0.011336
iteration 4929 : loss : 0.104746, loss_ce: 0.014846
 26%|███████▉                      | 53/200 [54:24<2:32:46, 62.36s/it]iteration 4930 : loss : 0.029228, loss_ce: 0.010856
iteration 4931 : loss : 0.096454, loss_ce: 0.007292
iteration 4932 : loss : 0.032508, loss_ce: 0.016070
iteration 4933 : loss : 0.078133, loss_ce: 0.005176
iteration 4934 : loss : 0.034599, loss_ce: 0.011267
iteration 4935 : loss : 0.033218, loss_ce: 0.010458
iteration 4936 : loss : 0.034909, loss_ce: 0.009476
iteration 4937 : loss : 0.034250, loss_ce: 0.013164
iteration 4938 : loss : 0.082242, loss_ce: 0.012691
iteration 4939 : loss : 0.034024, loss_ce: 0.013917
iteration 4940 : loss : 0.043279, loss_ce: 0.009500
iteration 4941 : loss : 0.032554, loss_ce: 0.013007
iteration 4942 : loss : 0.112015, loss_ce: 0.006298
iteration 4943 : loss : 0.041522, loss_ce: 0.012220
iteration 4944 : loss : 0.036435, loss_ce: 0.007772
iteration 4945 : loss : 0.033229, loss_ce: 0.012186
iteration 4946 : loss : 0.028028, loss_ce: 0.007851
iteration 4947 : loss : 0.033691, loss_ce: 0.011236
iteration 4948 : loss : 0.036843, loss_ce: 0.012338
iteration 4949 : loss : 0.028454, loss_ce: 0.008894
iteration 4950 : loss : 0.031026, loss_ce: 0.008155
iteration 4951 : loss : 0.032877, loss_ce: 0.012686
iteration 4952 : loss : 0.078145, loss_ce: 0.009478
iteration 4953 : loss : 0.037918, loss_ce: 0.016315
iteration 4954 : loss : 0.038916, loss_ce: 0.014923
iteration 4955 : loss : 0.035586, loss_ce: 0.012364
iteration 4956 : loss : 0.040211, loss_ce: 0.014659
iteration 4957 : loss : 0.038495, loss_ce: 0.019115
iteration 4958 : loss : 0.034307, loss_ce: 0.013929
iteration 4959 : loss : 0.037313, loss_ce: 0.009611
iteration 4960 : loss : 0.044109, loss_ce: 0.015598
iteration 4961 : loss : 0.043134, loss_ce: 0.017326
iteration 4962 : loss : 0.066230, loss_ce: 0.012401
iteration 4963 : loss : 0.037506, loss_ce: 0.011991
iteration 4964 : loss : 0.038044, loss_ce: 0.017628
iteration 4965 : loss : 0.082180, loss_ce: 0.008213
iteration 4966 : loss : 0.028683, loss_ce: 0.011324
iteration 4967 : loss : 0.035463, loss_ce: 0.008212
iteration 4968 : loss : 0.041284, loss_ce: 0.015498
iteration 4969 : loss : 0.041817, loss_ce: 0.010392
iteration 4970 : loss : 0.057253, loss_ce: 0.008922
iteration 4971 : loss : 0.085635, loss_ce: 0.012624
iteration 4972 : loss : 0.041751, loss_ce: 0.015919
iteration 4973 : loss : 0.032420, loss_ce: 0.016109
iteration 4974 : loss : 0.035893, loss_ce: 0.009146
iteration 4975 : loss : 0.044755, loss_ce: 0.012327
iteration 4976 : loss : 0.029319, loss_ce: 0.010034
iteration 4977 : loss : 0.030735, loss_ce: 0.007470
iteration 4978 : loss : 0.039235, loss_ce: 0.016367
iteration 4979 : loss : 0.031885, loss_ce: 0.016657
iteration 4980 : loss : 0.036305, loss_ce: 0.012431
iteration 4981 : loss : 0.033881, loss_ce: 0.013356
iteration 4982 : loss : 0.031201, loss_ce: 0.009760
iteration 4983 : loss : 0.037008, loss_ce: 0.014476
iteration 4984 : loss : 0.127705, loss_ce: 0.003937
iteration 4985 : loss : 0.037694, loss_ce: 0.014606
iteration 4986 : loss : 0.032856, loss_ce: 0.007498
iteration 4987 : loss : 0.036258, loss_ce: 0.009777
iteration 4988 : loss : 0.035313, loss_ce: 0.015822
iteration 4989 : loss : 0.031470, loss_ce: 0.014788
iteration 4990 : loss : 0.034893, loss_ce: 0.009551
iteration 4991 : loss : 0.041335, loss_ce: 0.006910
iteration 4992 : loss : 0.033358, loss_ce: 0.010986
iteration 4993 : loss : 0.056731, loss_ce: 0.007615
iteration 4994 : loss : 0.038478, loss_ce: 0.015249
iteration 4995 : loss : 0.079037, loss_ce: 0.005466
iteration 4996 : loss : 0.035979, loss_ce: 0.014995
iteration 4997 : loss : 0.073096, loss_ce: 0.004323
iteration 4998 : loss : 0.030971, loss_ce: 0.012640
iteration 4999 : loss : 0.033849, loss_ce: 0.009615
iteration 5000 : loss : 0.041548, loss_ce: 0.015552
iteration 5001 : loss : 0.031220, loss_ce: 0.010598
iteration 5002 : loss : 0.041419, loss_ce: 0.009958
iteration 5003 : loss : 0.034244, loss_ce: 0.015734
iteration 5004 : loss : 0.033481, loss_ce: 0.014693
iteration 5005 : loss : 0.036804, loss_ce: 0.013128
iteration 5006 : loss : 0.087326, loss_ce: 0.009635
iteration 5007 : loss : 0.041876, loss_ce: 0.007019
iteration 5008 : loss : 0.082264, loss_ce: 0.013933
iteration 5009 : loss : 0.041128, loss_ce: 0.017942
iteration 5010 : loss : 0.036329, loss_ce: 0.007112
iteration 5011 : loss : 0.036326, loss_ce: 0.010209
iteration 5012 : loss : 0.036642, loss_ce: 0.012049
iteration 5013 : loss : 0.054096, loss_ce: 0.008142
iteration 5014 : loss : 0.081319, loss_ce: 0.008096
iteration 5015 : loss : 0.035894, loss_ce: 0.019060
iteration 5016 : loss : 0.035962, loss_ce: 0.010030
iteration 5017 : loss : 0.024328, loss_ce: 0.005375
iteration 5018 : loss : 0.029377, loss_ce: 0.010452
iteration 5019 : loss : 0.049917, loss_ce: 0.011763
iteration 5020 : loss : 0.036569, loss_ce: 0.016315
iteration 5021 : loss : 0.045456, loss_ce: 0.013442
iteration 5022 : loss : 0.409244, loss_ce: 0.006789
 27%|████████                      | 54/200 [55:26<2:31:08, 62.12s/it]iteration 5023 : loss : 0.045293, loss_ce: 0.009958
iteration 5024 : loss : 0.038346, loss_ce: 0.011305
iteration 5025 : loss : 0.046346, loss_ce: 0.014357
iteration 5026 : loss : 0.063077, loss_ce: 0.020172
iteration 5027 : loss : 0.047505, loss_ce: 0.026752
iteration 5028 : loss : 0.053521, loss_ce: 0.020831
iteration 5029 : loss : 0.048320, loss_ce: 0.027340
iteration 5030 : loss : 0.038865, loss_ce: 0.022762
iteration 5031 : loss : 0.041400, loss_ce: 0.018094
iteration 5032 : loss : 0.038127, loss_ce: 0.016581
iteration 5033 : loss : 0.044547, loss_ce: 0.015592
iteration 5034 : loss : 0.043484, loss_ce: 0.014765
iteration 5035 : loss : 0.089630, loss_ce: 0.013339
iteration 5036 : loss : 0.032339, loss_ce: 0.013192
iteration 5037 : loss : 0.035562, loss_ce: 0.013072
iteration 5038 : loss : 0.038335, loss_ce: 0.010652
iteration 5039 : loss : 0.043359, loss_ce: 0.013562
iteration 5040 : loss : 0.040311, loss_ce: 0.012165
iteration 5041 : loss : 0.035877, loss_ce: 0.010706
iteration 5042 : loss : 0.032920, loss_ce: 0.010049
iteration 5043 : loss : 0.031570, loss_ce: 0.010263
iteration 5044 : loss : 0.036958, loss_ce: 0.013717
iteration 5045 : loss : 0.037422, loss_ce: 0.015176
iteration 5046 : loss : 0.092337, loss_ce: 0.013547
iteration 5047 : loss : 0.046110, loss_ce: 0.011630
iteration 5048 : loss : 0.045718, loss_ce: 0.011831
iteration 5049 : loss : 0.032999, loss_ce: 0.014444
iteration 5050 : loss : 0.106735, loss_ce: 0.007836
iteration 5051 : loss : 0.033585, loss_ce: 0.011984
iteration 5052 : loss : 0.037425, loss_ce: 0.017112
iteration 5053 : loss : 0.041852, loss_ce: 0.013450
iteration 5054 : loss : 0.035183, loss_ce: 0.010582
iteration 5055 : loss : 0.033958, loss_ce: 0.009117
iteration 5056 : loss : 0.082323, loss_ce: 0.007646
iteration 5057 : loss : 0.046359, loss_ce: 0.014826
iteration 5058 : loss : 0.034427, loss_ce: 0.011294
iteration 5059 : loss : 0.040587, loss_ce: 0.012933
iteration 5060 : loss : 0.041991, loss_ce: 0.015908
iteration 5061 : loss : 0.034826, loss_ce: 0.010519
iteration 5062 : loss : 0.031380, loss_ce: 0.010556
iteration 5063 : loss : 0.034286, loss_ce: 0.014233
iteration 5064 : loss : 0.033242, loss_ce: 0.007655
iteration 5065 : loss : 0.050479, loss_ce: 0.007727
iteration 5066 : loss : 0.035512, loss_ce: 0.016295
iteration 5067 : loss : 0.089712, loss_ce: 0.009470
iteration 5068 : loss : 0.039362, loss_ce: 0.012248
iteration 5069 : loss : 0.038266, loss_ce: 0.013566
iteration 5070 : loss : 0.038263, loss_ce: 0.007607
iteration 5071 : loss : 0.040920, loss_ce: 0.018316
iteration 5072 : loss : 0.042345, loss_ce: 0.017878
iteration 5073 : loss : 0.042163, loss_ce: 0.016925
iteration 5074 : loss : 0.041967, loss_ce: 0.011055
iteration 5075 : loss : 0.042559, loss_ce: 0.015534
iteration 5076 : loss : 0.025345, loss_ce: 0.008130
iteration 5077 : loss : 0.030869, loss_ce: 0.011815
iteration 5078 : loss : 0.029577, loss_ce: 0.010825
iteration 5079 : loss : 0.094678, loss_ce: 0.008067
iteration 5080 : loss : 0.034566, loss_ce: 0.011350
iteration 5081 : loss : 0.039020, loss_ce: 0.010169
iteration 5082 : loss : 0.038395, loss_ce: 0.013531
iteration 5083 : loss : 0.031277, loss_ce: 0.013108
iteration 5084 : loss : 0.041727, loss_ce: 0.016131
iteration 5085 : loss : 0.034561, loss_ce: 0.011984
iteration 5086 : loss : 0.042427, loss_ce: 0.013133
iteration 5087 : loss : 0.031787, loss_ce: 0.006305
iteration 5088 : loss : 0.028921, loss_ce: 0.009136
iteration 5089 : loss : 0.082733, loss_ce: 0.010705
iteration 5090 : loss : 0.026525, loss_ce: 0.008223
iteration 5091 : loss : 0.040276, loss_ce: 0.013061
iteration 5092 : loss : 0.039034, loss_ce: 0.018618
iteration 5093 : loss : 0.034848, loss_ce: 0.011526
iteration 5094 : loss : 0.036898, loss_ce: 0.011308
iteration 5095 : loss : 0.132305, loss_ce: 0.008037
iteration 5096 : loss : 0.034634, loss_ce: 0.013181
iteration 5097 : loss : 0.036603, loss_ce: 0.007010
iteration 5098 : loss : 0.028798, loss_ce: 0.009098
iteration 5099 : loss : 0.026204, loss_ce: 0.010280
iteration 5100 : loss : 0.034318, loss_ce: 0.010012
iteration 5101 : loss : 0.042504, loss_ce: 0.017459
iteration 5102 : loss : 0.044750, loss_ce: 0.011183
iteration 5103 : loss : 0.040517, loss_ce: 0.011889
iteration 5104 : loss : 0.048992, loss_ce: 0.013316
iteration 5105 : loss : 0.038056, loss_ce: 0.014608
iteration 5106 : loss : 0.063080, loss_ce: 0.010670
iteration 5107 : loss : 0.036372, loss_ce: 0.016337
iteration 5108 : loss : 0.040590, loss_ce: 0.008435
iteration 5109 : loss : 0.036494, loss_ce: 0.008267
iteration 5110 : loss : 0.024166, loss_ce: 0.007460
iteration 5111 : loss : 0.052517, loss_ce: 0.011643
iteration 5112 : loss : 0.031532, loss_ce: 0.012255
iteration 5113 : loss : 0.057466, loss_ce: 0.004086
iteration 5114 : loss : 0.036230, loss_ce: 0.011669
iteration 5115 : loss : 0.136830, loss_ce: 0.008605
 28%|████████▎                     | 55/200 [56:27<2:29:29, 61.86s/it]iteration 5116 : loss : 0.049369, loss_ce: 0.016121
iteration 5117 : loss : 0.039593, loss_ce: 0.011324
iteration 5118 : loss : 0.042513, loss_ce: 0.020324
iteration 5119 : loss : 0.066291, loss_ce: 0.008735
iteration 5120 : loss : 0.034610, loss_ce: 0.015570
iteration 5121 : loss : 0.034565, loss_ce: 0.012336
iteration 5122 : loss : 0.036396, loss_ce: 0.015500
iteration 5123 : loss : 0.038120, loss_ce: 0.008811
iteration 5124 : loss : 0.044538, loss_ce: 0.017771
iteration 5125 : loss : 0.039105, loss_ce: 0.016602
iteration 5126 : loss : 0.040751, loss_ce: 0.014742
iteration 5127 : loss : 0.030307, loss_ce: 0.008025
iteration 5128 : loss : 0.039016, loss_ce: 0.008786
iteration 5129 : loss : 0.040720, loss_ce: 0.014801
iteration 5130 : loss : 0.081706, loss_ce: 0.009110
iteration 5131 : loss : 0.036388, loss_ce: 0.014925
iteration 5132 : loss : 0.032815, loss_ce: 0.015382
iteration 5133 : loss : 0.035575, loss_ce: 0.009775
iteration 5134 : loss : 0.028947, loss_ce: 0.013188
iteration 5135 : loss : 0.032793, loss_ce: 0.008313
iteration 5136 : loss : 0.036303, loss_ce: 0.008603
iteration 5137 : loss : 0.036906, loss_ce: 0.015309
iteration 5138 : loss : 0.036447, loss_ce: 0.013389
iteration 5139 : loss : 0.033901, loss_ce: 0.012989
iteration 5140 : loss : 0.043308, loss_ce: 0.018335
iteration 5141 : loss : 0.035192, loss_ce: 0.010713
iteration 5142 : loss : 0.040316, loss_ce: 0.011146
iteration 5143 : loss : 0.040213, loss_ce: 0.015174
iteration 5144 : loss : 0.048653, loss_ce: 0.012064
iteration 5145 : loss : 0.041746, loss_ce: 0.013207
iteration 5146 : loss : 0.034505, loss_ce: 0.009437
iteration 5147 : loss : 0.040362, loss_ce: 0.016578
iteration 5148 : loss : 0.034589, loss_ce: 0.010618
iteration 5149 : loss : 0.036908, loss_ce: 0.008878
iteration 5150 : loss : 0.035484, loss_ce: 0.015026
iteration 5151 : loss : 0.033516, loss_ce: 0.012371
iteration 5152 : loss : 0.039106, loss_ce: 0.013861
iteration 5153 : loss : 0.039537, loss_ce: 0.011868
iteration 5154 : loss : 0.081405, loss_ce: 0.014998
iteration 5155 : loss : 0.033170, loss_ce: 0.014200
iteration 5156 : loss : 0.026491, loss_ce: 0.006605
iteration 5157 : loss : 0.031273, loss_ce: 0.006579
iteration 5158 : loss : 0.029525, loss_ce: 0.010952
iteration 5159 : loss : 0.029703, loss_ce: 0.013038
iteration 5160 : loss : 0.036572, loss_ce: 0.010283
iteration 5161 : loss : 0.035266, loss_ce: 0.011727
iteration 5162 : loss : 0.085651, loss_ce: 0.011624
iteration 5163 : loss : 0.032422, loss_ce: 0.011986
iteration 5164 : loss : 0.064183, loss_ce: 0.013335
iteration 5165 : loss : 0.033297, loss_ce: 0.010141
iteration 5166 : loss : 0.031520, loss_ce: 0.011280
iteration 5167 : loss : 0.086980, loss_ce: 0.012018
iteration 5168 : loss : 0.042342, loss_ce: 0.015876
iteration 5169 : loss : 0.034370, loss_ce: 0.013287
iteration 5170 : loss : 0.037438, loss_ce: 0.011945
iteration 5171 : loss : 0.032525, loss_ce: 0.009981
iteration 5172 : loss : 0.032223, loss_ce: 0.009811
iteration 5173 : loss : 0.033149, loss_ce: 0.008051
iteration 5174 : loss : 0.033329, loss_ce: 0.006112
iteration 5175 : loss : 0.024427, loss_ce: 0.007384
iteration 5176 : loss : 0.036758, loss_ce: 0.014044
iteration 5177 : loss : 0.041433, loss_ce: 0.012496
iteration 5178 : loss : 0.087121, loss_ce: 0.012450
iteration 5179 : loss : 0.029672, loss_ce: 0.011352
iteration 5180 : loss : 0.040703, loss_ce: 0.012068
iteration 5181 : loss : 0.083546, loss_ce: 0.009719
iteration 5182 : loss : 0.038350, loss_ce: 0.015834
iteration 5183 : loss : 0.035563, loss_ce: 0.016078
iteration 5184 : loss : 0.033842, loss_ce: 0.011225
iteration 5185 : loss : 0.034141, loss_ce: 0.011098
iteration 5186 : loss : 0.042565, loss_ce: 0.015518
iteration 5187 : loss : 0.039937, loss_ce: 0.009762
iteration 5188 : loss : 0.027605, loss_ce: 0.011821
iteration 5189 : loss : 0.039591, loss_ce: 0.010745
iteration 5190 : loss : 0.073805, loss_ce: 0.009535
iteration 5191 : loss : 0.082862, loss_ce: 0.005262
iteration 5192 : loss : 0.034038, loss_ce: 0.014786
iteration 5193 : loss : 0.099488, loss_ce: 0.007447
iteration 5194 : loss : 0.034508, loss_ce: 0.010978
iteration 5195 : loss : 0.039529, loss_ce: 0.010705
iteration 5196 : loss : 0.043588, loss_ce: 0.009537
iteration 5197 : loss : 0.034548, loss_ce: 0.008728
iteration 5198 : loss : 0.048387, loss_ce: 0.009588
iteration 5199 : loss : 0.036995, loss_ce: 0.013346
iteration 5200 : loss : 0.089553, loss_ce: 0.007187
iteration 5201 : loss : 0.035872, loss_ce: 0.010082
iteration 5202 : loss : 0.037570, loss_ce: 0.008723
iteration 5203 : loss : 0.033626, loss_ce: 0.009933
iteration 5204 : loss : 0.038458, loss_ce: 0.014052
iteration 5205 : loss : 0.037513, loss_ce: 0.008670
iteration 5206 : loss : 0.032133, loss_ce: 0.011322
iteration 5207 : loss : 0.047986, loss_ce: 0.008313
iteration 5208 : loss : 0.063241, loss_ce: 0.031562
 28%|████████▍                     | 56/200 [57:29<2:28:20, 61.81s/it]iteration 5209 : loss : 0.031744, loss_ce: 0.010265
iteration 5210 : loss : 0.034894, loss_ce: 0.014627
iteration 5211 : loss : 0.040951, loss_ce: 0.008679
iteration 5212 : loss : 0.030844, loss_ce: 0.014690
iteration 5213 : loss : 0.086248, loss_ce: 0.006941
iteration 5214 : loss : 0.087997, loss_ce: 0.010018
iteration 5215 : loss : 0.036429, loss_ce: 0.009203
iteration 5216 : loss : 0.035795, loss_ce: 0.011447
iteration 5217 : loss : 0.058548, loss_ce: 0.009034
iteration 5218 : loss : 0.039406, loss_ce: 0.012012
iteration 5219 : loss : 0.033297, loss_ce: 0.008088
iteration 5220 : loss : 0.051597, loss_ce: 0.010951
iteration 5221 : loss : 0.033972, loss_ce: 0.013470
iteration 5222 : loss : 0.036717, loss_ce: 0.008099
iteration 5223 : loss : 0.065922, loss_ce: 0.006081
iteration 5224 : loss : 0.034313, loss_ce: 0.010451
iteration 5225 : loss : 0.036409, loss_ce: 0.013682
iteration 5226 : loss : 0.044350, loss_ce: 0.010327
iteration 5227 : loss : 0.031075, loss_ce: 0.008680
iteration 5228 : loss : 0.034836, loss_ce: 0.009543
iteration 5229 : loss : 0.035312, loss_ce: 0.012100
iteration 5230 : loss : 0.026861, loss_ce: 0.014262
iteration 5231 : loss : 0.039061, loss_ce: 0.014151
iteration 5232 : loss : 0.035802, loss_ce: 0.012128
iteration 5233 : loss : 0.054161, loss_ce: 0.015844
iteration 5234 : loss : 0.031023, loss_ce: 0.009292
iteration 5235 : loss : 0.040218, loss_ce: 0.010548
iteration 5236 : loss : 0.036127, loss_ce: 0.012026
iteration 5237 : loss : 0.042704, loss_ce: 0.012072
iteration 5238 : loss : 0.036495, loss_ce: 0.012368
iteration 5239 : loss : 0.087179, loss_ce: 0.013130
iteration 5240 : loss : 0.031963, loss_ce: 0.013587
iteration 5241 : loss : 0.051914, loss_ce: 0.015189
iteration 5242 : loss : 0.037264, loss_ce: 0.014723
iteration 5243 : loss : 0.063951, loss_ce: 0.009229
iteration 5244 : loss : 0.027195, loss_ce: 0.007988
iteration 5245 : loss : 0.048277, loss_ce: 0.014397
iteration 5246 : loss : 0.042981, loss_ce: 0.019858
iteration 5247 : loss : 0.040600, loss_ce: 0.008702
iteration 5248 : loss : 0.041491, loss_ce: 0.011271
iteration 5249 : loss : 0.034742, loss_ce: 0.012969
iteration 5250 : loss : 0.032513, loss_ce: 0.010727
iteration 5251 : loss : 0.051002, loss_ce: 0.010216
iteration 5252 : loss : 0.044699, loss_ce: 0.010771
iteration 5253 : loss : 0.047206, loss_ce: 0.013691
iteration 5254 : loss : 0.034925, loss_ce: 0.009909
iteration 5255 : loss : 0.032193, loss_ce: 0.011895
iteration 5256 : loss : 0.070897, loss_ce: 0.007954
iteration 5257 : loss : 0.041440, loss_ce: 0.009822
iteration 5258 : loss : 0.039104, loss_ce: 0.010828
iteration 5259 : loss : 0.047959, loss_ce: 0.021510
iteration 5260 : loss : 0.033042, loss_ce: 0.010518
iteration 5261 : loss : 0.043360, loss_ce: 0.012570
iteration 5262 : loss : 0.033251, loss_ce: 0.014549
iteration 5263 : loss : 0.035548, loss_ce: 0.013177
iteration 5264 : loss : 0.093107, loss_ce: 0.007629
iteration 5265 : loss : 0.036640, loss_ce: 0.018525
iteration 5266 : loss : 0.043172, loss_ce: 0.011292
iteration 5267 : loss : 0.039703, loss_ce: 0.015154
iteration 5268 : loss : 0.039198, loss_ce: 0.009461
iteration 5269 : loss : 0.083030, loss_ce: 0.010167
iteration 5270 : loss : 0.037744, loss_ce: 0.011691
iteration 5271 : loss : 0.038811, loss_ce: 0.010127
iteration 5272 : loss : 0.029113, loss_ce: 0.008718
iteration 5273 : loss : 0.039315, loss_ce: 0.013575
iteration 5274 : loss : 0.036753, loss_ce: 0.012014
iteration 5275 : loss : 0.045529, loss_ce: 0.011744
iteration 5276 : loss : 0.184690, loss_ce: 0.003841
iteration 5277 : loss : 0.026438, loss_ce: 0.010445
iteration 5278 : loss : 0.034477, loss_ce: 0.016163
iteration 5279 : loss : 0.029952, loss_ce: 0.009995
iteration 5280 : loss : 0.033712, loss_ce: 0.012301
iteration 5281 : loss : 0.039336, loss_ce: 0.013269
iteration 5282 : loss : 0.035828, loss_ce: 0.018664
iteration 5283 : loss : 0.044840, loss_ce: 0.012755
iteration 5284 : loss : 0.039015, loss_ce: 0.013631
iteration 5285 : loss : 0.031050, loss_ce: 0.012743
iteration 5286 : loss : 0.069332, loss_ce: 0.009648
iteration 5287 : loss : 0.039385, loss_ce: 0.017511
iteration 5288 : loss : 0.039403, loss_ce: 0.013898
iteration 5289 : loss : 0.042028, loss_ce: 0.014697
iteration 5290 : loss : 0.031445, loss_ce: 0.012918
iteration 5291 : loss : 0.040297, loss_ce: 0.008438
iteration 5292 : loss : 0.036475, loss_ce: 0.015374
iteration 5293 : loss : 0.033474, loss_ce: 0.013166
iteration 5294 : loss : 0.034179, loss_ce: 0.013207
iteration 5295 : loss : 0.037072, loss_ce: 0.015885
iteration 5296 : loss : 0.032991, loss_ce: 0.014560
iteration 5297 : loss : 0.031880, loss_ce: 0.011393
iteration 5298 : loss : 0.030397, loss_ce: 0.006627
iteration 5299 : loss : 0.036287, loss_ce: 0.015580
iteration 5300 : loss : 0.034998, loss_ce: 0.015217
iteration 5301 : loss : 0.444387, loss_ce: 0.000752
 28%|████████▌                     | 57/200 [58:32<2:28:27, 62.29s/it]iteration 5302 : loss : 0.034932, loss_ce: 0.014516
iteration 5303 : loss : 0.038933, loss_ce: 0.010982
iteration 5304 : loss : 0.080508, loss_ce: 0.011788
iteration 5305 : loss : 0.041370, loss_ce: 0.012247
iteration 5306 : loss : 0.035972, loss_ce: 0.009204
iteration 5307 : loss : 0.026165, loss_ce: 0.009052
iteration 5308 : loss : 0.035930, loss_ce: 0.011286
iteration 5309 : loss : 0.033338, loss_ce: 0.016571
iteration 5310 : loss : 0.031011, loss_ce: 0.008578
iteration 5311 : loss : 0.032720, loss_ce: 0.015158
iteration 5312 : loss : 0.031633, loss_ce: 0.013561
iteration 5313 : loss : 0.027915, loss_ce: 0.008254
iteration 5314 : loss : 0.038282, loss_ce: 0.006615
iteration 5315 : loss : 0.033255, loss_ce: 0.009973
iteration 5316 : loss : 0.032560, loss_ce: 0.015578
iteration 5317 : loss : 0.031318, loss_ce: 0.011384
iteration 5318 : loss : 0.031727, loss_ce: 0.010026
iteration 5319 : loss : 0.028334, loss_ce: 0.013437
iteration 5320 : loss : 0.038350, loss_ce: 0.009618
iteration 5321 : loss : 0.026972, loss_ce: 0.005551
iteration 5322 : loss : 0.034791, loss_ce: 0.009854
iteration 5323 : loss : 0.029160, loss_ce: 0.007123
iteration 5324 : loss : 0.042570, loss_ce: 0.010162
iteration 5325 : loss : 0.041759, loss_ce: 0.011676
iteration 5326 : loss : 0.028294, loss_ce: 0.012192
iteration 5327 : loss : 0.033840, loss_ce: 0.011337
iteration 5328 : loss : 0.035961, loss_ce: 0.008206
iteration 5329 : loss : 0.032871, loss_ce: 0.014667
iteration 5330 : loss : 0.035510, loss_ce: 0.016868
iteration 5331 : loss : 0.027525, loss_ce: 0.006351
iteration 5332 : loss : 0.034683, loss_ce: 0.009928
iteration 5333 : loss : 0.027915, loss_ce: 0.009900
iteration 5334 : loss : 0.031230, loss_ce: 0.011110
iteration 5335 : loss : 0.034223, loss_ce: 0.013293
iteration 5336 : loss : 0.032286, loss_ce: 0.012673
iteration 5337 : loss : 0.034298, loss_ce: 0.011428
iteration 5338 : loss : 0.026260, loss_ce: 0.008461
iteration 5339 : loss : 0.039694, loss_ce: 0.016104
iteration 5340 : loss : 0.048252, loss_ce: 0.013453
iteration 5341 : loss : 0.033069, loss_ce: 0.012171
iteration 5342 : loss : 0.033088, loss_ce: 0.013248
iteration 5343 : loss : 0.035218, loss_ce: 0.014022
iteration 5344 : loss : 0.041975, loss_ce: 0.013614
iteration 5345 : loss : 0.028152, loss_ce: 0.007245
iteration 5346 : loss : 0.033052, loss_ce: 0.009919
iteration 5347 : loss : 0.034366, loss_ce: 0.011197
iteration 5348 : loss : 0.032397, loss_ce: 0.015469
iteration 5349 : loss : 0.033037, loss_ce: 0.010244
iteration 5350 : loss : 0.031922, loss_ce: 0.011002
iteration 5351 : loss : 0.048681, loss_ce: 0.007776
iteration 5352 : loss : 0.030981, loss_ce: 0.011774
iteration 5353 : loss : 0.031973, loss_ce: 0.009418
iteration 5354 : loss : 0.038983, loss_ce: 0.008269
iteration 5355 : loss : 0.042760, loss_ce: 0.006182
iteration 5356 : loss : 0.052755, loss_ce: 0.006997
iteration 5357 : loss : 0.032685, loss_ce: 0.014230
iteration 5358 : loss : 0.082145, loss_ce: 0.006024
iteration 5359 : loss : 0.082825, loss_ce: 0.011010
iteration 5360 : loss : 0.032986, loss_ce: 0.010470
iteration 5361 : loss : 0.034842, loss_ce: 0.014097
iteration 5362 : loss : 0.035041, loss_ce: 0.015484
iteration 5363 : loss : 0.031072, loss_ce: 0.007262
iteration 5364 : loss : 0.033314, loss_ce: 0.015511
iteration 5365 : loss : 0.035314, loss_ce: 0.010485
iteration 5366 : loss : 0.031328, loss_ce: 0.008127
iteration 5367 : loss : 0.038442, loss_ce: 0.018422
iteration 5368 : loss : 0.037509, loss_ce: 0.011392
iteration 5369 : loss : 0.030647, loss_ce: 0.009542
iteration 5370 : loss : 0.029587, loss_ce: 0.011304
iteration 5371 : loss : 0.030057, loss_ce: 0.014283
iteration 5372 : loss : 0.039956, loss_ce: 0.015364
iteration 5373 : loss : 0.030397, loss_ce: 0.008923
iteration 5374 : loss : 0.084357, loss_ce: 0.011638
iteration 5375 : loss : 0.028243, loss_ce: 0.005366
iteration 5376 : loss : 0.027367, loss_ce: 0.005944
iteration 5377 : loss : 0.040960, loss_ce: 0.019910
iteration 5378 : loss : 0.040717, loss_ce: 0.011558
iteration 5379 : loss : 0.029992, loss_ce: 0.010796
iteration 5380 : loss : 0.039909, loss_ce: 0.008120
iteration 5381 : loss : 0.037818, loss_ce: 0.007874
iteration 5382 : loss : 0.030358, loss_ce: 0.010253
iteration 5383 : loss : 0.026220, loss_ce: 0.006311
iteration 5384 : loss : 0.031439, loss_ce: 0.007570
iteration 5385 : loss : 0.037662, loss_ce: 0.007401
iteration 5386 : loss : 0.031463, loss_ce: 0.011573
iteration 5387 : loss : 0.029542, loss_ce: 0.009491
iteration 5388 : loss : 0.031233, loss_ce: 0.012548
iteration 5389 : loss : 0.029513, loss_ce: 0.009480
iteration 5390 : loss : 0.042428, loss_ce: 0.008940
iteration 5391 : loss : 0.035646, loss_ce: 0.009468
iteration 5392 : loss : 0.032249, loss_ce: 0.012958
iteration 5393 : loss : 0.125274, loss_ce: 0.006566
iteration 5394 : loss : 0.095138, loss_ce: 0.012360
 29%|████████▋                     | 58/200 [59:34<2:26:58, 62.10s/it]iteration 5395 : loss : 0.031371, loss_ce: 0.013082
iteration 5396 : loss : 0.036960, loss_ce: 0.015307
iteration 5397 : loss : 0.086089, loss_ce: 0.006829
iteration 5398 : loss : 0.034824, loss_ce: 0.006854
iteration 5399 : loss : 0.081648, loss_ce: 0.008040
iteration 5400 : loss : 0.081435, loss_ce: 0.009800
iteration 5401 : loss : 0.035219, loss_ce: 0.009223
iteration 5402 : loss : 0.033562, loss_ce: 0.015234
iteration 5403 : loss : 0.031381, loss_ce: 0.007478
iteration 5404 : loss : 0.029030, loss_ce: 0.009342
iteration 5405 : loss : 0.028271, loss_ce: 0.010951
iteration 5406 : loss : 0.030836, loss_ce: 0.010781
iteration 5407 : loss : 0.039722, loss_ce: 0.014316
iteration 5408 : loss : 0.035047, loss_ce: 0.014879
iteration 5409 : loss : 0.039242, loss_ce: 0.014283
iteration 5410 : loss : 0.038131, loss_ce: 0.011075
iteration 5411 : loss : 0.035320, loss_ce: 0.009271
iteration 5412 : loss : 0.031947, loss_ce: 0.010606
iteration 5413 : loss : 0.077232, loss_ce: 0.007847
iteration 5414 : loss : 0.027091, loss_ce: 0.005778
iteration 5415 : loss : 0.029214, loss_ce: 0.008976
iteration 5416 : loss : 0.028303, loss_ce: 0.009129
iteration 5417 : loss : 0.031745, loss_ce: 0.012513
iteration 5418 : loss : 0.029849, loss_ce: 0.009062
iteration 5419 : loss : 0.035968, loss_ce: 0.012354
iteration 5420 : loss : 0.034756, loss_ce: 0.015651
iteration 5421 : loss : 0.029697, loss_ce: 0.011186
iteration 5422 : loss : 0.044676, loss_ce: 0.016198
iteration 5423 : loss : 0.029199, loss_ce: 0.013662
iteration 5424 : loss : 0.048170, loss_ce: 0.008839
iteration 5425 : loss : 0.032943, loss_ce: 0.009327
iteration 5426 : loss : 0.031052, loss_ce: 0.010662
iteration 5427 : loss : 0.032165, loss_ce: 0.012815
iteration 5428 : loss : 0.025015, loss_ce: 0.010999
iteration 5429 : loss : 0.031625, loss_ce: 0.011479
iteration 5430 : loss : 0.036905, loss_ce: 0.011465
iteration 5431 : loss : 0.030396, loss_ce: 0.013118
iteration 5432 : loss : 0.034094, loss_ce: 0.014947
iteration 5433 : loss : 0.031520, loss_ce: 0.013724
iteration 5434 : loss : 0.033993, loss_ce: 0.007559
iteration 5435 : loss : 0.029482, loss_ce: 0.013184
iteration 5436 : loss : 0.030030, loss_ce: 0.006831
iteration 5437 : loss : 0.037024, loss_ce: 0.009610
iteration 5438 : loss : 0.031994, loss_ce: 0.010302
iteration 5439 : loss : 0.029842, loss_ce: 0.009774
iteration 5440 : loss : 0.030458, loss_ce: 0.006821
iteration 5441 : loss : 0.038902, loss_ce: 0.013636
iteration 5442 : loss : 0.030822, loss_ce: 0.010796
iteration 5443 : loss : 0.029666, loss_ce: 0.009604
iteration 5444 : loss : 0.080780, loss_ce: 0.008823
iteration 5445 : loss : 0.031536, loss_ce: 0.009979
iteration 5446 : loss : 0.030551, loss_ce: 0.010417
iteration 5447 : loss : 0.038912, loss_ce: 0.012029
iteration 5448 : loss : 0.029192, loss_ce: 0.009913
iteration 5449 : loss : 0.036466, loss_ce: 0.009187
iteration 5450 : loss : 0.042454, loss_ce: 0.008029
iteration 5451 : loss : 0.037002, loss_ce: 0.019376
iteration 5452 : loss : 0.082076, loss_ce: 0.007289
iteration 5453 : loss : 0.035515, loss_ce: 0.012224
iteration 5454 : loss : 0.082358, loss_ce: 0.011076
iteration 5455 : loss : 0.078162, loss_ce: 0.006521
iteration 5456 : loss : 0.030015, loss_ce: 0.008682
iteration 5457 : loss : 0.038796, loss_ce: 0.013861
iteration 5458 : loss : 0.028258, loss_ce: 0.011846
iteration 5459 : loss : 0.057387, loss_ce: 0.014616
iteration 5460 : loss : 0.079477, loss_ce: 0.007151
iteration 5461 : loss : 0.081844, loss_ce: 0.009984
iteration 5462 : loss : 0.036723, loss_ce: 0.009414
iteration 5463 : loss : 0.053748, loss_ce: 0.009413
iteration 5464 : loss : 0.045363, loss_ce: 0.012724
iteration 5465 : loss : 0.042339, loss_ce: 0.009893
iteration 5466 : loss : 0.028048, loss_ce: 0.010320
iteration 5467 : loss : 0.024876, loss_ce: 0.007066
iteration 5468 : loss : 0.040590, loss_ce: 0.019347
iteration 5469 : loss : 0.033191, loss_ce: 0.010766
iteration 5470 : loss : 0.033202, loss_ce: 0.010986
iteration 5471 : loss : 0.031908, loss_ce: 0.009734
iteration 5472 : loss : 0.031556, loss_ce: 0.013045
iteration 5473 : loss : 0.033219, loss_ce: 0.009405
iteration 5474 : loss : 0.034490, loss_ce: 0.012298
iteration 5475 : loss : 0.031754, loss_ce: 0.012486
iteration 5476 : loss : 0.030339, loss_ce: 0.010471
iteration 5477 : loss : 0.037791, loss_ce: 0.010987
iteration 5478 : loss : 0.032847, loss_ce: 0.009739
iteration 5479 : loss : 0.031801, loss_ce: 0.011493
iteration 5480 : loss : 0.030584, loss_ce: 0.010579
iteration 5481 : loss : 0.029133, loss_ce: 0.007614
iteration 5482 : loss : 0.027982, loss_ce: 0.009924
iteration 5483 : loss : 0.026739, loss_ce: 0.007648
iteration 5484 : loss : 0.036069, loss_ce: 0.008901
iteration 5485 : loss : 0.082871, loss_ce: 0.012661
iteration 5486 : loss : 0.041030, loss_ce: 0.013173
iteration 5487 : loss : 0.156257, loss_ce: 0.033562
 30%|████████▎                   | 59/200 [1:00:36<2:25:45, 62.02s/it]iteration 5488 : loss : 0.030583, loss_ce: 0.008728
iteration 5489 : loss : 0.033507, loss_ce: 0.011073
iteration 5490 : loss : 0.030380, loss_ce: 0.009603
iteration 5491 : loss : 0.057944, loss_ce: 0.011272
iteration 5492 : loss : 0.039641, loss_ce: 0.017055
iteration 5493 : loss : 0.036742, loss_ce: 0.014615
iteration 5494 : loss : 0.041182, loss_ce: 0.016665
iteration 5495 : loss : 0.032798, loss_ce: 0.015962
iteration 5496 : loss : 0.037353, loss_ce: 0.010840
iteration 5497 : loss : 0.038813, loss_ce: 0.012668
iteration 5498 : loss : 0.084465, loss_ce: 0.009019
iteration 5499 : loss : 0.030896, loss_ce: 0.012916
iteration 5500 : loss : 0.043853, loss_ce: 0.015763
iteration 5501 : loss : 0.035762, loss_ce: 0.009732
iteration 5502 : loss : 0.057312, loss_ce: 0.012826
iteration 5503 : loss : 0.047217, loss_ce: 0.016791
iteration 5504 : loss : 0.029187, loss_ce: 0.011086
iteration 5505 : loss : 0.038775, loss_ce: 0.012894
iteration 5506 : loss : 0.033899, loss_ce: 0.012630
iteration 5507 : loss : 0.030188, loss_ce: 0.013916
iteration 5508 : loss : 0.036572, loss_ce: 0.014390
iteration 5509 : loss : 0.030844, loss_ce: 0.012450
iteration 5510 : loss : 0.031840, loss_ce: 0.011667
iteration 5511 : loss : 0.036652, loss_ce: 0.014328
iteration 5512 : loss : 0.039117, loss_ce: 0.012532
iteration 5513 : loss : 0.037048, loss_ce: 0.012167
iteration 5514 : loss : 0.031861, loss_ce: 0.014593
iteration 5515 : loss : 0.039712, loss_ce: 0.010670
iteration 5516 : loss : 0.033991, loss_ce: 0.012227
iteration 5517 : loss : 0.046212, loss_ce: 0.015195
iteration 5518 : loss : 0.093549, loss_ce: 0.009760
iteration 5519 : loss : 0.041937, loss_ce: 0.013494
iteration 5520 : loss : 0.027240, loss_ce: 0.005975
iteration 5521 : loss : 0.026588, loss_ce: 0.006426
iteration 5522 : loss : 0.038608, loss_ce: 0.013504
iteration 5523 : loss : 0.036634, loss_ce: 0.012865
iteration 5524 : loss : 0.078993, loss_ce: 0.004798
iteration 5525 : loss : 0.036695, loss_ce: 0.010450
iteration 5526 : loss : 0.043068, loss_ce: 0.008447
iteration 5527 : loss : 0.032448, loss_ce: 0.012089
iteration 5528 : loss : 0.038933, loss_ce: 0.009409
iteration 5529 : loss : 0.047953, loss_ce: 0.011784
iteration 5530 : loss : 0.033651, loss_ce: 0.012927
iteration 5531 : loss : 0.033635, loss_ce: 0.010582
iteration 5532 : loss : 0.038223, loss_ce: 0.010737
iteration 5533 : loss : 0.100820, loss_ce: 0.004554
iteration 5534 : loss : 0.035194, loss_ce: 0.012121
iteration 5535 : loss : 0.032806, loss_ce: 0.013816
iteration 5536 : loss : 0.052546, loss_ce: 0.011121
iteration 5537 : loss : 0.084501, loss_ce: 0.008123
iteration 5538 : loss : 0.042257, loss_ce: 0.021549
iteration 5539 : loss : 0.042139, loss_ce: 0.012385
iteration 5540 : loss : 0.030091, loss_ce: 0.007710
iteration 5541 : loss : 0.029450, loss_ce: 0.010040
iteration 5542 : loss : 0.042419, loss_ce: 0.015681
iteration 5543 : loss : 0.087339, loss_ce: 0.006612
iteration 5544 : loss : 0.034201, loss_ce: 0.015819
iteration 5545 : loss : 0.033973, loss_ce: 0.010086
iteration 5546 : loss : 0.032322, loss_ce: 0.010786
iteration 5547 : loss : 0.043416, loss_ce: 0.012345
iteration 5548 : loss : 0.089949, loss_ce: 0.010745
iteration 5549 : loss : 0.036220, loss_ce: 0.013013
iteration 5550 : loss : 0.039668, loss_ce: 0.011039
iteration 5551 : loss : 0.044649, loss_ce: 0.024861
iteration 5552 : loss : 0.042682, loss_ce: 0.014643
iteration 5553 : loss : 0.033181, loss_ce: 0.008020
iteration 5554 : loss : 0.036018, loss_ce: 0.010744
iteration 5555 : loss : 0.035767, loss_ce: 0.015229
iteration 5556 : loss : 0.038309, loss_ce: 0.012142
iteration 5557 : loss : 0.032948, loss_ce: 0.010347
iteration 5558 : loss : 0.036029, loss_ce: 0.008933
iteration 5559 : loss : 0.032352, loss_ce: 0.011793
iteration 5560 : loss : 0.047075, loss_ce: 0.009207
iteration 5561 : loss : 0.046829, loss_ce: 0.008233
iteration 5562 : loss : 0.028194, loss_ce: 0.008997
iteration 5563 : loss : 0.031264, loss_ce: 0.009496
iteration 5564 : loss : 0.031525, loss_ce: 0.013419
iteration 5565 : loss : 0.032116, loss_ce: 0.011642
iteration 5566 : loss : 0.032929, loss_ce: 0.013551
iteration 5567 : loss : 0.071015, loss_ce: 0.011841
iteration 5568 : loss : 0.030803, loss_ce: 0.012650
iteration 5569 : loss : 0.035327, loss_ce: 0.014273
iteration 5570 : loss : 0.043627, loss_ce: 0.010083
iteration 5571 : loss : 0.088504, loss_ce: 0.006738
iteration 5572 : loss : 0.036520, loss_ce: 0.008722
iteration 5573 : loss : 0.037424, loss_ce: 0.013381
iteration 5574 : loss : 0.039629, loss_ce: 0.012921
iteration 5575 : loss : 0.027945, loss_ce: 0.008788
iteration 5576 : loss : 0.032625, loss_ce: 0.015926
iteration 5577 : loss : 0.032142, loss_ce: 0.012842
iteration 5578 : loss : 0.037220, loss_ce: 0.016714
iteration 5579 : loss : 0.029865, loss_ce: 0.010054
iteration 5580 : loss : 0.296187, loss_ce: 0.004371
 30%|████████▍                   | 60/200 [1:01:37<2:24:29, 61.93s/it]iteration 5581 : loss : 0.027071, loss_ce: 0.005757
iteration 5582 : loss : 0.037777, loss_ce: 0.015299
iteration 5583 : loss : 0.039841, loss_ce: 0.011197
iteration 5584 : loss : 0.051563, loss_ce: 0.012064
iteration 5585 : loss : 0.037087, loss_ce: 0.017456
iteration 5586 : loss : 0.038935, loss_ce: 0.017337
iteration 5587 : loss : 0.040916, loss_ce: 0.011218
iteration 5588 : loss : 0.026940, loss_ce: 0.006502
iteration 5589 : loss : 0.034508, loss_ce: 0.011175
iteration 5590 : loss : 0.034799, loss_ce: 0.007823
iteration 5591 : loss : 0.081782, loss_ce: 0.009115
iteration 5592 : loss : 0.042088, loss_ce: 0.015831
iteration 5593 : loss : 0.032676, loss_ce: 0.008788
iteration 5594 : loss : 0.040057, loss_ce: 0.007925
iteration 5595 : loss : 0.033310, loss_ce: 0.007967
iteration 5596 : loss : 0.040099, loss_ce: 0.015008
iteration 5597 : loss : 0.028212, loss_ce: 0.008517
iteration 5598 : loss : 0.034435, loss_ce: 0.015373
iteration 5599 : loss : 0.029466, loss_ce: 0.011649
iteration 5600 : loss : 0.030260, loss_ce: 0.006759
iteration 5601 : loss : 0.078597, loss_ce: 0.009973
iteration 5602 : loss : 0.084880, loss_ce: 0.011681
iteration 5603 : loss : 0.031985, loss_ce: 0.010624
iteration 5604 : loss : 0.028118, loss_ce: 0.012450
iteration 5605 : loss : 0.030539, loss_ce: 0.010815
iteration 5606 : loss : 0.053419, loss_ce: 0.007105
iteration 5607 : loss : 0.024695, loss_ce: 0.006483
iteration 5608 : loss : 0.039120, loss_ce: 0.011500
iteration 5609 : loss : 0.031953, loss_ce: 0.009265
iteration 5610 : loss : 0.044617, loss_ce: 0.010839
iteration 5611 : loss : 0.033832, loss_ce: 0.012095
iteration 5612 : loss : 0.085157, loss_ce: 0.007426
iteration 5613 : loss : 0.081642, loss_ce: 0.010624
iteration 5614 : loss : 0.037287, loss_ce: 0.015414
iteration 5615 : loss : 0.038506, loss_ce: 0.015724
iteration 5616 : loss : 0.045825, loss_ce: 0.019651
iteration 5617 : loss : 0.029076, loss_ce: 0.008095
iteration 5618 : loss : 0.038633, loss_ce: 0.012624
iteration 5619 : loss : 0.080590, loss_ce: 0.011465
iteration 5620 : loss : 0.040098, loss_ce: 0.009328
iteration 5621 : loss : 0.028244, loss_ce: 0.009803
iteration 5622 : loss : 0.036959, loss_ce: 0.014004
iteration 5623 : loss : 0.033605, loss_ce: 0.013383
iteration 5624 : loss : 0.032925, loss_ce: 0.015045
iteration 5625 : loss : 0.031542, loss_ce: 0.016684
iteration 5626 : loss : 0.032258, loss_ce: 0.012653
iteration 5627 : loss : 0.034821, loss_ce: 0.009187
iteration 5628 : loss : 0.029532, loss_ce: 0.012264
iteration 5629 : loss : 0.041226, loss_ce: 0.016153
iteration 5630 : loss : 0.032272, loss_ce: 0.014691
iteration 5631 : loss : 0.030603, loss_ce: 0.012170
iteration 5632 : loss : 0.023092, loss_ce: 0.005517
iteration 5633 : loss : 0.028354, loss_ce: 0.009160
iteration 5634 : loss : 0.044909, loss_ce: 0.015242
iteration 5635 : loss : 0.030443, loss_ce: 0.007622
iteration 5636 : loss : 0.046098, loss_ce: 0.017920
iteration 5637 : loss : 0.033691, loss_ce: 0.011086
iteration 5638 : loss : 0.032132, loss_ce: 0.012144
iteration 5639 : loss : 0.032492, loss_ce: 0.007194
iteration 5640 : loss : 0.041481, loss_ce: 0.008460
iteration 5641 : loss : 0.078803, loss_ce: 0.004349
iteration 5642 : loss : 0.028573, loss_ce: 0.011480
iteration 5643 : loss : 0.040861, loss_ce: 0.016392
iteration 5644 : loss : 0.030053, loss_ce: 0.012924
iteration 5645 : loss : 0.037238, loss_ce: 0.012317
iteration 5646 : loss : 0.058645, loss_ce: 0.008275
iteration 5647 : loss : 0.029560, loss_ce: 0.009066
iteration 5648 : loss : 0.035536, loss_ce: 0.015325
iteration 5649 : loss : 0.032528, loss_ce: 0.010294
iteration 5650 : loss : 0.034216, loss_ce: 0.010850
iteration 5651 : loss : 0.026431, loss_ce: 0.009668
iteration 5652 : loss : 0.026218, loss_ce: 0.008059
iteration 5653 : loss : 0.059323, loss_ce: 0.011724
iteration 5654 : loss : 0.040684, loss_ce: 0.012775
iteration 5655 : loss : 0.033332, loss_ce: 0.006429
iteration 5656 : loss : 0.035361, loss_ce: 0.009937
iteration 5657 : loss : 0.032430, loss_ce: 0.015383
iteration 5658 : loss : 0.042190, loss_ce: 0.019189
iteration 5659 : loss : 0.042431, loss_ce: 0.013416
iteration 5660 : loss : 0.035615, loss_ce: 0.010397
iteration 5661 : loss : 0.038762, loss_ce: 0.014026
iteration 5662 : loss : 0.081150, loss_ce: 0.010222
iteration 5663 : loss : 0.038741, loss_ce: 0.014601
iteration 5664 : loss : 0.036471, loss_ce: 0.010460
iteration 5665 : loss : 0.036210, loss_ce: 0.015399
iteration 5666 : loss : 0.023720, loss_ce: 0.005194
iteration 5667 : loss : 0.037107, loss_ce: 0.010850
iteration 5668 : loss : 0.042623, loss_ce: 0.008095
iteration 5669 : loss : 0.037836, loss_ce: 0.014540
iteration 5670 : loss : 0.035748, loss_ce: 0.009717
iteration 5671 : loss : 0.026969, loss_ce: 0.009734
iteration 5672 : loss : 0.037124, loss_ce: 0.009627
iteration 5673 : loss : 0.096378, loss_ce: 0.023061
 30%|████████▌                   | 61/200 [1:02:39<2:23:21, 61.88s/it]iteration 5674 : loss : 0.030151, loss_ce: 0.007981
iteration 5675 : loss : 0.049694, loss_ce: 0.014396
iteration 5676 : loss : 0.041303, loss_ce: 0.016003
iteration 5677 : loss : 0.110658, loss_ce: 0.007706
iteration 5678 : loss : 0.033134, loss_ce: 0.012018
iteration 5679 : loss : 0.036210, loss_ce: 0.009188
iteration 5680 : loss : 0.059092, loss_ce: 0.019635
iteration 5681 : loss : 0.041557, loss_ce: 0.012517
iteration 5682 : loss : 0.039706, loss_ce: 0.016726
iteration 5683 : loss : 0.030841, loss_ce: 0.008652
iteration 5684 : loss : 0.024135, loss_ce: 0.007343
iteration 5685 : loss : 0.048799, loss_ce: 0.007013
iteration 5686 : loss : 0.033348, loss_ce: 0.013584
iteration 5687 : loss : 0.037576, loss_ce: 0.012448
iteration 5688 : loss : 0.033801, loss_ce: 0.008729
iteration 5689 : loss : 0.038361, loss_ce: 0.013276
iteration 5690 : loss : 0.029333, loss_ce: 0.010451
iteration 5691 : loss : 0.034850, loss_ce: 0.011010
iteration 5692 : loss : 0.036732, loss_ce: 0.012552
iteration 5693 : loss : 0.035240, loss_ce: 0.010866
iteration 5694 : loss : 0.033307, loss_ce: 0.011845
iteration 5695 : loss : 0.034368, loss_ce: 0.019285
iteration 5696 : loss : 0.046678, loss_ce: 0.008204
iteration 5697 : loss : 0.031880, loss_ce: 0.010410
iteration 5698 : loss : 0.031799, loss_ce: 0.010474
iteration 5699 : loss : 0.033135, loss_ce: 0.013553
iteration 5700 : loss : 0.045136, loss_ce: 0.008060
iteration 5701 : loss : 0.040409, loss_ce: 0.018494
iteration 5702 : loss : 0.023691, loss_ce: 0.008430
iteration 5703 : loss : 0.066327, loss_ce: 0.009556
iteration 5704 : loss : 0.038693, loss_ce: 0.006257
iteration 5705 : loss : 0.031874, loss_ce: 0.010131
iteration 5706 : loss : 0.036720, loss_ce: 0.015491
iteration 5707 : loss : 0.035467, loss_ce: 0.016164
iteration 5708 : loss : 0.034170, loss_ce: 0.015202
iteration 5709 : loss : 0.044472, loss_ce: 0.011655
iteration 5710 : loss : 0.080149, loss_ce: 0.009073
iteration 5711 : loss : 0.042623, loss_ce: 0.007419
iteration 5712 : loss : 0.029019, loss_ce: 0.005703
iteration 5713 : loss : 0.035139, loss_ce: 0.011836
iteration 5714 : loss : 0.034474, loss_ce: 0.014030
iteration 5715 : loss : 0.038555, loss_ce: 0.014817
iteration 5716 : loss : 0.040624, loss_ce: 0.008164
iteration 5717 : loss : 0.043804, loss_ce: 0.013245
iteration 5718 : loss : 0.036634, loss_ce: 0.014577
iteration 5719 : loss : 0.040116, loss_ce: 0.011516
iteration 5720 : loss : 0.038415, loss_ce: 0.011357
iteration 5721 : loss : 0.034412, loss_ce: 0.009016
iteration 5722 : loss : 0.039590, loss_ce: 0.006857
iteration 5723 : loss : 0.033864, loss_ce: 0.014711
iteration 5724 : loss : 0.049604, loss_ce: 0.019481
iteration 5725 : loss : 0.039907, loss_ce: 0.011740
iteration 5726 : loss : 0.037861, loss_ce: 0.009587
iteration 5727 : loss : 0.036508, loss_ce: 0.011934
iteration 5728 : loss : 0.029318, loss_ce: 0.008111
iteration 5729 : loss : 0.035981, loss_ce: 0.008802
iteration 5730 : loss : 0.035170, loss_ce: 0.017068
iteration 5731 : loss : 0.036750, loss_ce: 0.008756
iteration 5732 : loss : 0.032320, loss_ce: 0.008096
iteration 5733 : loss : 0.049860, loss_ce: 0.014522
iteration 5734 : loss : 0.047625, loss_ce: 0.007197
iteration 5735 : loss : 0.047415, loss_ce: 0.010632
iteration 5736 : loss : 0.078331, loss_ce: 0.010686
iteration 5737 : loss : 0.035564, loss_ce: 0.016365
iteration 5738 : loss : 0.029745, loss_ce: 0.010322
iteration 5739 : loss : 0.082840, loss_ce: 0.006609
iteration 5740 : loss : 0.033680, loss_ce: 0.013905
iteration 5741 : loss : 0.047431, loss_ce: 0.014596
iteration 5742 : loss : 0.032719, loss_ce: 0.011946
iteration 5743 : loss : 0.030594, loss_ce: 0.011098
iteration 5744 : loss : 0.036376, loss_ce: 0.007872
iteration 5745 : loss : 0.033366, loss_ce: 0.009551
iteration 5746 : loss : 0.037934, loss_ce: 0.008544
iteration 5747 : loss : 0.081313, loss_ce: 0.007404
iteration 5748 : loss : 0.034972, loss_ce: 0.011789
iteration 5749 : loss : 0.029006, loss_ce: 0.012677
iteration 5750 : loss : 0.037591, loss_ce: 0.015863
iteration 5751 : loss : 0.032871, loss_ce: 0.010455
iteration 5752 : loss : 0.022877, loss_ce: 0.006856
iteration 5753 : loss : 0.035545, loss_ce: 0.012756
iteration 5754 : loss : 0.034594, loss_ce: 0.004533
iteration 5755 : loss : 0.035956, loss_ce: 0.011714
iteration 5756 : loss : 0.029041, loss_ce: 0.009292
iteration 5757 : loss : 0.038449, loss_ce: 0.013078
iteration 5758 : loss : 0.027047, loss_ce: 0.013095
iteration 5759 : loss : 0.031978, loss_ce: 0.010281
iteration 5760 : loss : 0.034759, loss_ce: 0.009186
iteration 5761 : loss : 0.037822, loss_ce: 0.013067
iteration 5762 : loss : 0.034273, loss_ce: 0.011652
iteration 5763 : loss : 0.028789, loss_ce: 0.009368
iteration 5764 : loss : 0.031229, loss_ce: 0.013584
iteration 5765 : loss : 0.038042, loss_ce: 0.009648
iteration 5766 : loss : 0.444100, loss_ce: 0.000660
 31%|████████▋                   | 62/200 [1:03:41<2:22:09, 61.81s/it]iteration 5767 : loss : 0.022231, loss_ce: 0.009091
iteration 5768 : loss : 0.032150, loss_ce: 0.012071
iteration 5769 : loss : 0.027608, loss_ce: 0.012040
iteration 5770 : loss : 0.038578, loss_ce: 0.010983
iteration 5771 : loss : 0.031449, loss_ce: 0.014890
iteration 5772 : loss : 0.029166, loss_ce: 0.007292
iteration 5773 : loss : 0.029991, loss_ce: 0.009038
iteration 5774 : loss : 0.033752, loss_ce: 0.009813
iteration 5775 : loss : 0.034736, loss_ce: 0.005834
iteration 5776 : loss : 0.028748, loss_ce: 0.006866
iteration 5777 : loss : 0.029359, loss_ce: 0.009627
iteration 5778 : loss : 0.033718, loss_ce: 0.014764
iteration 5779 : loss : 0.042632, loss_ce: 0.014659
iteration 5780 : loss : 0.080080, loss_ce: 0.007810
iteration 5781 : loss : 0.033715, loss_ce: 0.005141
iteration 5782 : loss : 0.032122, loss_ce: 0.013256
iteration 5783 : loss : 0.028679, loss_ce: 0.013807
iteration 5784 : loss : 0.052649, loss_ce: 0.010757
iteration 5785 : loss : 0.047346, loss_ce: 0.008662
iteration 5786 : loss : 0.029531, loss_ce: 0.009174
iteration 5787 : loss : 0.079371, loss_ce: 0.007945
iteration 5788 : loss : 0.032375, loss_ce: 0.011278
iteration 5789 : loss : 0.030897, loss_ce: 0.010168
iteration 5790 : loss : 0.037138, loss_ce: 0.006585
iteration 5791 : loss : 0.033117, loss_ce: 0.010634
iteration 5792 : loss : 0.029781, loss_ce: 0.010885
iteration 5793 : loss : 0.032339, loss_ce: 0.015920
iteration 5794 : loss : 0.045279, loss_ce: 0.017786
iteration 5795 : loss : 0.038212, loss_ce: 0.010677
iteration 5796 : loss : 0.029257, loss_ce: 0.008797
iteration 5797 : loss : 0.033730, loss_ce: 0.015198
iteration 5798 : loss : 0.032179, loss_ce: 0.010070
iteration 5799 : loss : 0.026177, loss_ce: 0.008783
iteration 5800 : loss : 0.029729, loss_ce: 0.010699
iteration 5801 : loss : 0.031805, loss_ce: 0.014587
iteration 5802 : loss : 0.037053, loss_ce: 0.012128
iteration 5803 : loss : 0.031604, loss_ce: 0.010463
iteration 5804 : loss : 0.032144, loss_ce: 0.009246
iteration 5805 : loss : 0.035180, loss_ce: 0.010554
iteration 5806 : loss : 0.042087, loss_ce: 0.010846
iteration 5807 : loss : 0.031822, loss_ce: 0.011296
iteration 5808 : loss : 0.038201, loss_ce: 0.012657
iteration 5809 : loss : 0.034800, loss_ce: 0.014069
iteration 5810 : loss : 0.027046, loss_ce: 0.008990
iteration 5811 : loss : 0.031668, loss_ce: 0.011399
iteration 5812 : loss : 0.039686, loss_ce: 0.011654
iteration 5813 : loss : 0.036154, loss_ce: 0.013946
iteration 5814 : loss : 0.027785, loss_ce: 0.004980
iteration 5815 : loss : 0.037182, loss_ce: 0.010077
iteration 5816 : loss : 0.031950, loss_ce: 0.012998
iteration 5817 : loss : 0.038711, loss_ce: 0.011393
iteration 5818 : loss : 0.081537, loss_ce: 0.006697
iteration 5819 : loss : 0.038875, loss_ce: 0.011420
iteration 5820 : loss : 0.025043, loss_ce: 0.007097
iteration 5821 : loss : 0.034199, loss_ce: 0.015154
iteration 5822 : loss : 0.037540, loss_ce: 0.006991
iteration 5823 : loss : 0.033856, loss_ce: 0.006961
iteration 5824 : loss : 0.025687, loss_ce: 0.010345
iteration 5825 : loss : 0.033345, loss_ce: 0.014805
iteration 5826 : loss : 0.037592, loss_ce: 0.015163
iteration 5827 : loss : 0.074092, loss_ce: 0.007312
iteration 5828 : loss : 0.029799, loss_ce: 0.006977
iteration 5829 : loss : 0.079917, loss_ce: 0.010533
iteration 5830 : loss : 0.034211, loss_ce: 0.017344
iteration 5831 : loss : 0.036505, loss_ce: 0.020565
iteration 5832 : loss : 0.083966, loss_ce: 0.006057
iteration 5833 : loss : 0.032332, loss_ce: 0.013018
iteration 5834 : loss : 0.027200, loss_ce: 0.006850
iteration 5835 : loss : 0.030651, loss_ce: 0.008852
iteration 5836 : loss : 0.033822, loss_ce: 0.010528
iteration 5837 : loss : 0.028169, loss_ce: 0.008844
iteration 5838 : loss : 0.020942, loss_ce: 0.007053
iteration 5839 : loss : 0.028522, loss_ce: 0.012802
iteration 5840 : loss : 0.077991, loss_ce: 0.010603
iteration 5841 : loss : 0.028503, loss_ce: 0.011257
iteration 5842 : loss : 0.032822, loss_ce: 0.012765
iteration 5843 : loss : 0.032540, loss_ce: 0.008107
iteration 5844 : loss : 0.029624, loss_ce: 0.010975
iteration 5845 : loss : 0.027396, loss_ce: 0.012093
iteration 5846 : loss : 0.031644, loss_ce: 0.010483
iteration 5847 : loss : 0.033751, loss_ce: 0.012997
iteration 5848 : loss : 0.041033, loss_ce: 0.008812
iteration 5849 : loss : 0.030652, loss_ce: 0.009382
iteration 5850 : loss : 0.030039, loss_ce: 0.011290
iteration 5851 : loss : 0.025317, loss_ce: 0.008451
iteration 5852 : loss : 0.030707, loss_ce: 0.007280
iteration 5853 : loss : 0.029067, loss_ce: 0.010843
iteration 5854 : loss : 0.092064, loss_ce: 0.003073
iteration 5855 : loss : 0.026969, loss_ce: 0.009788
iteration 5856 : loss : 0.035528, loss_ce: 0.010383
iteration 5857 : loss : 0.032768, loss_ce: 0.015462
iteration 5858 : loss : 0.034690, loss_ce: 0.011858
iteration 5859 : loss : 0.389486, loss_ce: 0.000903
 32%|████████▊                   | 63/200 [1:04:42<2:21:00, 61.75s/it]iteration 5860 : loss : 0.029850, loss_ce: 0.014137
iteration 5861 : loss : 0.031105, loss_ce: 0.010491
iteration 5862 : loss : 0.031692, loss_ce: 0.011796
iteration 5863 : loss : 0.032331, loss_ce: 0.013455
iteration 5864 : loss : 0.034113, loss_ce: 0.013307
iteration 5865 : loss : 0.033888, loss_ce: 0.011784
iteration 5866 : loss : 0.030642, loss_ce: 0.012762
iteration 5867 : loss : 0.032640, loss_ce: 0.014761
iteration 5868 : loss : 0.025399, loss_ce: 0.005347
iteration 5869 : loss : 0.031650, loss_ce: 0.008976
iteration 5870 : loss : 0.043785, loss_ce: 0.008917
iteration 5871 : loss : 0.025220, loss_ce: 0.007332
iteration 5872 : loss : 0.038201, loss_ce: 0.017841
iteration 5873 : loss : 0.029950, loss_ce: 0.010214
iteration 5874 : loss : 0.029146, loss_ce: 0.007449
iteration 5875 : loss : 0.078924, loss_ce: 0.009420
iteration 5876 : loss : 0.026701, loss_ce: 0.008439
iteration 5877 : loss : 0.029360, loss_ce: 0.009932
iteration 5878 : loss : 0.029128, loss_ce: 0.008920
iteration 5879 : loss : 0.026134, loss_ce: 0.004333
iteration 5880 : loss : 0.026232, loss_ce: 0.006477
iteration 5881 : loss : 0.037002, loss_ce: 0.008505
iteration 5882 : loss : 0.031128, loss_ce: 0.013149
iteration 5883 : loss : 0.023480, loss_ce: 0.005989
iteration 5884 : loss : 0.037522, loss_ce: 0.010152
iteration 5885 : loss : 0.030636, loss_ce: 0.011053
iteration 5886 : loss : 0.026595, loss_ce: 0.011856
iteration 5887 : loss : 0.032682, loss_ce: 0.013755
iteration 5888 : loss : 0.028409, loss_ce: 0.014960
iteration 5889 : loss : 0.031587, loss_ce: 0.013578
iteration 5890 : loss : 0.030206, loss_ce: 0.012540
iteration 5891 : loss : 0.026791, loss_ce: 0.010675
iteration 5892 : loss : 0.045566, loss_ce: 0.011746
iteration 5893 : loss : 0.030047, loss_ce: 0.007605
iteration 5894 : loss : 0.029871, loss_ce: 0.010468
iteration 5895 : loss : 0.036950, loss_ce: 0.010440
iteration 5896 : loss : 0.033336, loss_ce: 0.018527
iteration 5897 : loss : 0.054624, loss_ce: 0.011704
iteration 5898 : loss : 0.033401, loss_ce: 0.012047
iteration 5899 : loss : 0.028518, loss_ce: 0.008804
iteration 5900 : loss : 0.031833, loss_ce: 0.006877
iteration 5901 : loss : 0.031843, loss_ce: 0.007600
iteration 5902 : loss : 0.036752, loss_ce: 0.015548
iteration 5903 : loss : 0.037497, loss_ce: 0.005507
iteration 5904 : loss : 0.081917, loss_ce: 0.005551
iteration 5905 : loss : 0.034130, loss_ce: 0.012949
iteration 5906 : loss : 0.044041, loss_ce: 0.012279
iteration 5907 : loss : 0.048874, loss_ce: 0.008674
iteration 5908 : loss : 0.081053, loss_ce: 0.010142
iteration 5909 : loss : 0.028112, loss_ce: 0.008853
iteration 5910 : loss : 0.036497, loss_ce: 0.011981
iteration 5911 : loss : 0.083787, loss_ce: 0.011186
iteration 5912 : loss : 0.039512, loss_ce: 0.017720
iteration 5913 : loss : 0.029820, loss_ce: 0.008655
iteration 5914 : loss : 0.034816, loss_ce: 0.008968
iteration 5915 : loss : 0.030639, loss_ce: 0.011115
iteration 5916 : loss : 0.028394, loss_ce: 0.010949
iteration 5917 : loss : 0.028343, loss_ce: 0.007063
iteration 5918 : loss : 0.083063, loss_ce: 0.009797
iteration 5919 : loss : 0.032040, loss_ce: 0.007921
iteration 5920 : loss : 0.033282, loss_ce: 0.011634
iteration 5921 : loss : 0.030717, loss_ce: 0.009056
iteration 5922 : loss : 0.031056, loss_ce: 0.006164
iteration 5923 : loss : 0.030762, loss_ce: 0.009477
iteration 5924 : loss : 0.035071, loss_ce: 0.012438
iteration 5925 : loss : 0.041577, loss_ce: 0.013907
iteration 5926 : loss : 0.035289, loss_ce: 0.012394
iteration 5927 : loss : 0.083905, loss_ce: 0.006812
iteration 5928 : loss : 0.033815, loss_ce: 0.007244
iteration 5929 : loss : 0.027139, loss_ce: 0.008621
iteration 5930 : loss : 0.137859, loss_ce: 0.010230
iteration 5931 : loss : 0.026362, loss_ce: 0.005326
iteration 5932 : loss : 0.042843, loss_ce: 0.015023
iteration 5933 : loss : 0.029420, loss_ce: 0.012674
iteration 5934 : loss : 0.024082, loss_ce: 0.007456
iteration 5935 : loss : 0.030244, loss_ce: 0.007175
iteration 5936 : loss : 0.082422, loss_ce: 0.006799
iteration 5937 : loss : 0.031103, loss_ce: 0.007636
iteration 5938 : loss : 0.033042, loss_ce: 0.016194
iteration 5939 : loss : 0.030886, loss_ce: 0.012305
iteration 5940 : loss : 0.028444, loss_ce: 0.010032
iteration 5941 : loss : 0.030418, loss_ce: 0.012551
iteration 5942 : loss : 0.044307, loss_ce: 0.006674
iteration 5943 : loss : 0.030001, loss_ce: 0.010562
iteration 5944 : loss : 0.039350, loss_ce: 0.013709
iteration 5945 : loss : 0.029784, loss_ce: 0.014408
iteration 5946 : loss : 0.033375, loss_ce: 0.012610
iteration 5947 : loss : 0.034418, loss_ce: 0.015005
iteration 5948 : loss : 0.028924, loss_ce: 0.007657
iteration 5949 : loss : 0.029232, loss_ce: 0.009708
iteration 5950 : loss : 0.038665, loss_ce: 0.006506
iteration 5951 : loss : 0.033081, loss_ce: 0.004412
iteration 5952 : loss : 0.190029, loss_ce: 0.012868
 32%|████████▉                   | 64/200 [1:05:44<2:19:50, 61.70s/it]iteration 5953 : loss : 0.024764, loss_ce: 0.005318
iteration 5954 : loss : 0.031230, loss_ce: 0.011700
iteration 5955 : loss : 0.034199, loss_ce: 0.009336
iteration 5956 : loss : 0.031071, loss_ce: 0.013531
iteration 5957 : loss : 0.031609, loss_ce: 0.009515
iteration 5958 : loss : 0.039742, loss_ce: 0.011646
iteration 5959 : loss : 0.032432, loss_ce: 0.008947
iteration 5960 : loss : 0.030328, loss_ce: 0.007673
iteration 5961 : loss : 0.033606, loss_ce: 0.013368
iteration 5962 : loss : 0.032881, loss_ce: 0.010554
iteration 5963 : loss : 0.031978, loss_ce: 0.011757
iteration 5964 : loss : 0.025654, loss_ce: 0.007961
iteration 5965 : loss : 0.035723, loss_ce: 0.008708
iteration 5966 : loss : 0.035310, loss_ce: 0.017348
iteration 5967 : loss : 0.028759, loss_ce: 0.009293
iteration 5968 : loss : 0.033225, loss_ce: 0.003840
iteration 5969 : loss : 0.081484, loss_ce: 0.012097
iteration 5970 : loss : 0.034902, loss_ce: 0.008783
iteration 5971 : loss : 0.027196, loss_ce: 0.012099
iteration 5972 : loss : 0.032131, loss_ce: 0.012333
iteration 5973 : loss : 0.039517, loss_ce: 0.019049
iteration 5974 : loss : 0.029935, loss_ce: 0.010159
iteration 5975 : loss : 0.038336, loss_ce: 0.009819
iteration 5976 : loss : 0.031140, loss_ce: 0.009575
iteration 5977 : loss : 0.052733, loss_ce: 0.010888
iteration 5978 : loss : 0.030344, loss_ce: 0.008048
iteration 5979 : loss : 0.030567, loss_ce: 0.011831
iteration 5980 : loss : 0.047410, loss_ce: 0.005919
iteration 5981 : loss : 0.029192, loss_ce: 0.010735
iteration 5982 : loss : 0.075603, loss_ce: 0.007830
iteration 5983 : loss : 0.026297, loss_ce: 0.009613
iteration 5984 : loss : 0.039025, loss_ce: 0.008794
iteration 5985 : loss : 0.040715, loss_ce: 0.012240
iteration 5986 : loss : 0.032161, loss_ce: 0.013663
iteration 5987 : loss : 0.036198, loss_ce: 0.011953
iteration 5988 : loss : 0.030728, loss_ce: 0.007339
iteration 5989 : loss : 0.056111, loss_ce: 0.006282
iteration 5990 : loss : 0.041854, loss_ce: 0.009218
iteration 5991 : loss : 0.036920, loss_ce: 0.015013
iteration 5992 : loss : 0.028421, loss_ce: 0.008373
iteration 5993 : loss : 0.038024, loss_ce: 0.009765
iteration 5994 : loss : 0.074706, loss_ce: 0.004096
iteration 5995 : loss : 0.037598, loss_ce: 0.017683
iteration 5996 : loss : 0.036391, loss_ce: 0.007391
iteration 5997 : loss : 0.030087, loss_ce: 0.010489
iteration 5998 : loss : 0.032165, loss_ce: 0.013835
iteration 5999 : loss : 0.082435, loss_ce: 0.010995
iteration 6000 : loss : 0.038425, loss_ce: 0.013162
iteration 6001 : loss : 0.032676, loss_ce: 0.010373
iteration 6002 : loss : 0.037262, loss_ce: 0.009871
iteration 6003 : loss : 0.038679, loss_ce: 0.009118
iteration 6004 : loss : 0.029193, loss_ce: 0.011588
iteration 6005 : loss : 0.031328, loss_ce: 0.009242
iteration 6006 : loss : 0.032129, loss_ce: 0.010865
iteration 6007 : loss : 0.036974, loss_ce: 0.015038
iteration 6008 : loss : 0.039040, loss_ce: 0.016843
iteration 6009 : loss : 0.030290, loss_ce: 0.011666
iteration 6010 : loss : 0.032856, loss_ce: 0.012396
iteration 6011 : loss : 0.027791, loss_ce: 0.011651
iteration 6012 : loss : 0.032574, loss_ce: 0.004751
iteration 6013 : loss : 0.027234, loss_ce: 0.013485
iteration 6014 : loss : 0.031965, loss_ce: 0.010093
iteration 6015 : loss : 0.031514, loss_ce: 0.012391
iteration 6016 : loss : 0.030081, loss_ce: 0.010976
iteration 6017 : loss : 0.029252, loss_ce: 0.010403
iteration 6018 : loss : 0.033861, loss_ce: 0.011998
iteration 6019 : loss : 0.026984, loss_ce: 0.009684
iteration 6020 : loss : 0.083575, loss_ce: 0.012363
iteration 6021 : loss : 0.033273, loss_ce: 0.012834
iteration 6022 : loss : 0.026017, loss_ce: 0.010242
iteration 6023 : loss : 0.088049, loss_ce: 0.010795
iteration 6024 : loss : 0.026691, loss_ce: 0.007808
iteration 6025 : loss : 0.030345, loss_ce: 0.006890
iteration 6026 : loss : 0.034147, loss_ce: 0.008408
iteration 6027 : loss : 0.030921, loss_ce: 0.016618
iteration 6028 : loss : 0.024722, loss_ce: 0.009610
iteration 6029 : loss : 0.023307, loss_ce: 0.008947
iteration 6030 : loss : 0.027914, loss_ce: 0.007332
iteration 6031 : loss : 0.030998, loss_ce: 0.013217
iteration 6032 : loss : 0.029410, loss_ce: 0.009797
iteration 6033 : loss : 0.026903, loss_ce: 0.010698
iteration 6034 : loss : 0.035080, loss_ce: 0.012673
iteration 6035 : loss : 0.033379, loss_ce: 0.010695
iteration 6036 : loss : 0.031298, loss_ce: 0.007601
iteration 6037 : loss : 0.033887, loss_ce: 0.010763
iteration 6038 : loss : 0.028969, loss_ce: 0.007875
iteration 6039 : loss : 0.033905, loss_ce: 0.011593
iteration 6040 : loss : 0.027658, loss_ce: 0.009495
iteration 6041 : loss : 0.031838, loss_ce: 0.013739
iteration 6042 : loss : 0.034934, loss_ce: 0.012928
iteration 6043 : loss : 0.042677, loss_ce: 0.013754
iteration 6044 : loss : 0.076860, loss_ce: 0.004924
iteration 6045 : loss : 0.189055, loss_ce: 0.011155
 32%|█████████                   | 65/200 [1:06:46<2:18:46, 61.68s/it]iteration 6046 : loss : 0.029429, loss_ce: 0.010585
iteration 6047 : loss : 0.034853, loss_ce: 0.010694
iteration 6048 : loss : 0.036242, loss_ce: 0.014725
iteration 6049 : loss : 0.035452, loss_ce: 0.008599
iteration 6050 : loss : 0.037028, loss_ce: 0.007051
iteration 6051 : loss : 0.033737, loss_ce: 0.009047
iteration 6052 : loss : 0.073922, loss_ce: 0.004284
iteration 6053 : loss : 0.031299, loss_ce: 0.004214
iteration 6054 : loss : 0.028444, loss_ce: 0.009907
iteration 6055 : loss : 0.032355, loss_ce: 0.009362
iteration 6056 : loss : 0.029184, loss_ce: 0.008286
iteration 6057 : loss : 0.030078, loss_ce: 0.012716
iteration 6058 : loss : 0.028968, loss_ce: 0.010730
iteration 6059 : loss : 0.025396, loss_ce: 0.010209
iteration 6060 : loss : 0.031511, loss_ce: 0.010384
iteration 6061 : loss : 0.027244, loss_ce: 0.006210
iteration 6062 : loss : 0.027566, loss_ce: 0.011677
iteration 6063 : loss : 0.026062, loss_ce: 0.008682
iteration 6064 : loss : 0.029725, loss_ce: 0.007927
iteration 6065 : loss : 0.081961, loss_ce: 0.006477
iteration 6066 : loss : 0.029690, loss_ce: 0.013000
iteration 6067 : loss : 0.024141, loss_ce: 0.009061
iteration 6068 : loss : 0.082656, loss_ce: 0.009738
iteration 6069 : loss : 0.033039, loss_ce: 0.010314
iteration 6070 : loss : 0.035154, loss_ce: 0.018086
iteration 6071 : loss : 0.027823, loss_ce: 0.009642
iteration 6072 : loss : 0.027342, loss_ce: 0.012996
iteration 6073 : loss : 0.086647, loss_ce: 0.007782
iteration 6074 : loss : 0.030264, loss_ce: 0.012441
iteration 6075 : loss : 0.026204, loss_ce: 0.010238
iteration 6076 : loss : 0.029470, loss_ce: 0.010905
iteration 6077 : loss : 0.034829, loss_ce: 0.009994
iteration 6078 : loss : 0.030239, loss_ce: 0.009063
iteration 6079 : loss : 0.029683, loss_ce: 0.009466
iteration 6080 : loss : 0.030539, loss_ce: 0.011900
iteration 6081 : loss : 0.034922, loss_ce: 0.014450
iteration 6082 : loss : 0.029976, loss_ce: 0.011497
iteration 6083 : loss : 0.044514, loss_ce: 0.007432
iteration 6084 : loss : 0.037004, loss_ce: 0.014869
iteration 6085 : loss : 0.031787, loss_ce: 0.009171
iteration 6086 : loss : 0.027530, loss_ce: 0.009041
iteration 6087 : loss : 0.030308, loss_ce: 0.015276
iteration 6088 : loss : 0.026898, loss_ce: 0.009236
iteration 6089 : loss : 0.023125, loss_ce: 0.007023
iteration 6090 : loss : 0.032760, loss_ce: 0.010430
iteration 6091 : loss : 0.025753, loss_ce: 0.007068
iteration 6092 : loss : 0.034360, loss_ce: 0.012014
iteration 6093 : loss : 0.028849, loss_ce: 0.012757
iteration 6094 : loss : 0.030503, loss_ce: 0.009100
iteration 6095 : loss : 0.027249, loss_ce: 0.004759
iteration 6096 : loss : 0.034088, loss_ce: 0.012466
iteration 6097 : loss : 0.029086, loss_ce: 0.011061
iteration 6098 : loss : 0.028419, loss_ce: 0.010845
iteration 6099 : loss : 0.026798, loss_ce: 0.009297
iteration 6100 : loss : 0.052429, loss_ce: 0.011965
iteration 6101 : loss : 0.035842, loss_ce: 0.012515
iteration 6102 : loss : 0.029291, loss_ce: 0.014912
iteration 6103 : loss : 0.037550, loss_ce: 0.009839
iteration 6104 : loss : 0.032502, loss_ce: 0.012127
iteration 6105 : loss : 0.095795, loss_ce: 0.009573
iteration 6106 : loss : 0.030713, loss_ce: 0.014300
iteration 6107 : loss : 0.036172, loss_ce: 0.016609
iteration 6108 : loss : 0.060779, loss_ce: 0.009372
iteration 6109 : loss : 0.082198, loss_ce: 0.010759
iteration 6110 : loss : 0.081901, loss_ce: 0.008353
iteration 6111 : loss : 0.036198, loss_ce: 0.008022
iteration 6112 : loss : 0.030989, loss_ce: 0.008281
iteration 6113 : loss : 0.034205, loss_ce: 0.010807
iteration 6114 : loss : 0.046102, loss_ce: 0.007102
iteration 6115 : loss : 0.084029, loss_ce: 0.008840
iteration 6116 : loss : 0.028632, loss_ce: 0.009458
iteration 6117 : loss : 0.035074, loss_ce: 0.005533
iteration 6118 : loss : 0.039540, loss_ce: 0.012093
iteration 6119 : loss : 0.034336, loss_ce: 0.013239
iteration 6120 : loss : 0.040729, loss_ce: 0.009511
iteration 6121 : loss : 0.028989, loss_ce: 0.010072
iteration 6122 : loss : 0.024228, loss_ce: 0.009104
iteration 6123 : loss : 0.029789, loss_ce: 0.009635
iteration 6124 : loss : 0.032258, loss_ce: 0.010983
iteration 6125 : loss : 0.049571, loss_ce: 0.004772
iteration 6126 : loss : 0.034094, loss_ce: 0.012560
iteration 6127 : loss : 0.035734, loss_ce: 0.013213
iteration 6128 : loss : 0.038140, loss_ce: 0.013826
iteration 6129 : loss : 0.033115, loss_ce: 0.012473
iteration 6130 : loss : 0.042875, loss_ce: 0.010507
iteration 6131 : loss : 0.031185, loss_ce: 0.012428
iteration 6132 : loss : 0.080683, loss_ce: 0.006846
iteration 6133 : loss : 0.037780, loss_ce: 0.016904
iteration 6134 : loss : 0.036134, loss_ce: 0.011421
iteration 6135 : loss : 0.036011, loss_ce: 0.014160
iteration 6136 : loss : 0.044125, loss_ce: 0.021167
iteration 6137 : loss : 0.038334, loss_ce: 0.012381
iteration 6138 : loss : 0.393033, loss_ce: 0.008018
 33%|█████████▏                  | 66/200 [1:07:47<2:17:36, 61.62s/it]iteration 6139 : loss : 0.031272, loss_ce: 0.011128
iteration 6140 : loss : 0.090183, loss_ce: 0.010891
iteration 6141 : loss : 0.034617, loss_ce: 0.020161
iteration 6142 : loss : 0.041855, loss_ce: 0.021620
iteration 6143 : loss : 0.051637, loss_ce: 0.026490
iteration 6144 : loss : 0.042570, loss_ce: 0.021318
iteration 6145 : loss : 0.116684, loss_ce: 0.024041
iteration 6146 : loss : 0.037286, loss_ce: 0.015107
iteration 6147 : loss : 0.045361, loss_ce: 0.014544
iteration 6148 : loss : 0.046263, loss_ce: 0.013851
iteration 6149 : loss : 0.078340, loss_ce: 0.013294
iteration 6150 : loss : 0.046060, loss_ce: 0.019995
iteration 6151 : loss : 0.050953, loss_ce: 0.018011
iteration 6152 : loss : 0.043053, loss_ce: 0.010652
iteration 6153 : loss : 0.039971, loss_ce: 0.016687
iteration 6154 : loss : 0.036625, loss_ce: 0.013685
iteration 6155 : loss : 0.037443, loss_ce: 0.015115
iteration 6156 : loss : 0.031909, loss_ce: 0.011138
iteration 6157 : loss : 0.031324, loss_ce: 0.010207
iteration 6158 : loss : 0.036632, loss_ce: 0.010126
iteration 6159 : loss : 0.039098, loss_ce: 0.012547
iteration 6160 : loss : 0.035949, loss_ce: 0.014463
iteration 6161 : loss : 0.083558, loss_ce: 0.005259
iteration 6162 : loss : 0.053251, loss_ce: 0.018179
iteration 6163 : loss : 0.030770, loss_ce: 0.008784
iteration 6164 : loss : 0.028246, loss_ce: 0.011307
iteration 6165 : loss : 0.092710, loss_ce: 0.012079
iteration 6166 : loss : 0.041535, loss_ce: 0.019163
iteration 6167 : loss : 0.029920, loss_ce: 0.010640
iteration 6168 : loss : 0.039870, loss_ce: 0.011275
iteration 6169 : loss : 0.040038, loss_ce: 0.014966
iteration 6170 : loss : 0.032167, loss_ce: 0.007944
iteration 6171 : loss : 0.029007, loss_ce: 0.008090
iteration 6172 : loss : 0.030719, loss_ce: 0.011696
iteration 6173 : loss : 0.042926, loss_ce: 0.012518
iteration 6174 : loss : 0.033005, loss_ce: 0.011663
iteration 6175 : loss : 0.033832, loss_ce: 0.015524
iteration 6176 : loss : 0.034576, loss_ce: 0.010893
iteration 6177 : loss : 0.044578, loss_ce: 0.009474
iteration 6178 : loss : 0.047352, loss_ce: 0.014896
iteration 6179 : loss : 0.039725, loss_ce: 0.015089
iteration 6180 : loss : 0.042422, loss_ce: 0.011763
iteration 6181 : loss : 0.030480, loss_ce: 0.012787
iteration 6182 : loss : 0.038644, loss_ce: 0.016884
iteration 6183 : loss : 0.038285, loss_ce: 0.016803
iteration 6184 : loss : 0.042943, loss_ce: 0.011657
iteration 6185 : loss : 0.026465, loss_ce: 0.006215
iteration 6186 : loss : 0.031411, loss_ce: 0.011915
iteration 6187 : loss : 0.038789, loss_ce: 0.014487
iteration 6188 : loss : 0.037281, loss_ce: 0.011228
iteration 6189 : loss : 0.046479, loss_ce: 0.014876
iteration 6190 : loss : 0.035372, loss_ce: 0.017381
iteration 6191 : loss : 0.024580, loss_ce: 0.007200
iteration 6192 : loss : 0.034423, loss_ce: 0.012891
iteration 6193 : loss : 0.031924, loss_ce: 0.011396
iteration 6194 : loss : 0.033529, loss_ce: 0.013166
iteration 6195 : loss : 0.054321, loss_ce: 0.007462
iteration 6196 : loss : 0.038236, loss_ce: 0.011348
iteration 6197 : loss : 0.030073, loss_ce: 0.012985
iteration 6198 : loss : 0.035777, loss_ce: 0.019676
iteration 6199 : loss : 0.030800, loss_ce: 0.013076
iteration 6200 : loss : 0.039098, loss_ce: 0.008892
iteration 6201 : loss : 0.070468, loss_ce: 0.012565
iteration 6202 : loss : 0.032897, loss_ce: 0.012374
iteration 6203 : loss : 0.043292, loss_ce: 0.011381
iteration 6204 : loss : 0.025373, loss_ce: 0.009718
iteration 6205 : loss : 0.025099, loss_ce: 0.007239
iteration 6206 : loss : 0.038389, loss_ce: 0.015611
iteration 6207 : loss : 0.037414, loss_ce: 0.014908
iteration 6208 : loss : 0.040488, loss_ce: 0.014237
iteration 6209 : loss : 0.053145, loss_ce: 0.011531
iteration 6210 : loss : 0.038457, loss_ce: 0.012957
iteration 6211 : loss : 0.058813, loss_ce: 0.010325
iteration 6212 : loss : 0.031743, loss_ce: 0.009723
iteration 6213 : loss : 0.037282, loss_ce: 0.010777
iteration 6214 : loss : 0.040044, loss_ce: 0.005936
iteration 6215 : loss : 0.035992, loss_ce: 0.009787
iteration 6216 : loss : 0.036540, loss_ce: 0.011905
iteration 6217 : loss : 0.028559, loss_ce: 0.010645
iteration 6218 : loss : 0.035382, loss_ce: 0.009766
iteration 6219 : loss : 0.035944, loss_ce: 0.013760
iteration 6220 : loss : 0.035669, loss_ce: 0.012777
iteration 6221 : loss : 0.035491, loss_ce: 0.011833
iteration 6222 : loss : 0.027076, loss_ce: 0.007133
iteration 6223 : loss : 0.135329, loss_ce: 0.008102
iteration 6224 : loss : 0.039939, loss_ce: 0.016029
iteration 6225 : loss : 0.032047, loss_ce: 0.013401
iteration 6226 : loss : 0.030997, loss_ce: 0.009424
iteration 6227 : loss : 0.033069, loss_ce: 0.014533
iteration 6228 : loss : 0.033931, loss_ce: 0.013275
iteration 6229 : loss : 0.070175, loss_ce: 0.009393
iteration 6230 : loss : 0.035237, loss_ce: 0.009521
iteration 6231 : loss : 0.391463, loss_ce: 0.001528
 34%|█████████▍                  | 67/200 [1:08:49<2:16:37, 61.63s/it]iteration 6232 : loss : 0.027561, loss_ce: 0.009363
iteration 6233 : loss : 0.033379, loss_ce: 0.009980
iteration 6234 : loss : 0.028343, loss_ce: 0.005807
iteration 6235 : loss : 0.034633, loss_ce: 0.011717
iteration 6236 : loss : 0.040412, loss_ce: 0.016337
iteration 6237 : loss : 0.027362, loss_ce: 0.008811
iteration 6238 : loss : 0.031676, loss_ce: 0.014115
iteration 6239 : loss : 0.031933, loss_ce: 0.014583
iteration 6240 : loss : 0.032746, loss_ce: 0.012026
iteration 6241 : loss : 0.027698, loss_ce: 0.011811
iteration 6242 : loss : 0.031713, loss_ce: 0.011854
iteration 6243 : loss : 0.031151, loss_ce: 0.010274
iteration 6244 : loss : 0.038494, loss_ce: 0.011404
iteration 6245 : loss : 0.026615, loss_ce: 0.010467
iteration 6246 : loss : 0.081229, loss_ce: 0.006651
iteration 6247 : loss : 0.029525, loss_ce: 0.013046
iteration 6248 : loss : 0.030989, loss_ce: 0.009839
iteration 6249 : loss : 0.030517, loss_ce: 0.008991
iteration 6250 : loss : 0.026960, loss_ce: 0.011710
iteration 6251 : loss : 0.028872, loss_ce: 0.009928
iteration 6252 : loss : 0.082022, loss_ce: 0.005152
iteration 6253 : loss : 0.047436, loss_ce: 0.009858
iteration 6254 : loss : 0.028107, loss_ce: 0.010798
iteration 6255 : loss : 0.033742, loss_ce: 0.013350
iteration 6256 : loss : 0.025876, loss_ce: 0.010062
iteration 6257 : loss : 0.025105, loss_ce: 0.009675
iteration 6258 : loss : 0.032853, loss_ce: 0.013672
iteration 6259 : loss : 0.029443, loss_ce: 0.010429
iteration 6260 : loss : 0.078597, loss_ce: 0.007518
iteration 6261 : loss : 0.040150, loss_ce: 0.012768
iteration 6262 : loss : 0.033765, loss_ce: 0.014181
iteration 6263 : loss : 0.030422, loss_ce: 0.011023
iteration 6264 : loss : 0.080991, loss_ce: 0.005539
iteration 6265 : loss : 0.031736, loss_ce: 0.013036
iteration 6266 : loss : 0.032495, loss_ce: 0.016226
iteration 6267 : loss : 0.032282, loss_ce: 0.011180
iteration 6268 : loss : 0.033591, loss_ce: 0.010853
iteration 6269 : loss : 0.034856, loss_ce: 0.009535
iteration 6270 : loss : 0.029285, loss_ce: 0.010859
iteration 6271 : loss : 0.024390, loss_ce: 0.007211
iteration 6272 : loss : 0.042896, loss_ce: 0.010400
iteration 6273 : loss : 0.032587, loss_ce: 0.013381
iteration 6274 : loss : 0.034861, loss_ce: 0.007216
iteration 6275 : loss : 0.081302, loss_ce: 0.004909
iteration 6276 : loss : 0.029737, loss_ce: 0.012286
iteration 6277 : loss : 0.033304, loss_ce: 0.014431
iteration 6278 : loss : 0.030419, loss_ce: 0.009627
iteration 6279 : loss : 0.054141, loss_ce: 0.010128
iteration 6280 : loss : 0.032029, loss_ce: 0.014876
iteration 6281 : loss : 0.033982, loss_ce: 0.006813
iteration 6282 : loss : 0.034698, loss_ce: 0.013348
iteration 6283 : loss : 0.027231, loss_ce: 0.009303
iteration 6284 : loss : 0.029039, loss_ce: 0.009609
iteration 6285 : loss : 0.036528, loss_ce: 0.004844
iteration 6286 : loss : 0.029214, loss_ce: 0.012666
iteration 6287 : loss : 0.081902, loss_ce: 0.008628
iteration 6288 : loss : 0.029630, loss_ce: 0.010016
iteration 6289 : loss : 0.038097, loss_ce: 0.007573
iteration 6290 : loss : 0.029112, loss_ce: 0.011757
iteration 6291 : loss : 0.026128, loss_ce: 0.007540
iteration 6292 : loss : 0.036703, loss_ce: 0.014946
iteration 6293 : loss : 0.057147, loss_ce: 0.010098
iteration 6294 : loss : 0.099636, loss_ce: 0.006903
iteration 6295 : loss : 0.031359, loss_ce: 0.012940
iteration 6296 : loss : 0.039679, loss_ce: 0.013186
iteration 6297 : loss : 0.041024, loss_ce: 0.012279
iteration 6298 : loss : 0.036344, loss_ce: 0.013099
iteration 6299 : loss : 0.032132, loss_ce: 0.006073
iteration 6300 : loss : 0.043697, loss_ce: 0.012762
iteration 6301 : loss : 0.031468, loss_ce: 0.013833
iteration 6302 : loss : 0.086252, loss_ce: 0.009524
iteration 6303 : loss : 0.030540, loss_ce: 0.013681
iteration 6304 : loss : 0.029079, loss_ce: 0.010720
iteration 6305 : loss : 0.029152, loss_ce: 0.010588
iteration 6306 : loss : 0.042891, loss_ce: 0.010834
iteration 6307 : loss : 0.034927, loss_ce: 0.016441
iteration 6308 : loss : 0.036432, loss_ce: 0.016853
iteration 6309 : loss : 0.026809, loss_ce: 0.007539
iteration 6310 : loss : 0.046101, loss_ce: 0.007971
iteration 6311 : loss : 0.029834, loss_ce: 0.010138
iteration 6312 : loss : 0.025339, loss_ce: 0.008642
iteration 6313 : loss : 0.079981, loss_ce: 0.009179
iteration 6314 : loss : 0.030902, loss_ce: 0.010166
iteration 6315 : loss : 0.085392, loss_ce: 0.007516
iteration 6316 : loss : 0.031635, loss_ce: 0.004335
iteration 6317 : loss : 0.037381, loss_ce: 0.017824
iteration 6318 : loss : 0.031014, loss_ce: 0.013093
iteration 6319 : loss : 0.044492, loss_ce: 0.008673
iteration 6320 : loss : 0.051089, loss_ce: 0.013362
iteration 6321 : loss : 0.034218, loss_ce: 0.011350
iteration 6322 : loss : 0.028493, loss_ce: 0.007717
iteration 6323 : loss : 0.027898, loss_ce: 0.008794
iteration 6324 : loss : 0.099392, loss_ce: 0.029015
 34%|█████████▌                  | 68/200 [1:09:51<2:15:38, 61.66s/it]iteration 6325 : loss : 0.036607, loss_ce: 0.008345
iteration 6326 : loss : 0.085231, loss_ce: 0.011647
iteration 6327 : loss : 0.040687, loss_ce: 0.012662
iteration 6328 : loss : 0.028026, loss_ce: 0.011501
iteration 6329 : loss : 0.042088, loss_ce: 0.011075
iteration 6330 : loss : 0.047377, loss_ce: 0.012842
iteration 6331 : loss : 0.044866, loss_ce: 0.013232
iteration 6332 : loss : 0.037330, loss_ce: 0.011002
iteration 6333 : loss : 0.037366, loss_ce: 0.017790
iteration 6334 : loss : 0.037696, loss_ce: 0.013983
iteration 6335 : loss : 0.037833, loss_ce: 0.013562
iteration 6336 : loss : 0.032529, loss_ce: 0.008964
iteration 6337 : loss : 0.035186, loss_ce: 0.014092
iteration 6338 : loss : 0.033857, loss_ce: 0.010369
iteration 6339 : loss : 0.029975, loss_ce: 0.010200
iteration 6340 : loss : 0.032120, loss_ce: 0.009852
iteration 6341 : loss : 0.034594, loss_ce: 0.011668
iteration 6342 : loss : 0.084465, loss_ce: 0.009118
iteration 6343 : loss : 0.039193, loss_ce: 0.013463
iteration 6344 : loss : 0.035358, loss_ce: 0.017430
iteration 6345 : loss : 0.029913, loss_ce: 0.009280
iteration 6346 : loss : 0.030240, loss_ce: 0.011229
iteration 6347 : loss : 0.036880, loss_ce: 0.011446
iteration 6348 : loss : 0.080281, loss_ce: 0.006468
iteration 6349 : loss : 0.079442, loss_ce: 0.009418
iteration 6350 : loss : 0.064665, loss_ce: 0.014524
iteration 6351 : loss : 0.033307, loss_ce: 0.013522
iteration 6352 : loss : 0.037301, loss_ce: 0.015939
iteration 6353 : loss : 0.038274, loss_ce: 0.010064
iteration 6354 : loss : 0.028772, loss_ce: 0.012555
iteration 6355 : loss : 0.028533, loss_ce: 0.010399
iteration 6356 : loss : 0.030324, loss_ce: 0.012159
iteration 6357 : loss : 0.030147, loss_ce: 0.010262
iteration 6358 : loss : 0.032649, loss_ce: 0.009115
iteration 6359 : loss : 0.030818, loss_ce: 0.011380
iteration 6360 : loss : 0.038181, loss_ce: 0.015166
iteration 6361 : loss : 0.079304, loss_ce: 0.004669
iteration 6362 : loss : 0.039123, loss_ce: 0.014105
iteration 6363 : loss : 0.034138, loss_ce: 0.013616
iteration 6364 : loss : 0.025452, loss_ce: 0.010296
iteration 6365 : loss : 0.032765, loss_ce: 0.005864
iteration 6366 : loss : 0.030913, loss_ce: 0.006740
iteration 6367 : loss : 0.032767, loss_ce: 0.013827
iteration 6368 : loss : 0.032524, loss_ce: 0.006930
iteration 6369 : loss : 0.023245, loss_ce: 0.007885
iteration 6370 : loss : 0.032269, loss_ce: 0.010805
iteration 6371 : loss : 0.035966, loss_ce: 0.010981
iteration 6372 : loss : 0.039510, loss_ce: 0.018805
iteration 6373 : loss : 0.035993, loss_ce: 0.013987
iteration 6374 : loss : 0.027063, loss_ce: 0.010614
iteration 6375 : loss : 0.028102, loss_ce: 0.009862
iteration 6376 : loss : 0.034929, loss_ce: 0.009086
iteration 6377 : loss : 0.031247, loss_ce: 0.007876
iteration 6378 : loss : 0.034369, loss_ce: 0.008902
iteration 6379 : loss : 0.035827, loss_ce: 0.012244
iteration 6380 : loss : 0.043174, loss_ce: 0.011778
iteration 6381 : loss : 0.034539, loss_ce: 0.012023
iteration 6382 : loss : 0.028407, loss_ce: 0.012301
iteration 6383 : loss : 0.033359, loss_ce: 0.009740
iteration 6384 : loss : 0.037894, loss_ce: 0.015642
iteration 6385 : loss : 0.025552, loss_ce: 0.012014
iteration 6386 : loss : 0.028594, loss_ce: 0.010736
iteration 6387 : loss : 0.032644, loss_ce: 0.012927
iteration 6388 : loss : 0.027088, loss_ce: 0.011119
iteration 6389 : loss : 0.032943, loss_ce: 0.011229
iteration 6390 : loss : 0.076327, loss_ce: 0.004782
iteration 6391 : loss : 0.036321, loss_ce: 0.011423
iteration 6392 : loss : 0.028646, loss_ce: 0.009059
iteration 6393 : loss : 0.033209, loss_ce: 0.010703
iteration 6394 : loss : 0.087488, loss_ce: 0.007942
iteration 6395 : loss : 0.035430, loss_ce: 0.010207
iteration 6396 : loss : 0.028077, loss_ce: 0.011846
iteration 6397 : loss : 0.035043, loss_ce: 0.009969
iteration 6398 : loss : 0.030705, loss_ce: 0.011651
iteration 6399 : loss : 0.033560, loss_ce: 0.011104
iteration 6400 : loss : 0.033282, loss_ce: 0.012692
iteration 6401 : loss : 0.031438, loss_ce: 0.008056
iteration 6402 : loss : 0.021909, loss_ce: 0.005153
iteration 6403 : loss : 0.027897, loss_ce: 0.012585
iteration 6404 : loss : 0.024347, loss_ce: 0.011087
iteration 6405 : loss : 0.028993, loss_ce: 0.011491
iteration 6406 : loss : 0.033064, loss_ce: 0.015628
iteration 6407 : loss : 0.031279, loss_ce: 0.010976
iteration 6408 : loss : 0.087630, loss_ce: 0.008385
iteration 6409 : loss : 0.058836, loss_ce: 0.008023
iteration 6410 : loss : 0.031864, loss_ce: 0.011854
iteration 6411 : loss : 0.031262, loss_ce: 0.008306
iteration 6412 : loss : 0.037848, loss_ce: 0.005726
iteration 6413 : loss : 0.050399, loss_ce: 0.007885
iteration 6414 : loss : 0.054157, loss_ce: 0.016217
iteration 6415 : loss : 0.038631, loss_ce: 0.008719
iteration 6416 : loss : 0.024498, loss_ce: 0.007805
iteration 6417 : loss : 0.391924, loss_ce: 0.001811
 34%|█████████▋                  | 69/200 [1:10:52<2:14:37, 61.66s/it]iteration 6418 : loss : 0.047526, loss_ce: 0.010060
iteration 6419 : loss : 0.027901, loss_ce: 0.010979
iteration 6420 : loss : 0.034172, loss_ce: 0.009658
iteration 6421 : loss : 0.030988, loss_ce: 0.008538
iteration 6422 : loss : 0.030725, loss_ce: 0.016498
iteration 6423 : loss : 0.028634, loss_ce: 0.011211
iteration 6424 : loss : 0.029084, loss_ce: 0.007583
iteration 6425 : loss : 0.032139, loss_ce: 0.012587
iteration 6426 : loss : 0.078550, loss_ce: 0.003441
iteration 6427 : loss : 0.022862, loss_ce: 0.007172
iteration 6428 : loss : 0.037129, loss_ce: 0.014753
iteration 6429 : loss : 0.030784, loss_ce: 0.007889
iteration 6430 : loss : 0.030612, loss_ce: 0.006592
iteration 6431 : loss : 0.032633, loss_ce: 0.013441
iteration 6432 : loss : 0.034284, loss_ce: 0.010028
iteration 6433 : loss : 0.039409, loss_ce: 0.007743
iteration 6434 : loss : 0.035653, loss_ce: 0.018332
iteration 6435 : loss : 0.030405, loss_ce: 0.012016
iteration 6436 : loss : 0.063424, loss_ce: 0.007450
iteration 6437 : loss : 0.029673, loss_ce: 0.009717
iteration 6438 : loss : 0.043838, loss_ce: 0.006394
iteration 6439 : loss : 0.032918, loss_ce: 0.010583
iteration 6440 : loss : 0.030132, loss_ce: 0.009507
iteration 6441 : loss : 0.040445, loss_ce: 0.015310
iteration 6442 : loss : 0.041580, loss_ce: 0.008581
iteration 6443 : loss : 0.030215, loss_ce: 0.010413
iteration 6444 : loss : 0.080692, loss_ce: 0.009514
iteration 6445 : loss : 0.034098, loss_ce: 0.011094
iteration 6446 : loss : 0.037418, loss_ce: 0.013527
iteration 6447 : loss : 0.083151, loss_ce: 0.006544
iteration 6448 : loss : 0.029978, loss_ce: 0.009062
iteration 6449 : loss : 0.027875, loss_ce: 0.009843
iteration 6450 : loss : 0.032313, loss_ce: 0.012166
iteration 6451 : loss : 0.030117, loss_ce: 0.012281
iteration 6452 : loss : 0.036812, loss_ce: 0.018973
iteration 6453 : loss : 0.035486, loss_ce: 0.016237
iteration 6454 : loss : 0.078003, loss_ce: 0.006675
iteration 6455 : loss : 0.034757, loss_ce: 0.010908
iteration 6456 : loss : 0.028940, loss_ce: 0.009362
iteration 6457 : loss : 0.032518, loss_ce: 0.011873
iteration 6458 : loss : 0.032507, loss_ce: 0.010594
iteration 6459 : loss : 0.045343, loss_ce: 0.012861
iteration 6460 : loss : 0.027938, loss_ce: 0.008883
iteration 6461 : loss : 0.031800, loss_ce: 0.009114
iteration 6462 : loss : 0.060557, loss_ce: 0.009870
iteration 6463 : loss : 0.035944, loss_ce: 0.014479
iteration 6464 : loss : 0.035662, loss_ce: 0.010666
iteration 6465 : loss : 0.026684, loss_ce: 0.009419
iteration 6466 : loss : 0.033628, loss_ce: 0.007567
iteration 6467 : loss : 0.046573, loss_ce: 0.019634
iteration 6468 : loss : 0.041571, loss_ce: 0.007728
iteration 6469 : loss : 0.027138, loss_ce: 0.010310
iteration 6470 : loss : 0.083251, loss_ce: 0.015228
iteration 6471 : loss : 0.038908, loss_ce: 0.010557
iteration 6472 : loss : 0.032998, loss_ce: 0.015358
iteration 6473 : loss : 0.027690, loss_ce: 0.006894
iteration 6474 : loss : 0.033033, loss_ce: 0.009328
iteration 6475 : loss : 0.041412, loss_ce: 0.011559
iteration 6476 : loss : 0.031901, loss_ce: 0.006676
iteration 6477 : loss : 0.027030, loss_ce: 0.010781
iteration 6478 : loss : 0.028822, loss_ce: 0.006183
iteration 6479 : loss : 0.032064, loss_ce: 0.012286
iteration 6480 : loss : 0.027250, loss_ce: 0.010063
iteration 6481 : loss : 0.027999, loss_ce: 0.012196
iteration 6482 : loss : 0.032075, loss_ce: 0.011797
iteration 6483 : loss : 0.080461, loss_ce: 0.010436
iteration 6484 : loss : 0.039262, loss_ce: 0.011411
iteration 6485 : loss : 0.042030, loss_ce: 0.010913
iteration 6486 : loss : 0.127804, loss_ce: 0.005709
iteration 6487 : loss : 0.027892, loss_ce: 0.007890
iteration 6488 : loss : 0.031545, loss_ce: 0.010660
iteration 6489 : loss : 0.029152, loss_ce: 0.012303
iteration 6490 : loss : 0.079863, loss_ce: 0.008296
iteration 6491 : loss : 0.082911, loss_ce: 0.009280
iteration 6492 : loss : 0.031751, loss_ce: 0.011473
iteration 6493 : loss : 0.028519, loss_ce: 0.007632
iteration 6494 : loss : 0.033307, loss_ce: 0.010600
iteration 6495 : loss : 0.031350, loss_ce: 0.014185
iteration 6496 : loss : 0.085660, loss_ce: 0.005220
iteration 6497 : loss : 0.029369, loss_ce: 0.009785
iteration 6498 : loss : 0.036039, loss_ce: 0.017447
iteration 6499 : loss : 0.030807, loss_ce: 0.010539
iteration 6500 : loss : 0.030846, loss_ce: 0.014607
iteration 6501 : loss : 0.029483, loss_ce: 0.009964
iteration 6502 : loss : 0.033212, loss_ce: 0.012418
iteration 6503 : loss : 0.029524, loss_ce: 0.011250
iteration 6504 : loss : 0.034412, loss_ce: 0.013917
iteration 6505 : loss : 0.030175, loss_ce: 0.014128
iteration 6506 : loss : 0.079076, loss_ce: 0.009450
iteration 6507 : loss : 0.044349, loss_ce: 0.010529
iteration 6508 : loss : 0.025276, loss_ce: 0.011534
iteration 6509 : loss : 0.026238, loss_ce: 0.006804
iteration 6510 : loss : 0.096929, loss_ce: 0.016888
 35%|█████████▊                  | 70/200 [1:11:54<2:13:33, 61.64s/it]iteration 6511 : loss : 0.032895, loss_ce: 0.009075
iteration 6512 : loss : 0.030950, loss_ce: 0.011967
iteration 6513 : loss : 0.033361, loss_ce: 0.010463
iteration 6514 : loss : 0.029930, loss_ce: 0.010184
iteration 6515 : loss : 0.030211, loss_ce: 0.008456
iteration 6516 : loss : 0.031726, loss_ce: 0.009111
iteration 6517 : loss : 0.028450, loss_ce: 0.005864
iteration 6518 : loss : 0.055500, loss_ce: 0.012347
iteration 6519 : loss : 0.030945, loss_ce: 0.011806
iteration 6520 : loss : 0.037564, loss_ce: 0.009255
iteration 6521 : loss : 0.035353, loss_ce: 0.010654
iteration 6522 : loss : 0.029032, loss_ce: 0.010034
iteration 6523 : loss : 0.038819, loss_ce: 0.010661
iteration 6524 : loss : 0.031392, loss_ce: 0.012393
iteration 6525 : loss : 0.030810, loss_ce: 0.010480
iteration 6526 : loss : 0.028922, loss_ce: 0.010566
iteration 6527 : loss : 0.028493, loss_ce: 0.014820
iteration 6528 : loss : 0.041570, loss_ce: 0.010193
iteration 6529 : loss : 0.029183, loss_ce: 0.009888
iteration 6530 : loss : 0.041168, loss_ce: 0.008630
iteration 6531 : loss : 0.039137, loss_ce: 0.013395
iteration 6532 : loss : 0.033525, loss_ce: 0.012480
iteration 6533 : loss : 0.028196, loss_ce: 0.006616
iteration 6534 : loss : 0.040228, loss_ce: 0.011026
iteration 6535 : loss : 0.032885, loss_ce: 0.009890
iteration 6536 : loss : 0.080416, loss_ce: 0.007406
iteration 6537 : loss : 0.025666, loss_ce: 0.009079
iteration 6538 : loss : 0.030850, loss_ce: 0.010490
iteration 6539 : loss : 0.028856, loss_ce: 0.010146
iteration 6540 : loss : 0.037652, loss_ce: 0.006443
iteration 6541 : loss : 0.028124, loss_ce: 0.006242
iteration 6542 : loss : 0.123559, loss_ce: 0.002279
iteration 6543 : loss : 0.029720, loss_ce: 0.010832
iteration 6544 : loss : 0.078379, loss_ce: 0.008257
iteration 6545 : loss : 0.040257, loss_ce: 0.013462
iteration 6546 : loss : 0.028066, loss_ce: 0.012560
iteration 6547 : loss : 0.031023, loss_ce: 0.011459
iteration 6548 : loss : 0.036464, loss_ce: 0.021794
iteration 6549 : loss : 0.032983, loss_ce: 0.009181
iteration 6550 : loss : 0.037986, loss_ce: 0.009045
iteration 6551 : loss : 0.033202, loss_ce: 0.012965
iteration 6552 : loss : 0.027457, loss_ce: 0.007828
iteration 6553 : loss : 0.034593, loss_ce: 0.016458
iteration 6554 : loss : 0.026792, loss_ce: 0.007382
iteration 6555 : loss : 0.028115, loss_ce: 0.014034
iteration 6556 : loss : 0.034519, loss_ce: 0.011519
iteration 6557 : loss : 0.024198, loss_ce: 0.007909
iteration 6558 : loss : 0.028108, loss_ce: 0.012701
iteration 6559 : loss : 0.076414, loss_ce: 0.007419
iteration 6560 : loss : 0.029209, loss_ce: 0.008792
iteration 6561 : loss : 0.032942, loss_ce: 0.013552
iteration 6562 : loss : 0.078130, loss_ce: 0.006257
iteration 6563 : loss : 0.078268, loss_ce: 0.005968
iteration 6564 : loss : 0.061285, loss_ce: 0.011706
iteration 6565 : loss : 0.031546, loss_ce: 0.010702
iteration 6566 : loss : 0.077692, loss_ce: 0.005158
iteration 6567 : loss : 0.075778, loss_ce: 0.008405
iteration 6568 : loss : 0.029526, loss_ce: 0.009114
iteration 6569 : loss : 0.030626, loss_ce: 0.012880
iteration 6570 : loss : 0.028517, loss_ce: 0.009325
iteration 6571 : loss : 0.034971, loss_ce: 0.014844
iteration 6572 : loss : 0.055842, loss_ce: 0.011239
iteration 6573 : loss : 0.028181, loss_ce: 0.011852
iteration 6574 : loss : 0.030636, loss_ce: 0.013544
iteration 6575 : loss : 0.036235, loss_ce: 0.017762
iteration 6576 : loss : 0.027743, loss_ce: 0.008777
iteration 6577 : loss : 0.027272, loss_ce: 0.007644
iteration 6578 : loss : 0.030754, loss_ce: 0.008563
iteration 6579 : loss : 0.031154, loss_ce: 0.017817
iteration 6580 : loss : 0.057653, loss_ce: 0.006635
iteration 6581 : loss : 0.030636, loss_ce: 0.011979
iteration 6582 : loss : 0.026600, loss_ce: 0.009557
iteration 6583 : loss : 0.079116, loss_ce: 0.009999
iteration 6584 : loss : 0.083936, loss_ce: 0.006984
iteration 6585 : loss : 0.029333, loss_ce: 0.008525
iteration 6586 : loss : 0.033264, loss_ce: 0.008526
iteration 6587 : loss : 0.039911, loss_ce: 0.015584
iteration 6588 : loss : 0.043968, loss_ce: 0.011603
iteration 6589 : loss : 0.033262, loss_ce: 0.012150
iteration 6590 : loss : 0.028808, loss_ce: 0.010314
iteration 6591 : loss : 0.030484, loss_ce: 0.004464
iteration 6592 : loss : 0.034236, loss_ce: 0.007983
iteration 6593 : loss : 0.038499, loss_ce: 0.011618
iteration 6594 : loss : 0.034651, loss_ce: 0.009388
iteration 6595 : loss : 0.038561, loss_ce: 0.015488
iteration 6596 : loss : 0.028582, loss_ce: 0.008213
iteration 6597 : loss : 0.037463, loss_ce: 0.012857
iteration 6598 : loss : 0.036799, loss_ce: 0.008539
iteration 6599 : loss : 0.038493, loss_ce: 0.010342
iteration 6600 : loss : 0.034507, loss_ce: 0.009188
iteration 6601 : loss : 0.023107, loss_ce: 0.008198
iteration 6602 : loss : 0.032175, loss_ce: 0.012293
iteration 6603 : loss : 0.443652, loss_ce: 0.000459
 36%|█████████▉                  | 71/200 [1:12:55<2:12:30, 61.63s/it]iteration 6604 : loss : 0.030680, loss_ce: 0.010144
iteration 6605 : loss : 0.030032, loss_ce: 0.009770
iteration 6606 : loss : 0.031974, loss_ce: 0.008645
iteration 6607 : loss : 0.029150, loss_ce: 0.010110
iteration 6608 : loss : 0.033994, loss_ce: 0.011563
iteration 6609 : loss : 0.034476, loss_ce: 0.015197
iteration 6610 : loss : 0.037449, loss_ce: 0.018452
iteration 6611 : loss : 0.050038, loss_ce: 0.007205
iteration 6612 : loss : 0.023690, loss_ce: 0.005994
iteration 6613 : loss : 0.079232, loss_ce: 0.008819
iteration 6614 : loss : 0.036592, loss_ce: 0.010950
iteration 6615 : loss : 0.033648, loss_ce: 0.011186
iteration 6616 : loss : 0.034240, loss_ce: 0.010092
iteration 6617 : loss : 0.029364, loss_ce: 0.010892
iteration 6618 : loss : 0.046654, loss_ce: 0.008583
iteration 6619 : loss : 0.033652, loss_ce: 0.014867
iteration 6620 : loss : 0.033977, loss_ce: 0.016936
iteration 6621 : loss : 0.037061, loss_ce: 0.013807
iteration 6622 : loss : 0.029285, loss_ce: 0.015749
iteration 6623 : loss : 0.035707, loss_ce: 0.006121
iteration 6624 : loss : 0.081492, loss_ce: 0.006506
iteration 6625 : loss : 0.027014, loss_ce: 0.010151
iteration 6626 : loss : 0.033876, loss_ce: 0.012549
iteration 6627 : loss : 0.032941, loss_ce: 0.008875
iteration 6628 : loss : 0.025879, loss_ce: 0.007133
iteration 6629 : loss : 0.028530, loss_ce: 0.008727
iteration 6630 : loss : 0.033954, loss_ce: 0.012823
iteration 6631 : loss : 0.026887, loss_ce: 0.008147
iteration 6632 : loss : 0.044408, loss_ce: 0.011058
iteration 6633 : loss : 0.026027, loss_ce: 0.009724
iteration 6634 : loss : 0.030077, loss_ce: 0.006614
iteration 6635 : loss : 0.033917, loss_ce: 0.010469
iteration 6636 : loss : 0.026166, loss_ce: 0.008176
iteration 6637 : loss : 0.030689, loss_ce: 0.007548
iteration 6638 : loss : 0.032284, loss_ce: 0.011591
iteration 6639 : loss : 0.037078, loss_ce: 0.007994
iteration 6640 : loss : 0.031160, loss_ce: 0.008092
iteration 6641 : loss : 0.028919, loss_ce: 0.011383
iteration 6642 : loss : 0.033613, loss_ce: 0.011989
iteration 6643 : loss : 0.037175, loss_ce: 0.014319
iteration 6644 : loss : 0.037176, loss_ce: 0.009518
iteration 6645 : loss : 0.023222, loss_ce: 0.007480
iteration 6646 : loss : 0.034014, loss_ce: 0.010122
iteration 6647 : loss : 0.025892, loss_ce: 0.007184
iteration 6648 : loss : 0.029301, loss_ce: 0.011717
iteration 6649 : loss : 0.028892, loss_ce: 0.012272
iteration 6650 : loss : 0.046088, loss_ce: 0.009354
iteration 6651 : loss : 0.047060, loss_ce: 0.013665
iteration 6652 : loss : 0.031024, loss_ce: 0.005796
iteration 6653 : loss : 0.027597, loss_ce: 0.008923
iteration 6654 : loss : 0.029988, loss_ce: 0.011652
iteration 6655 : loss : 0.031757, loss_ce: 0.007088
iteration 6656 : loss : 0.026537, loss_ce: 0.009691
iteration 6657 : loss : 0.025709, loss_ce: 0.005413
iteration 6658 : loss : 0.031046, loss_ce: 0.013610
iteration 6659 : loss : 0.031568, loss_ce: 0.006984
iteration 6660 : loss : 0.026055, loss_ce: 0.009647
iteration 6661 : loss : 0.029352, loss_ce: 0.008995
iteration 6662 : loss : 0.047266, loss_ce: 0.010853
iteration 6663 : loss : 0.084190, loss_ce: 0.007462
iteration 6664 : loss : 0.033231, loss_ce: 0.010096
iteration 6665 : loss : 0.028943, loss_ce: 0.012924
iteration 6666 : loss : 0.037394, loss_ce: 0.009815
iteration 6667 : loss : 0.031075, loss_ce: 0.014119
iteration 6668 : loss : 0.027104, loss_ce: 0.011664
iteration 6669 : loss : 0.031795, loss_ce: 0.010669
iteration 6670 : loss : 0.032497, loss_ce: 0.019496
iteration 6671 : loss : 0.035296, loss_ce: 0.011381
iteration 6672 : loss : 0.079669, loss_ce: 0.011048
iteration 6673 : loss : 0.081257, loss_ce: 0.010082
iteration 6674 : loss : 0.027801, loss_ce: 0.008095
iteration 6675 : loss : 0.023278, loss_ce: 0.008932
iteration 6676 : loss : 0.027917, loss_ce: 0.007926
iteration 6677 : loss : 0.029219, loss_ce: 0.013525
iteration 6678 : loss : 0.028127, loss_ce: 0.009082
iteration 6679 : loss : 0.039922, loss_ce: 0.004935
iteration 6680 : loss : 0.028401, loss_ce: 0.013431
iteration 6681 : loss : 0.034604, loss_ce: 0.011294
iteration 6682 : loss : 0.037447, loss_ce: 0.012954
iteration 6683 : loss : 0.028268, loss_ce: 0.005592
iteration 6684 : loss : 0.032866, loss_ce: 0.013216
iteration 6685 : loss : 0.035549, loss_ce: 0.006360
iteration 6686 : loss : 0.030557, loss_ce: 0.011494
iteration 6687 : loss : 0.031891, loss_ce: 0.009499
iteration 6688 : loss : 0.079669, loss_ce: 0.006709
iteration 6689 : loss : 0.026790, loss_ce: 0.010130
iteration 6690 : loss : 0.080691, loss_ce: 0.009210
iteration 6691 : loss : 0.029158, loss_ce: 0.014147
iteration 6692 : loss : 0.025639, loss_ce: 0.006863
iteration 6693 : loss : 0.078734, loss_ce: 0.008318
iteration 6694 : loss : 0.027103, loss_ce: 0.009491
iteration 6695 : loss : 0.036824, loss_ce: 0.007975
iteration 6696 : loss : 0.204651, loss_ce: 0.011733
 36%|██████████                  | 72/200 [1:13:57<2:11:24, 61.60s/it]iteration 6697 : loss : 0.029609, loss_ce: 0.011599
iteration 6698 : loss : 0.031662, loss_ce: 0.010630
iteration 6699 : loss : 0.032538, loss_ce: 0.014106
iteration 6700 : loss : 0.031390, loss_ce: 0.005889
iteration 6701 : loss : 0.031261, loss_ce: 0.014990
iteration 6702 : loss : 0.038880, loss_ce: 0.009880
iteration 6703 : loss : 0.038968, loss_ce: 0.015696
iteration 6704 : loss : 0.027159, loss_ce: 0.010179
iteration 6705 : loss : 0.047037, loss_ce: 0.006343
iteration 6706 : loss : 0.035685, loss_ce: 0.012592
iteration 6707 : loss : 0.086282, loss_ce: 0.002901
iteration 6708 : loss : 0.037368, loss_ce: 0.005669
iteration 6709 : loss : 0.028387, loss_ce: 0.008589
iteration 6710 : loss : 0.037887, loss_ce: 0.016100
iteration 6711 : loss : 0.033795, loss_ce: 0.016910
iteration 6712 : loss : 0.031042, loss_ce: 0.010416
iteration 6713 : loss : 0.033572, loss_ce: 0.009426
iteration 6714 : loss : 0.035523, loss_ce: 0.014928
iteration 6715 : loss : 0.027836, loss_ce: 0.014553
iteration 6716 : loss : 0.034276, loss_ce: 0.020763
iteration 6717 : loss : 0.030758, loss_ce: 0.007888
iteration 6718 : loss : 0.025104, loss_ce: 0.009564
iteration 6719 : loss : 0.033426, loss_ce: 0.011623
iteration 6720 : loss : 0.037083, loss_ce: 0.011979
iteration 6721 : loss : 0.037676, loss_ce: 0.008836
iteration 6722 : loss : 0.032824, loss_ce: 0.010203
iteration 6723 : loss : 0.028458, loss_ce: 0.013456
iteration 6724 : loss : 0.035660, loss_ce: 0.008064
iteration 6725 : loss : 0.039857, loss_ce: 0.010904
iteration 6726 : loss : 0.042173, loss_ce: 0.020564
iteration 6727 : loss : 0.030719, loss_ce: 0.010960
iteration 6728 : loss : 0.030714, loss_ce: 0.012540
iteration 6729 : loss : 0.031984, loss_ce: 0.011351
iteration 6730 : loss : 0.026382, loss_ce: 0.007797
iteration 6731 : loss : 0.033852, loss_ce: 0.014075
iteration 6732 : loss : 0.033184, loss_ce: 0.012551
iteration 6733 : loss : 0.031721, loss_ce: 0.007541
iteration 6734 : loss : 0.074016, loss_ce: 0.009372
iteration 6735 : loss : 0.028490, loss_ce: 0.007074
iteration 6736 : loss : 0.029142, loss_ce: 0.012096
iteration 6737 : loss : 0.032732, loss_ce: 0.010572
iteration 6738 : loss : 0.026566, loss_ce: 0.012932
iteration 6739 : loss : 0.042582, loss_ce: 0.010564
iteration 6740 : loss : 0.029714, loss_ce: 0.007195
iteration 6741 : loss : 0.031121, loss_ce: 0.013173
iteration 6742 : loss : 0.031139, loss_ce: 0.013239
iteration 6743 : loss : 0.024078, loss_ce: 0.007600
iteration 6744 : loss : 0.028370, loss_ce: 0.011133
iteration 6745 : loss : 0.035108, loss_ce: 0.016832
iteration 6746 : loss : 0.026039, loss_ce: 0.009552
iteration 6747 : loss : 0.076914, loss_ce: 0.006324
iteration 6748 : loss : 0.024387, loss_ce: 0.007211
iteration 6749 : loss : 0.029869, loss_ce: 0.012964
iteration 6750 : loss : 0.028692, loss_ce: 0.012072
iteration 6751 : loss : 0.037097, loss_ce: 0.006649
iteration 6752 : loss : 0.033358, loss_ce: 0.009898
iteration 6753 : loss : 0.033827, loss_ce: 0.006070
iteration 6754 : loss : 0.085325, loss_ce: 0.008226
iteration 6755 : loss : 0.027872, loss_ce: 0.008943
iteration 6756 : loss : 0.029531, loss_ce: 0.011145
iteration 6757 : loss : 0.025422, loss_ce: 0.008826
iteration 6758 : loss : 0.026506, loss_ce: 0.007286
iteration 6759 : loss : 0.022800, loss_ce: 0.004963
iteration 6760 : loss : 0.021975, loss_ce: 0.009665
iteration 6761 : loss : 0.027390, loss_ce: 0.013993
iteration 6762 : loss : 0.025912, loss_ce: 0.011198
iteration 6763 : loss : 0.029146, loss_ce: 0.008564
iteration 6764 : loss : 0.046924, loss_ce: 0.012964
iteration 6765 : loss : 0.027171, loss_ce: 0.011220
iteration 6766 : loss : 0.030791, loss_ce: 0.006343
iteration 6767 : loss : 0.034075, loss_ce: 0.010942
iteration 6768 : loss : 0.033035, loss_ce: 0.009365
iteration 6769 : loss : 0.082774, loss_ce: 0.009054
iteration 6770 : loss : 0.033812, loss_ce: 0.010997
iteration 6771 : loss : 0.027400, loss_ce: 0.008016
iteration 6772 : loss : 0.030490, loss_ce: 0.014640
iteration 6773 : loss : 0.022556, loss_ce: 0.009129
iteration 6774 : loss : 0.036249, loss_ce: 0.009599
iteration 6775 : loss : 0.078578, loss_ce: 0.007802
iteration 6776 : loss : 0.026505, loss_ce: 0.009103
iteration 6777 : loss : 0.026933, loss_ce: 0.009654
iteration 6778 : loss : 0.033395, loss_ce: 0.010496
iteration 6779 : loss : 0.031978, loss_ce: 0.013314
iteration 6780 : loss : 0.028728, loss_ce: 0.008727
iteration 6781 : loss : 0.028745, loss_ce: 0.008979
iteration 6782 : loss : 0.028530, loss_ce: 0.008317
iteration 6783 : loss : 0.075213, loss_ce: 0.005740
iteration 6784 : loss : 0.024096, loss_ce: 0.008487
iteration 6785 : loss : 0.025840, loss_ce: 0.009510
iteration 6786 : loss : 0.031256, loss_ce: 0.014437
iteration 6787 : loss : 0.034054, loss_ce: 0.010843
iteration 6788 : loss : 0.036437, loss_ce: 0.011003
iteration 6789 : loss : 0.239680, loss_ce: 0.021046
 36%|██████████▏                 | 73/200 [1:14:58<2:10:16, 61.55s/it]iteration 6790 : loss : 0.025893, loss_ce: 0.009599
iteration 6791 : loss : 0.026911, loss_ce: 0.011426
iteration 6792 : loss : 0.033469, loss_ce: 0.011408
iteration 6793 : loss : 0.030334, loss_ce: 0.007650
iteration 6794 : loss : 0.027416, loss_ce: 0.005339
iteration 6795 : loss : 0.034727, loss_ce: 0.010033
iteration 6796 : loss : 0.034175, loss_ce: 0.014392
iteration 6797 : loss : 0.022796, loss_ce: 0.006870
iteration 6798 : loss : 0.032492, loss_ce: 0.009390
iteration 6799 : loss : 0.026469, loss_ce: 0.007428
iteration 6800 : loss : 0.036029, loss_ce: 0.012674
iteration 6801 : loss : 0.037056, loss_ce: 0.011355
iteration 6802 : loss : 0.029112, loss_ce: 0.011865
iteration 6803 : loss : 0.029605, loss_ce: 0.009854
iteration 6804 : loss : 0.027412, loss_ce: 0.006998
iteration 6805 : loss : 0.036885, loss_ce: 0.011486
iteration 6806 : loss : 0.030827, loss_ce: 0.012303
iteration 6807 : loss : 0.030380, loss_ce: 0.010778
iteration 6808 : loss : 0.025958, loss_ce: 0.009316
iteration 6809 : loss : 0.033466, loss_ce: 0.009214
iteration 6810 : loss : 0.028213, loss_ce: 0.011025
iteration 6811 : loss : 0.022909, loss_ce: 0.009745
iteration 6812 : loss : 0.026340, loss_ce: 0.008630
iteration 6813 : loss : 0.029795, loss_ce: 0.012798
iteration 6814 : loss : 0.033083, loss_ce: 0.006147
iteration 6815 : loss : 0.032233, loss_ce: 0.010526
iteration 6816 : loss : 0.034242, loss_ce: 0.008709
iteration 6817 : loss : 0.035083, loss_ce: 0.007659
iteration 6818 : loss : 0.028789, loss_ce: 0.012767
iteration 6819 : loss : 0.024278, loss_ce: 0.007499
iteration 6820 : loss : 0.031875, loss_ce: 0.008563
iteration 6821 : loss : 0.025961, loss_ce: 0.006104
iteration 6822 : loss : 0.028603, loss_ce: 0.010407
iteration 6823 : loss : 0.039783, loss_ce: 0.012058
iteration 6824 : loss : 0.084637, loss_ce: 0.008294
iteration 6825 : loss : 0.026425, loss_ce: 0.013268
iteration 6826 : loss : 0.029398, loss_ce: 0.010590
iteration 6827 : loss : 0.030125, loss_ce: 0.009302
iteration 6828 : loss : 0.030991, loss_ce: 0.008055
iteration 6829 : loss : 0.031330, loss_ce: 0.009247
iteration 6830 : loss : 0.025280, loss_ce: 0.007763
iteration 6831 : loss : 0.026448, loss_ce: 0.009637
iteration 6832 : loss : 0.031152, loss_ce: 0.015249
iteration 6833 : loss : 0.026266, loss_ce: 0.007911
iteration 6834 : loss : 0.026668, loss_ce: 0.008701
iteration 6835 : loss : 0.029907, loss_ce: 0.008182
iteration 6836 : loss : 0.035592, loss_ce: 0.005994
iteration 6837 : loss : 0.023694, loss_ce: 0.007441
iteration 6838 : loss : 0.031857, loss_ce: 0.010647
iteration 6839 : loss : 0.065137, loss_ce: 0.014033
iteration 6840 : loss : 0.028413, loss_ce: 0.012137
iteration 6841 : loss : 0.028116, loss_ce: 0.008697
iteration 6842 : loss : 0.025920, loss_ce: 0.009554
iteration 6843 : loss : 0.028339, loss_ce: 0.010721
iteration 6844 : loss : 0.027211, loss_ce: 0.008472
iteration 6845 : loss : 0.085303, loss_ce: 0.005968
iteration 6846 : loss : 0.030958, loss_ce: 0.016337
iteration 6847 : loss : 0.026497, loss_ce: 0.009740
iteration 6848 : loss : 0.035496, loss_ce: 0.010694
iteration 6849 : loss : 0.046681, loss_ce: 0.006652
iteration 6850 : loss : 0.028413, loss_ce: 0.009318
iteration 6851 : loss : 0.031027, loss_ce: 0.013214
iteration 6852 : loss : 0.035712, loss_ce: 0.015384
iteration 6853 : loss : 0.032923, loss_ce: 0.013664
iteration 6854 : loss : 0.027186, loss_ce: 0.011483
iteration 6855 : loss : 0.026342, loss_ce: 0.006117
iteration 6856 : loss : 0.037058, loss_ce: 0.010226
iteration 6857 : loss : 0.025385, loss_ce: 0.011030
iteration 6858 : loss : 0.028629, loss_ce: 0.008277
iteration 6859 : loss : 0.030737, loss_ce: 0.010651
iteration 6860 : loss : 0.028108, loss_ce: 0.009351
iteration 6861 : loss : 0.035468, loss_ce: 0.017046
iteration 6862 : loss : 0.028875, loss_ce: 0.011607
iteration 6863 : loss : 0.028193, loss_ce: 0.011931
iteration 6864 : loss : 0.053288, loss_ce: 0.007011
iteration 6865 : loss : 0.026145, loss_ce: 0.008411
iteration 6866 : loss : 0.029117, loss_ce: 0.008819
iteration 6867 : loss : 0.032511, loss_ce: 0.010977
iteration 6868 : loss : 0.033646, loss_ce: 0.014731
iteration 6869 : loss : 0.049394, loss_ce: 0.015285
iteration 6870 : loss : 0.033689, loss_ce: 0.014064
iteration 6871 : loss : 0.029873, loss_ce: 0.007659
iteration 6872 : loss : 0.027956, loss_ce: 0.008397
iteration 6873 : loss : 0.030608, loss_ce: 0.008813
iteration 6874 : loss : 0.029117, loss_ce: 0.009797
iteration 6875 : loss : 0.024134, loss_ce: 0.006898
iteration 6876 : loss : 0.030044, loss_ce: 0.008663
iteration 6877 : loss : 0.034454, loss_ce: 0.008946
iteration 6878 : loss : 0.028533, loss_ce: 0.009107
iteration 6879 : loss : 0.026247, loss_ce: 0.007218
iteration 6880 : loss : 0.027536, loss_ce: 0.009389
iteration 6881 : loss : 0.035704, loss_ce: 0.008243
iteration 6882 : loss : 0.138083, loss_ce: 0.018027
 37%|██████████▎                 | 74/200 [1:16:00<2:09:16, 61.56s/it]iteration 6883 : loss : 0.028002, loss_ce: 0.011527
iteration 6884 : loss : 0.028074, loss_ce: 0.012799
iteration 6885 : loss : 0.057191, loss_ce: 0.008924
iteration 6886 : loss : 0.027347, loss_ce: 0.010396
iteration 6887 : loss : 0.032982, loss_ce: 0.013398
iteration 6888 : loss : 0.039922, loss_ce: 0.012422
iteration 6889 : loss : 0.027210, loss_ce: 0.006949
iteration 6890 : loss : 0.032031, loss_ce: 0.012251
iteration 6891 : loss : 0.035072, loss_ce: 0.009673
iteration 6892 : loss : 0.023969, loss_ce: 0.008465
iteration 6893 : loss : 0.030869, loss_ce: 0.011010
iteration 6894 : loss : 0.027555, loss_ce: 0.010906
iteration 6895 : loss : 0.025925, loss_ce: 0.006285
iteration 6896 : loss : 0.126983, loss_ce: 0.007051
iteration 6897 : loss : 0.034899, loss_ce: 0.019065
iteration 6898 : loss : 0.031104, loss_ce: 0.008726
iteration 6899 : loss : 0.034704, loss_ce: 0.005854
iteration 6900 : loss : 0.036438, loss_ce: 0.009419
iteration 6901 : loss : 0.039012, loss_ce: 0.009325
iteration 6902 : loss : 0.026403, loss_ce: 0.008239
iteration 6903 : loss : 0.038090, loss_ce: 0.008504
iteration 6904 : loss : 0.039743, loss_ce: 0.006552
iteration 6905 : loss : 0.030295, loss_ce: 0.008336
iteration 6906 : loss : 0.031870, loss_ce: 0.013570
iteration 6907 : loss : 0.033086, loss_ce: 0.014242
iteration 6908 : loss : 0.029958, loss_ce: 0.012946
iteration 6909 : loss : 0.033154, loss_ce: 0.015080
iteration 6910 : loss : 0.037383, loss_ce: 0.009658
iteration 6911 : loss : 0.035105, loss_ce: 0.008711
iteration 6912 : loss : 0.023945, loss_ce: 0.008868
iteration 6913 : loss : 0.026699, loss_ce: 0.007922
iteration 6914 : loss : 0.042704, loss_ce: 0.013381
iteration 6915 : loss : 0.027498, loss_ce: 0.010697
iteration 6916 : loss : 0.029964, loss_ce: 0.011367
iteration 6917 : loss : 0.031669, loss_ce: 0.009887
iteration 6918 : loss : 0.037825, loss_ce: 0.008426
iteration 6919 : loss : 0.082436, loss_ce: 0.008017
iteration 6920 : loss : 0.031436, loss_ce: 0.008663
iteration 6921 : loss : 0.030088, loss_ce: 0.008276
iteration 6922 : loss : 0.076270, loss_ce: 0.010544
iteration 6923 : loss : 0.030568, loss_ce: 0.010064
iteration 6924 : loss : 0.037702, loss_ce: 0.010785
iteration 6925 : loss : 0.081957, loss_ce: 0.013163
iteration 6926 : loss : 0.030047, loss_ce: 0.011271
iteration 6927 : loss : 0.028651, loss_ce: 0.010792
iteration 6928 : loss : 0.032040, loss_ce: 0.010775
iteration 6929 : loss : 0.028200, loss_ce: 0.009091
iteration 6930 : loss : 0.029919, loss_ce: 0.010983
iteration 6931 : loss : 0.026227, loss_ce: 0.010670
iteration 6932 : loss : 0.027533, loss_ce: 0.012134
iteration 6933 : loss : 0.028871, loss_ce: 0.012727
iteration 6934 : loss : 0.028676, loss_ce: 0.010769
iteration 6935 : loss : 0.031064, loss_ce: 0.011119
iteration 6936 : loss : 0.025458, loss_ce: 0.008676
iteration 6937 : loss : 0.026663, loss_ce: 0.008620
iteration 6938 : loss : 0.133248, loss_ce: 0.005478
iteration 6939 : loss : 0.040806, loss_ce: 0.009745
iteration 6940 : loss : 0.032721, loss_ce: 0.008969
iteration 6941 : loss : 0.031187, loss_ce: 0.012206
iteration 6942 : loss : 0.025087, loss_ce: 0.010077
iteration 6943 : loss : 0.034872, loss_ce: 0.008097
iteration 6944 : loss : 0.025306, loss_ce: 0.007841
iteration 6945 : loss : 0.029952, loss_ce: 0.007192
iteration 6946 : loss : 0.041407, loss_ce: 0.010609
iteration 6947 : loss : 0.025535, loss_ce: 0.006542
iteration 6948 : loss : 0.028224, loss_ce: 0.007316
iteration 6949 : loss : 0.028835, loss_ce: 0.010320
iteration 6950 : loss : 0.031964, loss_ce: 0.011260
iteration 6951 : loss : 0.080863, loss_ce: 0.011307
iteration 6952 : loss : 0.032223, loss_ce: 0.012264
iteration 6953 : loss : 0.030836, loss_ce: 0.012754
iteration 6954 : loss : 0.032948, loss_ce: 0.007349
iteration 6955 : loss : 0.033574, loss_ce: 0.014270
iteration 6956 : loss : 0.036688, loss_ce: 0.007975
iteration 6957 : loss : 0.026224, loss_ce: 0.007159
iteration 6958 : loss : 0.037636, loss_ce: 0.008678
iteration 6959 : loss : 0.026499, loss_ce: 0.008837
iteration 6960 : loss : 0.034895, loss_ce: 0.017252
iteration 6961 : loss : 0.027414, loss_ce: 0.012689
iteration 6962 : loss : 0.031265, loss_ce: 0.010871
iteration 6963 : loss : 0.129909, loss_ce: 0.005613
iteration 6964 : loss : 0.079669, loss_ce: 0.008585
iteration 6965 : loss : 0.031378, loss_ce: 0.009831
iteration 6966 : loss : 0.039136, loss_ce: 0.018629
iteration 6967 : loss : 0.023595, loss_ce: 0.010899
iteration 6968 : loss : 0.026227, loss_ce: 0.009261
iteration 6969 : loss : 0.032199, loss_ce: 0.005788
iteration 6970 : loss : 0.027812, loss_ce: 0.007371
iteration 6971 : loss : 0.024932, loss_ce: 0.008863
iteration 6972 : loss : 0.034019, loss_ce: 0.015468
iteration 6973 : loss : 0.027982, loss_ce: 0.008030
iteration 6974 : loss : 0.079090, loss_ce: 0.007401
iteration 6975 : loss : 0.087907, loss_ce: 0.015292
 38%|██████████▌                 | 75/200 [1:17:01<2:08:11, 61.53s/it]iteration 6976 : loss : 0.031352, loss_ce: 0.009773
iteration 6977 : loss : 0.026324, loss_ce: 0.009423
iteration 6978 : loss : 0.033476, loss_ce: 0.012756
iteration 6979 : loss : 0.026398, loss_ce: 0.009063
iteration 6980 : loss : 0.031114, loss_ce: 0.011670
iteration 6981 : loss : 0.034778, loss_ce: 0.007629
iteration 6982 : loss : 0.030748, loss_ce: 0.015130
iteration 6983 : loss : 0.030105, loss_ce: 0.010217
iteration 6984 : loss : 0.035998, loss_ce: 0.011843
iteration 6985 : loss : 0.029090, loss_ce: 0.013026
iteration 6986 : loss : 0.035188, loss_ce: 0.013283
iteration 6987 : loss : 0.027367, loss_ce: 0.007905
iteration 6988 : loss : 0.039630, loss_ce: 0.014527
iteration 6989 : loss : 0.029391, loss_ce: 0.007524
iteration 6990 : loss : 0.025056, loss_ce: 0.011315
iteration 6991 : loss : 0.025628, loss_ce: 0.008880
iteration 6992 : loss : 0.025532, loss_ce: 0.007095
iteration 6993 : loss : 0.031770, loss_ce: 0.011358
iteration 6994 : loss : 0.034064, loss_ce: 0.005463
iteration 6995 : loss : 0.029344, loss_ce: 0.013433
iteration 6996 : loss : 0.028470, loss_ce: 0.009719
iteration 6997 : loss : 0.024522, loss_ce: 0.008652
iteration 6998 : loss : 0.031151, loss_ce: 0.014448
iteration 6999 : loss : 0.026852, loss_ce: 0.008804
iteration 7000 : loss : 0.039751, loss_ce: 0.008597
iteration 7001 : loss : 0.031033, loss_ce: 0.006994
iteration 7002 : loss : 0.029250, loss_ce: 0.008577
iteration 7003 : loss : 0.076815, loss_ce: 0.010829
iteration 7004 : loss : 0.024840, loss_ce: 0.007120
iteration 7005 : loss : 0.030907, loss_ce: 0.012027
iteration 7006 : loss : 0.082919, loss_ce: 0.007275
iteration 7007 : loss : 0.024848, loss_ce: 0.008248
iteration 7008 : loss : 0.024303, loss_ce: 0.009759
iteration 7009 : loss : 0.029657, loss_ce: 0.013896
iteration 7010 : loss : 0.026302, loss_ce: 0.013612
iteration 7011 : loss : 0.029586, loss_ce: 0.008022
iteration 7012 : loss : 0.025040, loss_ce: 0.005729
iteration 7013 : loss : 0.035336, loss_ce: 0.010225
iteration 7014 : loss : 0.029080, loss_ce: 0.011697
iteration 7015 : loss : 0.031086, loss_ce: 0.009314
iteration 7016 : loss : 0.030628, loss_ce: 0.008628
iteration 7017 : loss : 0.028152, loss_ce: 0.014155
iteration 7018 : loss : 0.028584, loss_ce: 0.009672
iteration 7019 : loss : 0.035230, loss_ce: 0.008309
iteration 7020 : loss : 0.082128, loss_ce: 0.012821
iteration 7021 : loss : 0.033480, loss_ce: 0.014148
iteration 7022 : loss : 0.024475, loss_ce: 0.008496
iteration 7023 : loss : 0.029683, loss_ce: 0.006654
iteration 7024 : loss : 0.033663, loss_ce: 0.015369
iteration 7025 : loss : 0.027716, loss_ce: 0.008609
iteration 7026 : loss : 0.029491, loss_ce: 0.007342
iteration 7027 : loss : 0.035022, loss_ce: 0.017634
iteration 7028 : loss : 0.028061, loss_ce: 0.008732
iteration 7029 : loss : 0.047117, loss_ce: 0.012896
iteration 7030 : loss : 0.027062, loss_ce: 0.011111
iteration 7031 : loss : 0.039683, loss_ce: 0.010963
iteration 7032 : loss : 0.034488, loss_ce: 0.011447
iteration 7033 : loss : 0.030059, loss_ce: 0.008176
iteration 7034 : loss : 0.034993, loss_ce: 0.013619
iteration 7035 : loss : 0.028311, loss_ce: 0.008168
iteration 7036 : loss : 0.022064, loss_ce: 0.005936
iteration 7037 : loss : 0.080614, loss_ce: 0.007843
iteration 7038 : loss : 0.037416, loss_ce: 0.007861
iteration 7039 : loss : 0.034365, loss_ce: 0.006026
iteration 7040 : loss : 0.030194, loss_ce: 0.010246
iteration 7041 : loss : 0.074337, loss_ce: 0.006121
iteration 7042 : loss : 0.028496, loss_ce: 0.006115
iteration 7043 : loss : 0.027182, loss_ce: 0.010349
iteration 7044 : loss : 0.024860, loss_ce: 0.007797
iteration 7045 : loss : 0.029401, loss_ce: 0.014588
iteration 7046 : loss : 0.031905, loss_ce: 0.009165
iteration 7047 : loss : 0.032076, loss_ce: 0.012361
iteration 7048 : loss : 0.031580, loss_ce: 0.009683
iteration 7049 : loss : 0.027897, loss_ce: 0.009909
iteration 7050 : loss : 0.035970, loss_ce: 0.004051
iteration 7051 : loss : 0.028473, loss_ce: 0.008282
iteration 7052 : loss : 0.028199, loss_ce: 0.011952
iteration 7053 : loss : 0.073598, loss_ce: 0.005752
iteration 7054 : loss : 0.031118, loss_ce: 0.010100
iteration 7055 : loss : 0.025269, loss_ce: 0.009421
iteration 7056 : loss : 0.051812, loss_ce: 0.010742
iteration 7057 : loss : 0.027018, loss_ce: 0.012273
iteration 7058 : loss : 0.030007, loss_ce: 0.008964
iteration 7059 : loss : 0.032382, loss_ce: 0.009743
iteration 7060 : loss : 0.034598, loss_ce: 0.008026
iteration 7061 : loss : 0.032793, loss_ce: 0.012312
iteration 7062 : loss : 0.028285, loss_ce: 0.006781
iteration 7063 : loss : 0.021887, loss_ce: 0.006092
iteration 7064 : loss : 0.028224, loss_ce: 0.011140
iteration 7065 : loss : 0.032385, loss_ce: 0.008305
iteration 7066 : loss : 0.023726, loss_ce: 0.006748
iteration 7067 : loss : 0.038031, loss_ce: 0.007688
iteration 7068 : loss : 0.286306, loss_ce: 0.001684
 38%|██████████▋                 | 76/200 [1:18:03<2:07:13, 61.56s/it]iteration 7069 : loss : 0.024967, loss_ce: 0.009367
iteration 7070 : loss : 0.021381, loss_ce: 0.008184
iteration 7071 : loss : 0.030064, loss_ce: 0.006836
iteration 7072 : loss : 0.022458, loss_ce: 0.006946
iteration 7073 : loss : 0.030270, loss_ce: 0.008799
iteration 7074 : loss : 0.023198, loss_ce: 0.008474
iteration 7075 : loss : 0.032484, loss_ce: 0.010646
iteration 7076 : loss : 0.030560, loss_ce: 0.006243
iteration 7077 : loss : 0.023539, loss_ce: 0.009116
iteration 7078 : loss : 0.026881, loss_ce: 0.007466
iteration 7079 : loss : 0.026195, loss_ce: 0.011588
iteration 7080 : loss : 0.078428, loss_ce: 0.007648
iteration 7081 : loss : 0.031649, loss_ce: 0.008015
iteration 7082 : loss : 0.028048, loss_ce: 0.011422
iteration 7083 : loss : 0.031846, loss_ce: 0.008910
iteration 7084 : loss : 0.035308, loss_ce: 0.006882
iteration 7085 : loss : 0.034218, loss_ce: 0.012302
iteration 7086 : loss : 0.023320, loss_ce: 0.007399
iteration 7087 : loss : 0.025388, loss_ce: 0.007328
iteration 7088 : loss : 0.026800, loss_ce: 0.010482
iteration 7089 : loss : 0.028308, loss_ce: 0.013993
iteration 7090 : loss : 0.023489, loss_ce: 0.005845
iteration 7091 : loss : 0.053763, loss_ce: 0.011671
iteration 7092 : loss : 0.029101, loss_ce: 0.006617
iteration 7093 : loss : 0.032197, loss_ce: 0.009190
iteration 7094 : loss : 0.083952, loss_ce: 0.011985
iteration 7095 : loss : 0.030690, loss_ce: 0.006417
iteration 7096 : loss : 0.066942, loss_ce: 0.006688
iteration 7097 : loss : 0.030262, loss_ce: 0.009815
iteration 7098 : loss : 0.081288, loss_ce: 0.008294
iteration 7099 : loss : 0.034782, loss_ce: 0.005948
iteration 7100 : loss : 0.034755, loss_ce: 0.011259
iteration 7101 : loss : 0.032902, loss_ce: 0.016469
iteration 7102 : loss : 0.038372, loss_ce: 0.008438
iteration 7103 : loss : 0.032192, loss_ce: 0.009535
iteration 7104 : loss : 0.031763, loss_ce: 0.013820
iteration 7105 : loss : 0.036098, loss_ce: 0.007474
iteration 7106 : loss : 0.023077, loss_ce: 0.006826
iteration 7107 : loss : 0.021952, loss_ce: 0.006090
iteration 7108 : loss : 0.029229, loss_ce: 0.013286
iteration 7109 : loss : 0.032331, loss_ce: 0.007913
iteration 7110 : loss : 0.031101, loss_ce: 0.009924
iteration 7111 : loss : 0.035048, loss_ce: 0.006199
iteration 7112 : loss : 0.031687, loss_ce: 0.012883
iteration 7113 : loss : 0.028638, loss_ce: 0.011917
iteration 7114 : loss : 0.026175, loss_ce: 0.010835
iteration 7115 : loss : 0.030667, loss_ce: 0.016379
iteration 7116 : loss : 0.032762, loss_ce: 0.013889
iteration 7117 : loss : 0.029358, loss_ce: 0.012610
iteration 7118 : loss : 0.098600, loss_ce: 0.006221
iteration 7119 : loss : 0.077858, loss_ce: 0.006091
iteration 7120 : loss : 0.029889, loss_ce: 0.005758
iteration 7121 : loss : 0.029445, loss_ce: 0.010910
iteration 7122 : loss : 0.026337, loss_ce: 0.009972
iteration 7123 : loss : 0.031918, loss_ce: 0.009418
iteration 7124 : loss : 0.028130, loss_ce: 0.006892
iteration 7125 : loss : 0.031540, loss_ce: 0.013976
iteration 7126 : loss : 0.029970, loss_ce: 0.008887
iteration 7127 : loss : 0.034844, loss_ce: 0.009983
iteration 7128 : loss : 0.029359, loss_ce: 0.008065
iteration 7129 : loss : 0.037704, loss_ce: 0.007712
iteration 7130 : loss : 0.042188, loss_ce: 0.010540
iteration 7131 : loss : 0.031489, loss_ce: 0.013572
iteration 7132 : loss : 0.026072, loss_ce: 0.009332
iteration 7133 : loss : 0.028582, loss_ce: 0.009076
iteration 7134 : loss : 0.030580, loss_ce: 0.010404
iteration 7135 : loss : 0.033327, loss_ce: 0.014686
iteration 7136 : loss : 0.025952, loss_ce: 0.010574
iteration 7137 : loss : 0.034488, loss_ce: 0.012972
iteration 7138 : loss : 0.026692, loss_ce: 0.009871
iteration 7139 : loss : 0.025832, loss_ce: 0.012325
iteration 7140 : loss : 0.041174, loss_ce: 0.006087
iteration 7141 : loss : 0.030694, loss_ce: 0.012216
iteration 7142 : loss : 0.028375, loss_ce: 0.010112
iteration 7143 : loss : 0.027979, loss_ce: 0.009359
iteration 7144 : loss : 0.040832, loss_ce: 0.009410
iteration 7145 : loss : 0.030074, loss_ce: 0.015778
iteration 7146 : loss : 0.036358, loss_ce: 0.008947
iteration 7147 : loss : 0.026800, loss_ce: 0.011421
iteration 7148 : loss : 0.031665, loss_ce: 0.011009
iteration 7149 : loss : 0.032454, loss_ce: 0.010892
iteration 7150 : loss : 0.027975, loss_ce: 0.010914
iteration 7151 : loss : 0.033043, loss_ce: 0.008309
iteration 7152 : loss : 0.049531, loss_ce: 0.010085
iteration 7153 : loss : 0.041819, loss_ce: 0.010588
iteration 7154 : loss : 0.043087, loss_ce: 0.013781
iteration 7155 : loss : 0.033727, loss_ce: 0.014316
iteration 7156 : loss : 0.035006, loss_ce: 0.011158
iteration 7157 : loss : 0.028498, loss_ce: 0.013124
iteration 7158 : loss : 0.027217, loss_ce: 0.008666
iteration 7159 : loss : 0.035565, loss_ce: 0.014128
iteration 7160 : loss : 0.025855, loss_ce: 0.006362
iteration 7161 : loss : 0.041870, loss_ce: 0.013516
 38%|██████████▊                 | 77/200 [1:19:05<2:06:13, 61.57s/it]iteration 7162 : loss : 0.035865, loss_ce: 0.010430
iteration 7163 : loss : 0.035515, loss_ce: 0.016870
iteration 7164 : loss : 0.026098, loss_ce: 0.005648
iteration 7165 : loss : 0.030053, loss_ce: 0.015964
iteration 7166 : loss : 0.050363, loss_ce: 0.008989
iteration 7167 : loss : 0.028925, loss_ce: 0.007689
iteration 7168 : loss : 0.035233, loss_ce: 0.012821
iteration 7169 : loss : 0.032452, loss_ce: 0.008299
iteration 7170 : loss : 0.026672, loss_ce: 0.009786
iteration 7171 : loss : 0.031317, loss_ce: 0.008065
iteration 7172 : loss : 0.028869, loss_ce: 0.006313
iteration 7173 : loss : 0.027965, loss_ce: 0.012823
iteration 7174 : loss : 0.031985, loss_ce: 0.012116
iteration 7175 : loss : 0.028292, loss_ce: 0.012001
iteration 7176 : loss : 0.026970, loss_ce: 0.008423
iteration 7177 : loss : 0.029671, loss_ce: 0.009517
iteration 7178 : loss : 0.025378, loss_ce: 0.008169
iteration 7179 : loss : 0.026302, loss_ce: 0.011293
iteration 7180 : loss : 0.035046, loss_ce: 0.008007
iteration 7181 : loss : 0.025325, loss_ce: 0.006733
iteration 7182 : loss : 0.033291, loss_ce: 0.004077
iteration 7183 : loss : 0.042460, loss_ce: 0.010197
iteration 7184 : loss : 0.022455, loss_ce: 0.006613
iteration 7185 : loss : 0.030697, loss_ce: 0.009764
iteration 7186 : loss : 0.079427, loss_ce: 0.007121
iteration 7187 : loss : 0.035568, loss_ce: 0.014806
iteration 7188 : loss : 0.080495, loss_ce: 0.009909
iteration 7189 : loss : 0.025308, loss_ce: 0.009676
iteration 7190 : loss : 0.026728, loss_ce: 0.007713
iteration 7191 : loss : 0.028304, loss_ce: 0.007795
iteration 7192 : loss : 0.033074, loss_ce: 0.014259
iteration 7193 : loss : 0.031078, loss_ce: 0.009336
iteration 7194 : loss : 0.030983, loss_ce: 0.008045
iteration 7195 : loss : 0.024979, loss_ce: 0.007256
iteration 7196 : loss : 0.038176, loss_ce: 0.011866
iteration 7197 : loss : 0.030148, loss_ce: 0.008012
iteration 7198 : loss : 0.032834, loss_ce: 0.012544
iteration 7199 : loss : 0.033300, loss_ce: 0.008049
iteration 7200 : loss : 0.031109, loss_ce: 0.010044
iteration 7201 : loss : 0.027654, loss_ce: 0.012724
iteration 7202 : loss : 0.031765, loss_ce: 0.012869
iteration 7203 : loss : 0.039369, loss_ce: 0.010849
iteration 7204 : loss : 0.038357, loss_ce: 0.008291
iteration 7205 : loss : 0.028156, loss_ce: 0.007856
iteration 7206 : loss : 0.025571, loss_ce: 0.007529
iteration 7207 : loss : 0.035395, loss_ce: 0.007343
iteration 7208 : loss : 0.032039, loss_ce: 0.010911
iteration 7209 : loss : 0.028595, loss_ce: 0.010455
iteration 7210 : loss : 0.036106, loss_ce: 0.008916
iteration 7211 : loss : 0.027500, loss_ce: 0.010666
iteration 7212 : loss : 0.071595, loss_ce: 0.011417
iteration 7213 : loss : 0.030107, loss_ce: 0.010656
iteration 7214 : loss : 0.029001, loss_ce: 0.009548
iteration 7215 : loss : 0.030341, loss_ce: 0.011823
iteration 7216 : loss : 0.025440, loss_ce: 0.006966
iteration 7217 : loss : 0.025712, loss_ce: 0.010532
iteration 7218 : loss : 0.024290, loss_ce: 0.008860
iteration 7219 : loss : 0.036388, loss_ce: 0.011753
iteration 7220 : loss : 0.031922, loss_ce: 0.011737
iteration 7221 : loss : 0.025061, loss_ce: 0.010925
iteration 7222 : loss : 0.026526, loss_ce: 0.011544
iteration 7223 : loss : 0.044252, loss_ce: 0.009547
iteration 7224 : loss : 0.040855, loss_ce: 0.007610
iteration 7225 : loss : 0.035801, loss_ce: 0.009455
iteration 7226 : loss : 0.024379, loss_ce: 0.006895
iteration 7227 : loss : 0.026898, loss_ce: 0.012778
iteration 7228 : loss : 0.029441, loss_ce: 0.008295
iteration 7229 : loss : 0.030170, loss_ce: 0.009213
iteration 7230 : loss : 0.033513, loss_ce: 0.010229
iteration 7231 : loss : 0.029749, loss_ce: 0.007786
iteration 7232 : loss : 0.029461, loss_ce: 0.010429
iteration 7233 : loss : 0.025257, loss_ce: 0.007175
iteration 7234 : loss : 0.035065, loss_ce: 0.007655
iteration 7235 : loss : 0.028890, loss_ce: 0.010548
iteration 7236 : loss : 0.078392, loss_ce: 0.009536
iteration 7237 : loss : 0.027764, loss_ce: 0.006444
iteration 7238 : loss : 0.077768, loss_ce: 0.010563
iteration 7239 : loss : 0.026473, loss_ce: 0.011929
iteration 7240 : loss : 0.077788, loss_ce: 0.005927
iteration 7241 : loss : 0.027951, loss_ce: 0.007030
iteration 7242 : loss : 0.030523, loss_ce: 0.013928
iteration 7243 : loss : 0.028461, loss_ce: 0.006529
iteration 7244 : loss : 0.030516, loss_ce: 0.010903
iteration 7245 : loss : 0.030388, loss_ce: 0.010621
iteration 7246 : loss : 0.028581, loss_ce: 0.011650
iteration 7247 : loss : 0.029555, loss_ce: 0.008758
iteration 7248 : loss : 0.033734, loss_ce: 0.011720
iteration 7249 : loss : 0.024277, loss_ce: 0.009143
iteration 7250 : loss : 0.029519, loss_ce: 0.011067
iteration 7251 : loss : 0.040827, loss_ce: 0.015295
iteration 7252 : loss : 0.025764, loss_ce: 0.010030
iteration 7253 : loss : 0.026135, loss_ce: 0.009973
iteration 7254 : loss : 0.248620, loss_ce: 0.006308
 39%|██████████▉                 | 78/200 [1:20:06<2:05:11, 61.57s/it]iteration 7255 : loss : 0.023677, loss_ce: 0.010959
iteration 7256 : loss : 0.027144, loss_ce: 0.009757
iteration 7257 : loss : 0.025631, loss_ce: 0.008929
iteration 7258 : loss : 0.028266, loss_ce: 0.009060
iteration 7259 : loss : 0.030473, loss_ce: 0.006826
iteration 7260 : loss : 0.029920, loss_ce: 0.010449
iteration 7261 : loss : 0.029129, loss_ce: 0.016658
iteration 7262 : loss : 0.034400, loss_ce: 0.011684
iteration 7263 : loss : 0.037463, loss_ce: 0.005969
iteration 7264 : loss : 0.023089, loss_ce: 0.006547
iteration 7265 : loss : 0.023037, loss_ce: 0.011038
iteration 7266 : loss : 0.027361, loss_ce: 0.008114
iteration 7267 : loss : 0.029729, loss_ce: 0.008878
iteration 7268 : loss : 0.030393, loss_ce: 0.010695
iteration 7269 : loss : 0.032145, loss_ce: 0.009187
iteration 7270 : loss : 0.026920, loss_ce: 0.007764
iteration 7271 : loss : 0.027007, loss_ce: 0.006314
iteration 7272 : loss : 0.025063, loss_ce: 0.008651
iteration 7273 : loss : 0.028213, loss_ce: 0.011186
iteration 7274 : loss : 0.074661, loss_ce: 0.008854
iteration 7275 : loss : 0.025776, loss_ce: 0.008545
iteration 7276 : loss : 0.029952, loss_ce: 0.010878
iteration 7277 : loss : 0.033447, loss_ce: 0.015219
iteration 7278 : loss : 0.025396, loss_ce: 0.008168
iteration 7279 : loss : 0.030419, loss_ce: 0.009737
iteration 7280 : loss : 0.028483, loss_ce: 0.011322
iteration 7281 : loss : 0.031579, loss_ce: 0.013361
iteration 7282 : loss : 0.032465, loss_ce: 0.009583
iteration 7283 : loss : 0.031844, loss_ce: 0.009966
iteration 7284 : loss : 0.027408, loss_ce: 0.010490
iteration 7285 : loss : 0.026904, loss_ce: 0.009143
iteration 7286 : loss : 0.034582, loss_ce: 0.010869
iteration 7287 : loss : 0.082914, loss_ce: 0.010315
iteration 7288 : loss : 0.023982, loss_ce: 0.010326
iteration 7289 : loss : 0.032789, loss_ce: 0.011331
iteration 7290 : loss : 0.027654, loss_ce: 0.008921
iteration 7291 : loss : 0.032008, loss_ce: 0.011026
iteration 7292 : loss : 0.061649, loss_ce: 0.006560
iteration 7293 : loss : 0.028062, loss_ce: 0.011919
iteration 7294 : loss : 0.024268, loss_ce: 0.009760
iteration 7295 : loss : 0.033786, loss_ce: 0.010972
iteration 7296 : loss : 0.032564, loss_ce: 0.009551
iteration 7297 : loss : 0.034286, loss_ce: 0.011325
iteration 7298 : loss : 0.040065, loss_ce: 0.009759
iteration 7299 : loss : 0.033879, loss_ce: 0.013291
iteration 7300 : loss : 0.027499, loss_ce: 0.006116
iteration 7301 : loss : 0.027747, loss_ce: 0.009209
iteration 7302 : loss : 0.036813, loss_ce: 0.013982
iteration 7303 : loss : 0.035091, loss_ce: 0.010508
iteration 7304 : loss : 0.028739, loss_ce: 0.014019
iteration 7305 : loss : 0.032547, loss_ce: 0.012060
iteration 7306 : loss : 0.037970, loss_ce: 0.009022
iteration 7307 : loss : 0.029783, loss_ce: 0.006906
iteration 7308 : loss : 0.032564, loss_ce: 0.008307
iteration 7309 : loss : 0.060251, loss_ce: 0.008617
iteration 7310 : loss : 0.038465, loss_ce: 0.011944
iteration 7311 : loss : 0.030988, loss_ce: 0.010707
iteration 7312 : loss : 0.028593, loss_ce: 0.011697
iteration 7313 : loss : 0.033139, loss_ce: 0.010857
iteration 7314 : loss : 0.025472, loss_ce: 0.006882
iteration 7315 : loss : 0.025195, loss_ce: 0.008537
iteration 7316 : loss : 0.080922, loss_ce: 0.007071
iteration 7317 : loss : 0.030643, loss_ce: 0.015186
iteration 7318 : loss : 0.032662, loss_ce: 0.012906
iteration 7319 : loss : 0.046739, loss_ce: 0.012579
iteration 7320 : loss : 0.032069, loss_ce: 0.005139
iteration 7321 : loss : 0.028001, loss_ce: 0.006661
iteration 7322 : loss : 0.032041, loss_ce: 0.012713
iteration 7323 : loss : 0.035720, loss_ce: 0.009924
iteration 7324 : loss : 0.029909, loss_ce: 0.013293
iteration 7325 : loss : 0.024912, loss_ce: 0.008157
iteration 7326 : loss : 0.030309, loss_ce: 0.011329
iteration 7327 : loss : 0.027937, loss_ce: 0.009542
iteration 7328 : loss : 0.027061, loss_ce: 0.011840
iteration 7329 : loss : 0.028208, loss_ce: 0.012482
iteration 7330 : loss : 0.029332, loss_ce: 0.012839
iteration 7331 : loss : 0.037081, loss_ce: 0.009566
iteration 7332 : loss : 0.080419, loss_ce: 0.008310
iteration 7333 : loss : 0.032452, loss_ce: 0.012425
iteration 7334 : loss : 0.028422, loss_ce: 0.009010
iteration 7335 : loss : 0.029313, loss_ce: 0.012855
iteration 7336 : loss : 0.035247, loss_ce: 0.008236
iteration 7337 : loss : 0.036481, loss_ce: 0.008880
iteration 7338 : loss : 0.035147, loss_ce: 0.012208
iteration 7339 : loss : 0.031493, loss_ce: 0.009387
iteration 7340 : loss : 0.033789, loss_ce: 0.013916
iteration 7341 : loss : 0.032535, loss_ce: 0.012689
iteration 7342 : loss : 0.034848, loss_ce: 0.008632
iteration 7343 : loss : 0.071870, loss_ce: 0.008232
iteration 7344 : loss : 0.090746, loss_ce: 0.008736
iteration 7345 : loss : 0.076393, loss_ce: 0.008480
iteration 7346 : loss : 0.027809, loss_ce: 0.008156
iteration 7347 : loss : 0.133356, loss_ce: 0.013928
 40%|███████████                 | 79/200 [1:21:08<2:04:10, 61.58s/it]iteration 7348 : loss : 0.068068, loss_ce: 0.014413
iteration 7349 : loss : 0.035736, loss_ce: 0.010337
iteration 7350 : loss : 0.033000, loss_ce: 0.015472
iteration 7351 : loss : 0.030492, loss_ce: 0.011468
iteration 7352 : loss : 0.079021, loss_ce: 0.007150
iteration 7353 : loss : 0.039711, loss_ce: 0.012424
iteration 7354 : loss : 0.035575, loss_ce: 0.008764
iteration 7355 : loss : 0.028641, loss_ce: 0.008500
iteration 7356 : loss : 0.029134, loss_ce: 0.011386
iteration 7357 : loss : 0.026933, loss_ce: 0.011420
iteration 7358 : loss : 0.030463, loss_ce: 0.009621
iteration 7359 : loss : 0.029161, loss_ce: 0.012559
iteration 7360 : loss : 0.027980, loss_ce: 0.009930
iteration 7361 : loss : 0.040981, loss_ce: 0.010628
iteration 7362 : loss : 0.029342, loss_ce: 0.009269
iteration 7363 : loss : 0.035430, loss_ce: 0.010420
iteration 7364 : loss : 0.026195, loss_ce: 0.010993
iteration 7365 : loss : 0.032440, loss_ce: 0.007945
iteration 7366 : loss : 0.025836, loss_ce: 0.007690
iteration 7367 : loss : 0.030068, loss_ce: 0.007734
iteration 7368 : loss : 0.028151, loss_ce: 0.009559
iteration 7369 : loss : 0.034259, loss_ce: 0.010095
iteration 7370 : loss : 0.033999, loss_ce: 0.012523
iteration 7371 : loss : 0.029263, loss_ce: 0.009142
iteration 7372 : loss : 0.035017, loss_ce: 0.009140
iteration 7373 : loss : 0.025844, loss_ce: 0.007917
iteration 7374 : loss : 0.028325, loss_ce: 0.007997
iteration 7375 : loss : 0.065830, loss_ce: 0.012301
iteration 7376 : loss : 0.037940, loss_ce: 0.015576
iteration 7377 : loss : 0.029971, loss_ce: 0.009326
iteration 7378 : loss : 0.033100, loss_ce: 0.019972
iteration 7379 : loss : 0.034004, loss_ce: 0.011839
iteration 7380 : loss : 0.034508, loss_ce: 0.009488
iteration 7381 : loss : 0.033837, loss_ce: 0.008193
iteration 7382 : loss : 0.031963, loss_ce: 0.011839
iteration 7383 : loss : 0.029120, loss_ce: 0.005250
iteration 7384 : loss : 0.027951, loss_ce: 0.009888
iteration 7385 : loss : 0.033261, loss_ce: 0.010069
iteration 7386 : loss : 0.031927, loss_ce: 0.010327
iteration 7387 : loss : 0.028559, loss_ce: 0.009153
iteration 7388 : loss : 0.023705, loss_ce: 0.006484
iteration 7389 : loss : 0.031233, loss_ce: 0.012014
iteration 7390 : loss : 0.028566, loss_ce: 0.009042
iteration 7391 : loss : 0.027315, loss_ce: 0.008862
iteration 7392 : loss : 0.030584, loss_ce: 0.011945
iteration 7393 : loss : 0.039468, loss_ce: 0.010003
iteration 7394 : loss : 0.025681, loss_ce: 0.006271
iteration 7395 : loss : 0.032745, loss_ce: 0.016528
iteration 7396 : loss : 0.080519, loss_ce: 0.006216
iteration 7397 : loss : 0.027213, loss_ce: 0.013000
iteration 7398 : loss : 0.033285, loss_ce: 0.008883
iteration 7399 : loss : 0.041134, loss_ce: 0.003529
iteration 7400 : loss : 0.031076, loss_ce: 0.011876
iteration 7401 : loss : 0.024363, loss_ce: 0.010828
iteration 7402 : loss : 0.044123, loss_ce: 0.016001
iteration 7403 : loss : 0.032197, loss_ce: 0.015088
iteration 7404 : loss : 0.026571, loss_ce: 0.009232
iteration 7405 : loss : 0.040317, loss_ce: 0.007826
iteration 7406 : loss : 0.026647, loss_ce: 0.009784
iteration 7407 : loss : 0.027629, loss_ce: 0.008524
iteration 7408 : loss : 0.024314, loss_ce: 0.010247
iteration 7409 : loss : 0.031785, loss_ce: 0.016972
iteration 7410 : loss : 0.031761, loss_ce: 0.013623
iteration 7411 : loss : 0.029724, loss_ce: 0.012780
iteration 7412 : loss : 0.034125, loss_ce: 0.009103
iteration 7413 : loss : 0.034410, loss_ce: 0.006562
iteration 7414 : loss : 0.035465, loss_ce: 0.011575
iteration 7415 : loss : 0.026552, loss_ce: 0.009612
iteration 7416 : loss : 0.031941, loss_ce: 0.008967
iteration 7417 : loss : 0.076013, loss_ce: 0.006997
iteration 7418 : loss : 0.127298, loss_ce: 0.005819
iteration 7419 : loss : 0.026278, loss_ce: 0.007090
iteration 7420 : loss : 0.029600, loss_ce: 0.010692
iteration 7421 : loss : 0.082034, loss_ce: 0.010810
iteration 7422 : loss : 0.026018, loss_ce: 0.008903
iteration 7423 : loss : 0.025656, loss_ce: 0.009564
iteration 7424 : loss : 0.028365, loss_ce: 0.008998
iteration 7425 : loss : 0.029707, loss_ce: 0.006827
iteration 7426 : loss : 0.025946, loss_ce: 0.008203
iteration 7427 : loss : 0.024709, loss_ce: 0.010078
iteration 7428 : loss : 0.022129, loss_ce: 0.007840
iteration 7429 : loss : 0.031553, loss_ce: 0.007218
iteration 7430 : loss : 0.027639, loss_ce: 0.007552
iteration 7431 : loss : 0.042555, loss_ce: 0.013281
iteration 7432 : loss : 0.027263, loss_ce: 0.012527
iteration 7433 : loss : 0.078489, loss_ce: 0.009040
iteration 7434 : loss : 0.030518, loss_ce: 0.007711
iteration 7435 : loss : 0.025174, loss_ce: 0.006629
iteration 7436 : loss : 0.023559, loss_ce: 0.010496
iteration 7437 : loss : 0.078283, loss_ce: 0.008895
iteration 7438 : loss : 0.029246, loss_ce: 0.010998
iteration 7439 : loss : 0.037921, loss_ce: 0.005966
iteration 7440 : loss : 0.111874, loss_ce: 0.010277
 40%|███████████▏                | 80/200 [1:22:09<2:03:09, 61.58s/it]iteration 7441 : loss : 0.082713, loss_ce: 0.005962
iteration 7442 : loss : 0.032224, loss_ce: 0.012012
iteration 7443 : loss : 0.031850, loss_ce: 0.018355
iteration 7444 : loss : 0.036053, loss_ce: 0.012129
iteration 7445 : loss : 0.037108, loss_ce: 0.015855
iteration 7446 : loss : 0.039592, loss_ce: 0.016539
iteration 7447 : loss : 0.030873, loss_ce: 0.009431
iteration 7448 : loss : 0.027916, loss_ce: 0.011297
iteration 7449 : loss : 0.037958, loss_ce: 0.012554
iteration 7450 : loss : 0.082750, loss_ce: 0.010894
iteration 7451 : loss : 0.032131, loss_ce: 0.013543
iteration 7452 : loss : 0.026437, loss_ce: 0.006682
iteration 7453 : loss : 0.080428, loss_ce: 0.007726
iteration 7454 : loss : 0.029847, loss_ce: 0.011667
iteration 7455 : loss : 0.044328, loss_ce: 0.010980
iteration 7456 : loss : 0.028798, loss_ce: 0.014778
iteration 7457 : loss : 0.028177, loss_ce: 0.007234
iteration 7458 : loss : 0.031539, loss_ce: 0.013880
iteration 7459 : loss : 0.080454, loss_ce: 0.010272
iteration 7460 : loss : 0.036465, loss_ce: 0.011544
iteration 7461 : loss : 0.037573, loss_ce: 0.015118
iteration 7462 : loss : 0.024435, loss_ce: 0.007407
iteration 7463 : loss : 0.042877, loss_ce: 0.009499
iteration 7464 : loss : 0.031299, loss_ce: 0.011208
iteration 7465 : loss : 0.035113, loss_ce: 0.017842
iteration 7466 : loss : 0.027252, loss_ce: 0.011627
iteration 7467 : loss : 0.031096, loss_ce: 0.009973
iteration 7468 : loss : 0.028527, loss_ce: 0.011978
iteration 7469 : loss : 0.027936, loss_ce: 0.008286
iteration 7470 : loss : 0.029641, loss_ce: 0.011749
iteration 7471 : loss : 0.026495, loss_ce: 0.010931
iteration 7472 : loss : 0.040693, loss_ce: 0.005933
iteration 7473 : loss : 0.028983, loss_ce: 0.012277
iteration 7474 : loss : 0.046778, loss_ce: 0.006409
iteration 7475 : loss : 0.027137, loss_ce: 0.010429
iteration 7476 : loss : 0.028107, loss_ce: 0.009679
iteration 7477 : loss : 0.037332, loss_ce: 0.010884
iteration 7478 : loss : 0.039989, loss_ce: 0.008667
iteration 7479 : loss : 0.026545, loss_ce: 0.008469
iteration 7480 : loss : 0.031288, loss_ce: 0.008973
iteration 7481 : loss : 0.030508, loss_ce: 0.010674
iteration 7482 : loss : 0.038507, loss_ce: 0.008200
iteration 7483 : loss : 0.028481, loss_ce: 0.008194
iteration 7484 : loss : 0.033117, loss_ce: 0.011374
iteration 7485 : loss : 0.045490, loss_ce: 0.010073
iteration 7486 : loss : 0.055134, loss_ce: 0.012484
iteration 7487 : loss : 0.033998, loss_ce: 0.012597
iteration 7488 : loss : 0.034950, loss_ce: 0.007003
iteration 7489 : loss : 0.030777, loss_ce: 0.013515
iteration 7490 : loss : 0.030572, loss_ce: 0.013276
iteration 7491 : loss : 0.044449, loss_ce: 0.015812
iteration 7492 : loss : 0.028289, loss_ce: 0.011411
iteration 7493 : loss : 0.033012, loss_ce: 0.008984
iteration 7494 : loss : 0.037349, loss_ce: 0.007834
iteration 7495 : loss : 0.029672, loss_ce: 0.011570
iteration 7496 : loss : 0.037012, loss_ce: 0.010726
iteration 7497 : loss : 0.037421, loss_ce: 0.015105
iteration 7498 : loss : 0.023822, loss_ce: 0.007852
iteration 7499 : loss : 0.029548, loss_ce: 0.011098
iteration 7500 : loss : 0.082009, loss_ce: 0.013515
iteration 7501 : loss : 0.031975, loss_ce: 0.014139
iteration 7502 : loss : 0.033717, loss_ce: 0.010906
iteration 7503 : loss : 0.077971, loss_ce: 0.009181
iteration 7504 : loss : 0.102395, loss_ce: 0.004708
iteration 7505 : loss : 0.027759, loss_ce: 0.009584
iteration 7506 : loss : 0.043743, loss_ce: 0.008443
iteration 7507 : loss : 0.026891, loss_ce: 0.012459
iteration 7508 : loss : 0.031337, loss_ce: 0.008634
iteration 7509 : loss : 0.026958, loss_ce: 0.010149
iteration 7510 : loss : 0.084038, loss_ce: 0.004653
iteration 7511 : loss : 0.030059, loss_ce: 0.010447
iteration 7512 : loss : 0.029402, loss_ce: 0.008944
iteration 7513 : loss : 0.028103, loss_ce: 0.009042
iteration 7514 : loss : 0.042222, loss_ce: 0.010077
iteration 7515 : loss : 0.032588, loss_ce: 0.015997
iteration 7516 : loss : 0.030500, loss_ce: 0.010734
iteration 7517 : loss : 0.037608, loss_ce: 0.011370
iteration 7518 : loss : 0.037702, loss_ce: 0.012060
iteration 7519 : loss : 0.028755, loss_ce: 0.008806
iteration 7520 : loss : 0.043775, loss_ce: 0.007215
iteration 7521 : loss : 0.037664, loss_ce: 0.011091
iteration 7522 : loss : 0.039142, loss_ce: 0.016776
iteration 7523 : loss : 0.033029, loss_ce: 0.011096
iteration 7524 : loss : 0.028544, loss_ce: 0.009945
iteration 7525 : loss : 0.035465, loss_ce: 0.015059
iteration 7526 : loss : 0.030799, loss_ce: 0.014299
iteration 7527 : loss : 0.032293, loss_ce: 0.008447
iteration 7528 : loss : 0.031497, loss_ce: 0.010635
iteration 7529 : loss : 0.029578, loss_ce: 0.012858
iteration 7530 : loss : 0.024967, loss_ce: 0.007888
iteration 7531 : loss : 0.026161, loss_ce: 0.010887
iteration 7532 : loss : 0.027527, loss_ce: 0.010387
iteration 7533 : loss : 0.083523, loss_ce: 0.011953
 40%|███████████▎                | 81/200 [1:23:11<2:02:06, 61.56s/it]iteration 7534 : loss : 0.030209, loss_ce: 0.012250
iteration 7535 : loss : 0.033038, loss_ce: 0.012009
iteration 7536 : loss : 0.025317, loss_ce: 0.010053
iteration 7537 : loss : 0.026097, loss_ce: 0.006386
iteration 7538 : loss : 0.030066, loss_ce: 0.011997
iteration 7539 : loss : 0.087749, loss_ce: 0.011611
iteration 7540 : loss : 0.028155, loss_ce: 0.012509
iteration 7541 : loss : 0.026572, loss_ce: 0.008952
iteration 7542 : loss : 0.033239, loss_ce: 0.014304
iteration 7543 : loss : 0.027434, loss_ce: 0.005433
iteration 7544 : loss : 0.032232, loss_ce: 0.015891
iteration 7545 : loss : 0.076820, loss_ce: 0.008525
iteration 7546 : loss : 0.032859, loss_ce: 0.014135
iteration 7547 : loss : 0.021884, loss_ce: 0.007485
iteration 7548 : loss : 0.028719, loss_ce: 0.013716
iteration 7549 : loss : 0.029854, loss_ce: 0.007322
iteration 7550 : loss : 0.028114, loss_ce: 0.012546
iteration 7551 : loss : 0.026206, loss_ce: 0.008545
iteration 7552 : loss : 0.024014, loss_ce: 0.006595
iteration 7553 : loss : 0.023103, loss_ce: 0.009295
iteration 7554 : loss : 0.028523, loss_ce: 0.013391
iteration 7555 : loss : 0.026693, loss_ce: 0.008744
iteration 7556 : loss : 0.028694, loss_ce: 0.008529
iteration 7557 : loss : 0.027011, loss_ce: 0.010215
iteration 7558 : loss : 0.032347, loss_ce: 0.010126
iteration 7559 : loss : 0.057303, loss_ce: 0.005615
iteration 7560 : loss : 0.034413, loss_ce: 0.014214
iteration 7561 : loss : 0.026928, loss_ce: 0.011323
iteration 7562 : loss : 0.044829, loss_ce: 0.011038
iteration 7563 : loss : 0.031019, loss_ce: 0.009897
iteration 7564 : loss : 0.029502, loss_ce: 0.009600
iteration 7565 : loss : 0.025732, loss_ce: 0.009510
iteration 7566 : loss : 0.033790, loss_ce: 0.007681
iteration 7567 : loss : 0.092291, loss_ce: 0.006294
iteration 7568 : loss : 0.032684, loss_ce: 0.007318
iteration 7569 : loss : 0.028490, loss_ce: 0.007733
iteration 7570 : loss : 0.028569, loss_ce: 0.008749
iteration 7571 : loss : 0.030697, loss_ce: 0.013178
iteration 7572 : loss : 0.038682, loss_ce: 0.009906
iteration 7573 : loss : 0.035539, loss_ce: 0.006623
iteration 7574 : loss : 0.029036, loss_ce: 0.008796
iteration 7575 : loss : 0.084118, loss_ce: 0.005887
iteration 7576 : loss : 0.031486, loss_ce: 0.011721
iteration 7577 : loss : 0.028035, loss_ce: 0.011088
iteration 7578 : loss : 0.030386, loss_ce: 0.012039
iteration 7579 : loss : 0.060722, loss_ce: 0.010221
iteration 7580 : loss : 0.024639, loss_ce: 0.009949
iteration 7581 : loss : 0.026886, loss_ce: 0.009365
iteration 7582 : loss : 0.023435, loss_ce: 0.008459
iteration 7583 : loss : 0.026897, loss_ce: 0.009579
iteration 7584 : loss : 0.025404, loss_ce: 0.012005
iteration 7585 : loss : 0.025667, loss_ce: 0.008616
iteration 7586 : loss : 0.029473, loss_ce: 0.010320
iteration 7587 : loss : 0.039645, loss_ce: 0.010543
iteration 7588 : loss : 0.029977, loss_ce: 0.011464
iteration 7589 : loss : 0.030475, loss_ce: 0.014679
iteration 7590 : loss : 0.034809, loss_ce: 0.010095
iteration 7591 : loss : 0.029105, loss_ce: 0.010952
iteration 7592 : loss : 0.025699, loss_ce: 0.011203
iteration 7593 : loss : 0.031244, loss_ce: 0.008327
iteration 7594 : loss : 0.033938, loss_ce: 0.008480
iteration 7595 : loss : 0.027014, loss_ce: 0.011208
iteration 7596 : loss : 0.027784, loss_ce: 0.007574
iteration 7597 : loss : 0.032818, loss_ce: 0.010364
iteration 7598 : loss : 0.131623, loss_ce: 0.006242
iteration 7599 : loss : 0.027326, loss_ce: 0.006953
iteration 7600 : loss : 0.030024, loss_ce: 0.009833
iteration 7601 : loss : 0.047010, loss_ce: 0.008770
iteration 7602 : loss : 0.031813, loss_ce: 0.006586
iteration 7603 : loss : 0.081894, loss_ce: 0.010825
iteration 7604 : loss : 0.028935, loss_ce: 0.011399
iteration 7605 : loss : 0.032433, loss_ce: 0.010281
iteration 7606 : loss : 0.033589, loss_ce: 0.013846
iteration 7607 : loss : 0.085784, loss_ce: 0.012847
iteration 7608 : loss : 0.030502, loss_ce: 0.010472
iteration 7609 : loss : 0.025112, loss_ce: 0.004756
iteration 7610 : loss : 0.084244, loss_ce: 0.009804
iteration 7611 : loss : 0.028118, loss_ce: 0.012802
iteration 7612 : loss : 0.029752, loss_ce: 0.009695
iteration 7613 : loss : 0.027813, loss_ce: 0.009409
iteration 7614 : loss : 0.037012, loss_ce: 0.009801
iteration 7615 : loss : 0.030199, loss_ce: 0.010561
iteration 7616 : loss : 0.026522, loss_ce: 0.006708
iteration 7617 : loss : 0.033542, loss_ce: 0.013228
iteration 7618 : loss : 0.030508, loss_ce: 0.007709
iteration 7619 : loss : 0.028809, loss_ce: 0.008060
iteration 7620 : loss : 0.032868, loss_ce: 0.010161
iteration 7621 : loss : 0.027151, loss_ce: 0.008585
iteration 7622 : loss : 0.034205, loss_ce: 0.011045
iteration 7623 : loss : 0.047142, loss_ce: 0.010206
iteration 7624 : loss : 0.029782, loss_ce: 0.009217
iteration 7625 : loss : 0.024196, loss_ce: 0.010270
iteration 7626 : loss : 0.092201, loss_ce: 0.029768
 41%|███████████▍                | 82/200 [1:24:13<2:01:09, 61.61s/it]iteration 7627 : loss : 0.031098, loss_ce: 0.008215
iteration 7628 : loss : 0.036772, loss_ce: 0.011995
iteration 7629 : loss : 0.030317, loss_ce: 0.010862
iteration 7630 : loss : 0.032829, loss_ce: 0.013310
iteration 7631 : loss : 0.025780, loss_ce: 0.008257
iteration 7632 : loss : 0.037371, loss_ce: 0.013831
iteration 7633 : loss : 0.031454, loss_ce: 0.014299
iteration 7634 : loss : 0.029004, loss_ce: 0.007762
iteration 7635 : loss : 0.040453, loss_ce: 0.012506
iteration 7636 : loss : 0.026762, loss_ce: 0.008484
iteration 7637 : loss : 0.029991, loss_ce: 0.007552
iteration 7638 : loss : 0.028576, loss_ce: 0.008338
iteration 7639 : loss : 0.034753, loss_ce: 0.006484
iteration 7640 : loss : 0.031052, loss_ce: 0.008535
iteration 7641 : loss : 0.027755, loss_ce: 0.007949
iteration 7642 : loss : 0.024015, loss_ce: 0.006318
iteration 7643 : loss : 0.023077, loss_ce: 0.008054
iteration 7644 : loss : 0.026700, loss_ce: 0.013082
iteration 7645 : loss : 0.029662, loss_ce: 0.013417
iteration 7646 : loss : 0.028346, loss_ce: 0.008322
iteration 7647 : loss : 0.082573, loss_ce: 0.005345
iteration 7648 : loss : 0.082161, loss_ce: 0.012322
iteration 7649 : loss : 0.031597, loss_ce: 0.012613
iteration 7650 : loss : 0.027081, loss_ce: 0.008385
iteration 7651 : loss : 0.030743, loss_ce: 0.010992
iteration 7652 : loss : 0.032998, loss_ce: 0.012301
iteration 7653 : loss : 0.075828, loss_ce: 0.007642
iteration 7654 : loss : 0.036873, loss_ce: 0.008136
iteration 7655 : loss : 0.026234, loss_ce: 0.009218
iteration 7656 : loss : 0.036647, loss_ce: 0.014753
iteration 7657 : loss : 0.028566, loss_ce: 0.010477
iteration 7658 : loss : 0.026351, loss_ce: 0.007443
iteration 7659 : loss : 0.027324, loss_ce: 0.010128
iteration 7660 : loss : 0.041324, loss_ce: 0.008494
iteration 7661 : loss : 0.078910, loss_ce: 0.007470
iteration 7662 : loss : 0.026230, loss_ce: 0.006064
iteration 7663 : loss : 0.036471, loss_ce: 0.013242
iteration 7664 : loss : 0.026267, loss_ce: 0.006414
iteration 7665 : loss : 0.077370, loss_ce: 0.009362
iteration 7666 : loss : 0.025802, loss_ce: 0.009027
iteration 7667 : loss : 0.035657, loss_ce: 0.010772
iteration 7668 : loss : 0.027317, loss_ce: 0.013546
iteration 7669 : loss : 0.027156, loss_ce: 0.011111
iteration 7670 : loss : 0.032211, loss_ce: 0.008144
iteration 7671 : loss : 0.032477, loss_ce: 0.014233
iteration 7672 : loss : 0.032106, loss_ce: 0.006141
iteration 7673 : loss : 0.028048, loss_ce: 0.009258
iteration 7674 : loss : 0.036663, loss_ce: 0.007026
iteration 7675 : loss : 0.030187, loss_ce: 0.015229
iteration 7676 : loss : 0.026911, loss_ce: 0.011844
iteration 7677 : loss : 0.027591, loss_ce: 0.007245
iteration 7678 : loss : 0.042403, loss_ce: 0.008600
iteration 7679 : loss : 0.025226, loss_ce: 0.006742
iteration 7680 : loss : 0.033181, loss_ce: 0.010606
iteration 7681 : loss : 0.028361, loss_ce: 0.012000
iteration 7682 : loss : 0.033148, loss_ce: 0.011187
iteration 7683 : loss : 0.077317, loss_ce: 0.006324
iteration 7684 : loss : 0.023304, loss_ce: 0.011951
iteration 7685 : loss : 0.027310, loss_ce: 0.009866
iteration 7686 : loss : 0.030730, loss_ce: 0.015107
iteration 7687 : loss : 0.028016, loss_ce: 0.009959
iteration 7688 : loss : 0.076940, loss_ce: 0.006213
iteration 7689 : loss : 0.029212, loss_ce: 0.014346
iteration 7690 : loss : 0.029826, loss_ce: 0.011102
iteration 7691 : loss : 0.086761, loss_ce: 0.004825
iteration 7692 : loss : 0.032282, loss_ce: 0.014385
iteration 7693 : loss : 0.031905, loss_ce: 0.011012
iteration 7694 : loss : 0.028947, loss_ce: 0.011106
iteration 7695 : loss : 0.037588, loss_ce: 0.009134
iteration 7696 : loss : 0.081099, loss_ce: 0.009469
iteration 7697 : loss : 0.028064, loss_ce: 0.011738
iteration 7698 : loss : 0.063942, loss_ce: 0.007939
iteration 7699 : loss : 0.035170, loss_ce: 0.019575
iteration 7700 : loss : 0.022526, loss_ce: 0.005535
iteration 7701 : loss : 0.026213, loss_ce: 0.010116
iteration 7702 : loss : 0.029953, loss_ce: 0.010523
iteration 7703 : loss : 0.027664, loss_ce: 0.009328
iteration 7704 : loss : 0.050198, loss_ce: 0.008168
iteration 7705 : loss : 0.026746, loss_ce: 0.008740
iteration 7706 : loss : 0.032676, loss_ce: 0.010588
iteration 7707 : loss : 0.034772, loss_ce: 0.018987
iteration 7708 : loss : 0.077736, loss_ce: 0.006423
iteration 7709 : loss : 0.030003, loss_ce: 0.009777
iteration 7710 : loss : 0.029716, loss_ce: 0.007191
iteration 7711 : loss : 0.030977, loss_ce: 0.009115
iteration 7712 : loss : 0.031602, loss_ce: 0.014358
iteration 7713 : loss : 0.041844, loss_ce: 0.010051
iteration 7714 : loss : 0.033845, loss_ce: 0.008227
iteration 7715 : loss : 0.026443, loss_ce: 0.010403
iteration 7716 : loss : 0.026242, loss_ce: 0.007963
iteration 7717 : loss : 0.033479, loss_ce: 0.008630
iteration 7718 : loss : 0.028858, loss_ce: 0.006393
iteration 7719 : loss : 0.340045, loss_ce: 0.001322
 42%|███████████▌                | 83/200 [1:25:14<2:00:05, 61.58s/it]iteration 7720 : loss : 0.030481, loss_ce: 0.012229
iteration 7721 : loss : 0.031418, loss_ce: 0.014836
iteration 7722 : loss : 0.031602, loss_ce: 0.009571
iteration 7723 : loss : 0.032069, loss_ce: 0.010905
iteration 7724 : loss : 0.030042, loss_ce: 0.012753
iteration 7725 : loss : 0.031199, loss_ce: 0.006725
iteration 7726 : loss : 0.025380, loss_ce: 0.010173
iteration 7727 : loss : 0.033026, loss_ce: 0.009872
iteration 7728 : loss : 0.077837, loss_ce: 0.006546
iteration 7729 : loss : 0.024963, loss_ce: 0.006025
iteration 7730 : loss : 0.081563, loss_ce: 0.009115
iteration 7731 : loss : 0.027152, loss_ce: 0.009228
iteration 7732 : loss : 0.028481, loss_ce: 0.010021
iteration 7733 : loss : 0.027931, loss_ce: 0.008124
iteration 7734 : loss : 0.037836, loss_ce: 0.012072
iteration 7735 : loss : 0.026826, loss_ce: 0.006747
iteration 7736 : loss : 0.027900, loss_ce: 0.007135
iteration 7737 : loss : 0.085540, loss_ce: 0.007663
iteration 7738 : loss : 0.036799, loss_ce: 0.010993
iteration 7739 : loss : 0.023833, loss_ce: 0.008915
iteration 7740 : loss : 0.027764, loss_ce: 0.011470
iteration 7741 : loss : 0.028998, loss_ce: 0.010252
iteration 7742 : loss : 0.035502, loss_ce: 0.011829
iteration 7743 : loss : 0.025755, loss_ce: 0.010422
iteration 7744 : loss : 0.079819, loss_ce: 0.009714
iteration 7745 : loss : 0.026396, loss_ce: 0.011443
iteration 7746 : loss : 0.025770, loss_ce: 0.007675
iteration 7747 : loss : 0.030989, loss_ce: 0.011825
iteration 7748 : loss : 0.031118, loss_ce: 0.010413
iteration 7749 : loss : 0.078251, loss_ce: 0.010244
iteration 7750 : loss : 0.079626, loss_ce: 0.009381
iteration 7751 : loss : 0.023141, loss_ce: 0.008395
iteration 7752 : loss : 0.028545, loss_ce: 0.011476
iteration 7753 : loss : 0.024810, loss_ce: 0.010109
iteration 7754 : loss : 0.027441, loss_ce: 0.012646
iteration 7755 : loss : 0.030606, loss_ce: 0.009310
iteration 7756 : loss : 0.030312, loss_ce: 0.016476
iteration 7757 : loss : 0.040394, loss_ce: 0.007955
iteration 7758 : loss : 0.028288, loss_ce: 0.011939
iteration 7759 : loss : 0.058102, loss_ce: 0.007472
iteration 7760 : loss : 0.028960, loss_ce: 0.012676
iteration 7761 : loss : 0.081896, loss_ce: 0.006973
iteration 7762 : loss : 0.023490, loss_ce: 0.007776
iteration 7763 : loss : 0.029079, loss_ce: 0.011537
iteration 7764 : loss : 0.030559, loss_ce: 0.006330
iteration 7765 : loss : 0.044179, loss_ce: 0.008261
iteration 7766 : loss : 0.032340, loss_ce: 0.014195
iteration 7767 : loss : 0.035366, loss_ce: 0.005019
iteration 7768 : loss : 0.026705, loss_ce: 0.007044
iteration 7769 : loss : 0.035122, loss_ce: 0.009121
iteration 7770 : loss : 0.026721, loss_ce: 0.007337
iteration 7771 : loss : 0.029884, loss_ce: 0.012524
iteration 7772 : loss : 0.023342, loss_ce: 0.007301
iteration 7773 : loss : 0.029348, loss_ce: 0.010931
iteration 7774 : loss : 0.029428, loss_ce: 0.012391
iteration 7775 : loss : 0.030415, loss_ce: 0.006841
iteration 7776 : loss : 0.026621, loss_ce: 0.005898
iteration 7777 : loss : 0.030390, loss_ce: 0.010471
iteration 7778 : loss : 0.031429, loss_ce: 0.013452
iteration 7779 : loss : 0.027577, loss_ce: 0.010330
iteration 7780 : loss : 0.038954, loss_ce: 0.011096
iteration 7781 : loss : 0.027319, loss_ce: 0.006813
iteration 7782 : loss : 0.032355, loss_ce: 0.017002
iteration 7783 : loss : 0.027859, loss_ce: 0.012843
iteration 7784 : loss : 0.028803, loss_ce: 0.012671
iteration 7785 : loss : 0.028867, loss_ce: 0.009259
iteration 7786 : loss : 0.078859, loss_ce: 0.009027
iteration 7787 : loss : 0.027140, loss_ce: 0.006256
iteration 7788 : loss : 0.021144, loss_ce: 0.006944
iteration 7789 : loss : 0.027263, loss_ce: 0.008977
iteration 7790 : loss : 0.031151, loss_ce: 0.013360
iteration 7791 : loss : 0.027167, loss_ce: 0.011406
iteration 7792 : loss : 0.030782, loss_ce: 0.013161
iteration 7793 : loss : 0.093674, loss_ce: 0.008068
iteration 7794 : loss : 0.028710, loss_ce: 0.007860
iteration 7795 : loss : 0.024908, loss_ce: 0.010912
iteration 7796 : loss : 0.024558, loss_ce: 0.008911
iteration 7797 : loss : 0.029623, loss_ce: 0.010567
iteration 7798 : loss : 0.030706, loss_ce: 0.009277
iteration 7799 : loss : 0.078879, loss_ce: 0.006444
iteration 7800 : loss : 0.025793, loss_ce: 0.009490
iteration 7801 : loss : 0.022425, loss_ce: 0.006597
iteration 7802 : loss : 0.084974, loss_ce: 0.007445
iteration 7803 : loss : 0.029780, loss_ce: 0.008754
iteration 7804 : loss : 0.027327, loss_ce: 0.006904
iteration 7805 : loss : 0.038263, loss_ce: 0.010512
iteration 7806 : loss : 0.032841, loss_ce: 0.012204
iteration 7807 : loss : 0.026669, loss_ce: 0.006038
iteration 7808 : loss : 0.022544, loss_ce: 0.005929
iteration 7809 : loss : 0.027998, loss_ce: 0.010823
iteration 7810 : loss : 0.035148, loss_ce: 0.011534
iteration 7811 : loss : 0.021104, loss_ce: 0.007127
iteration 7812 : loss : 0.052611, loss_ce: 0.027792
 42%|███████████▊                | 84/200 [1:26:16<1:59:02, 61.57s/it]iteration 7813 : loss : 0.031465, loss_ce: 0.012229
iteration 7814 : loss : 0.037789, loss_ce: 0.015221
iteration 7815 : loss : 0.028368, loss_ce: 0.009278
iteration 7816 : loss : 0.025764, loss_ce: 0.009117
iteration 7817 : loss : 0.030145, loss_ce: 0.009169
iteration 7818 : loss : 0.032666, loss_ce: 0.009422
iteration 7819 : loss : 0.027110, loss_ce: 0.008683
iteration 7820 : loss : 0.036485, loss_ce: 0.005376
iteration 7821 : loss : 0.079555, loss_ce: 0.010001
iteration 7822 : loss : 0.026448, loss_ce: 0.007042
iteration 7823 : loss : 0.038619, loss_ce: 0.016425
iteration 7824 : loss : 0.028710, loss_ce: 0.014659
iteration 7825 : loss : 0.033686, loss_ce: 0.012379
iteration 7826 : loss : 0.030430, loss_ce: 0.012131
iteration 7827 : loss : 0.031283, loss_ce: 0.012994
iteration 7828 : loss : 0.024968, loss_ce: 0.010794
iteration 7829 : loss : 0.037574, loss_ce: 0.011214
iteration 7830 : loss : 0.027874, loss_ce: 0.009653
iteration 7831 : loss : 0.029789, loss_ce: 0.014155
iteration 7832 : loss : 0.028208, loss_ce: 0.014054
iteration 7833 : loss : 0.030738, loss_ce: 0.011764
iteration 7834 : loss : 0.028601, loss_ce: 0.012251
iteration 7835 : loss : 0.023825, loss_ce: 0.012647
iteration 7836 : loss : 0.032359, loss_ce: 0.009311
iteration 7837 : loss : 0.026506, loss_ce: 0.010871
iteration 7838 : loss : 0.025896, loss_ce: 0.006338
iteration 7839 : loss : 0.025391, loss_ce: 0.008685
iteration 7840 : loss : 0.028363, loss_ce: 0.013710
iteration 7841 : loss : 0.037680, loss_ce: 0.007442
iteration 7842 : loss : 0.032610, loss_ce: 0.010033
iteration 7843 : loss : 0.024611, loss_ce: 0.011694
iteration 7844 : loss : 0.024118, loss_ce: 0.008392
iteration 7845 : loss : 0.029956, loss_ce: 0.010829
iteration 7846 : loss : 0.028989, loss_ce: 0.009455
iteration 7847 : loss : 0.027837, loss_ce: 0.006961
iteration 7848 : loss : 0.057080, loss_ce: 0.009534
iteration 7849 : loss : 0.049838, loss_ce: 0.008483
iteration 7850 : loss : 0.029687, loss_ce: 0.012010
iteration 7851 : loss : 0.023933, loss_ce: 0.008893
iteration 7852 : loss : 0.039141, loss_ce: 0.013290
iteration 7853 : loss : 0.035851, loss_ce: 0.009857
iteration 7854 : loss : 0.086096, loss_ce: 0.005456
iteration 7855 : loss : 0.034212, loss_ce: 0.011260
iteration 7856 : loss : 0.033999, loss_ce: 0.009556
iteration 7857 : loss : 0.033403, loss_ce: 0.012623
iteration 7858 : loss : 0.031376, loss_ce: 0.016153
iteration 7859 : loss : 0.024693, loss_ce: 0.008267
iteration 7860 : loss : 0.038038, loss_ce: 0.009198
iteration 7861 : loss : 0.026499, loss_ce: 0.011993
iteration 7862 : loss : 0.026545, loss_ce: 0.005856
iteration 7863 : loss : 0.077653, loss_ce: 0.004572
iteration 7864 : loss : 0.069830, loss_ce: 0.004429
iteration 7865 : loss : 0.029742, loss_ce: 0.010027
iteration 7866 : loss : 0.031613, loss_ce: 0.010050
iteration 7867 : loss : 0.031213, loss_ce: 0.006939
iteration 7868 : loss : 0.024159, loss_ce: 0.008153
iteration 7869 : loss : 0.028575, loss_ce: 0.012068
iteration 7870 : loss : 0.026572, loss_ce: 0.009135
iteration 7871 : loss : 0.027899, loss_ce: 0.008899
iteration 7872 : loss : 0.076893, loss_ce: 0.004001
iteration 7873 : loss : 0.032893, loss_ce: 0.009458
iteration 7874 : loss : 0.032003, loss_ce: 0.007588
iteration 7875 : loss : 0.028954, loss_ce: 0.012442
iteration 7876 : loss : 0.028352, loss_ce: 0.009709
iteration 7877 : loss : 0.032888, loss_ce: 0.011965
iteration 7878 : loss : 0.028402, loss_ce: 0.008644
iteration 7879 : loss : 0.026149, loss_ce: 0.010451
iteration 7880 : loss : 0.028607, loss_ce: 0.007870
iteration 7881 : loss : 0.029415, loss_ce: 0.010384
iteration 7882 : loss : 0.025758, loss_ce: 0.004231
iteration 7883 : loss : 0.026122, loss_ce: 0.010466
iteration 7884 : loss : 0.027009, loss_ce: 0.006027
iteration 7885 : loss : 0.027354, loss_ce: 0.007826
iteration 7886 : loss : 0.027459, loss_ce: 0.011922
iteration 7887 : loss : 0.025769, loss_ce: 0.009627
iteration 7888 : loss : 0.027269, loss_ce: 0.010849
iteration 7889 : loss : 0.082161, loss_ce: 0.009751
iteration 7890 : loss : 0.026092, loss_ce: 0.009822
iteration 7891 : loss : 0.023512, loss_ce: 0.009262
iteration 7892 : loss : 0.079720, loss_ce: 0.009860
iteration 7893 : loss : 0.026307, loss_ce: 0.009780
iteration 7894 : loss : 0.050507, loss_ce: 0.007073
iteration 7895 : loss : 0.027852, loss_ce: 0.006942
iteration 7896 : loss : 0.029724, loss_ce: 0.007545
iteration 7897 : loss : 0.029279, loss_ce: 0.008374
iteration 7898 : loss : 0.025094, loss_ce: 0.009328
iteration 7899 : loss : 0.030402, loss_ce: 0.011195
iteration 7900 : loss : 0.086616, loss_ce: 0.009368
iteration 7901 : loss : 0.082017, loss_ce: 0.011970
iteration 7902 : loss : 0.038982, loss_ce: 0.011277
iteration 7903 : loss : 0.031338, loss_ce: 0.013318
iteration 7904 : loss : 0.024043, loss_ce: 0.009061
iteration 7905 : loss : 0.302843, loss_ce: 0.006542
 42%|███████████▉                | 85/200 [1:27:17<1:58:00, 61.57s/it]iteration 7906 : loss : 0.029706, loss_ce: 0.010482
iteration 7907 : loss : 0.039631, loss_ce: 0.013491
iteration 7908 : loss : 0.033097, loss_ce: 0.007857
iteration 7909 : loss : 0.042251, loss_ce: 0.011638
iteration 7910 : loss : 0.040049, loss_ce: 0.011733
iteration 7911 : loss : 0.082376, loss_ce: 0.010088
iteration 7912 : loss : 0.036451, loss_ce: 0.010959
iteration 7913 : loss : 0.029582, loss_ce: 0.011935
iteration 7914 : loss : 0.033012, loss_ce: 0.011897
iteration 7915 : loss : 0.031228, loss_ce: 0.011832
iteration 7916 : loss : 0.044719, loss_ce: 0.007174
iteration 7917 : loss : 0.030456, loss_ce: 0.007450
iteration 7918 : loss : 0.032549, loss_ce: 0.010618
iteration 7919 : loss : 0.028712, loss_ce: 0.016241
iteration 7920 : loss : 0.028985, loss_ce: 0.008598
iteration 7921 : loss : 0.036504, loss_ce: 0.016343
iteration 7922 : loss : 0.032166, loss_ce: 0.009143
iteration 7923 : loss : 0.037811, loss_ce: 0.013989
iteration 7924 : loss : 0.031246, loss_ce: 0.010869
iteration 7925 : loss : 0.034901, loss_ce: 0.013769
iteration 7926 : loss : 0.026158, loss_ce: 0.011449
iteration 7927 : loss : 0.041805, loss_ce: 0.011046
iteration 7928 : loss : 0.034623, loss_ce: 0.010614
iteration 7929 : loss : 0.024626, loss_ce: 0.008360
iteration 7930 : loss : 0.028948, loss_ce: 0.009871
iteration 7931 : loss : 0.026497, loss_ce: 0.011735
iteration 7932 : loss : 0.028356, loss_ce: 0.009337
iteration 7933 : loss : 0.032856, loss_ce: 0.013243
iteration 7934 : loss : 0.031331, loss_ce: 0.009460
iteration 7935 : loss : 0.035150, loss_ce: 0.006519
iteration 7936 : loss : 0.024649, loss_ce: 0.007499
iteration 7937 : loss : 0.026659, loss_ce: 0.009970
iteration 7938 : loss : 0.026876, loss_ce: 0.008187
iteration 7939 : loss : 0.031649, loss_ce: 0.012517
iteration 7940 : loss : 0.036492, loss_ce: 0.011199
iteration 7941 : loss : 0.027577, loss_ce: 0.010004
iteration 7942 : loss : 0.031947, loss_ce: 0.010346
iteration 7943 : loss : 0.029884, loss_ce: 0.005062
iteration 7944 : loss : 0.031439, loss_ce: 0.008593
iteration 7945 : loss : 0.032999, loss_ce: 0.015746
iteration 7946 : loss : 0.031727, loss_ce: 0.008766
iteration 7947 : loss : 0.037974, loss_ce: 0.016732
iteration 7948 : loss : 0.033371, loss_ce: 0.013241
iteration 7949 : loss : 0.025800, loss_ce: 0.007622
iteration 7950 : loss : 0.029802, loss_ce: 0.008406
iteration 7951 : loss : 0.181572, loss_ce: 0.002943
iteration 7952 : loss : 0.087344, loss_ce: 0.006969
iteration 7953 : loss : 0.072002, loss_ce: 0.005659
iteration 7954 : loss : 0.027373, loss_ce: 0.008434
iteration 7955 : loss : 0.078641, loss_ce: 0.010324
iteration 7956 : loss : 0.028163, loss_ce: 0.007769
iteration 7957 : loss : 0.032284, loss_ce: 0.013949
iteration 7958 : loss : 0.025798, loss_ce: 0.009442
iteration 7959 : loss : 0.026161, loss_ce: 0.007805
iteration 7960 : loss : 0.032001, loss_ce: 0.009298
iteration 7961 : loss : 0.033903, loss_ce: 0.006625
iteration 7962 : loss : 0.030439, loss_ce: 0.008687
iteration 7963 : loss : 0.020876, loss_ce: 0.003464
iteration 7964 : loss : 0.030946, loss_ce: 0.010737
iteration 7965 : loss : 0.034141, loss_ce: 0.013187
iteration 7966 : loss : 0.031037, loss_ce: 0.010255
iteration 7967 : loss : 0.025375, loss_ce: 0.007314
iteration 7968 : loss : 0.025126, loss_ce: 0.008815
iteration 7969 : loss : 0.027111, loss_ce: 0.013627
iteration 7970 : loss : 0.065355, loss_ce: 0.003837
iteration 7971 : loss : 0.032880, loss_ce: 0.009885
iteration 7972 : loss : 0.031266, loss_ce: 0.006584
iteration 7973 : loss : 0.021129, loss_ce: 0.006518
iteration 7974 : loss : 0.036919, loss_ce: 0.010271
iteration 7975 : loss : 0.027205, loss_ce: 0.008713
iteration 7976 : loss : 0.032830, loss_ce: 0.017414
iteration 7977 : loss : 0.032627, loss_ce: 0.016228
iteration 7978 : loss : 0.035008, loss_ce: 0.010842
iteration 7979 : loss : 0.039149, loss_ce: 0.014548
iteration 7980 : loss : 0.029759, loss_ce: 0.009454
iteration 7981 : loss : 0.028979, loss_ce: 0.012563
iteration 7982 : loss : 0.022336, loss_ce: 0.008687
iteration 7983 : loss : 0.032190, loss_ce: 0.014405
iteration 7984 : loss : 0.020810, loss_ce: 0.009426
iteration 7985 : loss : 0.027874, loss_ce: 0.008872
iteration 7986 : loss : 0.024326, loss_ce: 0.006835
iteration 7987 : loss : 0.026302, loss_ce: 0.009712
iteration 7988 : loss : 0.027620, loss_ce: 0.013150
iteration 7989 : loss : 0.028167, loss_ce: 0.009990
iteration 7990 : loss : 0.029021, loss_ce: 0.011771
iteration 7991 : loss : 0.030489, loss_ce: 0.010856
iteration 7992 : loss : 0.033965, loss_ce: 0.011598
iteration 7993 : loss : 0.027760, loss_ce: 0.009330
iteration 7994 : loss : 0.032887, loss_ce: 0.006993
iteration 7995 : loss : 0.036793, loss_ce: 0.009768
iteration 7996 : loss : 0.030384, loss_ce: 0.010114
iteration 7997 : loss : 0.026509, loss_ce: 0.010267
iteration 7998 : loss : 0.391748, loss_ce: 0.001522
 43%|████████████                | 86/200 [1:28:19<1:56:59, 61.58s/it]iteration 7999 : loss : 0.025867, loss_ce: 0.013260
iteration 8000 : loss : 0.032219, loss_ce: 0.012332
iteration 8001 : loss : 0.030047, loss_ce: 0.006581
iteration 8002 : loss : 0.028426, loss_ce: 0.010907
iteration 8003 : loss : 0.037353, loss_ce: 0.008740
iteration 8004 : loss : 0.028835, loss_ce: 0.010253
iteration 8005 : loss : 0.037660, loss_ce: 0.015266
iteration 8006 : loss : 0.028227, loss_ce: 0.010391
iteration 8007 : loss : 0.023651, loss_ce: 0.007024
iteration 8008 : loss : 0.028887, loss_ce: 0.007020
iteration 8009 : loss : 0.025651, loss_ce: 0.011438
iteration 8010 : loss : 0.023297, loss_ce: 0.007030
iteration 8011 : loss : 0.033361, loss_ce: 0.007125
iteration 8012 : loss : 0.025160, loss_ce: 0.008110
iteration 8013 : loss : 0.021317, loss_ce: 0.007782
iteration 8014 : loss : 0.088331, loss_ce: 0.008610
iteration 8015 : loss : 0.026021, loss_ce: 0.007943
iteration 8016 : loss : 0.031136, loss_ce: 0.007679
iteration 8017 : loss : 0.045655, loss_ce: 0.009969
iteration 8018 : loss : 0.027496, loss_ce: 0.011682
iteration 8019 : loss : 0.028054, loss_ce: 0.009595
iteration 8020 : loss : 0.032281, loss_ce: 0.014797
iteration 8021 : loss : 0.028215, loss_ce: 0.010954
iteration 8022 : loss : 0.025999, loss_ce: 0.008663
iteration 8023 : loss : 0.080204, loss_ce: 0.007423
iteration 8024 : loss : 0.030774, loss_ce: 0.009556
iteration 8025 : loss : 0.027230, loss_ce: 0.010642
iteration 8026 : loss : 0.045599, loss_ce: 0.014065
iteration 8027 : loss : 0.071013, loss_ce: 0.009950
iteration 8028 : loss : 0.035665, loss_ce: 0.011919
iteration 8029 : loss : 0.025215, loss_ce: 0.011188
iteration 8030 : loss : 0.043239, loss_ce: 0.012178
iteration 8031 : loss : 0.035976, loss_ce: 0.013835
iteration 8032 : loss : 0.030130, loss_ce: 0.011373
iteration 8033 : loss : 0.033172, loss_ce: 0.012718
iteration 8034 : loss : 0.025394, loss_ce: 0.006961
iteration 8035 : loss : 0.027217, loss_ce: 0.012853
iteration 8036 : loss : 0.023733, loss_ce: 0.008500
iteration 8037 : loss : 0.029628, loss_ce: 0.009116
iteration 8038 : loss : 0.077133, loss_ce: 0.005837
iteration 8039 : loss : 0.031226, loss_ce: 0.009155
iteration 8040 : loss : 0.024853, loss_ce: 0.008691
iteration 8041 : loss : 0.027685, loss_ce: 0.009433
iteration 8042 : loss : 0.030365, loss_ce: 0.012512
iteration 8043 : loss : 0.021970, loss_ce: 0.006147
iteration 8044 : loss : 0.037790, loss_ce: 0.006673
iteration 8045 : loss : 0.033739, loss_ce: 0.009822
iteration 8046 : loss : 0.025407, loss_ce: 0.007809
iteration 8047 : loss : 0.029974, loss_ce: 0.016948
iteration 8048 : loss : 0.029588, loss_ce: 0.010183
iteration 8049 : loss : 0.077864, loss_ce: 0.009574
iteration 8050 : loss : 0.030428, loss_ce: 0.008335
iteration 8051 : loss : 0.025290, loss_ce: 0.008618
iteration 8052 : loss : 0.032697, loss_ce: 0.005085
iteration 8053 : loss : 0.026185, loss_ce: 0.005227
iteration 8054 : loss : 0.082786, loss_ce: 0.006079
iteration 8055 : loss : 0.027026, loss_ce: 0.009359
iteration 8056 : loss : 0.034696, loss_ce: 0.009753
iteration 8057 : loss : 0.029131, loss_ce: 0.009043
iteration 8058 : loss : 0.024063, loss_ce: 0.008376
iteration 8059 : loss : 0.022546, loss_ce: 0.008843
iteration 8060 : loss : 0.031898, loss_ce: 0.014057
iteration 8061 : loss : 0.030269, loss_ce: 0.012348
iteration 8062 : loss : 0.031867, loss_ce: 0.010982
iteration 8063 : loss : 0.031340, loss_ce: 0.012815
iteration 8064 : loss : 0.026891, loss_ce: 0.009340
iteration 8065 : loss : 0.025109, loss_ce: 0.010425
iteration 8066 : loss : 0.027639, loss_ce: 0.012514
iteration 8067 : loss : 0.028615, loss_ce: 0.008194
iteration 8068 : loss : 0.031945, loss_ce: 0.005710
iteration 8069 : loss : 0.021530, loss_ce: 0.006884
iteration 8070 : loss : 0.028831, loss_ce: 0.011063
iteration 8071 : loss : 0.026731, loss_ce: 0.008055
iteration 8072 : loss : 0.029620, loss_ce: 0.011000
iteration 8073 : loss : 0.025309, loss_ce: 0.007894
iteration 8074 : loss : 0.035862, loss_ce: 0.008039
iteration 8075 : loss : 0.031132, loss_ce: 0.008488
iteration 8076 : loss : 0.031510, loss_ce: 0.005474
iteration 8077 : loss : 0.033276, loss_ce: 0.009223
iteration 8078 : loss : 0.026845, loss_ce: 0.012757
iteration 8079 : loss : 0.027704, loss_ce: 0.007424
iteration 8080 : loss : 0.030143, loss_ce: 0.010002
iteration 8081 : loss : 0.027614, loss_ce: 0.009895
iteration 8082 : loss : 0.027289, loss_ce: 0.011732
iteration 8083 : loss : 0.029850, loss_ce: 0.006113
iteration 8084 : loss : 0.026408, loss_ce: 0.009404
iteration 8085 : loss : 0.038005, loss_ce: 0.018741
iteration 8086 : loss : 0.026744, loss_ce: 0.009190
iteration 8087 : loss : 0.036425, loss_ce: 0.010959
iteration 8088 : loss : 0.039190, loss_ce: 0.011151
iteration 8089 : loss : 0.082582, loss_ce: 0.009847
iteration 8090 : loss : 0.025919, loss_ce: 0.006228
iteration 8091 : loss : 0.289557, loss_ce: 0.018076
 44%|████████████▏               | 87/200 [1:29:20<1:55:58, 61.58s/it]iteration 8092 : loss : 0.024249, loss_ce: 0.008465
iteration 8093 : loss : 0.029127, loss_ce: 0.009718
iteration 8094 : loss : 0.027346, loss_ce: 0.009526
iteration 8095 : loss : 0.026092, loss_ce: 0.008765
iteration 8096 : loss : 0.025276, loss_ce: 0.011655
iteration 8097 : loss : 0.028102, loss_ce: 0.007855
iteration 8098 : loss : 0.029466, loss_ce: 0.010322
iteration 8099 : loss : 0.026049, loss_ce: 0.009663
iteration 8100 : loss : 0.038326, loss_ce: 0.006756
iteration 8101 : loss : 0.027198, loss_ce: 0.005130
iteration 8102 : loss : 0.032887, loss_ce: 0.011363
iteration 8103 : loss : 0.033622, loss_ce: 0.014758
iteration 8104 : loss : 0.038970, loss_ce: 0.009041
iteration 8105 : loss : 0.090480, loss_ce: 0.006362
iteration 8106 : loss : 0.079774, loss_ce: 0.013700
iteration 8107 : loss : 0.026511, loss_ce: 0.010948
iteration 8108 : loss : 0.026455, loss_ce: 0.009875
iteration 8109 : loss : 0.020578, loss_ce: 0.006654
iteration 8110 : loss : 0.031830, loss_ce: 0.007127
iteration 8111 : loss : 0.032929, loss_ce: 0.018354
iteration 8112 : loss : 0.029244, loss_ce: 0.005941
iteration 8113 : loss : 0.025198, loss_ce: 0.007463
iteration 8114 : loss : 0.025332, loss_ce: 0.004427
iteration 8115 : loss : 0.025173, loss_ce: 0.007665
iteration 8116 : loss : 0.033785, loss_ce: 0.009584
iteration 8117 : loss : 0.028161, loss_ce: 0.010144
iteration 8118 : loss : 0.031390, loss_ce: 0.010813
iteration 8119 : loss : 0.033258, loss_ce: 0.010628
iteration 8120 : loss : 0.028526, loss_ce: 0.008769
iteration 8121 : loss : 0.032394, loss_ce: 0.012029
iteration 8122 : loss : 0.027019, loss_ce: 0.011545
iteration 8123 : loss : 0.077091, loss_ce: 0.010286
iteration 8124 : loss : 0.024246, loss_ce: 0.008946
iteration 8125 : loss : 0.029728, loss_ce: 0.006477
iteration 8126 : loss : 0.022298, loss_ce: 0.007753
iteration 8127 : loss : 0.025815, loss_ce: 0.013081
iteration 8128 : loss : 0.027290, loss_ce: 0.011059
iteration 8129 : loss : 0.027147, loss_ce: 0.011968
iteration 8130 : loss : 0.022501, loss_ce: 0.004317
iteration 8131 : loss : 0.023944, loss_ce: 0.007380
iteration 8132 : loss : 0.030993, loss_ce: 0.012100
iteration 8133 : loss : 0.025062, loss_ce: 0.010165
iteration 8134 : loss : 0.035210, loss_ce: 0.013828
iteration 8135 : loss : 0.026820, loss_ce: 0.006853
iteration 8136 : loss : 0.026365, loss_ce: 0.009000
iteration 8137 : loss : 0.030013, loss_ce: 0.008918
iteration 8138 : loss : 0.024586, loss_ce: 0.009853
iteration 8139 : loss : 0.022756, loss_ce: 0.009258
iteration 8140 : loss : 0.030364, loss_ce: 0.006326
iteration 8141 : loss : 0.024083, loss_ce: 0.006548
iteration 8142 : loss : 0.024686, loss_ce: 0.008023
iteration 8143 : loss : 0.026093, loss_ce: 0.006008
iteration 8144 : loss : 0.028007, loss_ce: 0.009879
iteration 8145 : loss : 0.027570, loss_ce: 0.009528
iteration 8146 : loss : 0.023347, loss_ce: 0.006294
iteration 8147 : loss : 0.038019, loss_ce: 0.010100
iteration 8148 : loss : 0.027743, loss_ce: 0.013439
iteration 8149 : loss : 0.032789, loss_ce: 0.011709
iteration 8150 : loss : 0.030582, loss_ce: 0.011893
iteration 8151 : loss : 0.033431, loss_ce: 0.008130
iteration 8152 : loss : 0.032887, loss_ce: 0.009557
iteration 8153 : loss : 0.030777, loss_ce: 0.009679
iteration 8154 : loss : 0.124020, loss_ce: 0.003264
iteration 8155 : loss : 0.031908, loss_ce: 0.010097
iteration 8156 : loss : 0.028778, loss_ce: 0.011113
iteration 8157 : loss : 0.027111, loss_ce: 0.009426
iteration 8158 : loss : 0.032033, loss_ce: 0.014317
iteration 8159 : loss : 0.076237, loss_ce: 0.005841
iteration 8160 : loss : 0.026995, loss_ce: 0.010880
iteration 8161 : loss : 0.074412, loss_ce: 0.006890
iteration 8162 : loss : 0.025333, loss_ce: 0.008560
iteration 8163 : loss : 0.027293, loss_ce: 0.007752
iteration 8164 : loss : 0.027140, loss_ce: 0.006599
iteration 8165 : loss : 0.029800, loss_ce: 0.009495
iteration 8166 : loss : 0.030135, loss_ce: 0.010787
iteration 8167 : loss : 0.028744, loss_ce: 0.011169
iteration 8168 : loss : 0.024299, loss_ce: 0.007867
iteration 8169 : loss : 0.031755, loss_ce: 0.014296
iteration 8170 : loss : 0.025171, loss_ce: 0.008400
iteration 8171 : loss : 0.022595, loss_ce: 0.005491
iteration 8172 : loss : 0.053364, loss_ce: 0.009999
iteration 8173 : loss : 0.074052, loss_ce: 0.008287
iteration 8174 : loss : 0.026712, loss_ce: 0.006311
iteration 8175 : loss : 0.030050, loss_ce: 0.009985
iteration 8176 : loss : 0.025721, loss_ce: 0.009436
iteration 8177 : loss : 0.116954, loss_ce: 0.005202
iteration 8178 : loss : 0.026843, loss_ce: 0.013806
iteration 8179 : loss : 0.035610, loss_ce: 0.017107
iteration 8180 : loss : 0.043129, loss_ce: 0.016342
iteration 8181 : loss : 0.035911, loss_ce: 0.014104
iteration 8182 : loss : 0.038696, loss_ce: 0.015114
iteration 8183 : loss : 0.039328, loss_ce: 0.017475
iteration 8184 : loss : 0.073816, loss_ce: 0.012881
 44%|████████████▎               | 88/200 [1:30:22<1:54:59, 61.60s/it]iteration 8185 : loss : 0.047678, loss_ce: 0.012236
iteration 8186 : loss : 0.034977, loss_ce: 0.014706
iteration 8187 : loss : 0.033870, loss_ce: 0.017278
iteration 8188 : loss : 0.033507, loss_ce: 0.010266
iteration 8189 : loss : 0.033870, loss_ce: 0.006062
iteration 8190 : loss : 0.031518, loss_ce: 0.012850
iteration 8191 : loss : 0.023332, loss_ce: 0.009244
iteration 8192 : loss : 0.034410, loss_ce: 0.013951
iteration 8193 : loss : 0.043520, loss_ce: 0.016463
iteration 8194 : loss : 0.037407, loss_ce: 0.010086
iteration 8195 : loss : 0.022941, loss_ce: 0.003016
iteration 8196 : loss : 0.025240, loss_ce: 0.008928
iteration 8197 : loss : 0.027847, loss_ce: 0.006688
iteration 8198 : loss : 0.080748, loss_ce: 0.008004
iteration 8199 : loss : 0.035592, loss_ce: 0.010716
iteration 8200 : loss : 0.089241, loss_ce: 0.008789
iteration 8201 : loss : 0.032323, loss_ce: 0.017708
iteration 8202 : loss : 0.027718, loss_ce: 0.011123
iteration 8203 : loss : 0.032802, loss_ce: 0.012168
iteration 8204 : loss : 0.028928, loss_ce: 0.009589
iteration 8205 : loss : 0.028832, loss_ce: 0.012124
iteration 8206 : loss : 0.078792, loss_ce: 0.007429
iteration 8207 : loss : 0.025548, loss_ce: 0.008691
iteration 8208 : loss : 0.025935, loss_ce: 0.010742
iteration 8209 : loss : 0.026367, loss_ce: 0.010807
iteration 8210 : loss : 0.030168, loss_ce: 0.008937
iteration 8211 : loss : 0.029549, loss_ce: 0.013266
iteration 8212 : loss : 0.023543, loss_ce: 0.009231
iteration 8213 : loss : 0.029060, loss_ce: 0.011132
iteration 8214 : loss : 0.074363, loss_ce: 0.006829
iteration 8215 : loss : 0.087067, loss_ce: 0.004686
iteration 8216 : loss : 0.038270, loss_ce: 0.011846
iteration 8217 : loss : 0.029552, loss_ce: 0.011283
iteration 8218 : loss : 0.029498, loss_ce: 0.011584
iteration 8219 : loss : 0.035286, loss_ce: 0.007519
iteration 8220 : loss : 0.040594, loss_ce: 0.008883
iteration 8221 : loss : 0.032546, loss_ce: 0.009641
iteration 8222 : loss : 0.076305, loss_ce: 0.007717
iteration 8223 : loss : 0.029938, loss_ce: 0.011467
iteration 8224 : loss : 0.029323, loss_ce: 0.010607
iteration 8225 : loss : 0.037732, loss_ce: 0.011478
iteration 8226 : loss : 0.030450, loss_ce: 0.009601
iteration 8227 : loss : 0.028831, loss_ce: 0.009197
iteration 8228 : loss : 0.032243, loss_ce: 0.010246
iteration 8229 : loss : 0.027172, loss_ce: 0.007872
iteration 8230 : loss : 0.029579, loss_ce: 0.006814
iteration 8231 : loss : 0.031463, loss_ce: 0.017385
iteration 8232 : loss : 0.028199, loss_ce: 0.013593
iteration 8233 : loss : 0.036267, loss_ce: 0.009845
iteration 8234 : loss : 0.030792, loss_ce: 0.013311
iteration 8235 : loss : 0.082109, loss_ce: 0.008487
iteration 8236 : loss : 0.029218, loss_ce: 0.016383
iteration 8237 : loss : 0.024239, loss_ce: 0.006420
iteration 8238 : loss : 0.028893, loss_ce: 0.007885
iteration 8239 : loss : 0.026654, loss_ce: 0.009276
iteration 8240 : loss : 0.038347, loss_ce: 0.012997
iteration 8241 : loss : 0.036035, loss_ce: 0.008727
iteration 8242 : loss : 0.031499, loss_ce: 0.008485
iteration 8243 : loss : 0.028517, loss_ce: 0.010630
iteration 8244 : loss : 0.028750, loss_ce: 0.013078
iteration 8245 : loss : 0.085514, loss_ce: 0.003083
iteration 8246 : loss : 0.026849, loss_ce: 0.009859
iteration 8247 : loss : 0.032080, loss_ce: 0.013660
iteration 8248 : loss : 0.032599, loss_ce: 0.010203
iteration 8249 : loss : 0.033538, loss_ce: 0.011466
iteration 8250 : loss : 0.030917, loss_ce: 0.007264
iteration 8251 : loss : 0.029397, loss_ce: 0.008586
iteration 8252 : loss : 0.027709, loss_ce: 0.007862
iteration 8253 : loss : 0.031569, loss_ce: 0.011542
iteration 8254 : loss : 0.029738, loss_ce: 0.010905
iteration 8255 : loss : 0.029196, loss_ce: 0.011604
iteration 8256 : loss : 0.019876, loss_ce: 0.004264
iteration 8257 : loss : 0.031719, loss_ce: 0.011215
iteration 8258 : loss : 0.025597, loss_ce: 0.007081
iteration 8259 : loss : 0.021873, loss_ce: 0.005711
iteration 8260 : loss : 0.030341, loss_ce: 0.013393
iteration 8261 : loss : 0.027717, loss_ce: 0.012693
iteration 8262 : loss : 0.034925, loss_ce: 0.006881
iteration 8263 : loss : 0.078616, loss_ce: 0.011188
iteration 8264 : loss : 0.033104, loss_ce: 0.006581
iteration 8265 : loss : 0.030903, loss_ce: 0.007353
iteration 8266 : loss : 0.034956, loss_ce: 0.017507
iteration 8267 : loss : 0.035482, loss_ce: 0.012348
iteration 8268 : loss : 0.028927, loss_ce: 0.010797
iteration 8269 : loss : 0.028893, loss_ce: 0.010136
iteration 8270 : loss : 0.033387, loss_ce: 0.014039
iteration 8271 : loss : 0.026062, loss_ce: 0.010742
iteration 8272 : loss : 0.030244, loss_ce: 0.012814
iteration 8273 : loss : 0.025796, loss_ce: 0.007626
iteration 8274 : loss : 0.034392, loss_ce: 0.015576
iteration 8275 : loss : 0.029918, loss_ce: 0.009038
iteration 8276 : loss : 0.027635, loss_ce: 0.011395
iteration 8277 : loss : 0.030487, loss_ce: 0.016786
 44%|████████████▍               | 89/200 [1:31:24<1:53:54, 61.58s/it]iteration 8278 : loss : 0.025593, loss_ce: 0.010919
iteration 8279 : loss : 0.023036, loss_ce: 0.008562
iteration 8280 : loss : 0.032728, loss_ce: 0.011675
iteration 8281 : loss : 0.024749, loss_ce: 0.010150
iteration 8282 : loss : 0.026511, loss_ce: 0.009060
iteration 8283 : loss : 0.025933, loss_ce: 0.007920
iteration 8284 : loss : 0.081367, loss_ce: 0.008819
iteration 8285 : loss : 0.025513, loss_ce: 0.008086
iteration 8286 : loss : 0.033398, loss_ce: 0.018788
iteration 8287 : loss : 0.028142, loss_ce: 0.012431
iteration 8288 : loss : 0.028013, loss_ce: 0.008925
iteration 8289 : loss : 0.026719, loss_ce: 0.005887
iteration 8290 : loss : 0.028814, loss_ce: 0.005832
iteration 8291 : loss : 0.026951, loss_ce: 0.008389
iteration 8292 : loss : 0.029582, loss_ce: 0.010436
iteration 8293 : loss : 0.035878, loss_ce: 0.013556
iteration 8294 : loss : 0.030165, loss_ce: 0.008707
iteration 8295 : loss : 0.028103, loss_ce: 0.006641
iteration 8296 : loss : 0.035443, loss_ce: 0.005658
iteration 8297 : loss : 0.027062, loss_ce: 0.011795
iteration 8298 : loss : 0.031738, loss_ce: 0.008197
iteration 8299 : loss : 0.076389, loss_ce: 0.007722
iteration 8300 : loss : 0.033884, loss_ce: 0.007505
iteration 8301 : loss : 0.030086, loss_ce: 0.014163
iteration 8302 : loss : 0.031471, loss_ce: 0.008199
iteration 8303 : loss : 0.024199, loss_ce: 0.008139
iteration 8304 : loss : 0.072567, loss_ce: 0.006269
iteration 8305 : loss : 0.031750, loss_ce: 0.014880
iteration 8306 : loss : 0.035167, loss_ce: 0.010637
iteration 8307 : loss : 0.023022, loss_ce: 0.010230
iteration 8308 : loss : 0.039654, loss_ce: 0.008376
iteration 8309 : loss : 0.029246, loss_ce: 0.013339
iteration 8310 : loss : 0.026967, loss_ce: 0.010976
iteration 8311 : loss : 0.020838, loss_ce: 0.007212
iteration 8312 : loss : 0.181281, loss_ce: 0.003720
iteration 8313 : loss : 0.078972, loss_ce: 0.005595
iteration 8314 : loss : 0.032641, loss_ce: 0.013825
iteration 8315 : loss : 0.028024, loss_ce: 0.010248
iteration 8316 : loss : 0.030249, loss_ce: 0.012268
iteration 8317 : loss : 0.035112, loss_ce: 0.010943
iteration 8318 : loss : 0.043034, loss_ce: 0.012430
iteration 8319 : loss : 0.023591, loss_ce: 0.008324
iteration 8320 : loss : 0.080200, loss_ce: 0.006152
iteration 8321 : loss : 0.025006, loss_ce: 0.008970
iteration 8322 : loss : 0.026884, loss_ce: 0.008959
iteration 8323 : loss : 0.034807, loss_ce: 0.013034
iteration 8324 : loss : 0.032155, loss_ce: 0.006234
iteration 8325 : loss : 0.022068, loss_ce: 0.008880
iteration 8326 : loss : 0.077511, loss_ce: 0.007576
iteration 8327 : loss : 0.027195, loss_ce: 0.011623
iteration 8328 : loss : 0.028056, loss_ce: 0.008457
iteration 8329 : loss : 0.076839, loss_ce: 0.005997
iteration 8330 : loss : 0.027491, loss_ce: 0.008331
iteration 8331 : loss : 0.025654, loss_ce: 0.007453
iteration 8332 : loss : 0.024870, loss_ce: 0.009958
iteration 8333 : loss : 0.025845, loss_ce: 0.009517
iteration 8334 : loss : 0.029911, loss_ce: 0.007291
iteration 8335 : loss : 0.022826, loss_ce: 0.005958
iteration 8336 : loss : 0.032580, loss_ce: 0.009140
iteration 8337 : loss : 0.030165, loss_ce: 0.009544
iteration 8338 : loss : 0.033808, loss_ce: 0.007465
iteration 8339 : loss : 0.029143, loss_ce: 0.014260
iteration 8340 : loss : 0.027278, loss_ce: 0.010985
iteration 8341 : loss : 0.030190, loss_ce: 0.009729
iteration 8342 : loss : 0.079248, loss_ce: 0.008152
iteration 8343 : loss : 0.031008, loss_ce: 0.007553
iteration 8344 : loss : 0.024446, loss_ce: 0.007273
iteration 8345 : loss : 0.027880, loss_ce: 0.011356
iteration 8346 : loss : 0.033907, loss_ce: 0.010748
iteration 8347 : loss : 0.026090, loss_ce: 0.010511
iteration 8348 : loss : 0.036884, loss_ce: 0.005827
iteration 8349 : loss : 0.028616, loss_ce: 0.006457
iteration 8350 : loss : 0.028103, loss_ce: 0.009358
iteration 8351 : loss : 0.026550, loss_ce: 0.008175
iteration 8352 : loss : 0.078898, loss_ce: 0.008785
iteration 8353 : loss : 0.034407, loss_ce: 0.008552
iteration 8354 : loss : 0.032717, loss_ce: 0.008824
iteration 8355 : loss : 0.026031, loss_ce: 0.009329
iteration 8356 : loss : 0.028348, loss_ce: 0.010524
iteration 8357 : loss : 0.027375, loss_ce: 0.008562
iteration 8358 : loss : 0.029898, loss_ce: 0.016794
iteration 8359 : loss : 0.030926, loss_ce: 0.010185
iteration 8360 : loss : 0.025753, loss_ce: 0.013776
iteration 8361 : loss : 0.031318, loss_ce: 0.008977
iteration 8362 : loss : 0.027014, loss_ce: 0.010129
iteration 8363 : loss : 0.026315, loss_ce: 0.011667
iteration 8364 : loss : 0.033789, loss_ce: 0.012402
iteration 8365 : loss : 0.027520, loss_ce: 0.007938
iteration 8366 : loss : 0.025632, loss_ce: 0.009778
iteration 8367 : loss : 0.062298, loss_ce: 0.005118
iteration 8368 : loss : 0.029918, loss_ce: 0.015924
iteration 8369 : loss : 0.027543, loss_ce: 0.009325
iteration 8370 : loss : 0.126160, loss_ce: 0.021908
 45%|████████████▌               | 90/200 [1:32:25<1:52:51, 61.56s/it]iteration 8371 : loss : 0.029023, loss_ce: 0.007471
iteration 8372 : loss : 0.034082, loss_ce: 0.015325
iteration 8373 : loss : 0.027346, loss_ce: 0.012512
iteration 8374 : loss : 0.037819, loss_ce: 0.011924
iteration 8375 : loss : 0.031248, loss_ce: 0.015477
iteration 8376 : loss : 0.045687, loss_ce: 0.015567
iteration 8377 : loss : 0.039968, loss_ce: 0.017649
iteration 8378 : loss : 0.036456, loss_ce: 0.009646
iteration 8379 : loss : 0.037979, loss_ce: 0.007918
iteration 8380 : loss : 0.035628, loss_ce: 0.011009
iteration 8381 : loss : 0.029517, loss_ce: 0.008515
iteration 8382 : loss : 0.037249, loss_ce: 0.010975
iteration 8383 : loss : 0.031175, loss_ce: 0.013904
iteration 8384 : loss : 0.083465, loss_ce: 0.008303
iteration 8385 : loss : 0.077898, loss_ce: 0.007914
iteration 8386 : loss : 0.043591, loss_ce: 0.015590
iteration 8387 : loss : 0.039401, loss_ce: 0.012594
iteration 8388 : loss : 0.037219, loss_ce: 0.010535
iteration 8389 : loss : 0.027813, loss_ce: 0.003741
iteration 8390 : loss : 0.050773, loss_ce: 0.012687
iteration 8391 : loss : 0.030485, loss_ce: 0.012000
iteration 8392 : loss : 0.032744, loss_ce: 0.010440
iteration 8393 : loss : 0.043434, loss_ce: 0.008342
iteration 8394 : loss : 0.030838, loss_ce: 0.013628
iteration 8395 : loss : 0.030904, loss_ce: 0.009717
iteration 8396 : loss : 0.033597, loss_ce: 0.010200
iteration 8397 : loss : 0.047789, loss_ce: 0.009291
iteration 8398 : loss : 0.049624, loss_ce: 0.009053
iteration 8399 : loss : 0.033388, loss_ce: 0.014440
iteration 8400 : loss : 0.033081, loss_ce: 0.008581
iteration 8401 : loss : 0.035834, loss_ce: 0.012040
iteration 8402 : loss : 0.024413, loss_ce: 0.006321
iteration 8403 : loss : 0.027722, loss_ce: 0.007602
iteration 8404 : loss : 0.034872, loss_ce: 0.010288
iteration 8405 : loss : 0.033002, loss_ce: 0.014463
iteration 8406 : loss : 0.038965, loss_ce: 0.009330
iteration 8407 : loss : 0.032771, loss_ce: 0.011459
iteration 8408 : loss : 0.031440, loss_ce: 0.011354
iteration 8409 : loss : 0.033218, loss_ce: 0.015667
iteration 8410 : loss : 0.030805, loss_ce: 0.011100
iteration 8411 : loss : 0.033805, loss_ce: 0.013620
iteration 8412 : loss : 0.028866, loss_ce: 0.009691
iteration 8413 : loss : 0.025968, loss_ce: 0.007551
iteration 8414 : loss : 0.033347, loss_ce: 0.008995
iteration 8415 : loss : 0.027434, loss_ce: 0.006162
iteration 8416 : loss : 0.036369, loss_ce: 0.013075
iteration 8417 : loss : 0.027107, loss_ce: 0.011378
iteration 8418 : loss : 0.023220, loss_ce: 0.006610
iteration 8419 : loss : 0.034617, loss_ce: 0.007551
iteration 8420 : loss : 0.033341, loss_ce: 0.007568
iteration 8421 : loss : 0.028636, loss_ce: 0.010218
iteration 8422 : loss : 0.034271, loss_ce: 0.012505
iteration 8423 : loss : 0.031785, loss_ce: 0.012507
iteration 8424 : loss : 0.024633, loss_ce: 0.009803
iteration 8425 : loss : 0.028374, loss_ce: 0.013294
iteration 8426 : loss : 0.027968, loss_ce: 0.006360
iteration 8427 : loss : 0.031033, loss_ce: 0.009548
iteration 8428 : loss : 0.030092, loss_ce: 0.010980
iteration 8429 : loss : 0.082189, loss_ce: 0.012240
iteration 8430 : loss : 0.029978, loss_ce: 0.010870
iteration 8431 : loss : 0.032229, loss_ce: 0.008682
iteration 8432 : loss : 0.040174, loss_ce: 0.013540
iteration 8433 : loss : 0.030542, loss_ce: 0.011876
iteration 8434 : loss : 0.029244, loss_ce: 0.007260
iteration 8435 : loss : 0.028818, loss_ce: 0.008641
iteration 8436 : loss : 0.030440, loss_ce: 0.010766
iteration 8437 : loss : 0.031244, loss_ce: 0.008426
iteration 8438 : loss : 0.025938, loss_ce: 0.006716
iteration 8439 : loss : 0.083148, loss_ce: 0.004833
iteration 8440 : loss : 0.029749, loss_ce: 0.009416
iteration 8441 : loss : 0.028021, loss_ce: 0.010806
iteration 8442 : loss : 0.031397, loss_ce: 0.014135
iteration 8443 : loss : 0.034568, loss_ce: 0.009569
iteration 8444 : loss : 0.025502, loss_ce: 0.008817
iteration 8445 : loss : 0.028806, loss_ce: 0.013517
iteration 8446 : loss : 0.022292, loss_ce: 0.007129
iteration 8447 : loss : 0.027847, loss_ce: 0.010993
iteration 8448 : loss : 0.024347, loss_ce: 0.008892
iteration 8449 : loss : 0.030577, loss_ce: 0.008103
iteration 8450 : loss : 0.081423, loss_ce: 0.008161
iteration 8451 : loss : 0.032098, loss_ce: 0.008093
iteration 8452 : loss : 0.030140, loss_ce: 0.012732
iteration 8453 : loss : 0.038987, loss_ce: 0.013429
iteration 8454 : loss : 0.024104, loss_ce: 0.003317
iteration 8455 : loss : 0.030761, loss_ce: 0.016043
iteration 8456 : loss : 0.034133, loss_ce: 0.007958
iteration 8457 : loss : 0.029637, loss_ce: 0.012225
iteration 8458 : loss : 0.030528, loss_ce: 0.012523
iteration 8459 : loss : 0.032704, loss_ce: 0.014239
iteration 8460 : loss : 0.036362, loss_ce: 0.010553
iteration 8461 : loss : 0.090145, loss_ce: 0.006073
iteration 8462 : loss : 0.025743, loss_ce: 0.007479
iteration 8463 : loss : 0.102513, loss_ce: 0.019940
 46%|████████████▋               | 91/200 [1:33:27<1:51:49, 61.55s/it]iteration 8464 : loss : 0.037049, loss_ce: 0.012894
iteration 8465 : loss : 0.033605, loss_ce: 0.009807
iteration 8466 : loss : 0.027914, loss_ce: 0.007256
iteration 8467 : loss : 0.033599, loss_ce: 0.011965
iteration 8468 : loss : 0.034086, loss_ce: 0.015789
iteration 8469 : loss : 0.036384, loss_ce: 0.011790
iteration 8470 : loss : 0.033328, loss_ce: 0.010752
iteration 8471 : loss : 0.034024, loss_ce: 0.008104
iteration 8472 : loss : 0.032944, loss_ce: 0.011380
iteration 8473 : loss : 0.028199, loss_ce: 0.011664
iteration 8474 : loss : 0.072578, loss_ce: 0.009175
iteration 8475 : loss : 0.026841, loss_ce: 0.012981
iteration 8476 : loss : 0.082933, loss_ce: 0.005243
iteration 8477 : loss : 0.029497, loss_ce: 0.009071
iteration 8478 : loss : 0.083363, loss_ce: 0.011473
iteration 8479 : loss : 0.027376, loss_ce: 0.010136
iteration 8480 : loss : 0.036686, loss_ce: 0.009992
iteration 8481 : loss : 0.033687, loss_ce: 0.009792
iteration 8482 : loss : 0.035110, loss_ce: 0.011248
iteration 8483 : loss : 0.035179, loss_ce: 0.014212
iteration 8484 : loss : 0.082729, loss_ce: 0.007014
iteration 8485 : loss : 0.030711, loss_ce: 0.010285
iteration 8486 : loss : 0.030163, loss_ce: 0.011053
iteration 8487 : loss : 0.031503, loss_ce: 0.007981
iteration 8488 : loss : 0.026366, loss_ce: 0.006660
iteration 8489 : loss : 0.025350, loss_ce: 0.010615
iteration 8490 : loss : 0.034360, loss_ce: 0.010171
iteration 8491 : loss : 0.030728, loss_ce: 0.011984
iteration 8492 : loss : 0.038576, loss_ce: 0.011245
iteration 8493 : loss : 0.038517, loss_ce: 0.011758
iteration 8494 : loss : 0.032161, loss_ce: 0.008023
iteration 8495 : loss : 0.027288, loss_ce: 0.011049
iteration 8496 : loss : 0.026668, loss_ce: 0.007799
iteration 8497 : loss : 0.079575, loss_ce: 0.006099
iteration 8498 : loss : 0.027923, loss_ce: 0.011434
iteration 8499 : loss : 0.033357, loss_ce: 0.009052
iteration 8500 : loss : 0.030597, loss_ce: 0.010215
iteration 8501 : loss : 0.033905, loss_ce: 0.009735
iteration 8502 : loss : 0.027931, loss_ce: 0.010200
iteration 8503 : loss : 0.079488, loss_ce: 0.011081
iteration 8504 : loss : 0.078521, loss_ce: 0.008416
iteration 8505 : loss : 0.029898, loss_ce: 0.011623
iteration 8506 : loss : 0.024320, loss_ce: 0.006009
iteration 8507 : loss : 0.029939, loss_ce: 0.013094
iteration 8508 : loss : 0.031094, loss_ce: 0.014091
iteration 8509 : loss : 0.028982, loss_ce: 0.012881
iteration 8510 : loss : 0.023425, loss_ce: 0.009392
iteration 8511 : loss : 0.032380, loss_ce: 0.006858
iteration 8512 : loss : 0.078083, loss_ce: 0.008543
iteration 8513 : loss : 0.025180, loss_ce: 0.007196
iteration 8514 : loss : 0.028093, loss_ce: 0.011013
iteration 8515 : loss : 0.075501, loss_ce: 0.005219
iteration 8516 : loss : 0.033830, loss_ce: 0.006920
iteration 8517 : loss : 0.047659, loss_ce: 0.007287
iteration 8518 : loss : 0.027541, loss_ce: 0.006218
iteration 8519 : loss : 0.024611, loss_ce: 0.011046
iteration 8520 : loss : 0.025422, loss_ce: 0.008408
iteration 8521 : loss : 0.030668, loss_ce: 0.010318
iteration 8522 : loss : 0.027936, loss_ce: 0.008947
iteration 8523 : loss : 0.024456, loss_ce: 0.008017
iteration 8524 : loss : 0.025257, loss_ce: 0.010903
iteration 8525 : loss : 0.132105, loss_ce: 0.002102
iteration 8526 : loss : 0.027590, loss_ce: 0.007842
iteration 8527 : loss : 0.027100, loss_ce: 0.009523
iteration 8528 : loss : 0.036605, loss_ce: 0.010636
iteration 8529 : loss : 0.027970, loss_ce: 0.007477
iteration 8530 : loss : 0.032818, loss_ce: 0.011679
iteration 8531 : loss : 0.079629, loss_ce: 0.010897
iteration 8532 : loss : 0.032563, loss_ce: 0.013039
iteration 8533 : loss : 0.028246, loss_ce: 0.008645
iteration 8534 : loss : 0.032203, loss_ce: 0.011692
iteration 8535 : loss : 0.028165, loss_ce: 0.013485
iteration 8536 : loss : 0.032440, loss_ce: 0.013402
iteration 8537 : loss : 0.031437, loss_ce: 0.011438
iteration 8538 : loss : 0.028137, loss_ce: 0.010337
iteration 8539 : loss : 0.077936, loss_ce: 0.008192
iteration 8540 : loss : 0.026947, loss_ce: 0.009308
iteration 8541 : loss : 0.028882, loss_ce: 0.010215
iteration 8542 : loss : 0.035636, loss_ce: 0.015684
iteration 8543 : loss : 0.036760, loss_ce: 0.011478
iteration 8544 : loss : 0.027621, loss_ce: 0.010673
iteration 8545 : loss : 0.026405, loss_ce: 0.010913
iteration 8546 : loss : 0.024508, loss_ce: 0.008631
iteration 8547 : loss : 0.028858, loss_ce: 0.012351
iteration 8548 : loss : 0.027271, loss_ce: 0.008377
iteration 8549 : loss : 0.037121, loss_ce: 0.010931
iteration 8550 : loss : 0.028529, loss_ce: 0.007919
iteration 8551 : loss : 0.028487, loss_ce: 0.008115
iteration 8552 : loss : 0.034728, loss_ce: 0.005714
iteration 8553 : loss : 0.075789, loss_ce: 0.007148
iteration 8554 : loss : 0.023687, loss_ce: 0.008418
iteration 8555 : loss : 0.028193, loss_ce: 0.009230
iteration 8556 : loss : 0.389399, loss_ce: 0.000730
 46%|████████████▉               | 92/200 [1:34:28<1:50:53, 61.61s/it]iteration 8557 : loss : 0.033686, loss_ce: 0.012526
iteration 8558 : loss : 0.032395, loss_ce: 0.007677
iteration 8559 : loss : 0.027981, loss_ce: 0.008532
iteration 8560 : loss : 0.033851, loss_ce: 0.012720
iteration 8561 : loss : 0.076875, loss_ce: 0.003812
iteration 8562 : loss : 0.027787, loss_ce: 0.010733
iteration 8563 : loss : 0.029424, loss_ce: 0.006831
iteration 8564 : loss : 0.027134, loss_ce: 0.011010
iteration 8565 : loss : 0.078838, loss_ce: 0.008858
iteration 8566 : loss : 0.028590, loss_ce: 0.008860
iteration 8567 : loss : 0.027198, loss_ce: 0.010413
iteration 8568 : loss : 0.029176, loss_ce: 0.008268
iteration 8569 : loss : 0.031160, loss_ce: 0.011179
iteration 8570 : loss : 0.026600, loss_ce: 0.007593
iteration 8571 : loss : 0.025698, loss_ce: 0.009000
iteration 8572 : loss : 0.025399, loss_ce: 0.009138
iteration 8573 : loss : 0.025205, loss_ce: 0.010150
iteration 8574 : loss : 0.024982, loss_ce: 0.006646
iteration 8575 : loss : 0.022860, loss_ce: 0.005605
iteration 8576 : loss : 0.030432, loss_ce: 0.006032
iteration 8577 : loss : 0.021904, loss_ce: 0.007009
iteration 8578 : loss : 0.045168, loss_ce: 0.008988
iteration 8579 : loss : 0.032917, loss_ce: 0.013448
iteration 8580 : loss : 0.029256, loss_ce: 0.006313
iteration 8581 : loss : 0.027429, loss_ce: 0.006964
iteration 8582 : loss : 0.025781, loss_ce: 0.008081
iteration 8583 : loss : 0.030672, loss_ce: 0.010490
iteration 8584 : loss : 0.026400, loss_ce: 0.008491
iteration 8585 : loss : 0.028784, loss_ce: 0.007561
iteration 8586 : loss : 0.028219, loss_ce: 0.011986
iteration 8587 : loss : 0.025737, loss_ce: 0.011800
iteration 8588 : loss : 0.023500, loss_ce: 0.005371
iteration 8589 : loss : 0.030239, loss_ce: 0.008881
iteration 8590 : loss : 0.076814, loss_ce: 0.006856
iteration 8591 : loss : 0.032142, loss_ce: 0.010050
iteration 8592 : loss : 0.030475, loss_ce: 0.010727
iteration 8593 : loss : 0.028432, loss_ce: 0.011711
iteration 8594 : loss : 0.029693, loss_ce: 0.014008
iteration 8595 : loss : 0.033788, loss_ce: 0.009617
iteration 8596 : loss : 0.027088, loss_ce: 0.007144
iteration 8597 : loss : 0.034254, loss_ce: 0.008689
iteration 8598 : loss : 0.028349, loss_ce: 0.009435
iteration 8599 : loss : 0.027686, loss_ce: 0.008781
iteration 8600 : loss : 0.032952, loss_ce: 0.005398
iteration 8601 : loss : 0.231325, loss_ce: 0.004960
iteration 8602 : loss : 0.032863, loss_ce: 0.007152
iteration 8603 : loss : 0.024558, loss_ce: 0.008448
iteration 8604 : loss : 0.024942, loss_ce: 0.007536
iteration 8605 : loss : 0.030334, loss_ce: 0.009743
iteration 8606 : loss : 0.027092, loss_ce: 0.005954
iteration 8607 : loss : 0.024971, loss_ce: 0.011590
iteration 8608 : loss : 0.024142, loss_ce: 0.009592
iteration 8609 : loss : 0.027348, loss_ce: 0.014408
iteration 8610 : loss : 0.023597, loss_ce: 0.008128
iteration 8611 : loss : 0.021155, loss_ce: 0.004404
iteration 8612 : loss : 0.022494, loss_ce: 0.008529
iteration 8613 : loss : 0.024404, loss_ce: 0.009829
iteration 8614 : loss : 0.025558, loss_ce: 0.011112
iteration 8615 : loss : 0.032590, loss_ce: 0.009791
iteration 8616 : loss : 0.025593, loss_ce: 0.011472
iteration 8617 : loss : 0.029592, loss_ce: 0.012703
iteration 8618 : loss : 0.027698, loss_ce: 0.007283
iteration 8619 : loss : 0.027187, loss_ce: 0.008132
iteration 8620 : loss : 0.027247, loss_ce: 0.008241
iteration 8621 : loss : 0.032965, loss_ce: 0.013831
iteration 8622 : loss : 0.026347, loss_ce: 0.008254
iteration 8623 : loss : 0.026934, loss_ce: 0.011448
iteration 8624 : loss : 0.026600, loss_ce: 0.009107
iteration 8625 : loss : 0.035127, loss_ce: 0.010205
iteration 8626 : loss : 0.033287, loss_ce: 0.014042
iteration 8627 : loss : 0.025719, loss_ce: 0.008960
iteration 8628 : loss : 0.028381, loss_ce: 0.008573
iteration 8629 : loss : 0.027842, loss_ce: 0.012520
iteration 8630 : loss : 0.028041, loss_ce: 0.009306
iteration 8631 : loss : 0.026095, loss_ce: 0.008382
iteration 8632 : loss : 0.026024, loss_ce: 0.009892
iteration 8633 : loss : 0.026036, loss_ce: 0.010457
iteration 8634 : loss : 0.036584, loss_ce: 0.009713
iteration 8635 : loss : 0.026952, loss_ce: 0.009554
iteration 8636 : loss : 0.024168, loss_ce: 0.007645
iteration 8637 : loss : 0.021788, loss_ce: 0.005912
iteration 8638 : loss : 0.026536, loss_ce: 0.009901
iteration 8639 : loss : 0.026477, loss_ce: 0.009538
iteration 8640 : loss : 0.024898, loss_ce: 0.009570
iteration 8641 : loss : 0.029430, loss_ce: 0.015002
iteration 8642 : loss : 0.031835, loss_ce: 0.008886
iteration 8643 : loss : 0.032152, loss_ce: 0.013022
iteration 8644 : loss : 0.021701, loss_ce: 0.006007
iteration 8645 : loss : 0.028872, loss_ce: 0.012230
iteration 8646 : loss : 0.025502, loss_ce: 0.012856
iteration 8647 : loss : 0.027044, loss_ce: 0.010364
iteration 8648 : loss : 0.021490, loss_ce: 0.007189
iteration 8649 : loss : 0.241473, loss_ce: 0.010272
 46%|█████████████               | 93/200 [1:35:30<1:49:52, 61.61s/it]iteration 8650 : loss : 0.024368, loss_ce: 0.006764
iteration 8651 : loss : 0.027082, loss_ce: 0.013229
iteration 8652 : loss : 0.028706, loss_ce: 0.009556
iteration 8653 : loss : 0.027427, loss_ce: 0.012114
iteration 8654 : loss : 0.025161, loss_ce: 0.010253
iteration 8655 : loss : 0.027075, loss_ce: 0.013041
iteration 8656 : loss : 0.034856, loss_ce: 0.011347
iteration 8657 : loss : 0.028292, loss_ce: 0.011318
iteration 8658 : loss : 0.018856, loss_ce: 0.005997
iteration 8659 : loss : 0.026376, loss_ce: 0.007250
iteration 8660 : loss : 0.079399, loss_ce: 0.010136
iteration 8661 : loss : 0.029936, loss_ce: 0.010809
iteration 8662 : loss : 0.026671, loss_ce: 0.010078
iteration 8663 : loss : 0.039198, loss_ce: 0.008387
iteration 8664 : loss : 0.030119, loss_ce: 0.013822
iteration 8665 : loss : 0.076043, loss_ce: 0.006438
iteration 8666 : loss : 0.032403, loss_ce: 0.009950
iteration 8667 : loss : 0.024266, loss_ce: 0.010769
iteration 8668 : loss : 0.030161, loss_ce: 0.009524
iteration 8669 : loss : 0.024074, loss_ce: 0.007294
iteration 8670 : loss : 0.026158, loss_ce: 0.012012
iteration 8671 : loss : 0.028686, loss_ce: 0.011043
iteration 8672 : loss : 0.029403, loss_ce: 0.009757
iteration 8673 : loss : 0.027901, loss_ce: 0.011419
iteration 8674 : loss : 0.029817, loss_ce: 0.008914
iteration 8675 : loss : 0.080710, loss_ce: 0.008789
iteration 8676 : loss : 0.027669, loss_ce: 0.007987
iteration 8677 : loss : 0.029539, loss_ce: 0.008040
iteration 8678 : loss : 0.026358, loss_ce: 0.008819
iteration 8679 : loss : 0.028604, loss_ce: 0.010897
iteration 8680 : loss : 0.027414, loss_ce: 0.011972
iteration 8681 : loss : 0.044635, loss_ce: 0.005287
iteration 8682 : loss : 0.028501, loss_ce: 0.008967
iteration 8683 : loss : 0.024836, loss_ce: 0.010817
iteration 8684 : loss : 0.027221, loss_ce: 0.009199
iteration 8685 : loss : 0.024554, loss_ce: 0.006316
iteration 8686 : loss : 0.032258, loss_ce: 0.014254
iteration 8687 : loss : 0.075738, loss_ce: 0.006230
iteration 8688 : loss : 0.027873, loss_ce: 0.011623
iteration 8689 : loss : 0.031402, loss_ce: 0.010875
iteration 8690 : loss : 0.029006, loss_ce: 0.009106
iteration 8691 : loss : 0.027649, loss_ce: 0.008706
iteration 8692 : loss : 0.028999, loss_ce: 0.009039
iteration 8693 : loss : 0.032987, loss_ce: 0.007979
iteration 8694 : loss : 0.024233, loss_ce: 0.009970
iteration 8695 : loss : 0.077252, loss_ce: 0.009210
iteration 8696 : loss : 0.022500, loss_ce: 0.010556
iteration 8697 : loss : 0.025974, loss_ce: 0.011347
iteration 8698 : loss : 0.040813, loss_ce: 0.012441
iteration 8699 : loss : 0.027619, loss_ce: 0.014178
iteration 8700 : loss : 0.076949, loss_ce: 0.004831
iteration 8701 : loss : 0.022427, loss_ce: 0.008540
iteration 8702 : loss : 0.026515, loss_ce: 0.009796
iteration 8703 : loss : 0.023009, loss_ce: 0.009085
iteration 8704 : loss : 0.024017, loss_ce: 0.008874
iteration 8705 : loss : 0.030042, loss_ce: 0.011105
iteration 8706 : loss : 0.078418, loss_ce: 0.005949
iteration 8707 : loss : 0.022577, loss_ce: 0.006205
iteration 8708 : loss : 0.026242, loss_ce: 0.010291
iteration 8709 : loss : 0.027991, loss_ce: 0.006612
iteration 8710 : loss : 0.032693, loss_ce: 0.011821
iteration 8711 : loss : 0.029254, loss_ce: 0.010487
iteration 8712 : loss : 0.033703, loss_ce: 0.004356
iteration 8713 : loss : 0.028697, loss_ce: 0.004402
iteration 8714 : loss : 0.023370, loss_ce: 0.009063
iteration 8715 : loss : 0.028400, loss_ce: 0.009888
iteration 8716 : loss : 0.028080, loss_ce: 0.005896
iteration 8717 : loss : 0.034298, loss_ce: 0.006506
iteration 8718 : loss : 0.026353, loss_ce: 0.006812
iteration 8719 : loss : 0.027326, loss_ce: 0.009940
iteration 8720 : loss : 0.036128, loss_ce: 0.011934
iteration 8721 : loss : 0.025760, loss_ce: 0.010713
iteration 8722 : loss : 0.031329, loss_ce: 0.010024
iteration 8723 : loss : 0.024364, loss_ce: 0.004424
iteration 8724 : loss : 0.024877, loss_ce: 0.009224
iteration 8725 : loss : 0.028672, loss_ce: 0.008949
iteration 8726 : loss : 0.026650, loss_ce: 0.011191
iteration 8727 : loss : 0.025624, loss_ce: 0.009612
iteration 8728 : loss : 0.034773, loss_ce: 0.011232
iteration 8729 : loss : 0.077316, loss_ce: 0.009108
iteration 8730 : loss : 0.032576, loss_ce: 0.007267
iteration 8731 : loss : 0.027041, loss_ce: 0.010139
iteration 8732 : loss : 0.024765, loss_ce: 0.010076
iteration 8733 : loss : 0.026151, loss_ce: 0.009955
iteration 8734 : loss : 0.044655, loss_ce: 0.008644
iteration 8735 : loss : 0.031961, loss_ce: 0.011490
iteration 8736 : loss : 0.035931, loss_ce: 0.015490
iteration 8737 : loss : 0.022036, loss_ce: 0.007807
iteration 8738 : loss : 0.024516, loss_ce: 0.007463
iteration 8739 : loss : 0.028540, loss_ce: 0.005190
iteration 8740 : loss : 0.025648, loss_ce: 0.006569
iteration 8741 : loss : 0.076089, loss_ce: 0.005970
iteration 8742 : loss : 0.081524, loss_ce: 0.009564
 47%|█████████████▏              | 94/200 [1:36:32<1:48:49, 61.60s/it]iteration 8743 : loss : 0.029905, loss_ce: 0.009595
iteration 8744 : loss : 0.089207, loss_ce: 0.007149
iteration 8745 : loss : 0.026105, loss_ce: 0.007531
iteration 8746 : loss : 0.025743, loss_ce: 0.010374
iteration 8747 : loss : 0.029741, loss_ce: 0.011178
iteration 8748 : loss : 0.081705, loss_ce: 0.004816
iteration 8749 : loss : 0.032154, loss_ce: 0.012179
iteration 8750 : loss : 0.023096, loss_ce: 0.010904
iteration 8751 : loss : 0.033290, loss_ce: 0.011678
iteration 8752 : loss : 0.025462, loss_ce: 0.010075
iteration 8753 : loss : 0.026182, loss_ce: 0.006048
iteration 8754 : loss : 0.027862, loss_ce: 0.012198
iteration 8755 : loss : 0.041851, loss_ce: 0.011340
iteration 8756 : loss : 0.022418, loss_ce: 0.005298
iteration 8757 : loss : 0.024466, loss_ce: 0.008639
iteration 8758 : loss : 0.027150, loss_ce: 0.010118
iteration 8759 : loss : 0.024340, loss_ce: 0.008955
iteration 8760 : loss : 0.073888, loss_ce: 0.008502
iteration 8761 : loss : 0.030160, loss_ce: 0.009881
iteration 8762 : loss : 0.029383, loss_ce: 0.009108
iteration 8763 : loss : 0.026151, loss_ce: 0.006610
iteration 8764 : loss : 0.079717, loss_ce: 0.010751
iteration 8765 : loss : 0.029313, loss_ce: 0.007737
iteration 8766 : loss : 0.025584, loss_ce: 0.007379
iteration 8767 : loss : 0.027963, loss_ce: 0.011502
iteration 8768 : loss : 0.025732, loss_ce: 0.010205
iteration 8769 : loss : 0.027870, loss_ce: 0.009703
iteration 8770 : loss : 0.030696, loss_ce: 0.008839
iteration 8771 : loss : 0.125114, loss_ce: 0.002867
iteration 8772 : loss : 0.036438, loss_ce: 0.009223
iteration 8773 : loss : 0.026295, loss_ce: 0.011834
iteration 8774 : loss : 0.076492, loss_ce: 0.007927
iteration 8775 : loss : 0.022646, loss_ce: 0.006945
iteration 8776 : loss : 0.024800, loss_ce: 0.008162
iteration 8777 : loss : 0.029776, loss_ce: 0.008318
iteration 8778 : loss : 0.029125, loss_ce: 0.009967
iteration 8779 : loss : 0.033324, loss_ce: 0.005729
iteration 8780 : loss : 0.031991, loss_ce: 0.010872
iteration 8781 : loss : 0.037583, loss_ce: 0.009964
iteration 8782 : loss : 0.024324, loss_ce: 0.008976
iteration 8783 : loss : 0.085649, loss_ce: 0.007736
iteration 8784 : loss : 0.027844, loss_ce: 0.006265
iteration 8785 : loss : 0.035541, loss_ce: 0.008999
iteration 8786 : loss : 0.029383, loss_ce: 0.011755
iteration 8787 : loss : 0.073830, loss_ce: 0.013919
iteration 8788 : loss : 0.025919, loss_ce: 0.010137
iteration 8789 : loss : 0.024440, loss_ce: 0.009659
iteration 8790 : loss : 0.028906, loss_ce: 0.011250
iteration 8791 : loss : 0.033527, loss_ce: 0.010971
iteration 8792 : loss : 0.032550, loss_ce: 0.006846
iteration 8793 : loss : 0.026761, loss_ce: 0.008521
iteration 8794 : loss : 0.022913, loss_ce: 0.007007
iteration 8795 : loss : 0.024831, loss_ce: 0.013270
iteration 8796 : loss : 0.029475, loss_ce: 0.012104
iteration 8797 : loss : 0.023529, loss_ce: 0.005523
iteration 8798 : loss : 0.024987, loss_ce: 0.010002
iteration 8799 : loss : 0.025832, loss_ce: 0.005976
iteration 8800 : loss : 0.025544, loss_ce: 0.007708
iteration 8801 : loss : 0.028021, loss_ce: 0.007251
iteration 8802 : loss : 0.033775, loss_ce: 0.011284
iteration 8803 : loss : 0.027153, loss_ce: 0.014080
iteration 8804 : loss : 0.028128, loss_ce: 0.011915
iteration 8805 : loss : 0.024477, loss_ce: 0.007021
iteration 8806 : loss : 0.024841, loss_ce: 0.007508
iteration 8807 : loss : 0.029178, loss_ce: 0.010892
iteration 8808 : loss : 0.027960, loss_ce: 0.013313
iteration 8809 : loss : 0.031020, loss_ce: 0.012855
iteration 8810 : loss : 0.034423, loss_ce: 0.012513
iteration 8811 : loss : 0.023866, loss_ce: 0.007432
iteration 8812 : loss : 0.025534, loss_ce: 0.008679
iteration 8813 : loss : 0.021653, loss_ce: 0.006143
iteration 8814 : loss : 0.024312, loss_ce: 0.010283
iteration 8815 : loss : 0.033748, loss_ce: 0.008949
iteration 8816 : loss : 0.025474, loss_ce: 0.009307
iteration 8817 : loss : 0.025491, loss_ce: 0.006937
iteration 8818 : loss : 0.022832, loss_ce: 0.007174
iteration 8819 : loss : 0.029371, loss_ce: 0.010901
iteration 8820 : loss : 0.036213, loss_ce: 0.010394
iteration 8821 : loss : 0.027169, loss_ce: 0.011903
iteration 8822 : loss : 0.026238, loss_ce: 0.009546
iteration 8823 : loss : 0.026284, loss_ce: 0.008655
iteration 8824 : loss : 0.028202, loss_ce: 0.008947
iteration 8825 : loss : 0.022482, loss_ce: 0.006570
iteration 8826 : loss : 0.026071, loss_ce: 0.008961
iteration 8827 : loss : 0.029478, loss_ce: 0.010941
iteration 8828 : loss : 0.026239, loss_ce: 0.011049
iteration 8829 : loss : 0.033563, loss_ce: 0.009044
iteration 8830 : loss : 0.022056, loss_ce: 0.006125
iteration 8831 : loss : 0.080046, loss_ce: 0.010406
iteration 8832 : loss : 0.037693, loss_ce: 0.010612
iteration 8833 : loss : 0.030708, loss_ce: 0.006907
iteration 8834 : loss : 0.076289, loss_ce: 0.006865
iteration 8835 : loss : 0.244867, loss_ce: 0.026055
 48%|█████████████▎              | 95/200 [1:37:33<1:47:46, 61.59s/it]iteration 8836 : loss : 0.029156, loss_ce: 0.010891
iteration 8837 : loss : 0.027326, loss_ce: 0.011148
iteration 8838 : loss : 0.022112, loss_ce: 0.010267
iteration 8839 : loss : 0.030295, loss_ce: 0.011582
iteration 8840 : loss : 0.027665, loss_ce: 0.011253
iteration 8841 : loss : 0.029918, loss_ce: 0.005706
iteration 8842 : loss : 0.029393, loss_ce: 0.008078
iteration 8843 : loss : 0.023418, loss_ce: 0.009213
iteration 8844 : loss : 0.021157, loss_ce: 0.008713
iteration 8845 : loss : 0.084522, loss_ce: 0.006464
iteration 8846 : loss : 0.025560, loss_ce: 0.007208
iteration 8847 : loss : 0.031011, loss_ce: 0.012097
iteration 8848 : loss : 0.028275, loss_ce: 0.013207
iteration 8849 : loss : 0.025669, loss_ce: 0.005854
iteration 8850 : loss : 0.022768, loss_ce: 0.005690
iteration 8851 : loss : 0.025232, loss_ce: 0.009510
iteration 8852 : loss : 0.028353, loss_ce: 0.012766
iteration 8853 : loss : 0.029209, loss_ce: 0.011343
iteration 8854 : loss : 0.026281, loss_ce: 0.008776
iteration 8855 : loss : 0.029360, loss_ce: 0.010532
iteration 8856 : loss : 0.126035, loss_ce: 0.005309
iteration 8857 : loss : 0.021922, loss_ce: 0.006874
iteration 8858 : loss : 0.025030, loss_ce: 0.010151
iteration 8859 : loss : 0.028276, loss_ce: 0.006170
iteration 8860 : loss : 0.027038, loss_ce: 0.007963
iteration 8861 : loss : 0.025536, loss_ce: 0.008640
iteration 8862 : loss : 0.020742, loss_ce: 0.007262
iteration 8863 : loss : 0.112125, loss_ce: 0.004948
iteration 8864 : loss : 0.026743, loss_ce: 0.009273
iteration 8865 : loss : 0.029624, loss_ce: 0.009181
iteration 8866 : loss : 0.030670, loss_ce: 0.010561
iteration 8867 : loss : 0.027392, loss_ce: 0.010531
iteration 8868 : loss : 0.030898, loss_ce: 0.006226
iteration 8869 : loss : 0.028562, loss_ce: 0.011055
iteration 8870 : loss : 0.027423, loss_ce: 0.006797
iteration 8871 : loss : 0.027072, loss_ce: 0.009404
iteration 8872 : loss : 0.028998, loss_ce: 0.010141
iteration 8873 : loss : 0.035391, loss_ce: 0.011387
iteration 8874 : loss : 0.030038, loss_ce: 0.012560
iteration 8875 : loss : 0.027213, loss_ce: 0.008967
iteration 8876 : loss : 0.027590, loss_ce: 0.012170
iteration 8877 : loss : 0.029632, loss_ce: 0.007952
iteration 8878 : loss : 0.035607, loss_ce: 0.010706
iteration 8879 : loss : 0.030876, loss_ce: 0.013588
iteration 8880 : loss : 0.083365, loss_ce: 0.005902
iteration 8881 : loss : 0.028624, loss_ce: 0.007556
iteration 8882 : loss : 0.024866, loss_ce: 0.011706
iteration 8883 : loss : 0.029860, loss_ce: 0.012337
iteration 8884 : loss : 0.026859, loss_ce: 0.012177
iteration 8885 : loss : 0.031984, loss_ce: 0.010779
iteration 8886 : loss : 0.022535, loss_ce: 0.007315
iteration 8887 : loss : 0.023650, loss_ce: 0.008259
iteration 8888 : loss : 0.032952, loss_ce: 0.012571
iteration 8889 : loss : 0.030819, loss_ce: 0.015935
iteration 8890 : loss : 0.030268, loss_ce: 0.010883
iteration 8891 : loss : 0.027143, loss_ce: 0.007828
iteration 8892 : loss : 0.024882, loss_ce: 0.004977
iteration 8893 : loss : 0.028047, loss_ce: 0.008577
iteration 8894 : loss : 0.027381, loss_ce: 0.008672
iteration 8895 : loss : 0.025287, loss_ce: 0.007527
iteration 8896 : loss : 0.031350, loss_ce: 0.011006
iteration 8897 : loss : 0.025293, loss_ce: 0.009275
iteration 8898 : loss : 0.027018, loss_ce: 0.006013
iteration 8899 : loss : 0.026246, loss_ce: 0.011003
iteration 8900 : loss : 0.032550, loss_ce: 0.015605
iteration 8901 : loss : 0.034021, loss_ce: 0.007211
iteration 8902 : loss : 0.029318, loss_ce: 0.009717
iteration 8903 : loss : 0.031132, loss_ce: 0.009235
iteration 8904 : loss : 0.075195, loss_ce: 0.005616
iteration 8905 : loss : 0.071713, loss_ce: 0.003708
iteration 8906 : loss : 0.029497, loss_ce: 0.007647
iteration 8907 : loss : 0.023974, loss_ce: 0.006394
iteration 8908 : loss : 0.035860, loss_ce: 0.007007
iteration 8909 : loss : 0.028906, loss_ce: 0.008547
iteration 8910 : loss : 0.020836, loss_ce: 0.007966
iteration 8911 : loss : 0.128294, loss_ce: 0.004512
iteration 8912 : loss : 0.027705, loss_ce: 0.012579
iteration 8913 : loss : 0.028725, loss_ce: 0.009275
iteration 8914 : loss : 0.025732, loss_ce: 0.008704
iteration 8915 : loss : 0.025304, loss_ce: 0.008334
iteration 8916 : loss : 0.037435, loss_ce: 0.010344
iteration 8917 : loss : 0.023649, loss_ce: 0.006765
iteration 8918 : loss : 0.027955, loss_ce: 0.011515
iteration 8919 : loss : 0.033693, loss_ce: 0.014769
iteration 8920 : loss : 0.029147, loss_ce: 0.010962
iteration 8921 : loss : 0.036614, loss_ce: 0.012734
iteration 8922 : loss : 0.038109, loss_ce: 0.008711
iteration 8923 : loss : 0.025106, loss_ce: 0.007019
iteration 8924 : loss : 0.067248, loss_ce: 0.008215
iteration 8925 : loss : 0.023423, loss_ce: 0.008940
iteration 8926 : loss : 0.030415, loss_ce: 0.008757
iteration 8927 : loss : 0.021529, loss_ce: 0.008778
iteration 8928 : loss : 0.390584, loss_ce: 0.001137
 48%|█████████████▍              | 96/200 [1:38:35<1:46:46, 61.61s/it]iteration 8929 : loss : 0.026960, loss_ce: 0.010950
iteration 8930 : loss : 0.025974, loss_ce: 0.008265
iteration 8931 : loss : 0.031110, loss_ce: 0.012386
iteration 8932 : loss : 0.029633, loss_ce: 0.011309
iteration 8933 : loss : 0.034621, loss_ce: 0.010227
iteration 8934 : loss : 0.079857, loss_ce: 0.012087
iteration 8935 : loss : 0.030580, loss_ce: 0.011655
iteration 8936 : loss : 0.032243, loss_ce: 0.018070
iteration 8937 : loss : 0.027712, loss_ce: 0.009644
iteration 8938 : loss : 0.028690, loss_ce: 0.012309
iteration 8939 : loss : 0.035876, loss_ce: 0.011129
iteration 8940 : loss : 0.080319, loss_ce: 0.006517
iteration 8941 : loss : 0.027753, loss_ce: 0.005769
iteration 8942 : loss : 0.026723, loss_ce: 0.007476
iteration 8943 : loss : 0.030262, loss_ce: 0.008408
iteration 8944 : loss : 0.126529, loss_ce: 0.004959
iteration 8945 : loss : 0.024534, loss_ce: 0.007080
iteration 8946 : loss : 0.029545, loss_ce: 0.009716
iteration 8947 : loss : 0.028370, loss_ce: 0.013888
iteration 8948 : loss : 0.030560, loss_ce: 0.009526
iteration 8949 : loss : 0.046121, loss_ce: 0.008690
iteration 8950 : loss : 0.029972, loss_ce: 0.008454
iteration 8951 : loss : 0.021306, loss_ce: 0.007323
iteration 8952 : loss : 0.027119, loss_ce: 0.009628
iteration 8953 : loss : 0.067678, loss_ce: 0.005925
iteration 8954 : loss : 0.024082, loss_ce: 0.010307
iteration 8955 : loss : 0.022197, loss_ce: 0.005723
iteration 8956 : loss : 0.027589, loss_ce: 0.009778
iteration 8957 : loss : 0.073359, loss_ce: 0.007185
iteration 8958 : loss : 0.024417, loss_ce: 0.008795
iteration 8959 : loss : 0.021939, loss_ce: 0.008355
iteration 8960 : loss : 0.026033, loss_ce: 0.009372
iteration 8961 : loss : 0.031549, loss_ce: 0.009824
iteration 8962 : loss : 0.029845, loss_ce: 0.010509
iteration 8963 : loss : 0.031911, loss_ce: 0.009496
iteration 8964 : loss : 0.022586, loss_ce: 0.004505
iteration 8965 : loss : 0.030940, loss_ce: 0.010422
iteration 8966 : loss : 0.034627, loss_ce: 0.010315
iteration 8967 : loss : 0.024031, loss_ce: 0.008017
iteration 8968 : loss : 0.033117, loss_ce: 0.010511
iteration 8969 : loss : 0.031506, loss_ce: 0.008737
iteration 8970 : loss : 0.029973, loss_ce: 0.007356
iteration 8971 : loss : 0.033315, loss_ce: 0.011112
iteration 8972 : loss : 0.027041, loss_ce: 0.005682
iteration 8973 : loss : 0.026963, loss_ce: 0.008931
iteration 8974 : loss : 0.025378, loss_ce: 0.007307
iteration 8975 : loss : 0.023544, loss_ce: 0.009387
iteration 8976 : loss : 0.030010, loss_ce: 0.006966
iteration 8977 : loss : 0.026829, loss_ce: 0.007844
iteration 8978 : loss : 0.033520, loss_ce: 0.010460
iteration 8979 : loss : 0.029876, loss_ce: 0.012802
iteration 8980 : loss : 0.022542, loss_ce: 0.007048
iteration 8981 : loss : 0.039522, loss_ce: 0.007176
iteration 8982 : loss : 0.026817, loss_ce: 0.006585
iteration 8983 : loss : 0.024216, loss_ce: 0.007553
iteration 8984 : loss : 0.026274, loss_ce: 0.006795
iteration 8985 : loss : 0.031087, loss_ce: 0.008819
iteration 8986 : loss : 0.021162, loss_ce: 0.004682
iteration 8987 : loss : 0.028808, loss_ce: 0.010708
iteration 8988 : loss : 0.030972, loss_ce: 0.012232
iteration 8989 : loss : 0.030495, loss_ce: 0.005741
iteration 8990 : loss : 0.027938, loss_ce: 0.008125
iteration 8991 : loss : 0.032001, loss_ce: 0.008805
iteration 8992 : loss : 0.030173, loss_ce: 0.010224
iteration 8993 : loss : 0.022300, loss_ce: 0.004632
iteration 8994 : loss : 0.030427, loss_ce: 0.007013
iteration 8995 : loss : 0.024018, loss_ce: 0.007899
iteration 8996 : loss : 0.028989, loss_ce: 0.008916
iteration 8997 : loss : 0.029490, loss_ce: 0.015492
iteration 8998 : loss : 0.026684, loss_ce: 0.006832
iteration 8999 : loss : 0.027366, loss_ce: 0.008504
iteration 9000 : loss : 0.022388, loss_ce: 0.006737
iteration 9001 : loss : 0.030616, loss_ce: 0.013990
iteration 9002 : loss : 0.028568, loss_ce: 0.012100
iteration 9003 : loss : 0.025150, loss_ce: 0.008541
iteration 9004 : loss : 0.025745, loss_ce: 0.007514
iteration 9005 : loss : 0.027090, loss_ce: 0.007803
iteration 9006 : loss : 0.028233, loss_ce: 0.008434
iteration 9007 : loss : 0.025884, loss_ce: 0.009509
iteration 9008 : loss : 0.030518, loss_ce: 0.013883
iteration 9009 : loss : 0.023475, loss_ce: 0.008218
iteration 9010 : loss : 0.026496, loss_ce: 0.010959
iteration 9011 : loss : 0.025486, loss_ce: 0.006308
iteration 9012 : loss : 0.031912, loss_ce: 0.014927
iteration 9013 : loss : 0.025008, loss_ce: 0.008869
iteration 9014 : loss : 0.024520, loss_ce: 0.011909
iteration 9015 : loss : 0.025544, loss_ce: 0.010162
iteration 9016 : loss : 0.026301, loss_ce: 0.012947
iteration 9017 : loss : 0.020469, loss_ce: 0.006959
iteration 9018 : loss : 0.021509, loss_ce: 0.010482
iteration 9019 : loss : 0.026637, loss_ce: 0.008952
iteration 9020 : loss : 0.025611, loss_ce: 0.012108
iteration 9021 : loss : 0.391415, loss_ce: 0.002456
 48%|█████████████▌              | 97/200 [1:39:37<1:45:53, 61.68s/it]iteration 9022 : loss : 0.024818, loss_ce: 0.007713
iteration 9023 : loss : 0.031546, loss_ce: 0.011205
iteration 9024 : loss : 0.025598, loss_ce: 0.008630
iteration 9025 : loss : 0.027753, loss_ce: 0.013663
iteration 9026 : loss : 0.025541, loss_ce: 0.010401
iteration 9027 : loss : 0.026426, loss_ce: 0.013544
iteration 9028 : loss : 0.038946, loss_ce: 0.009069
iteration 9029 : loss : 0.024474, loss_ce: 0.006638
iteration 9030 : loss : 0.027848, loss_ce: 0.008319
iteration 9031 : loss : 0.030228, loss_ce: 0.006025
iteration 9032 : loss : 0.027121, loss_ce: 0.008863
iteration 9033 : loss : 0.028031, loss_ce: 0.012305
iteration 9034 : loss : 0.026614, loss_ce: 0.005929
iteration 9035 : loss : 0.027744, loss_ce: 0.009504
iteration 9036 : loss : 0.031884, loss_ce: 0.009609
iteration 9037 : loss : 0.035633, loss_ce: 0.007773
iteration 9038 : loss : 0.027985, loss_ce: 0.012890
iteration 9039 : loss : 0.026856, loss_ce: 0.010883
iteration 9040 : loss : 0.024715, loss_ce: 0.007537
iteration 9041 : loss : 0.034006, loss_ce: 0.010416
iteration 9042 : loss : 0.021107, loss_ce: 0.004432
iteration 9043 : loss : 0.028165, loss_ce: 0.007706
iteration 9044 : loss : 0.027088, loss_ce: 0.006917
iteration 9045 : loss : 0.028701, loss_ce: 0.009289
iteration 9046 : loss : 0.024818, loss_ce: 0.007773
iteration 9047 : loss : 0.131883, loss_ce: 0.007305
iteration 9048 : loss : 0.027039, loss_ce: 0.008263
iteration 9049 : loss : 0.027686, loss_ce: 0.008362
iteration 9050 : loss : 0.027613, loss_ce: 0.008513
iteration 9051 : loss : 0.021451, loss_ce: 0.008102
iteration 9052 : loss : 0.026491, loss_ce: 0.006697
iteration 9053 : loss : 0.024926, loss_ce: 0.010823
iteration 9054 : loss : 0.025285, loss_ce: 0.008692
iteration 9055 : loss : 0.028123, loss_ce: 0.011082
iteration 9056 : loss : 0.039130, loss_ce: 0.013805
iteration 9057 : loss : 0.024988, loss_ce: 0.010155
iteration 9058 : loss : 0.034293, loss_ce: 0.004184
iteration 9059 : loss : 0.076887, loss_ce: 0.007580
iteration 9060 : loss : 0.029664, loss_ce: 0.014791
iteration 9061 : loss : 0.022566, loss_ce: 0.009287
iteration 9062 : loss : 0.030471, loss_ce: 0.011145
iteration 9063 : loss : 0.022620, loss_ce: 0.008922
iteration 9064 : loss : 0.025813, loss_ce: 0.007964
iteration 9065 : loss : 0.031291, loss_ce: 0.008468
iteration 9066 : loss : 0.025315, loss_ce: 0.007193
iteration 9067 : loss : 0.027494, loss_ce: 0.006348
iteration 9068 : loss : 0.021311, loss_ce: 0.005418
iteration 9069 : loss : 0.077191, loss_ce: 0.007865
iteration 9070 : loss : 0.021811, loss_ce: 0.007462
iteration 9071 : loss : 0.082428, loss_ce: 0.004105
iteration 9072 : loss : 0.076009, loss_ce: 0.005908
iteration 9073 : loss : 0.082285, loss_ce: 0.007485
iteration 9074 : loss : 0.023301, loss_ce: 0.009230
iteration 9075 : loss : 0.036934, loss_ce: 0.007471
iteration 9076 : loss : 0.079327, loss_ce: 0.008251
iteration 9077 : loss : 0.029098, loss_ce: 0.013020
iteration 9078 : loss : 0.028938, loss_ce: 0.010982
iteration 9079 : loss : 0.028294, loss_ce: 0.007539
iteration 9080 : loss : 0.024450, loss_ce: 0.011459
iteration 9081 : loss : 0.030067, loss_ce: 0.009840
iteration 9082 : loss : 0.019810, loss_ce: 0.005336
iteration 9083 : loss : 0.032126, loss_ce: 0.013417
iteration 9084 : loss : 0.027525, loss_ce: 0.006827
iteration 9085 : loss : 0.026230, loss_ce: 0.013191
iteration 9086 : loss : 0.030372, loss_ce: 0.004010
iteration 9087 : loss : 0.027256, loss_ce: 0.014244
iteration 9088 : loss : 0.029053, loss_ce: 0.008285
iteration 9089 : loss : 0.027862, loss_ce: 0.009733
iteration 9090 : loss : 0.030555, loss_ce: 0.010368
iteration 9091 : loss : 0.035962, loss_ce: 0.006096
iteration 9092 : loss : 0.021526, loss_ce: 0.006968
iteration 9093 : loss : 0.025370, loss_ce: 0.006454
iteration 9094 : loss : 0.025303, loss_ce: 0.009542
iteration 9095 : loss : 0.026268, loss_ce: 0.012897
iteration 9096 : loss : 0.040929, loss_ce: 0.015703
iteration 9097 : loss : 0.023028, loss_ce: 0.007489
iteration 9098 : loss : 0.031439, loss_ce: 0.012666
iteration 9099 : loss : 0.028713, loss_ce: 0.009298
iteration 9100 : loss : 0.020011, loss_ce: 0.005813
iteration 9101 : loss : 0.031154, loss_ce: 0.006151
iteration 9102 : loss : 0.024047, loss_ce: 0.009933
iteration 9103 : loss : 0.026617, loss_ce: 0.009332
iteration 9104 : loss : 0.025016, loss_ce: 0.006565
iteration 9105 : loss : 0.024656, loss_ce: 0.010760
iteration 9106 : loss : 0.029773, loss_ce: 0.007460
iteration 9107 : loss : 0.029991, loss_ce: 0.012824
iteration 9108 : loss : 0.023960, loss_ce: 0.012694
iteration 9109 : loss : 0.083119, loss_ce: 0.008101
iteration 9110 : loss : 0.027993, loss_ce: 0.010348
iteration 9111 : loss : 0.024043, loss_ce: 0.009083
iteration 9112 : loss : 0.031668, loss_ce: 0.010127
iteration 9113 : loss : 0.022555, loss_ce: 0.007866
iteration 9114 : loss : 0.080775, loss_ce: 0.010016
 49%|█████████████▋              | 98/200 [1:40:38<1:44:49, 61.66s/it]iteration 9115 : loss : 0.024244, loss_ce: 0.009137
iteration 9116 : loss : 0.029763, loss_ce: 0.010255
iteration 9117 : loss : 0.035085, loss_ce: 0.008075
iteration 9118 : loss : 0.027136, loss_ce: 0.009662
iteration 9119 : loss : 0.025594, loss_ce: 0.010471
iteration 9120 : loss : 0.025950, loss_ce: 0.009194
iteration 9121 : loss : 0.023825, loss_ce: 0.009083
iteration 9122 : loss : 0.025106, loss_ce: 0.011871
iteration 9123 : loss : 0.026571, loss_ce: 0.008680
iteration 9124 : loss : 0.027532, loss_ce: 0.013278
iteration 9125 : loss : 0.026280, loss_ce: 0.008058
iteration 9126 : loss : 0.027300, loss_ce: 0.010461
iteration 9127 : loss : 0.077478, loss_ce: 0.007330
iteration 9128 : loss : 0.021486, loss_ce: 0.007304
iteration 9129 : loss : 0.028213, loss_ce: 0.012122
iteration 9130 : loss : 0.026353, loss_ce: 0.011789
iteration 9131 : loss : 0.023650, loss_ce: 0.008989
iteration 9132 : loss : 0.026431, loss_ce: 0.008294
iteration 9133 : loss : 0.094530, loss_ce: 0.006623
iteration 9134 : loss : 0.073812, loss_ce: 0.004627
iteration 9135 : loss : 0.028067, loss_ce: 0.008022
iteration 9136 : loss : 0.027190, loss_ce: 0.011997
iteration 9137 : loss : 0.027251, loss_ce: 0.008132
iteration 9138 : loss : 0.023580, loss_ce: 0.008696
iteration 9139 : loss : 0.030588, loss_ce: 0.013299
iteration 9140 : loss : 0.025533, loss_ce: 0.007181
iteration 9141 : loss : 0.033311, loss_ce: 0.012490
iteration 9142 : loss : 0.027161, loss_ce: 0.006342
iteration 9143 : loss : 0.029487, loss_ce: 0.011720
iteration 9144 : loss : 0.020675, loss_ce: 0.005666
iteration 9145 : loss : 0.024287, loss_ce: 0.006735
iteration 9146 : loss : 0.028929, loss_ce: 0.007583
iteration 9147 : loss : 0.023850, loss_ce: 0.007225
iteration 9148 : loss : 0.022994, loss_ce: 0.009427
iteration 9149 : loss : 0.037530, loss_ce: 0.009437
iteration 9150 : loss : 0.026722, loss_ce: 0.010980
iteration 9151 : loss : 0.021830, loss_ce: 0.007338
iteration 9152 : loss : 0.031467, loss_ce: 0.007660
iteration 9153 : loss : 0.028279, loss_ce: 0.010302
iteration 9154 : loss : 0.026224, loss_ce: 0.007383
iteration 9155 : loss : 0.025724, loss_ce: 0.007711
iteration 9156 : loss : 0.024064, loss_ce: 0.010255
iteration 9157 : loss : 0.031134, loss_ce: 0.009366
iteration 9158 : loss : 0.026398, loss_ce: 0.012861
iteration 9159 : loss : 0.072083, loss_ce: 0.006181
iteration 9160 : loss : 0.028983, loss_ce: 0.011889
iteration 9161 : loss : 0.027012, loss_ce: 0.010095
iteration 9162 : loss : 0.021593, loss_ce: 0.004042
iteration 9163 : loss : 0.025288, loss_ce: 0.006832
iteration 9164 : loss : 0.021476, loss_ce: 0.009411
iteration 9165 : loss : 0.027526, loss_ce: 0.007130
iteration 9166 : loss : 0.033232, loss_ce: 0.006335
iteration 9167 : loss : 0.026327, loss_ce: 0.008177
iteration 9168 : loss : 0.024158, loss_ce: 0.006338
iteration 9169 : loss : 0.090640, loss_ce: 0.009298
iteration 9170 : loss : 0.024776, loss_ce: 0.006480
iteration 9171 : loss : 0.022540, loss_ce: 0.007937
iteration 9172 : loss : 0.021969, loss_ce: 0.008773
iteration 9173 : loss : 0.022955, loss_ce: 0.008228
iteration 9174 : loss : 0.023728, loss_ce: 0.006271
iteration 9175 : loss : 0.026363, loss_ce: 0.010611
iteration 9176 : loss : 0.026029, loss_ce: 0.009945
iteration 9177 : loss : 0.030298, loss_ce: 0.010891
iteration 9178 : loss : 0.022459, loss_ce: 0.007830
iteration 9179 : loss : 0.030325, loss_ce: 0.012698
iteration 9180 : loss : 0.030527, loss_ce: 0.010782
iteration 9181 : loss : 0.025042, loss_ce: 0.004458
iteration 9182 : loss : 0.022797, loss_ce: 0.007463
iteration 9183 : loss : 0.031795, loss_ce: 0.010860
iteration 9184 : loss : 0.026397, loss_ce: 0.008377
iteration 9185 : loss : 0.026582, loss_ce: 0.013462
iteration 9186 : loss : 0.027927, loss_ce: 0.009903
iteration 9187 : loss : 0.024874, loss_ce: 0.008819
iteration 9188 : loss : 0.080019, loss_ce: 0.007011
iteration 9189 : loss : 0.027314, loss_ce: 0.011384
iteration 9190 : loss : 0.029211, loss_ce: 0.007449
iteration 9191 : loss : 0.029613, loss_ce: 0.008241
iteration 9192 : loss : 0.025207, loss_ce: 0.008482
iteration 9193 : loss : 0.029514, loss_ce: 0.012248
iteration 9194 : loss : 0.030310, loss_ce: 0.007108
iteration 9195 : loss : 0.025056, loss_ce: 0.009106
iteration 9196 : loss : 0.028613, loss_ce: 0.009159
iteration 9197 : loss : 0.021404, loss_ce: 0.007426
iteration 9198 : loss : 0.075253, loss_ce: 0.005453
iteration 9199 : loss : 0.030851, loss_ce: 0.012450
iteration 9200 : loss : 0.029186, loss_ce: 0.015430
iteration 9201 : loss : 0.030818, loss_ce: 0.005884
iteration 9202 : loss : 0.024426, loss_ce: 0.009478
iteration 9203 : loss : 0.024356, loss_ce: 0.006845
iteration 9204 : loss : 0.029486, loss_ce: 0.009689
iteration 9205 : loss : 0.026300, loss_ce: 0.007878
iteration 9206 : loss : 0.023678, loss_ce: 0.006476
iteration 9207 : loss : 0.187288, loss_ce: 0.020841
 50%|█████████████▊              | 99/200 [1:41:40<1:43:45, 61.64s/it]iteration 9208 : loss : 0.036204, loss_ce: 0.008269
iteration 9209 : loss : 0.026181, loss_ce: 0.010675
iteration 9210 : loss : 0.023354, loss_ce: 0.009169
iteration 9211 : loss : 0.133551, loss_ce: 0.007105
iteration 9212 : loss : 0.026829, loss_ce: 0.011248
iteration 9213 : loss : 0.025849, loss_ce: 0.008694
iteration 9214 : loss : 0.027251, loss_ce: 0.010640
iteration 9215 : loss : 0.030131, loss_ce: 0.014309
iteration 9216 : loss : 0.025052, loss_ce: 0.011144
iteration 9217 : loss : 0.024276, loss_ce: 0.012463
iteration 9218 : loss : 0.031886, loss_ce: 0.010681
iteration 9219 : loss : 0.080661, loss_ce: 0.008168
iteration 9220 : loss : 0.028809, loss_ce: 0.011778
iteration 9221 : loss : 0.029231, loss_ce: 0.008116
iteration 9222 : loss : 0.031966, loss_ce: 0.010387
iteration 9223 : loss : 0.022693, loss_ce: 0.006146
iteration 9224 : loss : 0.025741, loss_ce: 0.009535
iteration 9225 : loss : 0.032554, loss_ce: 0.009412
iteration 9226 : loss : 0.022992, loss_ce: 0.008866
iteration 9227 : loss : 0.021737, loss_ce: 0.009427
iteration 9228 : loss : 0.023003, loss_ce: 0.008035
iteration 9229 : loss : 0.024167, loss_ce: 0.008548
iteration 9230 : loss : 0.077052, loss_ce: 0.007768
iteration 9231 : loss : 0.031609, loss_ce: 0.012775
iteration 9232 : loss : 0.025098, loss_ce: 0.010814
iteration 9233 : loss : 0.021701, loss_ce: 0.007450
iteration 9234 : loss : 0.021432, loss_ce: 0.007861
iteration 9235 : loss : 0.028342, loss_ce: 0.009097
iteration 9236 : loss : 0.023774, loss_ce: 0.009521
iteration 9237 : loss : 0.077579, loss_ce: 0.009973
iteration 9238 : loss : 0.022341, loss_ce: 0.008040
iteration 9239 : loss : 0.076824, loss_ce: 0.006034
iteration 9240 : loss : 0.024440, loss_ce: 0.005838
iteration 9241 : loss : 0.020171, loss_ce: 0.008106
iteration 9242 : loss : 0.028840, loss_ce: 0.009166
iteration 9243 : loss : 0.022848, loss_ce: 0.007967
iteration 9244 : loss : 0.028579, loss_ce: 0.008330
iteration 9245 : loss : 0.029535, loss_ce: 0.011944
iteration 9246 : loss : 0.023278, loss_ce: 0.005715
iteration 9247 : loss : 0.021744, loss_ce: 0.010982
iteration 9248 : loss : 0.026873, loss_ce: 0.009512
iteration 9249 : loss : 0.078594, loss_ce: 0.003985
iteration 9250 : loss : 0.068738, loss_ce: 0.002488
iteration 9251 : loss : 0.021971, loss_ce: 0.007747
iteration 9252 : loss : 0.029085, loss_ce: 0.010559
iteration 9253 : loss : 0.077292, loss_ce: 0.011435
iteration 9254 : loss : 0.029276, loss_ce: 0.007846
iteration 9255 : loss : 0.021899, loss_ce: 0.007103
iteration 9256 : loss : 0.072489, loss_ce: 0.007794
iteration 9257 : loss : 0.026169, loss_ce: 0.011688
iteration 9258 : loss : 0.028597, loss_ce: 0.010988
iteration 9259 : loss : 0.030188, loss_ce: 0.013298
iteration 9260 : loss : 0.024991, loss_ce: 0.010932
iteration 9261 : loss : 0.022802, loss_ce: 0.007990
iteration 9262 : loss : 0.024954, loss_ce: 0.009721
iteration 9263 : loss : 0.026172, loss_ce: 0.008758
iteration 9264 : loss : 0.029123, loss_ce: 0.010508
iteration 9265 : loss : 0.031808, loss_ce: 0.007639
iteration 9266 : loss : 0.026884, loss_ce: 0.013611
iteration 9267 : loss : 0.029154, loss_ce: 0.009730
iteration 9268 : loss : 0.020123, loss_ce: 0.009159
iteration 9269 : loss : 0.027963, loss_ce: 0.009574
iteration 9270 : loss : 0.028212, loss_ce: 0.008932
iteration 9271 : loss : 0.031080, loss_ce: 0.015752
iteration 9272 : loss : 0.075541, loss_ce: 0.008186
iteration 9273 : loss : 0.018917, loss_ce: 0.005671
iteration 9274 : loss : 0.027569, loss_ce: 0.009633
iteration 9275 : loss : 0.079631, loss_ce: 0.005153
iteration 9276 : loss : 0.019402, loss_ce: 0.004637
iteration 9277 : loss : 0.028556, loss_ce: 0.007733
iteration 9278 : loss : 0.024886, loss_ce: 0.013438
iteration 9279 : loss : 0.023302, loss_ce: 0.010557
iteration 9280 : loss : 0.022075, loss_ce: 0.003827
iteration 9281 : loss : 0.026873, loss_ce: 0.010640
iteration 9282 : loss : 0.023235, loss_ce: 0.007569
iteration 9283 : loss : 0.023454, loss_ce: 0.006286
iteration 9284 : loss : 0.023764, loss_ce: 0.005124
iteration 9285 : loss : 0.041022, loss_ce: 0.005479
iteration 9286 : loss : 0.031559, loss_ce: 0.009649
iteration 9287 : loss : 0.027864, loss_ce: 0.008082
iteration 9288 : loss : 0.077797, loss_ce: 0.007187
iteration 9289 : loss : 0.025888, loss_ce: 0.008623
iteration 9290 : loss : 0.032747, loss_ce: 0.007317
iteration 9291 : loss : 0.074435, loss_ce: 0.005106
iteration 9292 : loss : 0.024143, loss_ce: 0.007198
iteration 9293 : loss : 0.026051, loss_ce: 0.009498
iteration 9294 : loss : 0.082495, loss_ce: 0.007887
iteration 9295 : loss : 0.025208, loss_ce: 0.007235
iteration 9296 : loss : 0.041755, loss_ce: 0.008627
iteration 9297 : loss : 0.031052, loss_ce: 0.010287
iteration 9298 : loss : 0.024623, loss_ce: 0.009794
iteration 9299 : loss : 0.035027, loss_ce: 0.007827
iteration 9300 : loss : 0.157429, loss_ce: 0.007321
 50%|█████████████▌             | 100/200 [1:42:41<1:42:43, 61.63s/it]iteration 9301 : loss : 0.033866, loss_ce: 0.010557
iteration 9302 : loss : 0.034093, loss_ce: 0.008686
iteration 9303 : loss : 0.027289, loss_ce: 0.010799
iteration 9304 : loss : 0.027187, loss_ce: 0.010099
iteration 9305 : loss : 0.027087, loss_ce: 0.011077
iteration 9306 : loss : 0.028779, loss_ce: 0.012809
iteration 9307 : loss : 0.030882, loss_ce: 0.008079
iteration 9308 : loss : 0.038251, loss_ce: 0.009639
iteration 9309 : loss : 0.029460, loss_ce: 0.009871
iteration 9310 : loss : 0.024443, loss_ce: 0.007585
iteration 9311 : loss : 0.034879, loss_ce: 0.009371
iteration 9312 : loss : 0.034527, loss_ce: 0.011945
iteration 9313 : loss : 0.076673, loss_ce: 0.006361
iteration 9314 : loss : 0.034633, loss_ce: 0.010533
iteration 9315 : loss : 0.059491, loss_ce: 0.007569
iteration 9316 : loss : 0.027184, loss_ce: 0.009529
iteration 9317 : loss : 0.027242, loss_ce: 0.009039
iteration 9318 : loss : 0.033082, loss_ce: 0.015451
iteration 9319 : loss : 0.026790, loss_ce: 0.008344
iteration 9320 : loss : 0.028300, loss_ce: 0.011968
iteration 9321 : loss : 0.030054, loss_ce: 0.012979
iteration 9322 : loss : 0.025939, loss_ce: 0.007657
iteration 9323 : loss : 0.032688, loss_ce: 0.008125
iteration 9324 : loss : 0.027254, loss_ce: 0.008799
iteration 9325 : loss : 0.029095, loss_ce: 0.008748
iteration 9326 : loss : 0.025321, loss_ce: 0.010086
iteration 9327 : loss : 0.027245, loss_ce: 0.009978
iteration 9328 : loss : 0.026171, loss_ce: 0.013309
iteration 9329 : loss : 0.026289, loss_ce: 0.010059
iteration 9330 : loss : 0.032233, loss_ce: 0.007532
iteration 9331 : loss : 0.026848, loss_ce: 0.007834
iteration 9332 : loss : 0.034781, loss_ce: 0.007030
iteration 9333 : loss : 0.027393, loss_ce: 0.010549
iteration 9334 : loss : 0.027673, loss_ce: 0.009288
iteration 9335 : loss : 0.025619, loss_ce: 0.010692
iteration 9336 : loss : 0.034724, loss_ce: 0.009029
iteration 9337 : loss : 0.077825, loss_ce: 0.005209
iteration 9338 : loss : 0.034397, loss_ce: 0.008939
iteration 9339 : loss : 0.031857, loss_ce: 0.011406
iteration 9340 : loss : 0.082091, loss_ce: 0.008533
iteration 9341 : loss : 0.024791, loss_ce: 0.009778
iteration 9342 : loss : 0.027539, loss_ce: 0.010694
iteration 9343 : loss : 0.077348, loss_ce: 0.010664
iteration 9344 : loss : 0.026558, loss_ce: 0.005953
iteration 9345 : loss : 0.024934, loss_ce: 0.006323
iteration 9346 : loss : 0.027669, loss_ce: 0.008929
iteration 9347 : loss : 0.027341, loss_ce: 0.007967
iteration 9348 : loss : 0.025621, loss_ce: 0.010090
iteration 9349 : loss : 0.025222, loss_ce: 0.011207
iteration 9350 : loss : 0.028357, loss_ce: 0.011129
iteration 9351 : loss : 0.037433, loss_ce: 0.021028
iteration 9352 : loss : 0.028203, loss_ce: 0.011198
iteration 9353 : loss : 0.027581, loss_ce: 0.009231
iteration 9354 : loss : 0.024378, loss_ce: 0.009182
iteration 9355 : loss : 0.022954, loss_ce: 0.007333
iteration 9356 : loss : 0.029418, loss_ce: 0.010445
iteration 9357 : loss : 0.022871, loss_ce: 0.004868
iteration 9358 : loss : 0.021187, loss_ce: 0.007466
iteration 9359 : loss : 0.023528, loss_ce: 0.011372
iteration 9360 : loss : 0.025048, loss_ce: 0.008573
iteration 9361 : loss : 0.080820, loss_ce: 0.008069
iteration 9362 : loss : 0.047134, loss_ce: 0.006678
iteration 9363 : loss : 0.031681, loss_ce: 0.011231
iteration 9364 : loss : 0.031475, loss_ce: 0.014601
iteration 9365 : loss : 0.026194, loss_ce: 0.012570
iteration 9366 : loss : 0.031547, loss_ce: 0.010109
iteration 9367 : loss : 0.035457, loss_ce: 0.007029
iteration 9368 : loss : 0.025163, loss_ce: 0.012675
iteration 9369 : loss : 0.025469, loss_ce: 0.010820
iteration 9370 : loss : 0.029001, loss_ce: 0.007845
iteration 9371 : loss : 0.028557, loss_ce: 0.005560
iteration 9372 : loss : 0.026490, loss_ce: 0.008337
iteration 9373 : loss : 0.040675, loss_ce: 0.004782
iteration 9374 : loss : 0.030367, loss_ce: 0.010150
iteration 9375 : loss : 0.025578, loss_ce: 0.008466
iteration 9376 : loss : 0.027150, loss_ce: 0.007576
iteration 9377 : loss : 0.033338, loss_ce: 0.007878
iteration 9378 : loss : 0.130480, loss_ce: 0.005834
iteration 9379 : loss : 0.028373, loss_ce: 0.011566
iteration 9380 : loss : 0.027280, loss_ce: 0.008037
iteration 9381 : loss : 0.025146, loss_ce: 0.009272
iteration 9382 : loss : 0.027864, loss_ce: 0.006600
iteration 9383 : loss : 0.027271, loss_ce: 0.005395
iteration 9384 : loss : 0.031522, loss_ce: 0.013329
iteration 9385 : loss : 0.028646, loss_ce: 0.008945
iteration 9386 : loss : 0.030926, loss_ce: 0.011875
iteration 9387 : loss : 0.029273, loss_ce: 0.010070
iteration 9388 : loss : 0.025071, loss_ce: 0.009608
iteration 9389 : loss : 0.134572, loss_ce: 0.002717
iteration 9390 : loss : 0.030116, loss_ce: 0.008525
iteration 9391 : loss : 0.024675, loss_ce: 0.011184
iteration 9392 : loss : 0.073534, loss_ce: 0.004995
iteration 9393 : loss : 0.237958, loss_ce: 0.010959
 50%|█████████████▋             | 101/200 [1:43:43<1:41:40, 61.62s/it]iteration 9394 : loss : 0.024023, loss_ce: 0.011233
iteration 9395 : loss : 0.042215, loss_ce: 0.006539
iteration 9396 : loss : 0.031821, loss_ce: 0.011310
iteration 9397 : loss : 0.026346, loss_ce: 0.009742
iteration 9398 : loss : 0.027411, loss_ce: 0.012709
iteration 9399 : loss : 0.029194, loss_ce: 0.010335
iteration 9400 : loss : 0.031784, loss_ce: 0.007508
iteration 9401 : loss : 0.028311, loss_ce: 0.005981
iteration 9402 : loss : 0.029060, loss_ce: 0.007611
iteration 9403 : loss : 0.075249, loss_ce: 0.005536
iteration 9404 : loss : 0.023617, loss_ce: 0.011867
iteration 9405 : loss : 0.074528, loss_ce: 0.006017
iteration 9406 : loss : 0.029947, loss_ce: 0.007909
iteration 9407 : loss : 0.025222, loss_ce: 0.010089
iteration 9408 : loss : 0.026324, loss_ce: 0.008980
iteration 9409 : loss : 0.076006, loss_ce: 0.007815
iteration 9410 : loss : 0.023935, loss_ce: 0.005799
iteration 9411 : loss : 0.023432, loss_ce: 0.009638
iteration 9412 : loss : 0.022051, loss_ce: 0.009458
iteration 9413 : loss : 0.025193, loss_ce: 0.011580
iteration 9414 : loss : 0.023638, loss_ce: 0.007559
iteration 9415 : loss : 0.023211, loss_ce: 0.005747
iteration 9416 : loss : 0.028729, loss_ce: 0.013874
iteration 9417 : loss : 0.027028, loss_ce: 0.015198
iteration 9418 : loss : 0.022566, loss_ce: 0.010546
iteration 9419 : loss : 0.035370, loss_ce: 0.011602
iteration 9420 : loss : 0.029666, loss_ce: 0.008203
iteration 9421 : loss : 0.026827, loss_ce: 0.011252
iteration 9422 : loss : 0.027375, loss_ce: 0.014013
iteration 9423 : loss : 0.035600, loss_ce: 0.010570
iteration 9424 : loss : 0.024696, loss_ce: 0.011661
iteration 9425 : loss : 0.024542, loss_ce: 0.009722
iteration 9426 : loss : 0.023454, loss_ce: 0.010159
iteration 9427 : loss : 0.025776, loss_ce: 0.012295
iteration 9428 : loss : 0.076530, loss_ce: 0.006297
iteration 9429 : loss : 0.023460, loss_ce: 0.004008
iteration 9430 : loss : 0.021564, loss_ce: 0.008201
iteration 9431 : loss : 0.020449, loss_ce: 0.008412
iteration 9432 : loss : 0.027180, loss_ce: 0.011284
iteration 9433 : loss : 0.024340, loss_ce: 0.009344
iteration 9434 : loss : 0.079040, loss_ce: 0.009830
iteration 9435 : loss : 0.023480, loss_ce: 0.010023
iteration 9436 : loss : 0.026532, loss_ce: 0.003895
iteration 9437 : loss : 0.038914, loss_ce: 0.005792
iteration 9438 : loss : 0.023492, loss_ce: 0.010208
iteration 9439 : loss : 0.027740, loss_ce: 0.007168
iteration 9440 : loss : 0.028453, loss_ce: 0.009083
iteration 9441 : loss : 0.022054, loss_ce: 0.008139
iteration 9442 : loss : 0.045000, loss_ce: 0.007677
iteration 9443 : loss : 0.033795, loss_ce: 0.008967
iteration 9444 : loss : 0.030194, loss_ce: 0.007220
iteration 9445 : loss : 0.051149, loss_ce: 0.008667
iteration 9446 : loss : 0.034509, loss_ce: 0.009768
iteration 9447 : loss : 0.030523, loss_ce: 0.012126
iteration 9448 : loss : 0.021985, loss_ce: 0.008808
iteration 9449 : loss : 0.026068, loss_ce: 0.006002
iteration 9450 : loss : 0.028773, loss_ce: 0.010760
iteration 9451 : loss : 0.031715, loss_ce: 0.008919
iteration 9452 : loss : 0.022061, loss_ce: 0.008593
iteration 9453 : loss : 0.028097, loss_ce: 0.005840
iteration 9454 : loss : 0.034020, loss_ce: 0.010491
iteration 9455 : loss : 0.034201, loss_ce: 0.008594
iteration 9456 : loss : 0.077149, loss_ce: 0.006084
iteration 9457 : loss : 0.027290, loss_ce: 0.007832
iteration 9458 : loss : 0.080260, loss_ce: 0.007504
iteration 9459 : loss : 0.034978, loss_ce: 0.009783
iteration 9460 : loss : 0.076978, loss_ce: 0.006657
iteration 9461 : loss : 0.078803, loss_ce: 0.006812
iteration 9462 : loss : 0.030135, loss_ce: 0.004323
iteration 9463 : loss : 0.032585, loss_ce: 0.008286
iteration 9464 : loss : 0.028504, loss_ce: 0.011323
iteration 9465 : loss : 0.034614, loss_ce: 0.012335
iteration 9466 : loss : 0.032324, loss_ce: 0.016768
iteration 9467 : loss : 0.087190, loss_ce: 0.008663
iteration 9468 : loss : 0.023251, loss_ce: 0.007586
iteration 9469 : loss : 0.029609, loss_ce: 0.011258
iteration 9470 : loss : 0.028678, loss_ce: 0.005831
iteration 9471 : loss : 0.026563, loss_ce: 0.007578
iteration 9472 : loss : 0.023053, loss_ce: 0.007455
iteration 9473 : loss : 0.031415, loss_ce: 0.010306
iteration 9474 : loss : 0.029298, loss_ce: 0.007397
iteration 9475 : loss : 0.021062, loss_ce: 0.004731
iteration 9476 : loss : 0.033137, loss_ce: 0.014937
iteration 9477 : loss : 0.041081, loss_ce: 0.007166
iteration 9478 : loss : 0.031031, loss_ce: 0.007006
iteration 9479 : loss : 0.021743, loss_ce: 0.006268
iteration 9480 : loss : 0.029440, loss_ce: 0.010661
iteration 9481 : loss : 0.020231, loss_ce: 0.006688
iteration 9482 : loss : 0.030858, loss_ce: 0.010926
iteration 9483 : loss : 0.027060, loss_ce: 0.008571
iteration 9484 : loss : 0.027301, loss_ce: 0.012752
iteration 9485 : loss : 0.026946, loss_ce: 0.011444
iteration 9486 : loss : 0.336206, loss_ce: 0.001313
 51%|█████████████▊             | 102/200 [1:44:45<1:40:42, 61.66s/it]iteration 9487 : loss : 0.074216, loss_ce: 0.008498
iteration 9488 : loss : 0.075616, loss_ce: 0.007205
iteration 9489 : loss : 0.029549, loss_ce: 0.009782
iteration 9490 : loss : 0.028172, loss_ce: 0.012035
iteration 9491 : loss : 0.036615, loss_ce: 0.009779
iteration 9492 : loss : 0.025481, loss_ce: 0.008330
iteration 9493 : loss : 0.076044, loss_ce: 0.009076
iteration 9494 : loss : 0.027254, loss_ce: 0.012383
iteration 9495 : loss : 0.021993, loss_ce: 0.004747
iteration 9496 : loss : 0.024404, loss_ce: 0.010895
iteration 9497 : loss : 0.075679, loss_ce: 0.006859
iteration 9498 : loss : 0.024229, loss_ce: 0.007965
iteration 9499 : loss : 0.027789, loss_ce: 0.007692
iteration 9500 : loss : 0.042848, loss_ce: 0.012255
iteration 9501 : loss : 0.029402, loss_ce: 0.011225
iteration 9502 : loss : 0.024996, loss_ce: 0.008403
iteration 9503 : loss : 0.019921, loss_ce: 0.004973
iteration 9504 : loss : 0.126418, loss_ce: 0.008519
iteration 9505 : loss : 0.023036, loss_ce: 0.007577
iteration 9506 : loss : 0.024882, loss_ce: 0.009326
iteration 9507 : loss : 0.025820, loss_ce: 0.007809
iteration 9508 : loss : 0.029229, loss_ce: 0.010679
iteration 9509 : loss : 0.024540, loss_ce: 0.007593
iteration 9510 : loss : 0.029801, loss_ce: 0.011378
iteration 9511 : loss : 0.032754, loss_ce: 0.014483
iteration 9512 : loss : 0.026400, loss_ce: 0.011328
iteration 9513 : loss : 0.019865, loss_ce: 0.003701
iteration 9514 : loss : 0.039584, loss_ce: 0.005083
iteration 9515 : loss : 0.023674, loss_ce: 0.006176
iteration 9516 : loss : 0.025938, loss_ce: 0.008098
iteration 9517 : loss : 0.026581, loss_ce: 0.005968
iteration 9518 : loss : 0.031213, loss_ce: 0.015982
iteration 9519 : loss : 0.024571, loss_ce: 0.005899
iteration 9520 : loss : 0.024961, loss_ce: 0.007914
iteration 9521 : loss : 0.085459, loss_ce: 0.010749
iteration 9522 : loss : 0.027596, loss_ce: 0.010027
iteration 9523 : loss : 0.028996, loss_ce: 0.008784
iteration 9524 : loss : 0.026650, loss_ce: 0.009216
iteration 9525 : loss : 0.024801, loss_ce: 0.007158
iteration 9526 : loss : 0.026178, loss_ce: 0.009490
iteration 9527 : loss : 0.022987, loss_ce: 0.008973
iteration 9528 : loss : 0.022842, loss_ce: 0.008193
iteration 9529 : loss : 0.035336, loss_ce: 0.016175
iteration 9530 : loss : 0.028033, loss_ce: 0.009302
iteration 9531 : loss : 0.023787, loss_ce: 0.005812
iteration 9532 : loss : 0.024596, loss_ce: 0.009143
iteration 9533 : loss : 0.023886, loss_ce: 0.007573
iteration 9534 : loss : 0.032612, loss_ce: 0.011667
iteration 9535 : loss : 0.031861, loss_ce: 0.010996
iteration 9536 : loss : 0.039623, loss_ce: 0.013862
iteration 9537 : loss : 0.029213, loss_ce: 0.009373
iteration 9538 : loss : 0.024487, loss_ce: 0.012508
iteration 9539 : loss : 0.029264, loss_ce: 0.011101
iteration 9540 : loss : 0.026587, loss_ce: 0.010494
iteration 9541 : loss : 0.025825, loss_ce: 0.011473
iteration 9542 : loss : 0.030519, loss_ce: 0.004496
iteration 9543 : loss : 0.028746, loss_ce: 0.011367
iteration 9544 : loss : 0.024236, loss_ce: 0.009157
iteration 9545 : loss : 0.028195, loss_ce: 0.006128
iteration 9546 : loss : 0.024906, loss_ce: 0.009553
iteration 9547 : loss : 0.037020, loss_ce: 0.009462
iteration 9548 : loss : 0.024414, loss_ce: 0.008779
iteration 9549 : loss : 0.024662, loss_ce: 0.010276
iteration 9550 : loss : 0.032834, loss_ce: 0.007372
iteration 9551 : loss : 0.026092, loss_ce: 0.009852
iteration 9552 : loss : 0.075048, loss_ce: 0.005328
iteration 9553 : loss : 0.030842, loss_ce: 0.014036
iteration 9554 : loss : 0.030684, loss_ce: 0.013752
iteration 9555 : loss : 0.020992, loss_ce: 0.007047
iteration 9556 : loss : 0.025525, loss_ce: 0.009968
iteration 9557 : loss : 0.023534, loss_ce: 0.006762
iteration 9558 : loss : 0.025134, loss_ce: 0.009436
iteration 9559 : loss : 0.026135, loss_ce: 0.008222
iteration 9560 : loss : 0.032190, loss_ce: 0.005226
iteration 9561 : loss : 0.079539, loss_ce: 0.003785
iteration 9562 : loss : 0.073113, loss_ce: 0.004757
iteration 9563 : loss : 0.025673, loss_ce: 0.006056
iteration 9564 : loss : 0.028129, loss_ce: 0.010170
iteration 9565 : loss : 0.027185, loss_ce: 0.011042
iteration 9566 : loss : 0.081609, loss_ce: 0.005637
iteration 9567 : loss : 0.025468, loss_ce: 0.010882
iteration 9568 : loss : 0.073051, loss_ce: 0.006383
iteration 9569 : loss : 0.025543, loss_ce: 0.013080
iteration 9570 : loss : 0.024558, loss_ce: 0.006798
iteration 9571 : loss : 0.032155, loss_ce: 0.009884
iteration 9572 : loss : 0.027360, loss_ce: 0.008296
iteration 9573 : loss : 0.020962, loss_ce: 0.008376
iteration 9574 : loss : 0.024830, loss_ce: 0.009441
iteration 9575 : loss : 0.028832, loss_ce: 0.010548
iteration 9576 : loss : 0.024823, loss_ce: 0.005816
iteration 9577 : loss : 0.026385, loss_ce: 0.010898
iteration 9578 : loss : 0.026514, loss_ce: 0.008556
iteration 9579 : loss : 0.236703, loss_ce: 0.009760
 52%|█████████████▉             | 103/200 [1:45:47<1:39:42, 61.68s/it]iteration 9580 : loss : 0.045043, loss_ce: 0.011447
iteration 9581 : loss : 0.027522, loss_ce: 0.016659
iteration 9582 : loss : 0.037706, loss_ce: 0.009942
iteration 9583 : loss : 0.032825, loss_ce: 0.007535
iteration 9584 : loss : 0.027833, loss_ce: 0.014356
iteration 9585 : loss : 0.023011, loss_ce: 0.007606
iteration 9586 : loss : 0.023315, loss_ce: 0.008188
iteration 9587 : loss : 0.073252, loss_ce: 0.005813
iteration 9588 : loss : 0.025769, loss_ce: 0.010341
iteration 9589 : loss : 0.023089, loss_ce: 0.006983
iteration 9590 : loss : 0.031750, loss_ce: 0.015716
iteration 9591 : loss : 0.028881, loss_ce: 0.008564
iteration 9592 : loss : 0.028422, loss_ce: 0.006805
iteration 9593 : loss : 0.024517, loss_ce: 0.011076
iteration 9594 : loss : 0.024770, loss_ce: 0.007780
iteration 9595 : loss : 0.041043, loss_ce: 0.011090
iteration 9596 : loss : 0.032623, loss_ce: 0.010065
iteration 9597 : loss : 0.016413, loss_ce: 0.005041
iteration 9598 : loss : 0.026345, loss_ce: 0.005779
iteration 9599 : loss : 0.024714, loss_ce: 0.010997
iteration 9600 : loss : 0.022526, loss_ce: 0.006490
iteration 9601 : loss : 0.024667, loss_ce: 0.006024
iteration 9602 : loss : 0.029314, loss_ce: 0.009824
iteration 9603 : loss : 0.074566, loss_ce: 0.007421
iteration 9604 : loss : 0.041856, loss_ce: 0.008148
iteration 9605 : loss : 0.041903, loss_ce: 0.010193
iteration 9606 : loss : 0.023804, loss_ce: 0.007039
iteration 9607 : loss : 0.023049, loss_ce: 0.005919
iteration 9608 : loss : 0.053752, loss_ce: 0.005783
iteration 9609 : loss : 0.026075, loss_ce: 0.006182
iteration 9610 : loss : 0.051853, loss_ce: 0.012119
iteration 9611 : loss : 0.034012, loss_ce: 0.006389
iteration 9612 : loss : 0.024694, loss_ce: 0.009058
iteration 9613 : loss : 0.045209, loss_ce: 0.017461
iteration 9614 : loss : 0.038992, loss_ce: 0.007514
iteration 9615 : loss : 0.025084, loss_ce: 0.007242
iteration 9616 : loss : 0.027468, loss_ce: 0.009741
iteration 9617 : loss : 0.037877, loss_ce: 0.013824
iteration 9618 : loss : 0.031103, loss_ce: 0.013358
iteration 9619 : loss : 0.029044, loss_ce: 0.009948
iteration 9620 : loss : 0.039603, loss_ce: 0.008563
iteration 9621 : loss : 0.034517, loss_ce: 0.006473
iteration 9622 : loss : 0.030132, loss_ce: 0.010342
iteration 9623 : loss : 0.028411, loss_ce: 0.008696
iteration 9624 : loss : 0.025192, loss_ce: 0.006759
iteration 9625 : loss : 0.031841, loss_ce: 0.010911
iteration 9626 : loss : 0.025302, loss_ce: 0.011517
iteration 9627 : loss : 0.023017, loss_ce: 0.009744
iteration 9628 : loss : 0.028642, loss_ce: 0.013188
iteration 9629 : loss : 0.027382, loss_ce: 0.010082
iteration 9630 : loss : 0.029043, loss_ce: 0.015843
iteration 9631 : loss : 0.026547, loss_ce: 0.009046
iteration 9632 : loss : 0.033686, loss_ce: 0.015837
iteration 9633 : loss : 0.078164, loss_ce: 0.008405
iteration 9634 : loss : 0.024513, loss_ce: 0.008738
iteration 9635 : loss : 0.024325, loss_ce: 0.007693
iteration 9636 : loss : 0.029051, loss_ce: 0.006625
iteration 9637 : loss : 0.028522, loss_ce: 0.010861
iteration 9638 : loss : 0.026413, loss_ce: 0.006293
iteration 9639 : loss : 0.027967, loss_ce: 0.007303
iteration 9640 : loss : 0.028628, loss_ce: 0.009072
iteration 9641 : loss : 0.021462, loss_ce: 0.005786
iteration 9642 : loss : 0.035968, loss_ce: 0.011418
iteration 9643 : loss : 0.023347, loss_ce: 0.009285
iteration 9644 : loss : 0.026565, loss_ce: 0.012058
iteration 9645 : loss : 0.027141, loss_ce: 0.008606
iteration 9646 : loss : 0.025359, loss_ce: 0.008856
iteration 9647 : loss : 0.032832, loss_ce: 0.014547
iteration 9648 : loss : 0.026828, loss_ce: 0.011107
iteration 9649 : loss : 0.026549, loss_ce: 0.011345
iteration 9650 : loss : 0.025637, loss_ce: 0.008452
iteration 9651 : loss : 0.023154, loss_ce: 0.007949
iteration 9652 : loss : 0.020982, loss_ce: 0.004825
iteration 9653 : loss : 0.026313, loss_ce: 0.005137
iteration 9654 : loss : 0.020470, loss_ce: 0.005576
iteration 9655 : loss : 0.024341, loss_ce: 0.010515
iteration 9656 : loss : 0.023684, loss_ce: 0.009012
iteration 9657 : loss : 0.027585, loss_ce: 0.006445
iteration 9658 : loss : 0.021738, loss_ce: 0.009476
iteration 9659 : loss : 0.026686, loss_ce: 0.009172
iteration 9660 : loss : 0.028753, loss_ce: 0.009123
iteration 9661 : loss : 0.023914, loss_ce: 0.010660
iteration 9662 : loss : 0.077820, loss_ce: 0.011654
iteration 9663 : loss : 0.028143, loss_ce: 0.010489
iteration 9664 : loss : 0.031155, loss_ce: 0.009707
iteration 9665 : loss : 0.023662, loss_ce: 0.005725
iteration 9666 : loss : 0.024727, loss_ce: 0.009467
iteration 9667 : loss : 0.019385, loss_ce: 0.005959
iteration 9668 : loss : 0.024842, loss_ce: 0.007948
iteration 9669 : loss : 0.024449, loss_ce: 0.007055
iteration 9670 : loss : 0.028577, loss_ce: 0.007565
iteration 9671 : loss : 0.028365, loss_ce: 0.010080
iteration 9672 : loss : 0.234171, loss_ce: 0.010488
 52%|██████████████             | 104/200 [1:46:49<1:38:50, 61.78s/it]iteration 9673 : loss : 0.029058, loss_ce: 0.010831
iteration 9674 : loss : 0.027919, loss_ce: 0.012298
iteration 9675 : loss : 0.028721, loss_ce: 0.013452
iteration 9676 : loss : 0.026462, loss_ce: 0.009416
iteration 9677 : loss : 0.026366, loss_ce: 0.010666
iteration 9678 : loss : 0.025381, loss_ce: 0.007457
iteration 9679 : loss : 0.026287, loss_ce: 0.007212
iteration 9680 : loss : 0.028631, loss_ce: 0.013480
iteration 9681 : loss : 0.034235, loss_ce: 0.009150
iteration 9682 : loss : 0.078145, loss_ce: 0.006878
iteration 9683 : loss : 0.027684, loss_ce: 0.007635
iteration 9684 : loss : 0.026413, loss_ce: 0.013751
iteration 9685 : loss : 0.021902, loss_ce: 0.007947
iteration 9686 : loss : 0.024643, loss_ce: 0.010880
iteration 9687 : loss : 0.032610, loss_ce: 0.009284
iteration 9688 : loss : 0.021896, loss_ce: 0.004875
iteration 9689 : loss : 0.025430, loss_ce: 0.008856
iteration 9690 : loss : 0.023083, loss_ce: 0.007584
iteration 9691 : loss : 0.079486, loss_ce: 0.005484
iteration 9692 : loss : 0.018642, loss_ce: 0.005302
iteration 9693 : loss : 0.028719, loss_ce: 0.008044
iteration 9694 : loss : 0.023455, loss_ce: 0.010173
iteration 9695 : loss : 0.080994, loss_ce: 0.008484
iteration 9696 : loss : 0.029214, loss_ce: 0.008418
iteration 9697 : loss : 0.025516, loss_ce: 0.011284
iteration 9698 : loss : 0.026630, loss_ce: 0.005853
iteration 9699 : loss : 0.025073, loss_ce: 0.008242
iteration 9700 : loss : 0.077556, loss_ce: 0.010649
iteration 9701 : loss : 0.020329, loss_ce: 0.005856
iteration 9702 : loss : 0.022365, loss_ce: 0.011912
iteration 9703 : loss : 0.025390, loss_ce: 0.010790
iteration 9704 : loss : 0.025506, loss_ce: 0.009308
iteration 9705 : loss : 0.021528, loss_ce: 0.007940
iteration 9706 : loss : 0.023566, loss_ce: 0.007359
iteration 9707 : loss : 0.024414, loss_ce: 0.006646
iteration 9708 : loss : 0.025068, loss_ce: 0.012702
iteration 9709 : loss : 0.025518, loss_ce: 0.008065
iteration 9710 : loss : 0.029397, loss_ce: 0.009236
iteration 9711 : loss : 0.029045, loss_ce: 0.012025
iteration 9712 : loss : 0.023353, loss_ce: 0.006660
iteration 9713 : loss : 0.072989, loss_ce: 0.003591
iteration 9714 : loss : 0.075831, loss_ce: 0.006510
iteration 9715 : loss : 0.027814, loss_ce: 0.007837
iteration 9716 : loss : 0.021678, loss_ce: 0.006792
iteration 9717 : loss : 0.024210, loss_ce: 0.011096
iteration 9718 : loss : 0.027523, loss_ce: 0.009277
iteration 9719 : loss : 0.026557, loss_ce: 0.008395
iteration 9720 : loss : 0.026634, loss_ce: 0.009007
iteration 9721 : loss : 0.026843, loss_ce: 0.008410
iteration 9722 : loss : 0.027640, loss_ce: 0.006629
iteration 9723 : loss : 0.028330, loss_ce: 0.009267
iteration 9724 : loss : 0.030072, loss_ce: 0.010901
iteration 9725 : loss : 0.022498, loss_ce: 0.005086
iteration 9726 : loss : 0.029882, loss_ce: 0.012089
iteration 9727 : loss : 0.026866, loss_ce: 0.008269
iteration 9728 : loss : 0.034319, loss_ce: 0.012080
iteration 9729 : loss : 0.030108, loss_ce: 0.012171
iteration 9730 : loss : 0.024081, loss_ce: 0.007305
iteration 9731 : loss : 0.022875, loss_ce: 0.006592
iteration 9732 : loss : 0.028926, loss_ce: 0.011813
iteration 9733 : loss : 0.026653, loss_ce: 0.007054
iteration 9734 : loss : 0.022292, loss_ce: 0.007053
iteration 9735 : loss : 0.022231, loss_ce: 0.007754
iteration 9736 : loss : 0.028469, loss_ce: 0.009420
iteration 9737 : loss : 0.026102, loss_ce: 0.006613
iteration 9738 : loss : 0.042292, loss_ce: 0.006272
iteration 9739 : loss : 0.032217, loss_ce: 0.011937
iteration 9740 : loss : 0.026457, loss_ce: 0.007809
iteration 9741 : loss : 0.022978, loss_ce: 0.008716
iteration 9742 : loss : 0.031791, loss_ce: 0.014955
iteration 9743 : loss : 0.027258, loss_ce: 0.010505
iteration 9744 : loss : 0.020892, loss_ce: 0.004995
iteration 9745 : loss : 0.078607, loss_ce: 0.009546
iteration 9746 : loss : 0.028225, loss_ce: 0.014524
iteration 9747 : loss : 0.029657, loss_ce: 0.011423
iteration 9748 : loss : 0.024670, loss_ce: 0.005537
iteration 9749 : loss : 0.035576, loss_ce: 0.008454
iteration 9750 : loss : 0.030651, loss_ce: 0.008920
iteration 9751 : loss : 0.039792, loss_ce: 0.012964
iteration 9752 : loss : 0.034030, loss_ce: 0.006923
iteration 9753 : loss : 0.076603, loss_ce: 0.005679
iteration 9754 : loss : 0.022330, loss_ce: 0.007950
iteration 9755 : loss : 0.028162, loss_ce: 0.009429
iteration 9756 : loss : 0.029865, loss_ce: 0.008056
iteration 9757 : loss : 0.029711, loss_ce: 0.006645
iteration 9758 : loss : 0.024017, loss_ce: 0.009414
iteration 9759 : loss : 0.025848, loss_ce: 0.008034
iteration 9760 : loss : 0.074355, loss_ce: 0.007026
iteration 9761 : loss : 0.025819, loss_ce: 0.006631
iteration 9762 : loss : 0.022524, loss_ce: 0.007233
iteration 9763 : loss : 0.027164, loss_ce: 0.012490
iteration 9764 : loss : 0.021628, loss_ce: 0.005014
iteration 9765 : loss : 0.073300, loss_ce: 0.011237
 52%|██████████████▏            | 105/200 [1:47:50<1:37:44, 61.73s/it]iteration 9766 : loss : 0.024282, loss_ce: 0.005689
iteration 9767 : loss : 0.024272, loss_ce: 0.008372
iteration 9768 : loss : 0.024480, loss_ce: 0.008484
iteration 9769 : loss : 0.026519, loss_ce: 0.010584
iteration 9770 : loss : 0.031817, loss_ce: 0.009125
iteration 9771 : loss : 0.029059, loss_ce: 0.011488
iteration 9772 : loss : 0.025851, loss_ce: 0.006623
iteration 9773 : loss : 0.024836, loss_ce: 0.009735
iteration 9774 : loss : 0.027453, loss_ce: 0.009190
iteration 9775 : loss : 0.021042, loss_ce: 0.007331
iteration 9776 : loss : 0.025571, loss_ce: 0.008231
iteration 9777 : loss : 0.027797, loss_ce: 0.012867
iteration 9778 : loss : 0.076516, loss_ce: 0.004446
iteration 9779 : loss : 0.026617, loss_ce: 0.009783
iteration 9780 : loss : 0.028901, loss_ce: 0.011223
iteration 9781 : loss : 0.025433, loss_ce: 0.006041
iteration 9782 : loss : 0.026847, loss_ce: 0.006619
iteration 9783 : loss : 0.022915, loss_ce: 0.006792
iteration 9784 : loss : 0.028904, loss_ce: 0.005929
iteration 9785 : loss : 0.024435, loss_ce: 0.010136
iteration 9786 : loss : 0.075852, loss_ce: 0.005802
iteration 9787 : loss : 0.025642, loss_ce: 0.009692
iteration 9788 : loss : 0.124901, loss_ce: 0.003035
iteration 9789 : loss : 0.027045, loss_ce: 0.010368
iteration 9790 : loss : 0.024671, loss_ce: 0.008452
iteration 9791 : loss : 0.026632, loss_ce: 0.007588
iteration 9792 : loss : 0.028089, loss_ce: 0.009508
iteration 9793 : loss : 0.026907, loss_ce: 0.006786
iteration 9794 : loss : 0.024999, loss_ce: 0.008284
iteration 9795 : loss : 0.028071, loss_ce: 0.006946
iteration 9796 : loss : 0.022764, loss_ce: 0.008738
iteration 9797 : loss : 0.027866, loss_ce: 0.009756
iteration 9798 : loss : 0.046974, loss_ce: 0.007861
iteration 9799 : loss : 0.021364, loss_ce: 0.008388
iteration 9800 : loss : 0.019305, loss_ce: 0.005383
iteration 9801 : loss : 0.031511, loss_ce: 0.009104
iteration 9802 : loss : 0.033306, loss_ce: 0.013005
iteration 9803 : loss : 0.026942, loss_ce: 0.009954
iteration 9804 : loss : 0.025798, loss_ce: 0.009710
iteration 9805 : loss : 0.027876, loss_ce: 0.009081
iteration 9806 : loss : 0.050560, loss_ce: 0.007390
iteration 9807 : loss : 0.021291, loss_ce: 0.005814
iteration 9808 : loss : 0.025277, loss_ce: 0.010581
iteration 9809 : loss : 0.025133, loss_ce: 0.012759
iteration 9810 : loss : 0.028768, loss_ce: 0.009175
iteration 9811 : loss : 0.023887, loss_ce: 0.009550
iteration 9812 : loss : 0.028607, loss_ce: 0.013051
iteration 9813 : loss : 0.030735, loss_ce: 0.008856
iteration 9814 : loss : 0.031113, loss_ce: 0.008458
iteration 9815 : loss : 0.022866, loss_ce: 0.008355
iteration 9816 : loss : 0.027920, loss_ce: 0.012380
iteration 9817 : loss : 0.032672, loss_ce: 0.012738
iteration 9818 : loss : 0.029894, loss_ce: 0.005907
iteration 9819 : loss : 0.029379, loss_ce: 0.012489
iteration 9820 : loss : 0.024720, loss_ce: 0.013533
iteration 9821 : loss : 0.029668, loss_ce: 0.007729
iteration 9822 : loss : 0.079832, loss_ce: 0.003062
iteration 9823 : loss : 0.024878, loss_ce: 0.010333
iteration 9824 : loss : 0.024956, loss_ce: 0.012113
iteration 9825 : loss : 0.026111, loss_ce: 0.007917
iteration 9826 : loss : 0.027622, loss_ce: 0.011884
iteration 9827 : loss : 0.024184, loss_ce: 0.006279
iteration 9828 : loss : 0.080621, loss_ce: 0.006138
iteration 9829 : loss : 0.028272, loss_ce: 0.010167
iteration 9830 : loss : 0.075799, loss_ce: 0.008815
iteration 9831 : loss : 0.024240, loss_ce: 0.009050
iteration 9832 : loss : 0.022554, loss_ce: 0.008175
iteration 9833 : loss : 0.026540, loss_ce: 0.008364
iteration 9834 : loss : 0.029916, loss_ce: 0.004810
iteration 9835 : loss : 0.030267, loss_ce: 0.008666
iteration 9836 : loss : 0.026724, loss_ce: 0.009766
iteration 9837 : loss : 0.025366, loss_ce: 0.009246
iteration 9838 : loss : 0.031012, loss_ce: 0.014333
iteration 9839 : loss : 0.022659, loss_ce: 0.007715
iteration 9840 : loss : 0.024822, loss_ce: 0.005252
iteration 9841 : loss : 0.031612, loss_ce: 0.016567
iteration 9842 : loss : 0.023558, loss_ce: 0.005140
iteration 9843 : loss : 0.082553, loss_ce: 0.004547
iteration 9844 : loss : 0.027260, loss_ce: 0.010882
iteration 9845 : loss : 0.026713, loss_ce: 0.010395
iteration 9846 : loss : 0.023454, loss_ce: 0.012567
iteration 9847 : loss : 0.024981, loss_ce: 0.012822
iteration 9848 : loss : 0.029740, loss_ce: 0.013130
iteration 9849 : loss : 0.023220, loss_ce: 0.006021
iteration 9850 : loss : 0.031669, loss_ce: 0.008273
iteration 9851 : loss : 0.023225, loss_ce: 0.006829
iteration 9852 : loss : 0.028114, loss_ce: 0.006750
iteration 9853 : loss : 0.022424, loss_ce: 0.009040
iteration 9854 : loss : 0.031836, loss_ce: 0.014275
iteration 9855 : loss : 0.025400, loss_ce: 0.007602
iteration 9856 : loss : 0.022315, loss_ce: 0.005148
iteration 9857 : loss : 0.032693, loss_ce: 0.007915
iteration 9858 : loss : 0.182514, loss_ce: 0.007908
 53%|██████████████▎            | 106/200 [1:48:52<1:36:38, 61.68s/it]iteration 9859 : loss : 0.031472, loss_ce: 0.009734
iteration 9860 : loss : 0.029532, loss_ce: 0.008021
iteration 9861 : loss : 0.027549, loss_ce: 0.014058
iteration 9862 : loss : 0.032525, loss_ce: 0.012015
iteration 9863 : loss : 0.030159, loss_ce: 0.012288
iteration 9864 : loss : 0.027499, loss_ce: 0.011260
iteration 9865 : loss : 0.021187, loss_ce: 0.007832
iteration 9866 : loss : 0.022638, loss_ce: 0.007529
iteration 9867 : loss : 0.022934, loss_ce: 0.009118
iteration 9868 : loss : 0.023702, loss_ce: 0.007191
iteration 9869 : loss : 0.019955, loss_ce: 0.007100
iteration 9870 : loss : 0.024969, loss_ce: 0.010036
iteration 9871 : loss : 0.023406, loss_ce: 0.008579
iteration 9872 : loss : 0.027130, loss_ce: 0.006483
iteration 9873 : loss : 0.027616, loss_ce: 0.011413
iteration 9874 : loss : 0.025431, loss_ce: 0.010280
iteration 9875 : loss : 0.022844, loss_ce: 0.005596
iteration 9876 : loss : 0.023294, loss_ce: 0.007750
iteration 9877 : loss : 0.023233, loss_ce: 0.007763
iteration 9878 : loss : 0.023919, loss_ce: 0.008672
iteration 9879 : loss : 0.026223, loss_ce: 0.007908
iteration 9880 : loss : 0.031405, loss_ce: 0.009519
iteration 9881 : loss : 0.030814, loss_ce: 0.009628
iteration 9882 : loss : 0.021368, loss_ce: 0.008439
iteration 9883 : loss : 0.023878, loss_ce: 0.008765
iteration 9884 : loss : 0.021601, loss_ce: 0.008361
iteration 9885 : loss : 0.074968, loss_ce: 0.003573
iteration 9886 : loss : 0.024229, loss_ce: 0.007793
iteration 9887 : loss : 0.025803, loss_ce: 0.009810
iteration 9888 : loss : 0.024967, loss_ce: 0.009288
iteration 9889 : loss : 0.027542, loss_ce: 0.011170
iteration 9890 : loss : 0.028638, loss_ce: 0.010467
iteration 9891 : loss : 0.024357, loss_ce: 0.007966
iteration 9892 : loss : 0.029782, loss_ce: 0.009085
iteration 9893 : loss : 0.033921, loss_ce: 0.009849
iteration 9894 : loss : 0.023223, loss_ce: 0.007025
iteration 9895 : loss : 0.023885, loss_ce: 0.008136
iteration 9896 : loss : 0.018928, loss_ce: 0.006066
iteration 9897 : loss : 0.028129, loss_ce: 0.008496
iteration 9898 : loss : 0.076667, loss_ce: 0.005154
iteration 9899 : loss : 0.034509, loss_ce: 0.012631
iteration 9900 : loss : 0.021566, loss_ce: 0.007888
iteration 9901 : loss : 0.026078, loss_ce: 0.010397
iteration 9902 : loss : 0.026906, loss_ce: 0.008872
iteration 9903 : loss : 0.024854, loss_ce: 0.010289
iteration 9904 : loss : 0.023384, loss_ce: 0.011400
iteration 9905 : loss : 0.025280, loss_ce: 0.009308
iteration 9906 : loss : 0.179817, loss_ce: 0.002792
iteration 9907 : loss : 0.030280, loss_ce: 0.006471
iteration 9908 : loss : 0.124774, loss_ce: 0.005815
iteration 9909 : loss : 0.036805, loss_ce: 0.007254
iteration 9910 : loss : 0.024285, loss_ce: 0.011175
iteration 9911 : loss : 0.025570, loss_ce: 0.006473
iteration 9912 : loss : 0.024901, loss_ce: 0.009578
iteration 9913 : loss : 0.024533, loss_ce: 0.011721
iteration 9914 : loss : 0.025470, loss_ce: 0.011332
iteration 9915 : loss : 0.028298, loss_ce: 0.010158
iteration 9916 : loss : 0.023512, loss_ce: 0.008261
iteration 9917 : loss : 0.026298, loss_ce: 0.010960
iteration 9918 : loss : 0.027502, loss_ce: 0.012025
iteration 9919 : loss : 0.027512, loss_ce: 0.005664
iteration 9920 : loss : 0.030743, loss_ce: 0.010649
iteration 9921 : loss : 0.028273, loss_ce: 0.007130
iteration 9922 : loss : 0.025476, loss_ce: 0.009881
iteration 9923 : loss : 0.032530, loss_ce: 0.005620
iteration 9924 : loss : 0.027438, loss_ce: 0.010175
iteration 9925 : loss : 0.023483, loss_ce: 0.007391
iteration 9926 : loss : 0.076876, loss_ce: 0.005588
iteration 9927 : loss : 0.026960, loss_ce: 0.004627
iteration 9928 : loss : 0.027302, loss_ce: 0.009663
iteration 9929 : loss : 0.029564, loss_ce: 0.006320
iteration 9930 : loss : 0.021432, loss_ce: 0.009852
iteration 9931 : loss : 0.023149, loss_ce: 0.006443
iteration 9932 : loss : 0.027322, loss_ce: 0.013802
iteration 9933 : loss : 0.081185, loss_ce: 0.008435
iteration 9934 : loss : 0.022837, loss_ce: 0.005385
iteration 9935 : loss : 0.024833, loss_ce: 0.010129
iteration 9936 : loss : 0.026047, loss_ce: 0.009821
iteration 9937 : loss : 0.021348, loss_ce: 0.007188
iteration 9938 : loss : 0.029525, loss_ce: 0.012782
iteration 9939 : loss : 0.029032, loss_ce: 0.011253
iteration 9940 : loss : 0.082082, loss_ce: 0.008227
iteration 9941 : loss : 0.025364, loss_ce: 0.011721
iteration 9942 : loss : 0.029154, loss_ce: 0.010673
iteration 9943 : loss : 0.024569, loss_ce: 0.011151
iteration 9944 : loss : 0.023605, loss_ce: 0.009991
iteration 9945 : loss : 0.025758, loss_ce: 0.006454
iteration 9946 : loss : 0.025583, loss_ce: 0.006371
iteration 9947 : loss : 0.025808, loss_ce: 0.007543
iteration 9948 : loss : 0.077683, loss_ce: 0.006448
iteration 9949 : loss : 0.025699, loss_ce: 0.009895
iteration 9950 : loss : 0.028533, loss_ce: 0.006554
iteration 9951 : loss : 0.442736, loss_ce: 0.000366
 54%|██████████████▍            | 107/200 [1:49:53<1:35:37, 61.70s/it]iteration 9952 : loss : 0.025240, loss_ce: 0.009548
iteration 9953 : loss : 0.025972, loss_ce: 0.008983
iteration 9954 : loss : 0.020835, loss_ce: 0.004727
iteration 9955 : loss : 0.023947, loss_ce: 0.005584
iteration 9956 : loss : 0.027467, loss_ce: 0.010396
iteration 9957 : loss : 0.026299, loss_ce: 0.014867
iteration 9958 : loss : 0.020115, loss_ce: 0.003299
iteration 9959 : loss : 0.071035, loss_ce: 0.005180
iteration 9960 : loss : 0.026956, loss_ce: 0.013450
iteration 9961 : loss : 0.030191, loss_ce: 0.007806
iteration 9962 : loss : 0.025796, loss_ce: 0.007746
iteration 9963 : loss : 0.074433, loss_ce: 0.004988
iteration 9964 : loss : 0.028258, loss_ce: 0.009454
iteration 9965 : loss : 0.029204, loss_ce: 0.009200
iteration 9966 : loss : 0.023457, loss_ce: 0.009309
iteration 9967 : loss : 0.025627, loss_ce: 0.005520
iteration 9968 : loss : 0.040598, loss_ce: 0.008860
iteration 9969 : loss : 0.023691, loss_ce: 0.009088
iteration 9970 : loss : 0.028104, loss_ce: 0.010309
iteration 9971 : loss : 0.023712, loss_ce: 0.008620
iteration 9972 : loss : 0.028576, loss_ce: 0.009287
iteration 9973 : loss : 0.024627, loss_ce: 0.010641
iteration 9974 : loss : 0.027304, loss_ce: 0.006915
iteration 9975 : loss : 0.029999, loss_ce: 0.010159
iteration 9976 : loss : 0.025335, loss_ce: 0.011763
iteration 9977 : loss : 0.027074, loss_ce: 0.008455
iteration 9978 : loss : 0.026927, loss_ce: 0.007357
iteration 9979 : loss : 0.028010, loss_ce: 0.009737
iteration 9980 : loss : 0.028229, loss_ce: 0.013315
iteration 9981 : loss : 0.026558, loss_ce: 0.009658
iteration 9982 : loss : 0.024546, loss_ce: 0.009349
iteration 9983 : loss : 0.026196, loss_ce: 0.009172
iteration 9984 : loss : 0.022859, loss_ce: 0.006916
iteration 9985 : loss : 0.022438, loss_ce: 0.008325
iteration 9986 : loss : 0.024160, loss_ce: 0.006722
iteration 9987 : loss : 0.024793, loss_ce: 0.009575
iteration 9988 : loss : 0.025143, loss_ce: 0.007827
iteration 9989 : loss : 0.045201, loss_ce: 0.005497
iteration 9990 : loss : 0.025345, loss_ce: 0.005800
iteration 9991 : loss : 0.026841, loss_ce: 0.008902
iteration 9992 : loss : 0.027064, loss_ce: 0.007443
iteration 9993 : loss : 0.025233, loss_ce: 0.007815
iteration 9994 : loss : 0.025174, loss_ce: 0.010281
iteration 9995 : loss : 0.024688, loss_ce: 0.010617
iteration 9996 : loss : 0.023236, loss_ce: 0.009854
iteration 9997 : loss : 0.085590, loss_ce: 0.010622
iteration 9998 : loss : 0.025091, loss_ce: 0.008028
iteration 9999 : loss : 0.024309, loss_ce: 0.005042
iteration 10000 : loss : 0.030132, loss_ce: 0.007952
iteration 10001 : loss : 0.021556, loss_ce: 0.004937
iteration 10002 : loss : 0.024632, loss_ce: 0.010965
iteration 10003 : loss : 0.030147, loss_ce: 0.008626
iteration 10004 : loss : 0.028173, loss_ce: 0.013755
iteration 10005 : loss : 0.029554, loss_ce: 0.009025
iteration 10006 : loss : 0.033487, loss_ce: 0.002905
iteration 10007 : loss : 0.033606, loss_ce: 0.010197
iteration 10008 : loss : 0.022603, loss_ce: 0.008630
iteration 10009 : loss : 0.023271, loss_ce: 0.005305
iteration 10010 : loss : 0.028956, loss_ce: 0.016559
iteration 10011 : loss : 0.025773, loss_ce: 0.009648
iteration 10012 : loss : 0.032071, loss_ce: 0.010915
iteration 10013 : loss : 0.021318, loss_ce: 0.006514
iteration 10014 : loss : 0.025016, loss_ce: 0.006268
iteration 10015 : loss : 0.023949, loss_ce: 0.011495
iteration 10016 : loss : 0.022849, loss_ce: 0.004393
iteration 10017 : loss : 0.033730, loss_ce: 0.009041
iteration 10018 : loss : 0.030905, loss_ce: 0.008460
iteration 10019 : loss : 0.026790, loss_ce: 0.008465
iteration 10020 : loss : 0.026588, loss_ce: 0.011978
iteration 10021 : loss : 0.079279, loss_ce: 0.006757
iteration 10022 : loss : 0.026541, loss_ce: 0.010462
iteration 10023 : loss : 0.024551, loss_ce: 0.004388
iteration 10024 : loss : 0.077772, loss_ce: 0.006289
iteration 10025 : loss : 0.027334, loss_ce: 0.008192
iteration 10026 : loss : 0.035467, loss_ce: 0.013004
iteration 10027 : loss : 0.028999, loss_ce: 0.010567
iteration 10028 : loss : 0.029943, loss_ce: 0.005362
iteration 10029 : loss : 0.025090, loss_ce: 0.009290
iteration 10030 : loss : 0.031626, loss_ce: 0.012508
iteration 10031 : loss : 0.027214, loss_ce: 0.010446
iteration 10032 : loss : 0.024764, loss_ce: 0.010842
iteration 10033 : loss : 0.022616, loss_ce: 0.005697
iteration 10034 : loss : 0.024709, loss_ce: 0.008968
iteration 10035 : loss : 0.022732, loss_ce: 0.007474
iteration 10036 : loss : 0.078679, loss_ce: 0.009404
iteration 10037 : loss : 0.032631, loss_ce: 0.005727
iteration 10038 : loss : 0.025784, loss_ce: 0.010466
iteration 10039 : loss : 0.026746, loss_ce: 0.009241
iteration 10040 : loss : 0.025066, loss_ce: 0.009253
iteration 10041 : loss : 0.026421, loss_ce: 0.008709
iteration 10042 : loss : 0.033823, loss_ce: 0.009174
iteration 10043 : loss : 0.026312, loss_ce: 0.012103
iteration 10044 : loss : 0.333833, loss_ce: 0.002407
 54%|██████████████▌            | 108/200 [1:50:55<1:34:33, 61.67s/it]iteration 10045 : loss : 0.023499, loss_ce: 0.008371
iteration 10046 : loss : 0.026667, loss_ce: 0.006004
iteration 10047 : loss : 0.028765, loss_ce: 0.009940
iteration 10048 : loss : 0.022626, loss_ce: 0.007410
iteration 10049 : loss : 0.023825, loss_ce: 0.006569
iteration 10050 : loss : 0.028647, loss_ce: 0.010605
iteration 10051 : loss : 0.028058, loss_ce: 0.012566
iteration 10052 : loss : 0.020338, loss_ce: 0.005304
iteration 10053 : loss : 0.021164, loss_ce: 0.005720
iteration 10054 : loss : 0.021479, loss_ce: 0.009444
iteration 10055 : loss : 0.022022, loss_ce: 0.007182
iteration 10056 : loss : 0.071705, loss_ce: 0.006134
iteration 10057 : loss : 0.025591, loss_ce: 0.006492
iteration 10058 : loss : 0.023856, loss_ce: 0.006659
iteration 10059 : loss : 0.024701, loss_ce: 0.006530
iteration 10060 : loss : 0.024288, loss_ce: 0.011626
iteration 10061 : loss : 0.027311, loss_ce: 0.008846
iteration 10062 : loss : 0.072076, loss_ce: 0.005851
iteration 10063 : loss : 0.020339, loss_ce: 0.008673
iteration 10064 : loss : 0.024726, loss_ce: 0.010076
iteration 10065 : loss : 0.028710, loss_ce: 0.008097
iteration 10066 : loss : 0.020976, loss_ce: 0.006479
iteration 10067 : loss : 0.028379, loss_ce: 0.008565
iteration 10068 : loss : 0.023254, loss_ce: 0.006271
iteration 10069 : loss : 0.035518, loss_ce: 0.010514
iteration 10070 : loss : 0.077497, loss_ce: 0.009127
iteration 10071 : loss : 0.030739, loss_ce: 0.012192
iteration 10072 : loss : 0.028379, loss_ce: 0.010541
iteration 10073 : loss : 0.035132, loss_ce: 0.007364
iteration 10074 : loss : 0.028165, loss_ce: 0.012417
iteration 10075 : loss : 0.023911, loss_ce: 0.006690
iteration 10076 : loss : 0.027178, loss_ce: 0.009154
iteration 10077 : loss : 0.024797, loss_ce: 0.007245
iteration 10078 : loss : 0.023319, loss_ce: 0.006860
iteration 10079 : loss : 0.026566, loss_ce: 0.006245
iteration 10080 : loss : 0.030192, loss_ce: 0.012930
iteration 10081 : loss : 0.029323, loss_ce: 0.008558
iteration 10082 : loss : 0.022479, loss_ce: 0.011235
iteration 10083 : loss : 0.025263, loss_ce: 0.009580
iteration 10084 : loss : 0.024330, loss_ce: 0.007065
iteration 10085 : loss : 0.024559, loss_ce: 0.011288
iteration 10086 : loss : 0.073583, loss_ce: 0.004329
iteration 10087 : loss : 0.029897, loss_ce: 0.009475
iteration 10088 : loss : 0.029701, loss_ce: 0.013539
iteration 10089 : loss : 0.027308, loss_ce: 0.009538
iteration 10090 : loss : 0.025287, loss_ce: 0.007756
iteration 10091 : loss : 0.022355, loss_ce: 0.007598
iteration 10092 : loss : 0.020581, loss_ce: 0.007656
iteration 10093 : loss : 0.072909, loss_ce: 0.004401
iteration 10094 : loss : 0.025259, loss_ce: 0.006266
iteration 10095 : loss : 0.025749, loss_ce: 0.009210
iteration 10096 : loss : 0.022487, loss_ce: 0.007083
iteration 10097 : loss : 0.034688, loss_ce: 0.009816
iteration 10098 : loss : 0.023330, loss_ce: 0.005920
iteration 10099 : loss : 0.024303, loss_ce: 0.012462
iteration 10100 : loss : 0.031874, loss_ce: 0.011058
iteration 10101 : loss : 0.083183, loss_ce: 0.002611
iteration 10102 : loss : 0.024765, loss_ce: 0.005696
iteration 10103 : loss : 0.029662, loss_ce: 0.015172
iteration 10104 : loss : 0.028523, loss_ce: 0.006178
iteration 10105 : loss : 0.031783, loss_ce: 0.007809
iteration 10106 : loss : 0.035275, loss_ce: 0.007243
iteration 10107 : loss : 0.026290, loss_ce: 0.008372
iteration 10108 : loss : 0.025639, loss_ce: 0.007093
iteration 10109 : loss : 0.026376, loss_ce: 0.005168
iteration 10110 : loss : 0.024540, loss_ce: 0.008441
iteration 10111 : loss : 0.030522, loss_ce: 0.015915
iteration 10112 : loss : 0.031006, loss_ce: 0.010645
iteration 10113 : loss : 0.032046, loss_ce: 0.016028
iteration 10114 : loss : 0.026113, loss_ce: 0.010710
iteration 10115 : loss : 0.030693, loss_ce: 0.013420
iteration 10116 : loss : 0.027021, loss_ce: 0.009235
iteration 10117 : loss : 0.036654, loss_ce: 0.008701
iteration 10118 : loss : 0.024012, loss_ce: 0.006879
iteration 10119 : loss : 0.031667, loss_ce: 0.009391
iteration 10120 : loss : 0.027841, loss_ce: 0.008980
iteration 10121 : loss : 0.026937, loss_ce: 0.013625
iteration 10122 : loss : 0.030430, loss_ce: 0.007590
iteration 10123 : loss : 0.020816, loss_ce: 0.007915
iteration 10124 : loss : 0.077508, loss_ce: 0.005736
iteration 10125 : loss : 0.023170, loss_ce: 0.008340
iteration 10126 : loss : 0.039736, loss_ce: 0.008223
iteration 10127 : loss : 0.024120, loss_ce: 0.008881
iteration 10128 : loss : 0.031018, loss_ce: 0.007376
iteration 10129 : loss : 0.118301, loss_ce: 0.004143
iteration 10130 : loss : 0.025037, loss_ce: 0.005611
iteration 10131 : loss : 0.034212, loss_ce: 0.013755
iteration 10132 : loss : 0.028346, loss_ce: 0.009548
iteration 10133 : loss : 0.034105, loss_ce: 0.009895
iteration 10134 : loss : 0.039865, loss_ce: 0.008454
iteration 10135 : loss : 0.024964, loss_ce: 0.009471
iteration 10136 : loss : 0.023523, loss_ce: 0.011479
iteration 10137 : loss : 0.035253, loss_ce: 0.010681
 55%|██████████████▋            | 109/200 [1:51:57<1:33:26, 61.61s/it]iteration 10138 : loss : 0.021080, loss_ce: 0.006913
iteration 10139 : loss : 0.029890, loss_ce: 0.012515
iteration 10140 : loss : 0.080603, loss_ce: 0.006363
iteration 10141 : loss : 0.024068, loss_ce: 0.010922
iteration 10142 : loss : 0.032709, loss_ce: 0.007744
iteration 10143 : loss : 0.028504, loss_ce: 0.010281
iteration 10144 : loss : 0.023254, loss_ce: 0.008205
iteration 10145 : loss : 0.027145, loss_ce: 0.011230
iteration 10146 : loss : 0.112736, loss_ce: 0.004940
iteration 10147 : loss : 0.026510, loss_ce: 0.006509
iteration 10148 : loss : 0.025147, loss_ce: 0.008348
iteration 10149 : loss : 0.078100, loss_ce: 0.008848
iteration 10150 : loss : 0.028286, loss_ce: 0.007507
iteration 10151 : loss : 0.028169, loss_ce: 0.011682
iteration 10152 : loss : 0.026281, loss_ce: 0.012974
iteration 10153 : loss : 0.024019, loss_ce: 0.008673
iteration 10154 : loss : 0.021428, loss_ce: 0.005656
iteration 10155 : loss : 0.026863, loss_ce: 0.008593
iteration 10156 : loss : 0.026258, loss_ce: 0.008928
iteration 10157 : loss : 0.048712, loss_ce: 0.005777
iteration 10158 : loss : 0.073855, loss_ce: 0.005345
iteration 10159 : loss : 0.030605, loss_ce: 0.008644
iteration 10160 : loss : 0.077938, loss_ce: 0.009651
iteration 10161 : loss : 0.026542, loss_ce: 0.008366
iteration 10162 : loss : 0.031040, loss_ce: 0.008219
iteration 10163 : loss : 0.024884, loss_ce: 0.009880
iteration 10164 : loss : 0.027435, loss_ce: 0.010191
iteration 10165 : loss : 0.025682, loss_ce: 0.007799
iteration 10166 : loss : 0.028952, loss_ce: 0.007275
iteration 10167 : loss : 0.033809, loss_ce: 0.008635
iteration 10168 : loss : 0.027473, loss_ce: 0.011137
iteration 10169 : loss : 0.020662, loss_ce: 0.008514
iteration 10170 : loss : 0.021692, loss_ce: 0.003799
iteration 10171 : loss : 0.023497, loss_ce: 0.007549
iteration 10172 : loss : 0.033669, loss_ce: 0.016983
iteration 10173 : loss : 0.031630, loss_ce: 0.013180
iteration 10174 : loss : 0.022885, loss_ce: 0.007180
iteration 10175 : loss : 0.028680, loss_ce: 0.008612
iteration 10176 : loss : 0.023443, loss_ce: 0.005150
iteration 10177 : loss : 0.023283, loss_ce: 0.006975
iteration 10178 : loss : 0.028426, loss_ce: 0.011655
iteration 10179 : loss : 0.026936, loss_ce: 0.013173
iteration 10180 : loss : 0.036019, loss_ce: 0.008653
iteration 10181 : loss : 0.027282, loss_ce: 0.011127
iteration 10182 : loss : 0.076788, loss_ce: 0.006508
iteration 10183 : loss : 0.025038, loss_ce: 0.005571
iteration 10184 : loss : 0.021416, loss_ce: 0.007355
iteration 10185 : loss : 0.026341, loss_ce: 0.011458
iteration 10186 : loss : 0.040000, loss_ce: 0.004459
iteration 10187 : loss : 0.025905, loss_ce: 0.008100
iteration 10188 : loss : 0.024730, loss_ce: 0.005698
iteration 10189 : loss : 0.066980, loss_ce: 0.009431
iteration 10190 : loss : 0.035642, loss_ce: 0.008448
iteration 10191 : loss : 0.026439, loss_ce: 0.008992
iteration 10192 : loss : 0.026025, loss_ce: 0.011162
iteration 10193 : loss : 0.026095, loss_ce: 0.008213
iteration 10194 : loss : 0.024872, loss_ce: 0.008712
iteration 10195 : loss : 0.028767, loss_ce: 0.009137
iteration 10196 : loss : 0.030580, loss_ce: 0.012758
iteration 10197 : loss : 0.023227, loss_ce: 0.006755
iteration 10198 : loss : 0.027512, loss_ce: 0.010522
iteration 10199 : loss : 0.024392, loss_ce: 0.009542
iteration 10200 : loss : 0.027917, loss_ce: 0.008388
iteration 10201 : loss : 0.023995, loss_ce: 0.006702
iteration 10202 : loss : 0.027635, loss_ce: 0.011787
iteration 10203 : loss : 0.027157, loss_ce: 0.007624
iteration 10204 : loss : 0.026694, loss_ce: 0.007009
iteration 10205 : loss : 0.034235, loss_ce: 0.012078
iteration 10206 : loss : 0.027022, loss_ce: 0.008328
iteration 10207 : loss : 0.031537, loss_ce: 0.008846
iteration 10208 : loss : 0.028032, loss_ce: 0.011109
iteration 10209 : loss : 0.029025, loss_ce: 0.010644
iteration 10210 : loss : 0.029955, loss_ce: 0.009312
iteration 10211 : loss : 0.023981, loss_ce: 0.005171
iteration 10212 : loss : 0.026314, loss_ce: 0.009081
iteration 10213 : loss : 0.032464, loss_ce: 0.014744
iteration 10214 : loss : 0.028449, loss_ce: 0.017124
iteration 10215 : loss : 0.024351, loss_ce: 0.004570
iteration 10216 : loss : 0.025609, loss_ce: 0.008858
iteration 10217 : loss : 0.021236, loss_ce: 0.006940
iteration 10218 : loss : 0.031124, loss_ce: 0.009700
iteration 10219 : loss : 0.031587, loss_ce: 0.006569
iteration 10220 : loss : 0.039525, loss_ce: 0.006025
iteration 10221 : loss : 0.085381, loss_ce: 0.009098
iteration 10222 : loss : 0.032385, loss_ce: 0.006650
iteration 10223 : loss : 0.031225, loss_ce: 0.011403
iteration 10224 : loss : 0.028729, loss_ce: 0.011714
iteration 10225 : loss : 0.023122, loss_ce: 0.008781
iteration 10226 : loss : 0.029485, loss_ce: 0.007783
iteration 10227 : loss : 0.028114, loss_ce: 0.013199
iteration 10228 : loss : 0.027351, loss_ce: 0.011174
iteration 10229 : loss : 0.020480, loss_ce: 0.007516
iteration 10230 : loss : 0.232171, loss_ce: 0.009020
 55%|██████████████▊            | 110/200 [1:52:58<1:32:24, 61.60s/it]iteration 10231 : loss : 0.017759, loss_ce: 0.005357
iteration 10232 : loss : 0.035384, loss_ce: 0.011089
iteration 10233 : loss : 0.025652, loss_ce: 0.010682
iteration 10234 : loss : 0.025155, loss_ce: 0.005316
iteration 10235 : loss : 0.026849, loss_ce: 0.007062
iteration 10236 : loss : 0.024755, loss_ce: 0.011065
iteration 10237 : loss : 0.028643, loss_ce: 0.011078
iteration 10238 : loss : 0.023960, loss_ce: 0.007149
iteration 10239 : loss : 0.027258, loss_ce: 0.007279
iteration 10240 : loss : 0.077893, loss_ce: 0.007894
iteration 10241 : loss : 0.028770, loss_ce: 0.009718
iteration 10242 : loss : 0.026084, loss_ce: 0.006492
iteration 10243 : loss : 0.024485, loss_ce: 0.006802
iteration 10244 : loss : 0.033070, loss_ce: 0.008443
iteration 10245 : loss : 0.027036, loss_ce: 0.006655
iteration 10246 : loss : 0.023554, loss_ce: 0.009093
iteration 10247 : loss : 0.028564, loss_ce: 0.012313
iteration 10248 : loss : 0.028338, loss_ce: 0.012522
iteration 10249 : loss : 0.022893, loss_ce: 0.004629
iteration 10250 : loss : 0.025184, loss_ce: 0.008858
iteration 10251 : loss : 0.023460, loss_ce: 0.007806
iteration 10252 : loss : 0.023474, loss_ce: 0.007676
iteration 10253 : loss : 0.027119, loss_ce: 0.007968
iteration 10254 : loss : 0.030833, loss_ce: 0.010652
iteration 10255 : loss : 0.024763, loss_ce: 0.010726
iteration 10256 : loss : 0.024564, loss_ce: 0.009484
iteration 10257 : loss : 0.023230, loss_ce: 0.005460
iteration 10258 : loss : 0.029062, loss_ce: 0.008355
iteration 10259 : loss : 0.028206, loss_ce: 0.009499
iteration 10260 : loss : 0.021969, loss_ce: 0.003726
iteration 10261 : loss : 0.021871, loss_ce: 0.008535
iteration 10262 : loss : 0.026566, loss_ce: 0.007959
iteration 10263 : loss : 0.022044, loss_ce: 0.006333
iteration 10264 : loss : 0.024946, loss_ce: 0.008371
iteration 10265 : loss : 0.019673, loss_ce: 0.005518
iteration 10266 : loss : 0.026206, loss_ce: 0.011832
iteration 10267 : loss : 0.022357, loss_ce: 0.007605
iteration 10268 : loss : 0.025241, loss_ce: 0.010362
iteration 10269 : loss : 0.034373, loss_ce: 0.008708
iteration 10270 : loss : 0.030539, loss_ce: 0.007531
iteration 10271 : loss : 0.024537, loss_ce: 0.008670
iteration 10272 : loss : 0.024815, loss_ce: 0.007408
iteration 10273 : loss : 0.024534, loss_ce: 0.004600
iteration 10274 : loss : 0.030467, loss_ce: 0.007800
iteration 10275 : loss : 0.026119, loss_ce: 0.012235
iteration 10276 : loss : 0.024892, loss_ce: 0.004837
iteration 10277 : loss : 0.029737, loss_ce: 0.009597
iteration 10278 : loss : 0.025285, loss_ce: 0.008685
iteration 10279 : loss : 0.024251, loss_ce: 0.008766
iteration 10280 : loss : 0.024536, loss_ce: 0.005206
iteration 10281 : loss : 0.024903, loss_ce: 0.009137
iteration 10282 : loss : 0.028591, loss_ce: 0.010741
iteration 10283 : loss : 0.026153, loss_ce: 0.010192
iteration 10284 : loss : 0.027228, loss_ce: 0.011173
iteration 10285 : loss : 0.024712, loss_ce: 0.008488
iteration 10286 : loss : 0.028129, loss_ce: 0.004398
iteration 10287 : loss : 0.023660, loss_ce: 0.010564
iteration 10288 : loss : 0.025947, loss_ce: 0.010317
iteration 10289 : loss : 0.024260, loss_ce: 0.007139
iteration 10290 : loss : 0.020574, loss_ce: 0.008438
iteration 10291 : loss : 0.027898, loss_ce: 0.008285
iteration 10292 : loss : 0.029771, loss_ce: 0.012547
iteration 10293 : loss : 0.026097, loss_ce: 0.007082
iteration 10294 : loss : 0.026626, loss_ce: 0.005863
iteration 10295 : loss : 0.029120, loss_ce: 0.009762
iteration 10296 : loss : 0.026989, loss_ce: 0.008246
iteration 10297 : loss : 0.033756, loss_ce: 0.010042
iteration 10298 : loss : 0.021733, loss_ce: 0.006169
iteration 10299 : loss : 0.023341, loss_ce: 0.012013
iteration 10300 : loss : 0.028291, loss_ce: 0.014090
iteration 10301 : loss : 0.028800, loss_ce: 0.011158
iteration 10302 : loss : 0.021957, loss_ce: 0.008070
iteration 10303 : loss : 0.024221, loss_ce: 0.009449
iteration 10304 : loss : 0.026385, loss_ce: 0.011987
iteration 10305 : loss : 0.029982, loss_ce: 0.013228
iteration 10306 : loss : 0.022588, loss_ce: 0.007151
iteration 10307 : loss : 0.025239, loss_ce: 0.010005
iteration 10308 : loss : 0.023573, loss_ce: 0.011823
iteration 10309 : loss : 0.032674, loss_ce: 0.015917
iteration 10310 : loss : 0.043426, loss_ce: 0.006346
iteration 10311 : loss : 0.025251, loss_ce: 0.007023
iteration 10312 : loss : 0.027669, loss_ce: 0.004300
iteration 10313 : loss : 0.031648, loss_ce: 0.012324
iteration 10314 : loss : 0.027457, loss_ce: 0.009507
iteration 10315 : loss : 0.023745, loss_ce: 0.010618
iteration 10316 : loss : 0.024349, loss_ce: 0.011124
iteration 10317 : loss : 0.026264, loss_ce: 0.007664
iteration 10318 : loss : 0.019597, loss_ce: 0.004677
iteration 10319 : loss : 0.025068, loss_ce: 0.011194
iteration 10320 : loss : 0.023852, loss_ce: 0.008048
iteration 10321 : loss : 0.128109, loss_ce: 0.006754
iteration 10322 : loss : 0.021536, loss_ce: 0.005219
iteration 10323 : loss : 0.337456, loss_ce: 0.000869
 56%|██████████████▉            | 111/200 [1:54:00<1:31:18, 61.56s/it]iteration 10324 : loss : 0.027312, loss_ce: 0.005555
iteration 10325 : loss : 0.078400, loss_ce: 0.010385
iteration 10326 : loss : 0.031122, loss_ce: 0.009547
iteration 10327 : loss : 0.023245, loss_ce: 0.010232
iteration 10328 : loss : 0.028597, loss_ce: 0.011478
iteration 10329 : loss : 0.085340, loss_ce: 0.009923
iteration 10330 : loss : 0.024529, loss_ce: 0.009693
iteration 10331 : loss : 0.027521, loss_ce: 0.008621
iteration 10332 : loss : 0.030794, loss_ce: 0.012435
iteration 10333 : loss : 0.019791, loss_ce: 0.006582
iteration 10334 : loss : 0.024290, loss_ce: 0.008899
iteration 10335 : loss : 0.024813, loss_ce: 0.006731
iteration 10336 : loss : 0.026970, loss_ce: 0.010734
iteration 10337 : loss : 0.026693, loss_ce: 0.007706
iteration 10338 : loss : 0.026368, loss_ce: 0.004925
iteration 10339 : loss : 0.025678, loss_ce: 0.009098
iteration 10340 : loss : 0.028090, loss_ce: 0.009041
iteration 10341 : loss : 0.021656, loss_ce: 0.006462
iteration 10342 : loss : 0.028733, loss_ce: 0.009960
iteration 10343 : loss : 0.024897, loss_ce: 0.008028
iteration 10344 : loss : 0.027300, loss_ce: 0.011767
iteration 10345 : loss : 0.077481, loss_ce: 0.006861
iteration 10346 : loss : 0.027820, loss_ce: 0.010910
iteration 10347 : loss : 0.029227, loss_ce: 0.015093
iteration 10348 : loss : 0.029838, loss_ce: 0.011105
iteration 10349 : loss : 0.034999, loss_ce: 0.008621
iteration 10350 : loss : 0.023990, loss_ce: 0.007575
iteration 10351 : loss : 0.027002, loss_ce: 0.007963
iteration 10352 : loss : 0.023211, loss_ce: 0.010268
iteration 10353 : loss : 0.022055, loss_ce: 0.003239
iteration 10354 : loss : 0.073192, loss_ce: 0.005356
iteration 10355 : loss : 0.026224, loss_ce: 0.011404
iteration 10356 : loss : 0.075414, loss_ce: 0.003123
iteration 10357 : loss : 0.026439, loss_ce: 0.010695
iteration 10358 : loss : 0.026771, loss_ce: 0.008244
iteration 10359 : loss : 0.024630, loss_ce: 0.008300
iteration 10360 : loss : 0.025353, loss_ce: 0.011322
iteration 10361 : loss : 0.020664, loss_ce: 0.007054
iteration 10362 : loss : 0.031766, loss_ce: 0.013771
iteration 10363 : loss : 0.021389, loss_ce: 0.006003
iteration 10364 : loss : 0.048052, loss_ce: 0.009666
iteration 10365 : loss : 0.022269, loss_ce: 0.008344
iteration 10366 : loss : 0.031684, loss_ce: 0.006146
iteration 10367 : loss : 0.021639, loss_ce: 0.003695
iteration 10368 : loss : 0.022929, loss_ce: 0.007150
iteration 10369 : loss : 0.031912, loss_ce: 0.007865
iteration 10370 : loss : 0.033239, loss_ce: 0.009940
iteration 10371 : loss : 0.023547, loss_ce: 0.006713
iteration 10372 : loss : 0.034247, loss_ce: 0.009850
iteration 10373 : loss : 0.021430, loss_ce: 0.007437
iteration 10374 : loss : 0.022820, loss_ce: 0.006841
iteration 10375 : loss : 0.026831, loss_ce: 0.010158
iteration 10376 : loss : 0.023253, loss_ce: 0.009739
iteration 10377 : loss : 0.023650, loss_ce: 0.011232
iteration 10378 : loss : 0.024923, loss_ce: 0.010844
iteration 10379 : loss : 0.026081, loss_ce: 0.009079
iteration 10380 : loss : 0.031214, loss_ce: 0.006416
iteration 10381 : loss : 0.023431, loss_ce: 0.008679
iteration 10382 : loss : 0.029713, loss_ce: 0.009754
iteration 10383 : loss : 0.030195, loss_ce: 0.007786
iteration 10384 : loss : 0.075428, loss_ce: 0.004130
iteration 10385 : loss : 0.021517, loss_ce: 0.008265
iteration 10386 : loss : 0.027536, loss_ce: 0.009711
iteration 10387 : loss : 0.027924, loss_ce: 0.014286
iteration 10388 : loss : 0.026904, loss_ce: 0.010550
iteration 10389 : loss : 0.023187, loss_ce: 0.005634
iteration 10390 : loss : 0.028823, loss_ce: 0.006306
iteration 10391 : loss : 0.023835, loss_ce: 0.005909
iteration 10392 : loss : 0.080422, loss_ce: 0.009327
iteration 10393 : loss : 0.023928, loss_ce: 0.008955
iteration 10394 : loss : 0.024083, loss_ce: 0.009698
iteration 10395 : loss : 0.022086, loss_ce: 0.003518
iteration 10396 : loss : 0.026082, loss_ce: 0.009969
iteration 10397 : loss : 0.022855, loss_ce: 0.009869
iteration 10398 : loss : 0.024002, loss_ce: 0.007912
iteration 10399 : loss : 0.030125, loss_ce: 0.009093
iteration 10400 : loss : 0.022896, loss_ce: 0.005182
iteration 10401 : loss : 0.025402, loss_ce: 0.008861
iteration 10402 : loss : 0.079071, loss_ce: 0.005868
iteration 10403 : loss : 0.027043, loss_ce: 0.007267
iteration 10404 : loss : 0.027167, loss_ce: 0.011026
iteration 10405 : loss : 0.061314, loss_ce: 0.007645
iteration 10406 : loss : 0.024638, loss_ce: 0.005818
iteration 10407 : loss : 0.027056, loss_ce: 0.008669
iteration 10408 : loss : 0.023507, loss_ce: 0.008180
iteration 10409 : loss : 0.037704, loss_ce: 0.014422
iteration 10410 : loss : 0.027618, loss_ce: 0.008629
iteration 10411 : loss : 0.023472, loss_ce: 0.007911
iteration 10412 : loss : 0.029177, loss_ce: 0.011358
iteration 10413 : loss : 0.030139, loss_ce: 0.006969
iteration 10414 : loss : 0.020092, loss_ce: 0.007601
iteration 10415 : loss : 0.023415, loss_ce: 0.008114
iteration 10416 : loss : 0.033319, loss_ce: 0.018586
 56%|███████████████            | 112/200 [1:55:01<1:30:16, 61.55s/it]iteration 10417 : loss : 0.022054, loss_ce: 0.007718
iteration 10418 : loss : 0.026271, loss_ce: 0.007833
iteration 10419 : loss : 0.026980, loss_ce: 0.004984
iteration 10420 : loss : 0.075260, loss_ce: 0.004762
iteration 10421 : loss : 0.024567, loss_ce: 0.010042
iteration 10422 : loss : 0.078965, loss_ce: 0.005698
iteration 10423 : loss : 0.020215, loss_ce: 0.003957
iteration 10424 : loss : 0.026305, loss_ce: 0.008952
iteration 10425 : loss : 0.026797, loss_ce: 0.008049
iteration 10426 : loss : 0.027906, loss_ce: 0.006107
iteration 10427 : loss : 0.027376, loss_ce: 0.009309
iteration 10428 : loss : 0.025844, loss_ce: 0.008614
iteration 10429 : loss : 0.025247, loss_ce: 0.007466
iteration 10430 : loss : 0.020426, loss_ce: 0.004901
iteration 10431 : loss : 0.025665, loss_ce: 0.010006
iteration 10432 : loss : 0.024791, loss_ce: 0.006939
iteration 10433 : loss : 0.023785, loss_ce: 0.009661
iteration 10434 : loss : 0.023068, loss_ce: 0.010461
iteration 10435 : loss : 0.022696, loss_ce: 0.008056
iteration 10436 : loss : 0.026587, loss_ce: 0.008050
iteration 10437 : loss : 0.023766, loss_ce: 0.009058
iteration 10438 : loss : 0.023673, loss_ce: 0.007830
iteration 10439 : loss : 0.026786, loss_ce: 0.011880
iteration 10440 : loss : 0.052638, loss_ce: 0.005395
iteration 10441 : loss : 0.026597, loss_ce: 0.012002
iteration 10442 : loss : 0.030057, loss_ce: 0.010265
iteration 10443 : loss : 0.033759, loss_ce: 0.008853
iteration 10444 : loss : 0.029824, loss_ce: 0.010301
iteration 10445 : loss : 0.076938, loss_ce: 0.009089
iteration 10446 : loss : 0.026546, loss_ce: 0.010549
iteration 10447 : loss : 0.024118, loss_ce: 0.005531
iteration 10448 : loss : 0.021890, loss_ce: 0.008032
iteration 10449 : loss : 0.028806, loss_ce: 0.006547
iteration 10450 : loss : 0.029576, loss_ce: 0.008050
iteration 10451 : loss : 0.037558, loss_ce: 0.017598
iteration 10452 : loss : 0.025189, loss_ce: 0.011232
iteration 10453 : loss : 0.027237, loss_ce: 0.007462
iteration 10454 : loss : 0.030040, loss_ce: 0.015198
iteration 10455 : loss : 0.025404, loss_ce: 0.010507
iteration 10456 : loss : 0.031376, loss_ce: 0.010504
iteration 10457 : loss : 0.027380, loss_ce: 0.010917
iteration 10458 : loss : 0.028141, loss_ce: 0.011834
iteration 10459 : loss : 0.025354, loss_ce: 0.009718
iteration 10460 : loss : 0.027208, loss_ce: 0.010554
iteration 10461 : loss : 0.023474, loss_ce: 0.008032
iteration 10462 : loss : 0.025828, loss_ce: 0.006648
iteration 10463 : loss : 0.035272, loss_ce: 0.007707
iteration 10464 : loss : 0.026518, loss_ce: 0.008316
iteration 10465 : loss : 0.042073, loss_ce: 0.006821
iteration 10466 : loss : 0.025914, loss_ce: 0.008404
iteration 10467 : loss : 0.023827, loss_ce: 0.006892
iteration 10468 : loss : 0.023895, loss_ce: 0.007185
iteration 10469 : loss : 0.071474, loss_ce: 0.005455
iteration 10470 : loss : 0.039326, loss_ce: 0.013918
iteration 10471 : loss : 0.026511, loss_ce: 0.008896
iteration 10472 : loss : 0.028049, loss_ce: 0.010889
iteration 10473 : loss : 0.024181, loss_ce: 0.007769
iteration 10474 : loss : 0.030446, loss_ce: 0.011590
iteration 10475 : loss : 0.020747, loss_ce: 0.008375
iteration 10476 : loss : 0.027115, loss_ce: 0.009102
iteration 10477 : loss : 0.024071, loss_ce: 0.008088
iteration 10478 : loss : 0.028836, loss_ce: 0.008289
iteration 10479 : loss : 0.029794, loss_ce: 0.010989
iteration 10480 : loss : 0.080570, loss_ce: 0.007004
iteration 10481 : loss : 0.026212, loss_ce: 0.010628
iteration 10482 : loss : 0.027375, loss_ce: 0.009355
iteration 10483 : loss : 0.025757, loss_ce: 0.006005
iteration 10484 : loss : 0.075298, loss_ce: 0.006937
iteration 10485 : loss : 0.024380, loss_ce: 0.008892
iteration 10486 : loss : 0.022714, loss_ce: 0.009316
iteration 10487 : loss : 0.023028, loss_ce: 0.007587
iteration 10488 : loss : 0.027224, loss_ce: 0.006134
iteration 10489 : loss : 0.028717, loss_ce: 0.003041
iteration 10490 : loss : 0.026463, loss_ce: 0.012611
iteration 10491 : loss : 0.021051, loss_ce: 0.007383
iteration 10492 : loss : 0.022464, loss_ce: 0.007225
iteration 10493 : loss : 0.028140, loss_ce: 0.010738
iteration 10494 : loss : 0.042975, loss_ce: 0.009092
iteration 10495 : loss : 0.026849, loss_ce: 0.010435
iteration 10496 : loss : 0.030946, loss_ce: 0.014095
iteration 10497 : loss : 0.027842, loss_ce: 0.009609
iteration 10498 : loss : 0.055955, loss_ce: 0.008256
iteration 10499 : loss : 0.022856, loss_ce: 0.009379
iteration 10500 : loss : 0.027911, loss_ce: 0.006901
iteration 10501 : loss : 0.028573, loss_ce: 0.009680
iteration 10502 : loss : 0.028077, loss_ce: 0.011554
iteration 10503 : loss : 0.027555, loss_ce: 0.007164
iteration 10504 : loss : 0.028171, loss_ce: 0.011457
iteration 10505 : loss : 0.025273, loss_ce: 0.009941
iteration 10506 : loss : 0.071545, loss_ce: 0.008093
iteration 10507 : loss : 0.023364, loss_ce: 0.007079
iteration 10508 : loss : 0.025486, loss_ce: 0.005805
iteration 10509 : loss : 0.391815, loss_ce: 0.001268
 56%|███████████████▎           | 113/200 [1:56:03<1:29:16, 61.57s/it]iteration 10510 : loss : 0.022926, loss_ce: 0.009341
iteration 10511 : loss : 0.032994, loss_ce: 0.011195
iteration 10512 : loss : 0.026795, loss_ce: 0.010575
iteration 10513 : loss : 0.028036, loss_ce: 0.011711
iteration 10514 : loss : 0.077320, loss_ce: 0.006871
iteration 10515 : loss : 0.031315, loss_ce: 0.010678
iteration 10516 : loss : 0.025783, loss_ce: 0.006846
iteration 10517 : loss : 0.031799, loss_ce: 0.007760
iteration 10518 : loss : 0.022741, loss_ce: 0.007335
iteration 10519 : loss : 0.024128, loss_ce: 0.007867
iteration 10520 : loss : 0.077529, loss_ce: 0.009092
iteration 10521 : loss : 0.028815, loss_ce: 0.008657
iteration 10522 : loss : 0.032421, loss_ce: 0.009109
iteration 10523 : loss : 0.020250, loss_ce: 0.007549
iteration 10524 : loss : 0.021863, loss_ce: 0.008470
iteration 10525 : loss : 0.032884, loss_ce: 0.008157
iteration 10526 : loss : 0.028626, loss_ce: 0.007603
iteration 10527 : loss : 0.080996, loss_ce: 0.007815
iteration 10528 : loss : 0.027071, loss_ce: 0.009055
iteration 10529 : loss : 0.026757, loss_ce: 0.008614
iteration 10530 : loss : 0.030236, loss_ce: 0.011537
iteration 10531 : loss : 0.029562, loss_ce: 0.010409
iteration 10532 : loss : 0.024098, loss_ce: 0.009676
iteration 10533 : loss : 0.026603, loss_ce: 0.010094
iteration 10534 : loss : 0.075426, loss_ce: 0.006561
iteration 10535 : loss : 0.025210, loss_ce: 0.011445
iteration 10536 : loss : 0.021750, loss_ce: 0.007486
iteration 10537 : loss : 0.021428, loss_ce: 0.004124
iteration 10538 : loss : 0.023948, loss_ce: 0.009129
iteration 10539 : loss : 0.078829, loss_ce: 0.008399
iteration 10540 : loss : 0.027771, loss_ce: 0.007070
iteration 10541 : loss : 0.029744, loss_ce: 0.008406
iteration 10542 : loss : 0.021388, loss_ce: 0.005505
iteration 10543 : loss : 0.020933, loss_ce: 0.007056
iteration 10544 : loss : 0.028519, loss_ce: 0.008413
iteration 10545 : loss : 0.021782, loss_ce: 0.007436
iteration 10546 : loss : 0.022307, loss_ce: 0.009460
iteration 10547 : loss : 0.024796, loss_ce: 0.007748
iteration 10548 : loss : 0.025879, loss_ce: 0.009117
iteration 10549 : loss : 0.026043, loss_ce: 0.012355
iteration 10550 : loss : 0.023236, loss_ce: 0.009289
iteration 10551 : loss : 0.026700, loss_ce: 0.009561
iteration 10552 : loss : 0.031044, loss_ce: 0.010877
iteration 10553 : loss : 0.024977, loss_ce: 0.007646
iteration 10554 : loss : 0.021212, loss_ce: 0.004594
iteration 10555 : loss : 0.053648, loss_ce: 0.007146
iteration 10556 : loss : 0.026103, loss_ce: 0.010779
iteration 10557 : loss : 0.021331, loss_ce: 0.008184
iteration 10558 : loss : 0.083166, loss_ce: 0.006278
iteration 10559 : loss : 0.027638, loss_ce: 0.013775
iteration 10560 : loss : 0.029354, loss_ce: 0.010627
iteration 10561 : loss : 0.027783, loss_ce: 0.010703
iteration 10562 : loss : 0.020490, loss_ce: 0.006376
iteration 10563 : loss : 0.027553, loss_ce: 0.010464
iteration 10564 : loss : 0.022955, loss_ce: 0.006802
iteration 10565 : loss : 0.031753, loss_ce: 0.011317
iteration 10566 : loss : 0.024305, loss_ce: 0.011826
iteration 10567 : loss : 0.028491, loss_ce: 0.008057
iteration 10568 : loss : 0.028161, loss_ce: 0.006877
iteration 10569 : loss : 0.030124, loss_ce: 0.010253
iteration 10570 : loss : 0.033917, loss_ce: 0.011883
iteration 10571 : loss : 0.020465, loss_ce: 0.006329
iteration 10572 : loss : 0.024965, loss_ce: 0.008017
iteration 10573 : loss : 0.073840, loss_ce: 0.003974
iteration 10574 : loss : 0.031972, loss_ce: 0.007854
iteration 10575 : loss : 0.024802, loss_ce: 0.008893
iteration 10576 : loss : 0.034990, loss_ce: 0.013022
iteration 10577 : loss : 0.022561, loss_ce: 0.008593
iteration 10578 : loss : 0.031120, loss_ce: 0.008051
iteration 10579 : loss : 0.026122, loss_ce: 0.012118
iteration 10580 : loss : 0.023143, loss_ce: 0.007429
iteration 10581 : loss : 0.031013, loss_ce: 0.005959
iteration 10582 : loss : 0.027593, loss_ce: 0.004753
iteration 10583 : loss : 0.027398, loss_ce: 0.011795
iteration 10584 : loss : 0.030155, loss_ce: 0.009602
iteration 10585 : loss : 0.022630, loss_ce: 0.008562
iteration 10586 : loss : 0.031064, loss_ce: 0.009626
iteration 10587 : loss : 0.029062, loss_ce: 0.009693
iteration 10588 : loss : 0.023076, loss_ce: 0.009476
iteration 10589 : loss : 0.030491, loss_ce: 0.010884
iteration 10590 : loss : 0.077324, loss_ce: 0.010344
iteration 10591 : loss : 0.028853, loss_ce: 0.011149
iteration 10592 : loss : 0.023978, loss_ce: 0.009029
iteration 10593 : loss : 0.031467, loss_ce: 0.010766
iteration 10594 : loss : 0.024020, loss_ce: 0.008035
iteration 10595 : loss : 0.032929, loss_ce: 0.006814
iteration 10596 : loss : 0.026552, loss_ce: 0.008384
iteration 10597 : loss : 0.026174, loss_ce: 0.007884
iteration 10598 : loss : 0.027044, loss_ce: 0.017191
iteration 10599 : loss : 0.021439, loss_ce: 0.006561
iteration 10600 : loss : 0.030530, loss_ce: 0.008083
iteration 10601 : loss : 0.032184, loss_ce: 0.009231
iteration 10602 : loss : 0.284170, loss_ce: 0.003009
 57%|███████████████▍           | 114/200 [1:57:04<1:28:15, 61.58s/it]iteration 10603 : loss : 0.023464, loss_ce: 0.011309
iteration 10604 : loss : 0.024357, loss_ce: 0.007237
iteration 10605 : loss : 0.023520, loss_ce: 0.007604
iteration 10606 : loss : 0.026302, loss_ce: 0.011154
iteration 10607 : loss : 0.031279, loss_ce: 0.015055
iteration 10608 : loss : 0.024927, loss_ce: 0.008381
iteration 10609 : loss : 0.025094, loss_ce: 0.008002
iteration 10610 : loss : 0.021953, loss_ce: 0.011575
iteration 10611 : loss : 0.023948, loss_ce: 0.004851
iteration 10612 : loss : 0.025196, loss_ce: 0.010664
iteration 10613 : loss : 0.032336, loss_ce: 0.006845
iteration 10614 : loss : 0.024068, loss_ce: 0.007347
iteration 10615 : loss : 0.027661, loss_ce: 0.011338
iteration 10616 : loss : 0.031413, loss_ce: 0.009339
iteration 10617 : loss : 0.035684, loss_ce: 0.011011
iteration 10618 : loss : 0.080222, loss_ce: 0.009969
iteration 10619 : loss : 0.083439, loss_ce: 0.004519
iteration 10620 : loss : 0.021791, loss_ce: 0.007620
iteration 10621 : loss : 0.072828, loss_ce: 0.005079
iteration 10622 : loss : 0.027960, loss_ce: 0.008059
iteration 10623 : loss : 0.025952, loss_ce: 0.007255
iteration 10624 : loss : 0.034060, loss_ce: 0.006949
iteration 10625 : loss : 0.025888, loss_ce: 0.009787
iteration 10626 : loss : 0.028227, loss_ce: 0.013499
iteration 10627 : loss : 0.075471, loss_ce: 0.005043
iteration 10628 : loss : 0.020386, loss_ce: 0.006641
iteration 10629 : loss : 0.073812, loss_ce: 0.005702
iteration 10630 : loss : 0.030046, loss_ce: 0.007881
iteration 10631 : loss : 0.025609, loss_ce: 0.010609
iteration 10632 : loss : 0.025846, loss_ce: 0.008376
iteration 10633 : loss : 0.033430, loss_ce: 0.009340
iteration 10634 : loss : 0.021862, loss_ce: 0.007134
iteration 10635 : loss : 0.028291, loss_ce: 0.011863
iteration 10636 : loss : 0.023817, loss_ce: 0.006641
iteration 10637 : loss : 0.023243, loss_ce: 0.007010
iteration 10638 : loss : 0.026382, loss_ce: 0.009564
iteration 10639 : loss : 0.024678, loss_ce: 0.009077
iteration 10640 : loss : 0.027704, loss_ce: 0.011314
iteration 10641 : loss : 0.026673, loss_ce: 0.008793
iteration 10642 : loss : 0.028964, loss_ce: 0.007212
iteration 10643 : loss : 0.026346, loss_ce: 0.010872
iteration 10644 : loss : 0.024987, loss_ce: 0.008546
iteration 10645 : loss : 0.032720, loss_ce: 0.015851
iteration 10646 : loss : 0.073509, loss_ce: 0.006112
iteration 10647 : loss : 0.023353, loss_ce: 0.007799
iteration 10648 : loss : 0.025545, loss_ce: 0.008488
iteration 10649 : loss : 0.019788, loss_ce: 0.006057
iteration 10650 : loss : 0.018339, loss_ce: 0.005241
iteration 10651 : loss : 0.025374, loss_ce: 0.010872
iteration 10652 : loss : 0.023899, loss_ce: 0.007766
iteration 10653 : loss : 0.028224, loss_ce: 0.010792
iteration 10654 : loss : 0.022980, loss_ce: 0.009669
iteration 10655 : loss : 0.022682, loss_ce: 0.008056
iteration 10656 : loss : 0.035032, loss_ce: 0.007738
iteration 10657 : loss : 0.033028, loss_ce: 0.011853
iteration 10658 : loss : 0.023686, loss_ce: 0.007772
iteration 10659 : loss : 0.038081, loss_ce: 0.007139
iteration 10660 : loss : 0.081952, loss_ce: 0.006439
iteration 10661 : loss : 0.025210, loss_ce: 0.006986
iteration 10662 : loss : 0.077249, loss_ce: 0.010001
iteration 10663 : loss : 0.031482, loss_ce: 0.012440
iteration 10664 : loss : 0.029226, loss_ce: 0.010003
iteration 10665 : loss : 0.027009, loss_ce: 0.013041
iteration 10666 : loss : 0.020501, loss_ce: 0.004820
iteration 10667 : loss : 0.023299, loss_ce: 0.007559
iteration 10668 : loss : 0.032148, loss_ce: 0.005291
iteration 10669 : loss : 0.024184, loss_ce: 0.007043
iteration 10670 : loss : 0.027430, loss_ce: 0.007944
iteration 10671 : loss : 0.025458, loss_ce: 0.009682
iteration 10672 : loss : 0.023351, loss_ce: 0.007350
iteration 10673 : loss : 0.025152, loss_ce: 0.009811
iteration 10674 : loss : 0.029537, loss_ce: 0.007124
iteration 10675 : loss : 0.025700, loss_ce: 0.011326
iteration 10676 : loss : 0.076460, loss_ce: 0.003668
iteration 10677 : loss : 0.024785, loss_ce: 0.009773
iteration 10678 : loss : 0.032087, loss_ce: 0.013022
iteration 10679 : loss : 0.025482, loss_ce: 0.007274
iteration 10680 : loss : 0.026659, loss_ce: 0.006898
iteration 10681 : loss : 0.023255, loss_ce: 0.008594
iteration 10682 : loss : 0.027654, loss_ce: 0.004382
iteration 10683 : loss : 0.028828, loss_ce: 0.008789
iteration 10684 : loss : 0.027994, loss_ce: 0.006820
iteration 10685 : loss : 0.023094, loss_ce: 0.008594
iteration 10686 : loss : 0.032524, loss_ce: 0.007142
iteration 10687 : loss : 0.027384, loss_ce: 0.014296
iteration 10688 : loss : 0.029162, loss_ce: 0.013225
iteration 10689 : loss : 0.077451, loss_ce: 0.004450
iteration 10690 : loss : 0.028738, loss_ce: 0.008676
iteration 10691 : loss : 0.028185, loss_ce: 0.014293
iteration 10692 : loss : 0.025630, loss_ce: 0.005627
iteration 10693 : loss : 0.039770, loss_ce: 0.006914
iteration 10694 : loss : 0.025657, loss_ce: 0.008172
iteration 10695 : loss : 0.263366, loss_ce: 0.002311
 57%|███████████████▌           | 115/200 [1:58:06<1:27:13, 61.57s/it]iteration 10696 : loss : 0.073318, loss_ce: 0.006815
iteration 10697 : loss : 0.028049, loss_ce: 0.010888
iteration 10698 : loss : 0.023066, loss_ce: 0.009280
iteration 10699 : loss : 0.034005, loss_ce: 0.014249
iteration 10700 : loss : 0.030428, loss_ce: 0.011274
iteration 10701 : loss : 0.081759, loss_ce: 0.008522
iteration 10702 : loss : 0.079418, loss_ce: 0.014783
iteration 10703 : loss : 0.035565, loss_ce: 0.017598
iteration 10704 : loss : 0.025068, loss_ce: 0.012457
iteration 10705 : loss : 0.027210, loss_ce: 0.013378
iteration 10706 : loss : 0.036465, loss_ce: 0.010198
iteration 10707 : loss : 0.084765, loss_ce: 0.011726
iteration 10708 : loss : 0.042395, loss_ce: 0.009474
iteration 10709 : loss : 0.020927, loss_ce: 0.005323
iteration 10710 : loss : 0.079157, loss_ce: 0.006649
iteration 10711 : loss : 0.029026, loss_ce: 0.011300
iteration 10712 : loss : 0.046498, loss_ce: 0.013471
iteration 10713 : loss : 0.024273, loss_ce: 0.010716
iteration 10714 : loss : 0.025139, loss_ce: 0.010243
iteration 10715 : loss : 0.026203, loss_ce: 0.006845
iteration 10716 : loss : 0.030295, loss_ce: 0.009971
iteration 10717 : loss : 0.028815, loss_ce: 0.010442
iteration 10718 : loss : 0.028569, loss_ce: 0.008929
iteration 10719 : loss : 0.029905, loss_ce: 0.011355
iteration 10720 : loss : 0.024445, loss_ce: 0.007985
iteration 10721 : loss : 0.025800, loss_ce: 0.013847
iteration 10722 : loss : 0.021924, loss_ce: 0.010253
iteration 10723 : loss : 0.032110, loss_ce: 0.013451
iteration 10724 : loss : 0.025065, loss_ce: 0.007221
iteration 10725 : loss : 0.024618, loss_ce: 0.013413
iteration 10726 : loss : 0.033350, loss_ce: 0.006426
iteration 10727 : loss : 0.027229, loss_ce: 0.009921
iteration 10728 : loss : 0.076028, loss_ce: 0.005540
iteration 10729 : loss : 0.024599, loss_ce: 0.009196
iteration 10730 : loss : 0.028187, loss_ce: 0.008297
iteration 10731 : loss : 0.026112, loss_ce: 0.011171
iteration 10732 : loss : 0.078656, loss_ce: 0.008542
iteration 10733 : loss : 0.020653, loss_ce: 0.007273
iteration 10734 : loss : 0.028375, loss_ce: 0.011383
iteration 10735 : loss : 0.026643, loss_ce: 0.009711
iteration 10736 : loss : 0.027069, loss_ce: 0.010218
iteration 10737 : loss : 0.027820, loss_ce: 0.007509
iteration 10738 : loss : 0.049303, loss_ce: 0.010899
iteration 10739 : loss : 0.024282, loss_ce: 0.009488
iteration 10740 : loss : 0.024290, loss_ce: 0.008965
iteration 10741 : loss : 0.028069, loss_ce: 0.009335
iteration 10742 : loss : 0.028757, loss_ce: 0.012177
iteration 10743 : loss : 0.026196, loss_ce: 0.010819
iteration 10744 : loss : 0.024913, loss_ce: 0.006460
iteration 10745 : loss : 0.028623, loss_ce: 0.012748
iteration 10746 : loss : 0.026014, loss_ce: 0.009488
iteration 10747 : loss : 0.033420, loss_ce: 0.009755
iteration 10748 : loss : 0.034110, loss_ce: 0.007535
iteration 10749 : loss : 0.032618, loss_ce: 0.007870
iteration 10750 : loss : 0.030293, loss_ce: 0.007845
iteration 10751 : loss : 0.022707, loss_ce: 0.007348
iteration 10752 : loss : 0.029728, loss_ce: 0.008498
iteration 10753 : loss : 0.028382, loss_ce: 0.012956
iteration 10754 : loss : 0.027205, loss_ce: 0.007871
iteration 10755 : loss : 0.027794, loss_ce: 0.009921
iteration 10756 : loss : 0.028815, loss_ce: 0.017804
iteration 10757 : loss : 0.027441, loss_ce: 0.005738
iteration 10758 : loss : 0.026332, loss_ce: 0.010681
iteration 10759 : loss : 0.023829, loss_ce: 0.008553
iteration 10760 : loss : 0.027716, loss_ce: 0.004899
iteration 10761 : loss : 0.022659, loss_ce: 0.009559
iteration 10762 : loss : 0.020346, loss_ce: 0.008368
iteration 10763 : loss : 0.025599, loss_ce: 0.008228
iteration 10764 : loss : 0.027563, loss_ce: 0.010679
iteration 10765 : loss : 0.028338, loss_ce: 0.008396
iteration 10766 : loss : 0.025999, loss_ce: 0.005148
iteration 10767 : loss : 0.025200, loss_ce: 0.010148
iteration 10768 : loss : 0.030445, loss_ce: 0.007219
iteration 10769 : loss : 0.018944, loss_ce: 0.005509
iteration 10770 : loss : 0.026736, loss_ce: 0.010249
iteration 10771 : loss : 0.023511, loss_ce: 0.008108
iteration 10772 : loss : 0.073066, loss_ce: 0.004931
iteration 10773 : loss : 0.025124, loss_ce: 0.004587
iteration 10774 : loss : 0.027183, loss_ce: 0.008401
iteration 10775 : loss : 0.081775, loss_ce: 0.008420
iteration 10776 : loss : 0.040441, loss_ce: 0.009592
iteration 10777 : loss : 0.026813, loss_ce: 0.011544
iteration 10778 : loss : 0.025247, loss_ce: 0.010362
iteration 10779 : loss : 0.022534, loss_ce: 0.011431
iteration 10780 : loss : 0.032297, loss_ce: 0.006593
iteration 10781 : loss : 0.022223, loss_ce: 0.008581
iteration 10782 : loss : 0.028412, loss_ce: 0.009841
iteration 10783 : loss : 0.073826, loss_ce: 0.007094
iteration 10784 : loss : 0.023069, loss_ce: 0.011035
iteration 10785 : loss : 0.026295, loss_ce: 0.009287
iteration 10786 : loss : 0.027669, loss_ce: 0.011846
iteration 10787 : loss : 0.024452, loss_ce: 0.006058
iteration 10788 : loss : 0.087678, loss_ce: 0.008402
 58%|███████████████▋           | 116/200 [1:59:08<1:26:13, 61.58s/it]iteration 10789 : loss : 0.024130, loss_ce: 0.007679
iteration 10790 : loss : 0.023077, loss_ce: 0.010569
iteration 10791 : loss : 0.032586, loss_ce: 0.010246
iteration 10792 : loss : 0.024637, loss_ce: 0.009621
iteration 10793 : loss : 0.025711, loss_ce: 0.005019
iteration 10794 : loss : 0.026736, loss_ce: 0.006181
iteration 10795 : loss : 0.024163, loss_ce: 0.007351
iteration 10796 : loss : 0.027135, loss_ce: 0.009098
iteration 10797 : loss : 0.025206, loss_ce: 0.008836
iteration 10798 : loss : 0.026684, loss_ce: 0.009201
iteration 10799 : loss : 0.030973, loss_ce: 0.017800
iteration 10800 : loss : 0.027830, loss_ce: 0.008323
iteration 10801 : loss : 0.030069, loss_ce: 0.013375
iteration 10802 : loss : 0.022137, loss_ce: 0.008557
iteration 10803 : loss : 0.026678, loss_ce: 0.006451
iteration 10804 : loss : 0.025866, loss_ce: 0.009854
iteration 10805 : loss : 0.028651, loss_ce: 0.006330
iteration 10806 : loss : 0.024328, loss_ce: 0.009650
iteration 10807 : loss : 0.026639, loss_ce: 0.009252
iteration 10808 : loss : 0.022406, loss_ce: 0.008504
iteration 10809 : loss : 0.028220, loss_ce: 0.006176
iteration 10810 : loss : 0.023222, loss_ce: 0.007147
iteration 10811 : loss : 0.028573, loss_ce: 0.007762
iteration 10812 : loss : 0.029830, loss_ce: 0.010595
iteration 10813 : loss : 0.075013, loss_ce: 0.005097
iteration 10814 : loss : 0.026279, loss_ce: 0.013153
iteration 10815 : loss : 0.025520, loss_ce: 0.008151
iteration 10816 : loss : 0.026544, loss_ce: 0.008617
iteration 10817 : loss : 0.023262, loss_ce: 0.008279
iteration 10818 : loss : 0.033947, loss_ce: 0.014719
iteration 10819 : loss : 0.021398, loss_ce: 0.004314
iteration 10820 : loss : 0.027360, loss_ce: 0.011289
iteration 10821 : loss : 0.025555, loss_ce: 0.008925
iteration 10822 : loss : 0.021349, loss_ce: 0.008370
iteration 10823 : loss : 0.028927, loss_ce: 0.011060
iteration 10824 : loss : 0.032473, loss_ce: 0.008165
iteration 10825 : loss : 0.027112, loss_ce: 0.009576
iteration 10826 : loss : 0.030369, loss_ce: 0.005728
iteration 10827 : loss : 0.020443, loss_ce: 0.005791
iteration 10828 : loss : 0.029891, loss_ce: 0.010861
iteration 10829 : loss : 0.021819, loss_ce: 0.006151
iteration 10830 : loss : 0.022432, loss_ce: 0.006912
iteration 10831 : loss : 0.024584, loss_ce: 0.009172
iteration 10832 : loss : 0.025219, loss_ce: 0.009035
iteration 10833 : loss : 0.082771, loss_ce: 0.004743
iteration 10834 : loss : 0.075347, loss_ce: 0.008563
iteration 10835 : loss : 0.024286, loss_ce: 0.008470
iteration 10836 : loss : 0.019602, loss_ce: 0.006907
iteration 10837 : loss : 0.022975, loss_ce: 0.008925
iteration 10838 : loss : 0.023678, loss_ce: 0.007375
iteration 10839 : loss : 0.027426, loss_ce: 0.008110
iteration 10840 : loss : 0.023038, loss_ce: 0.009255
iteration 10841 : loss : 0.023208, loss_ce: 0.009577
iteration 10842 : loss : 0.023246, loss_ce: 0.008401
iteration 10843 : loss : 0.022303, loss_ce: 0.007948
iteration 10844 : loss : 0.023209, loss_ce: 0.005633
iteration 10845 : loss : 0.028822, loss_ce: 0.004722
iteration 10846 : loss : 0.028706, loss_ce: 0.007363
iteration 10847 : loss : 0.023680, loss_ce: 0.008048
iteration 10848 : loss : 0.031932, loss_ce: 0.008449
iteration 10849 : loss : 0.026017, loss_ce: 0.008625
iteration 10850 : loss : 0.029095, loss_ce: 0.010169
iteration 10851 : loss : 0.029991, loss_ce: 0.011315
iteration 10852 : loss : 0.025003, loss_ce: 0.009663
iteration 10853 : loss : 0.025717, loss_ce: 0.008995
iteration 10854 : loss : 0.026026, loss_ce: 0.006488
iteration 10855 : loss : 0.021490, loss_ce: 0.007423
iteration 10856 : loss : 0.025719, loss_ce: 0.012345
iteration 10857 : loss : 0.076489, loss_ce: 0.008985
iteration 10858 : loss : 0.026535, loss_ce: 0.010080
iteration 10859 : loss : 0.025178, loss_ce: 0.007011
iteration 10860 : loss : 0.026190, loss_ce: 0.006158
iteration 10861 : loss : 0.025811, loss_ce: 0.008529
iteration 10862 : loss : 0.022507, loss_ce: 0.008252
iteration 10863 : loss : 0.026526, loss_ce: 0.007357
iteration 10864 : loss : 0.025436, loss_ce: 0.009916
iteration 10865 : loss : 0.023930, loss_ce: 0.008712
iteration 10866 : loss : 0.024606, loss_ce: 0.009655
iteration 10867 : loss : 0.026766, loss_ce: 0.008593
iteration 10868 : loss : 0.030767, loss_ce: 0.008543
iteration 10869 : loss : 0.024960, loss_ce: 0.005484
iteration 10870 : loss : 0.028829, loss_ce: 0.008408
iteration 10871 : loss : 0.023425, loss_ce: 0.009144
iteration 10872 : loss : 0.030927, loss_ce: 0.008379
iteration 10873 : loss : 0.027614, loss_ce: 0.007704
iteration 10874 : loss : 0.019750, loss_ce: 0.005532
iteration 10875 : loss : 0.022234, loss_ce: 0.010234
iteration 10876 : loss : 0.076245, loss_ce: 0.007505
iteration 10877 : loss : 0.024420, loss_ce: 0.011540
iteration 10878 : loss : 0.024087, loss_ce: 0.009360
iteration 10879 : loss : 0.024790, loss_ce: 0.008534
iteration 10880 : loss : 0.023539, loss_ce: 0.007962
iteration 10881 : loss : 0.441459, loss_ce: 0.000277
 58%|███████████████▊           | 117/200 [2:00:09<1:25:09, 61.56s/it]iteration 10882 : loss : 0.026693, loss_ce: 0.009914
iteration 10883 : loss : 0.028000, loss_ce: 0.007582
iteration 10884 : loss : 0.025750, loss_ce: 0.008151
iteration 10885 : loss : 0.025558, loss_ce: 0.004944
iteration 10886 : loss : 0.023752, loss_ce: 0.006201
iteration 10887 : loss : 0.047959, loss_ce: 0.010832
iteration 10888 : loss : 0.020478, loss_ce: 0.002887
iteration 10889 : loss : 0.022312, loss_ce: 0.007451
iteration 10890 : loss : 0.027127, loss_ce: 0.007281
iteration 10891 : loss : 0.024390, loss_ce: 0.006735
iteration 10892 : loss : 0.078907, loss_ce: 0.005588
iteration 10893 : loss : 0.024784, loss_ce: 0.010424
iteration 10894 : loss : 0.027521, loss_ce: 0.009606
iteration 10895 : loss : 0.024072, loss_ce: 0.007689
iteration 10896 : loss : 0.038240, loss_ce: 0.008932
iteration 10897 : loss : 0.019829, loss_ce: 0.005227
iteration 10898 : loss : 0.026918, loss_ce: 0.011174
iteration 10899 : loss : 0.023718, loss_ce: 0.011417
iteration 10900 : loss : 0.025157, loss_ce: 0.007831
iteration 10901 : loss : 0.023949, loss_ce: 0.006887
iteration 10902 : loss : 0.084723, loss_ce: 0.008464
iteration 10903 : loss : 0.026343, loss_ce: 0.010867
iteration 10904 : loss : 0.033843, loss_ce: 0.009749
iteration 10905 : loss : 0.032455, loss_ce: 0.006807
iteration 10906 : loss : 0.021488, loss_ce: 0.008038
iteration 10907 : loss : 0.023772, loss_ce: 0.004799
iteration 10908 : loss : 0.026503, loss_ce: 0.010220
iteration 10909 : loss : 0.018890, loss_ce: 0.007567
iteration 10910 : loss : 0.024534, loss_ce: 0.006361
iteration 10911 : loss : 0.023801, loss_ce: 0.008621
iteration 10912 : loss : 0.027331, loss_ce: 0.012581
iteration 10913 : loss : 0.025575, loss_ce: 0.011141
iteration 10914 : loss : 0.026068, loss_ce: 0.009354
iteration 10915 : loss : 0.122556, loss_ce: 0.002378
iteration 10916 : loss : 0.028823, loss_ce: 0.009406
iteration 10917 : loss : 0.022178, loss_ce: 0.004366
iteration 10918 : loss : 0.021896, loss_ce: 0.006338
iteration 10919 : loss : 0.026169, loss_ce: 0.011207
iteration 10920 : loss : 0.023319, loss_ce: 0.005170
iteration 10921 : loss : 0.029577, loss_ce: 0.010457
iteration 10922 : loss : 0.032513, loss_ce: 0.006133
iteration 10923 : loss : 0.022261, loss_ce: 0.008024
iteration 10924 : loss : 0.022499, loss_ce: 0.007494
iteration 10925 : loss : 0.025571, loss_ce: 0.007150
iteration 10926 : loss : 0.024393, loss_ce: 0.007393
iteration 10927 : loss : 0.020890, loss_ce: 0.003564
iteration 10928 : loss : 0.024326, loss_ce: 0.011500
iteration 10929 : loss : 0.022410, loss_ce: 0.007414
iteration 10930 : loss : 0.027829, loss_ce: 0.011544
iteration 10931 : loss : 0.030792, loss_ce: 0.007983
iteration 10932 : loss : 0.022958, loss_ce: 0.009756
iteration 10933 : loss : 0.022515, loss_ce: 0.008831
iteration 10934 : loss : 0.024407, loss_ce: 0.006550
iteration 10935 : loss : 0.035228, loss_ce: 0.008223
iteration 10936 : loss : 0.026371, loss_ce: 0.006460
iteration 10937 : loss : 0.027752, loss_ce: 0.011003
iteration 10938 : loss : 0.028126, loss_ce: 0.009411
iteration 10939 : loss : 0.021950, loss_ce: 0.010096
iteration 10940 : loss : 0.023688, loss_ce: 0.008127
iteration 10941 : loss : 0.022234, loss_ce: 0.006509
iteration 10942 : loss : 0.024318, loss_ce: 0.006944
iteration 10943 : loss : 0.026344, loss_ce: 0.008977
iteration 10944 : loss : 0.026481, loss_ce: 0.009835
iteration 10945 : loss : 0.027929, loss_ce: 0.014541
iteration 10946 : loss : 0.029701, loss_ce: 0.009996
iteration 10947 : loss : 0.023395, loss_ce: 0.007830
iteration 10948 : loss : 0.029801, loss_ce: 0.003412
iteration 10949 : loss : 0.023162, loss_ce: 0.007568
iteration 10950 : loss : 0.022478, loss_ce: 0.006118
iteration 10951 : loss : 0.024332, loss_ce: 0.007804
iteration 10952 : loss : 0.026442, loss_ce: 0.009432
iteration 10953 : loss : 0.019818, loss_ce: 0.007206
iteration 10954 : loss : 0.029171, loss_ce: 0.008286
iteration 10955 : loss : 0.026578, loss_ce: 0.011662
iteration 10956 : loss : 0.020840, loss_ce: 0.006390
iteration 10957 : loss : 0.021716, loss_ce: 0.010320
iteration 10958 : loss : 0.021898, loss_ce: 0.008808
iteration 10959 : loss : 0.028831, loss_ce: 0.010533
iteration 10960 : loss : 0.029842, loss_ce: 0.010536
iteration 10961 : loss : 0.026386, loss_ce: 0.008453
iteration 10962 : loss : 0.070248, loss_ce: 0.005213
iteration 10963 : loss : 0.026850, loss_ce: 0.013364
iteration 10964 : loss : 0.025687, loss_ce: 0.008756
iteration 10965 : loss : 0.025803, loss_ce: 0.014983
iteration 10966 : loss : 0.032201, loss_ce: 0.012336
iteration 10967 : loss : 0.074053, loss_ce: 0.003459
iteration 10968 : loss : 0.029361, loss_ce: 0.014257
iteration 10969 : loss : 0.022881, loss_ce: 0.009388
iteration 10970 : loss : 0.023159, loss_ce: 0.011475
iteration 10971 : loss : 0.030120, loss_ce: 0.011154
iteration 10972 : loss : 0.025946, loss_ce: 0.005909
iteration 10973 : loss : 0.025890, loss_ce: 0.009635
iteration 10974 : loss : 0.037939, loss_ce: 0.005937
 59%|███████████████▉           | 118/200 [2:01:11<1:24:10, 61.59s/it]iteration 10975 : loss : 0.022309, loss_ce: 0.005243
iteration 10976 : loss : 0.058285, loss_ce: 0.008307
iteration 10977 : loss : 0.027553, loss_ce: 0.005670
iteration 10978 : loss : 0.031859, loss_ce: 0.008166
iteration 10979 : loss : 0.027186, loss_ce: 0.009463
iteration 10980 : loss : 0.023813, loss_ce: 0.009237
iteration 10981 : loss : 0.028634, loss_ce: 0.010291
iteration 10982 : loss : 0.025443, loss_ce: 0.006462
iteration 10983 : loss : 0.024537, loss_ce: 0.008084
iteration 10984 : loss : 0.028785, loss_ce: 0.009297
iteration 10985 : loss : 0.024537, loss_ce: 0.007880
iteration 10986 : loss : 0.022385, loss_ce: 0.007841
iteration 10987 : loss : 0.025198, loss_ce: 0.007637
iteration 10988 : loss : 0.024720, loss_ce: 0.008026
iteration 10989 : loss : 0.023211, loss_ce: 0.009848
iteration 10990 : loss : 0.027283, loss_ce: 0.011044
iteration 10991 : loss : 0.022860, loss_ce: 0.006179
iteration 10992 : loss : 0.026606, loss_ce: 0.012166
iteration 10993 : loss : 0.022826, loss_ce: 0.006267
iteration 10994 : loss : 0.025303, loss_ce: 0.010778
iteration 10995 : loss : 0.029013, loss_ce: 0.009974
iteration 10996 : loss : 0.026790, loss_ce: 0.010217
iteration 10997 : loss : 0.025335, loss_ce: 0.010805
iteration 10998 : loss : 0.024276, loss_ce: 0.006430
iteration 10999 : loss : 0.019551, loss_ce: 0.007983
iteration 11000 : loss : 0.030276, loss_ce: 0.009698
iteration 11001 : loss : 0.021204, loss_ce: 0.006795
iteration 11002 : loss : 0.021654, loss_ce: 0.010336
iteration 11003 : loss : 0.024097, loss_ce: 0.010627
iteration 11004 : loss : 0.022221, loss_ce: 0.010314
iteration 11005 : loss : 0.021887, loss_ce: 0.006876
iteration 11006 : loss : 0.027084, loss_ce: 0.008564
iteration 11007 : loss : 0.026038, loss_ce: 0.008313
iteration 11008 : loss : 0.073400, loss_ce: 0.004794
iteration 11009 : loss : 0.024843, loss_ce: 0.008576
iteration 11010 : loss : 0.026167, loss_ce: 0.009823
iteration 11011 : loss : 0.026034, loss_ce: 0.010842
iteration 11012 : loss : 0.022712, loss_ce: 0.011872
iteration 11013 : loss : 0.028676, loss_ce: 0.012236
iteration 11014 : loss : 0.022411, loss_ce: 0.009440
iteration 11015 : loss : 0.025320, loss_ce: 0.011270
iteration 11016 : loss : 0.026125, loss_ce: 0.006938
iteration 11017 : loss : 0.024305, loss_ce: 0.011283
iteration 11018 : loss : 0.026497, loss_ce: 0.006623
iteration 11019 : loss : 0.075854, loss_ce: 0.009270
iteration 11020 : loss : 0.026418, loss_ce: 0.006191
iteration 11021 : loss : 0.055512, loss_ce: 0.004847
iteration 11022 : loss : 0.019385, loss_ce: 0.004776
iteration 11023 : loss : 0.022362, loss_ce: 0.008093
iteration 11024 : loss : 0.022204, loss_ce: 0.008479
iteration 11025 : loss : 0.023331, loss_ce: 0.007766
iteration 11026 : loss : 0.036030, loss_ce: 0.012224
iteration 11027 : loss : 0.052108, loss_ce: 0.007489
iteration 11028 : loss : 0.023881, loss_ce: 0.007551
iteration 11029 : loss : 0.024517, loss_ce: 0.008384
iteration 11030 : loss : 0.029590, loss_ce: 0.007543
iteration 11031 : loss : 0.021780, loss_ce: 0.006532
iteration 11032 : loss : 0.026631, loss_ce: 0.012109
iteration 11033 : loss : 0.020450, loss_ce: 0.010103
iteration 11034 : loss : 0.073650, loss_ce: 0.005788
iteration 11035 : loss : 0.024676, loss_ce: 0.008341
iteration 11036 : loss : 0.023281, loss_ce: 0.007224
iteration 11037 : loss : 0.025595, loss_ce: 0.009951
iteration 11038 : loss : 0.025743, loss_ce: 0.006570
iteration 11039 : loss : 0.030617, loss_ce: 0.006849
iteration 11040 : loss : 0.024405, loss_ce: 0.009061
iteration 11041 : loss : 0.029886, loss_ce: 0.013982
iteration 11042 : loss : 0.027037, loss_ce: 0.012459
iteration 11043 : loss : 0.027470, loss_ce: 0.009954
iteration 11044 : loss : 0.029156, loss_ce: 0.006643
iteration 11045 : loss : 0.121983, loss_ce: 0.005194
iteration 11046 : loss : 0.026108, loss_ce: 0.008577
iteration 11047 : loss : 0.026009, loss_ce: 0.008234
iteration 11048 : loss : 0.032207, loss_ce: 0.010994
iteration 11049 : loss : 0.027869, loss_ce: 0.006470
iteration 11050 : loss : 0.028366, loss_ce: 0.005898
iteration 11051 : loss : 0.027459, loss_ce: 0.007713
iteration 11052 : loss : 0.033841, loss_ce: 0.010147
iteration 11053 : loss : 0.027094, loss_ce: 0.004814
iteration 11054 : loss : 0.025135, loss_ce: 0.008724
iteration 11055 : loss : 0.027764, loss_ce: 0.007722
iteration 11056 : loss : 0.027126, loss_ce: 0.008886
iteration 11057 : loss : 0.023036, loss_ce: 0.007754
iteration 11058 : loss : 0.030521, loss_ce: 0.009089
iteration 11059 : loss : 0.031019, loss_ce: 0.010041
iteration 11060 : loss : 0.021042, loss_ce: 0.006498
iteration 11061 : loss : 0.075628, loss_ce: 0.004703
iteration 11062 : loss : 0.074940, loss_ce: 0.006187
iteration 11063 : loss : 0.027424, loss_ce: 0.013724
iteration 11064 : loss : 0.030780, loss_ce: 0.007592
iteration 11065 : loss : 0.025880, loss_ce: 0.006281
iteration 11066 : loss : 0.025560, loss_ce: 0.010211
iteration 11067 : loss : 0.233112, loss_ce: 0.009006
 60%|████████████████           | 119/200 [2:02:12<1:23:09, 61.59s/it]iteration 11068 : loss : 0.028069, loss_ce: 0.007167
iteration 11069 : loss : 0.023876, loss_ce: 0.008828
iteration 11070 : loss : 0.022925, loss_ce: 0.006288
iteration 11071 : loss : 0.027010, loss_ce: 0.007821
iteration 11072 : loss : 0.018565, loss_ce: 0.007003
iteration 11073 : loss : 0.022180, loss_ce: 0.009433
iteration 11074 : loss : 0.025675, loss_ce: 0.009338
iteration 11075 : loss : 0.022749, loss_ce: 0.005793
iteration 11076 : loss : 0.024139, loss_ce: 0.006934
iteration 11077 : loss : 0.018632, loss_ce: 0.006825
iteration 11078 : loss : 0.023780, loss_ce: 0.008225
iteration 11079 : loss : 0.025033, loss_ce: 0.009522
iteration 11080 : loss : 0.023434, loss_ce: 0.011984
iteration 11081 : loss : 0.025444, loss_ce: 0.005456
iteration 11082 : loss : 0.025669, loss_ce: 0.005886
iteration 11083 : loss : 0.076557, loss_ce: 0.008809
iteration 11084 : loss : 0.030141, loss_ce: 0.009021
iteration 11085 : loss : 0.022620, loss_ce: 0.006501
iteration 11086 : loss : 0.026967, loss_ce: 0.011238
iteration 11087 : loss : 0.071910, loss_ce: 0.004977
iteration 11088 : loss : 0.027164, loss_ce: 0.010948
iteration 11089 : loss : 0.022194, loss_ce: 0.009192
iteration 11090 : loss : 0.025535, loss_ce: 0.008351
iteration 11091 : loss : 0.030309, loss_ce: 0.010137
iteration 11092 : loss : 0.078030, loss_ce: 0.004527
iteration 11093 : loss : 0.023696, loss_ce: 0.010303
iteration 11094 : loss : 0.030764, loss_ce: 0.010525
iteration 11095 : loss : 0.023858, loss_ce: 0.012257
iteration 11096 : loss : 0.029390, loss_ce: 0.006977
iteration 11097 : loss : 0.023849, loss_ce: 0.007383
iteration 11098 : loss : 0.021116, loss_ce: 0.005682
iteration 11099 : loss : 0.026464, loss_ce: 0.012796
iteration 11100 : loss : 0.045843, loss_ce: 0.006831
iteration 11101 : loss : 0.023074, loss_ce: 0.010809
iteration 11102 : loss : 0.024545, loss_ce: 0.009145
iteration 11103 : loss : 0.024654, loss_ce: 0.007087
iteration 11104 : loss : 0.027345, loss_ce: 0.004791
iteration 11105 : loss : 0.026074, loss_ce: 0.008603
iteration 11106 : loss : 0.027524, loss_ce: 0.008668
iteration 11107 : loss : 0.025922, loss_ce: 0.012004
iteration 11108 : loss : 0.029782, loss_ce: 0.007928
iteration 11109 : loss : 0.027029, loss_ce: 0.013332
iteration 11110 : loss : 0.026704, loss_ce: 0.006626
iteration 11111 : loss : 0.080379, loss_ce: 0.006323
iteration 11112 : loss : 0.024073, loss_ce: 0.009794
iteration 11113 : loss : 0.026255, loss_ce: 0.012488
iteration 11114 : loss : 0.060561, loss_ce: 0.007691
iteration 11115 : loss : 0.022640, loss_ce: 0.009277
iteration 11116 : loss : 0.028441, loss_ce: 0.012034
iteration 11117 : loss : 0.030669, loss_ce: 0.013734
iteration 11118 : loss : 0.024191, loss_ce: 0.011369
iteration 11119 : loss : 0.027106, loss_ce: 0.005255
iteration 11120 : loss : 0.028076, loss_ce: 0.010900
iteration 11121 : loss : 0.022468, loss_ce: 0.005291
iteration 11122 : loss : 0.026314, loss_ce: 0.009354
iteration 11123 : loss : 0.027386, loss_ce: 0.010037
iteration 11124 : loss : 0.023791, loss_ce: 0.006806
iteration 11125 : loss : 0.031038, loss_ce: 0.008822
iteration 11126 : loss : 0.030691, loss_ce: 0.009178
iteration 11127 : loss : 0.028464, loss_ce: 0.012975
iteration 11128 : loss : 0.077957, loss_ce: 0.006634
iteration 11129 : loss : 0.075704, loss_ce: 0.004279
iteration 11130 : loss : 0.025369, loss_ce: 0.007417
iteration 11131 : loss : 0.026353, loss_ce: 0.011498
iteration 11132 : loss : 0.024002, loss_ce: 0.008009
iteration 11133 : loss : 0.030377, loss_ce: 0.009300
iteration 11134 : loss : 0.030900, loss_ce: 0.005813
iteration 11135 : loss : 0.023492, loss_ce: 0.009413
iteration 11136 : loss : 0.024713, loss_ce: 0.006995
iteration 11137 : loss : 0.082270, loss_ce: 0.008575
iteration 11138 : loss : 0.076651, loss_ce: 0.012404
iteration 11139 : loss : 0.031091, loss_ce: 0.013063
iteration 11140 : loss : 0.025812, loss_ce: 0.011829
iteration 11141 : loss : 0.025001, loss_ce: 0.008503
iteration 11142 : loss : 0.023033, loss_ce: 0.006862
iteration 11143 : loss : 0.023767, loss_ce: 0.006678
iteration 11144 : loss : 0.029532, loss_ce: 0.007627
iteration 11145 : loss : 0.026857, loss_ce: 0.008532
iteration 11146 : loss : 0.025098, loss_ce: 0.007629
iteration 11147 : loss : 0.029342, loss_ce: 0.009077
iteration 11148 : loss : 0.077458, loss_ce: 0.007175
iteration 11149 : loss : 0.025507, loss_ce: 0.008599
iteration 11150 : loss : 0.023345, loss_ce: 0.008601
iteration 11151 : loss : 0.074608, loss_ce: 0.005102
iteration 11152 : loss : 0.028358, loss_ce: 0.008757
iteration 11153 : loss : 0.027429, loss_ce: 0.008840
iteration 11154 : loss : 0.025620, loss_ce: 0.006994
iteration 11155 : loss : 0.024666, loss_ce: 0.009490
iteration 11156 : loss : 0.030774, loss_ce: 0.010035
iteration 11157 : loss : 0.031563, loss_ce: 0.014321
iteration 11158 : loss : 0.030030, loss_ce: 0.011870
iteration 11159 : loss : 0.026243, loss_ce: 0.006614
iteration 11160 : loss : 0.285469, loss_ce: 0.007017
 60%|████████████████▏          | 120/200 [2:03:14<1:22:08, 61.61s/it]iteration 11161 : loss : 0.023656, loss_ce: 0.010550
iteration 11162 : loss : 0.025406, loss_ce: 0.003302
iteration 11163 : loss : 0.025658, loss_ce: 0.009313
iteration 11164 : loss : 0.033410, loss_ce: 0.009656
iteration 11165 : loss : 0.079376, loss_ce: 0.006946
iteration 11166 : loss : 0.028935, loss_ce: 0.010477
iteration 11167 : loss : 0.023015, loss_ce: 0.006510
iteration 11168 : loss : 0.028092, loss_ce: 0.011421
iteration 11169 : loss : 0.029041, loss_ce: 0.007185
iteration 11170 : loss : 0.023494, loss_ce: 0.007188
iteration 11171 : loss : 0.031967, loss_ce: 0.009865
iteration 11172 : loss : 0.021404, loss_ce: 0.006981
iteration 11173 : loss : 0.029622, loss_ce: 0.009106
iteration 11174 : loss : 0.024125, loss_ce: 0.006947
iteration 11175 : loss : 0.033255, loss_ce: 0.007593
iteration 11176 : loss : 0.027140, loss_ce: 0.012520
iteration 11177 : loss : 0.027232, loss_ce: 0.012286
iteration 11178 : loss : 0.031243, loss_ce: 0.006747
iteration 11179 : loss : 0.023801, loss_ce: 0.004207
iteration 11180 : loss : 0.024315, loss_ce: 0.006655
iteration 11181 : loss : 0.036780, loss_ce: 0.010592
iteration 11182 : loss : 0.025861, loss_ce: 0.009078
iteration 11183 : loss : 0.028629, loss_ce: 0.007938
iteration 11184 : loss : 0.024813, loss_ce: 0.012700
iteration 11185 : loss : 0.024593, loss_ce: 0.010531
iteration 11186 : loss : 0.027552, loss_ce: 0.012882
iteration 11187 : loss : 0.024481, loss_ce: 0.008155
iteration 11188 : loss : 0.023796, loss_ce: 0.008681
iteration 11189 : loss : 0.029663, loss_ce: 0.014316
iteration 11190 : loss : 0.025393, loss_ce: 0.005437
iteration 11191 : loss : 0.018949, loss_ce: 0.008045
iteration 11192 : loss : 0.021863, loss_ce: 0.007276
iteration 11193 : loss : 0.026123, loss_ce: 0.008764
iteration 11194 : loss : 0.023021, loss_ce: 0.007220
iteration 11195 : loss : 0.033519, loss_ce: 0.009131
iteration 11196 : loss : 0.022770, loss_ce: 0.011143
iteration 11197 : loss : 0.025575, loss_ce: 0.009078
iteration 11198 : loss : 0.023221, loss_ce: 0.006423
iteration 11199 : loss : 0.029279, loss_ce: 0.008546
iteration 11200 : loss : 0.075241, loss_ce: 0.005116
iteration 11201 : loss : 0.073989, loss_ce: 0.006399
iteration 11202 : loss : 0.021615, loss_ce: 0.011403
iteration 11203 : loss : 0.027517, loss_ce: 0.008723
iteration 11204 : loss : 0.027503, loss_ce: 0.007922
iteration 11205 : loss : 0.032597, loss_ce: 0.012047
iteration 11206 : loss : 0.023521, loss_ce: 0.009288
iteration 11207 : loss : 0.027360, loss_ce: 0.009859
iteration 11208 : loss : 0.020860, loss_ce: 0.007580
iteration 11209 : loss : 0.024184, loss_ce: 0.006550
iteration 11210 : loss : 0.037199, loss_ce: 0.007434
iteration 11211 : loss : 0.022096, loss_ce: 0.007687
iteration 11212 : loss : 0.027393, loss_ce: 0.013092
iteration 11213 : loss : 0.028656, loss_ce: 0.007683
iteration 11214 : loss : 0.024034, loss_ce: 0.005568
iteration 11215 : loss : 0.028630, loss_ce: 0.010586
iteration 11216 : loss : 0.018883, loss_ce: 0.005125
iteration 11217 : loss : 0.023905, loss_ce: 0.004974
iteration 11218 : loss : 0.023386, loss_ce: 0.007917
iteration 11219 : loss : 0.074098, loss_ce: 0.006710
iteration 11220 : loss : 0.025047, loss_ce: 0.009099
iteration 11221 : loss : 0.024489, loss_ce: 0.007103
iteration 11222 : loss : 0.025091, loss_ce: 0.007530
iteration 11223 : loss : 0.025338, loss_ce: 0.007609
iteration 11224 : loss : 0.026914, loss_ce: 0.009179
iteration 11225 : loss : 0.027983, loss_ce: 0.009502
iteration 11226 : loss : 0.024485, loss_ce: 0.006572
iteration 11227 : loss : 0.026424, loss_ce: 0.008693
iteration 11228 : loss : 0.025987, loss_ce: 0.011432
iteration 11229 : loss : 0.025395, loss_ce: 0.011530
iteration 11230 : loss : 0.028748, loss_ce: 0.014304
iteration 11231 : loss : 0.025166, loss_ce: 0.005464
iteration 11232 : loss : 0.023107, loss_ce: 0.006581
iteration 11233 : loss : 0.022396, loss_ce: 0.008139
iteration 11234 : loss : 0.019153, loss_ce: 0.006921
iteration 11235 : loss : 0.022685, loss_ce: 0.006701
iteration 11236 : loss : 0.022935, loss_ce: 0.007505
iteration 11237 : loss : 0.023834, loss_ce: 0.008240
iteration 11238 : loss : 0.028194, loss_ce: 0.009555
iteration 11239 : loss : 0.024279, loss_ce: 0.009273
iteration 11240 : loss : 0.025474, loss_ce: 0.006572
iteration 11241 : loss : 0.024598, loss_ce: 0.008770
iteration 11242 : loss : 0.027449, loss_ce: 0.006424
iteration 11243 : loss : 0.020768, loss_ce: 0.009798
iteration 11244 : loss : 0.031362, loss_ce: 0.011617
iteration 11245 : loss : 0.019484, loss_ce: 0.007392
iteration 11246 : loss : 0.019762, loss_ce: 0.005729
iteration 11247 : loss : 0.021922, loss_ce: 0.005092
iteration 11248 : loss : 0.023399, loss_ce: 0.008476
iteration 11249 : loss : 0.026721, loss_ce: 0.009497
iteration 11250 : loss : 0.023723, loss_ce: 0.007175
iteration 11251 : loss : 0.020571, loss_ce: 0.007168
iteration 11252 : loss : 0.020924, loss_ce: 0.009601
iteration 11253 : loss : 0.284589, loss_ce: 0.006986
 60%|████████████████▎          | 121/200 [2:04:15<1:21:05, 61.59s/it]iteration 11254 : loss : 0.020980, loss_ce: 0.006013
iteration 11255 : loss : 0.023024, loss_ce: 0.009046
iteration 11256 : loss : 0.026752, loss_ce: 0.008098
iteration 11257 : loss : 0.071940, loss_ce: 0.004873
iteration 11258 : loss : 0.022886, loss_ce: 0.008230
iteration 11259 : loss : 0.022083, loss_ce: 0.008322
iteration 11260 : loss : 0.021816, loss_ce: 0.004342
iteration 11261 : loss : 0.025948, loss_ce: 0.007068
iteration 11262 : loss : 0.023806, loss_ce: 0.007210
iteration 11263 : loss : 0.024262, loss_ce: 0.007953
iteration 11264 : loss : 0.039089, loss_ce: 0.007663
iteration 11265 : loss : 0.026519, loss_ce: 0.008560
iteration 11266 : loss : 0.024935, loss_ce: 0.010432
iteration 11267 : loss : 0.024921, loss_ce: 0.007944
iteration 11268 : loss : 0.031886, loss_ce: 0.014182
iteration 11269 : loss : 0.033369, loss_ce: 0.007509
iteration 11270 : loss : 0.024617, loss_ce: 0.009792
iteration 11271 : loss : 0.022502, loss_ce: 0.008427
iteration 11272 : loss : 0.022626, loss_ce: 0.008217
iteration 11273 : loss : 0.021777, loss_ce: 0.006316
iteration 11274 : loss : 0.019359, loss_ce: 0.003333
iteration 11275 : loss : 0.024398, loss_ce: 0.005951
iteration 11276 : loss : 0.026040, loss_ce: 0.011912
iteration 11277 : loss : 0.021577, loss_ce: 0.006686
iteration 11278 : loss : 0.027990, loss_ce: 0.009167
iteration 11279 : loss : 0.022903, loss_ce: 0.008028
iteration 11280 : loss : 0.035151, loss_ce: 0.006963
iteration 11281 : loss : 0.027830, loss_ce: 0.011010
iteration 11282 : loss : 0.022346, loss_ce: 0.007535
iteration 11283 : loss : 0.035668, loss_ce: 0.008151
iteration 11284 : loss : 0.026389, loss_ce: 0.008298
iteration 11285 : loss : 0.022539, loss_ce: 0.007706
iteration 11286 : loss : 0.022101, loss_ce: 0.007661
iteration 11287 : loss : 0.026439, loss_ce: 0.008715
iteration 11288 : loss : 0.075497, loss_ce: 0.006483
iteration 11289 : loss : 0.022975, loss_ce: 0.007393
iteration 11290 : loss : 0.026892, loss_ce: 0.008354
iteration 11291 : loss : 0.023738, loss_ce: 0.009727
iteration 11292 : loss : 0.023034, loss_ce: 0.008037
iteration 11293 : loss : 0.023729, loss_ce: 0.009423
iteration 11294 : loss : 0.023820, loss_ce: 0.011329
iteration 11295 : loss : 0.035911, loss_ce: 0.008680
iteration 11296 : loss : 0.033397, loss_ce: 0.007950
iteration 11297 : loss : 0.074050, loss_ce: 0.006573
iteration 11298 : loss : 0.024271, loss_ce: 0.010001
iteration 11299 : loss : 0.023909, loss_ce: 0.005417
iteration 11300 : loss : 0.017352, loss_ce: 0.004891
iteration 11301 : loss : 0.022384, loss_ce: 0.007391
iteration 11302 : loss : 0.027051, loss_ce: 0.010359
iteration 11303 : loss : 0.028848, loss_ce: 0.008211
iteration 11304 : loss : 0.019712, loss_ce: 0.006791
iteration 11305 : loss : 0.020983, loss_ce: 0.004721
iteration 11306 : loss : 0.028615, loss_ce: 0.011541
iteration 11307 : loss : 0.023086, loss_ce: 0.007483
iteration 11308 : loss : 0.021654, loss_ce: 0.006557
iteration 11309 : loss : 0.027782, loss_ce: 0.011166
iteration 11310 : loss : 0.029235, loss_ce: 0.013401
iteration 11311 : loss : 0.026831, loss_ce: 0.011708
iteration 11312 : loss : 0.069173, loss_ce: 0.004632
iteration 11313 : loss : 0.023883, loss_ce: 0.007611
iteration 11314 : loss : 0.022015, loss_ce: 0.004157
iteration 11315 : loss : 0.027270, loss_ce: 0.008010
iteration 11316 : loss : 0.025312, loss_ce: 0.012226
iteration 11317 : loss : 0.030656, loss_ce: 0.014152
iteration 11318 : loss : 0.020669, loss_ce: 0.007697
iteration 11319 : loss : 0.028452, loss_ce: 0.008716
iteration 11320 : loss : 0.024892, loss_ce: 0.007267
iteration 11321 : loss : 0.025596, loss_ce: 0.011373
iteration 11322 : loss : 0.031338, loss_ce: 0.011397
iteration 11323 : loss : 0.023629, loss_ce: 0.011612
iteration 11324 : loss : 0.028658, loss_ce: 0.006051
iteration 11325 : loss : 0.024555, loss_ce: 0.009982
iteration 11326 : loss : 0.032859, loss_ce: 0.005337
iteration 11327 : loss : 0.024711, loss_ce: 0.006377
iteration 11328 : loss : 0.022681, loss_ce: 0.008837
iteration 11329 : loss : 0.026637, loss_ce: 0.009782
iteration 11330 : loss : 0.021050, loss_ce: 0.008118
iteration 11331 : loss : 0.076155, loss_ce: 0.004990
iteration 11332 : loss : 0.024223, loss_ce: 0.006764
iteration 11333 : loss : 0.076178, loss_ce: 0.010399
iteration 11334 : loss : 0.025400, loss_ce: 0.008504
iteration 11335 : loss : 0.021356, loss_ce: 0.008325
iteration 11336 : loss : 0.081090, loss_ce: 0.007447
iteration 11337 : loss : 0.022136, loss_ce: 0.008412
iteration 11338 : loss : 0.077460, loss_ce: 0.007997
iteration 11339 : loss : 0.021099, loss_ce: 0.006904
iteration 11340 : loss : 0.024994, loss_ce: 0.010083
iteration 11341 : loss : 0.022861, loss_ce: 0.008742
iteration 11342 : loss : 0.026203, loss_ce: 0.006969
iteration 11343 : loss : 0.025490, loss_ce: 0.011248
iteration 11344 : loss : 0.024044, loss_ce: 0.008625
iteration 11345 : loss : 0.025397, loss_ce: 0.007629
iteration 11346 : loss : 0.035508, loss_ce: 0.016358
 61%|████████████████▍          | 122/200 [2:05:17<1:20:02, 61.57s/it]iteration 11347 : loss : 0.022510, loss_ce: 0.009651
iteration 11348 : loss : 0.026722, loss_ce: 0.010338
iteration 11349 : loss : 0.026221, loss_ce: 0.006184
iteration 11350 : loss : 0.026009, loss_ce: 0.008591
iteration 11351 : loss : 0.027728, loss_ce: 0.010248
iteration 11352 : loss : 0.027623, loss_ce: 0.008292
iteration 11353 : loss : 0.026246, loss_ce: 0.008383
iteration 11354 : loss : 0.024088, loss_ce: 0.008091
iteration 11355 : loss : 0.027337, loss_ce: 0.006653
iteration 11356 : loss : 0.022196, loss_ce: 0.007022
iteration 11357 : loss : 0.026124, loss_ce: 0.008833
iteration 11358 : loss : 0.042417, loss_ce: 0.006601
iteration 11359 : loss : 0.027069, loss_ce: 0.011047
iteration 11360 : loss : 0.023786, loss_ce: 0.006304
iteration 11361 : loss : 0.020734, loss_ce: 0.006469
iteration 11362 : loss : 0.023268, loss_ce: 0.011267
iteration 11363 : loss : 0.029029, loss_ce: 0.008092
iteration 11364 : loss : 0.025557, loss_ce: 0.011847
iteration 11365 : loss : 0.024680, loss_ce: 0.007853
iteration 11366 : loss : 0.028234, loss_ce: 0.005386
iteration 11367 : loss : 0.022365, loss_ce: 0.008125
iteration 11368 : loss : 0.021177, loss_ce: 0.007636
iteration 11369 : loss : 0.023296, loss_ce: 0.006659
iteration 11370 : loss : 0.075668, loss_ce: 0.008330
iteration 11371 : loss : 0.032323, loss_ce: 0.008790
iteration 11372 : loss : 0.027771, loss_ce: 0.008299
iteration 11373 : loss : 0.080162, loss_ce: 0.003241
iteration 11374 : loss : 0.027918, loss_ce: 0.009690
iteration 11375 : loss : 0.024871, loss_ce: 0.004621
iteration 11376 : loss : 0.028566, loss_ce: 0.006999
iteration 11377 : loss : 0.025550, loss_ce: 0.011359
iteration 11378 : loss : 0.027623, loss_ce: 0.006543
iteration 11379 : loss : 0.026474, loss_ce: 0.013132
iteration 11380 : loss : 0.030922, loss_ce: 0.008820
iteration 11381 : loss : 0.026240, loss_ce: 0.008168
iteration 11382 : loss : 0.023190, loss_ce: 0.008810
iteration 11383 : loss : 0.025113, loss_ce: 0.009720
iteration 11384 : loss : 0.026111, loss_ce: 0.003969
iteration 11385 : loss : 0.022648, loss_ce: 0.003881
iteration 11386 : loss : 0.027362, loss_ce: 0.009480
iteration 11387 : loss : 0.026083, loss_ce: 0.008509
iteration 11388 : loss : 0.023909, loss_ce: 0.006126
iteration 11389 : loss : 0.029662, loss_ce: 0.005503
iteration 11390 : loss : 0.026291, loss_ce: 0.008870
iteration 11391 : loss : 0.024964, loss_ce: 0.010603
iteration 11392 : loss : 0.026549, loss_ce: 0.011084
iteration 11393 : loss : 0.023973, loss_ce: 0.008742
iteration 11394 : loss : 0.023145, loss_ce: 0.004561
iteration 11395 : loss : 0.024329, loss_ce: 0.006908
iteration 11396 : loss : 0.030025, loss_ce: 0.010055
iteration 11397 : loss : 0.024878, loss_ce: 0.009283
iteration 11398 : loss : 0.024768, loss_ce: 0.007735
iteration 11399 : loss : 0.021795, loss_ce: 0.009568
iteration 11400 : loss : 0.026476, loss_ce: 0.008105
iteration 11401 : loss : 0.026082, loss_ce: 0.012014
iteration 11402 : loss : 0.020432, loss_ce: 0.007062
iteration 11403 : loss : 0.024282, loss_ce: 0.010395
iteration 11404 : loss : 0.023896, loss_ce: 0.006022
iteration 11405 : loss : 0.026178, loss_ce: 0.010012
iteration 11406 : loss : 0.027409, loss_ce: 0.011816
iteration 11407 : loss : 0.022667, loss_ce: 0.012123
iteration 11408 : loss : 0.029542, loss_ce: 0.011840
iteration 11409 : loss : 0.024658, loss_ce: 0.011818
iteration 11410 : loss : 0.073757, loss_ce: 0.005131
iteration 11411 : loss : 0.020872, loss_ce: 0.005059
iteration 11412 : loss : 0.021979, loss_ce: 0.009162
iteration 11413 : loss : 0.021942, loss_ce: 0.007655
iteration 11414 : loss : 0.020507, loss_ce: 0.009515
iteration 11415 : loss : 0.025392, loss_ce: 0.007809
iteration 11416 : loss : 0.023753, loss_ce: 0.005330
iteration 11417 : loss : 0.027769, loss_ce: 0.006707
iteration 11418 : loss : 0.077896, loss_ce: 0.006761
iteration 11419 : loss : 0.025262, loss_ce: 0.007504
iteration 11420 : loss : 0.027171, loss_ce: 0.008183
iteration 11421 : loss : 0.022364, loss_ce: 0.011444
iteration 11422 : loss : 0.022107, loss_ce: 0.007901
iteration 11423 : loss : 0.021660, loss_ce: 0.004808
iteration 11424 : loss : 0.017258, loss_ce: 0.005688
iteration 11425 : loss : 0.032125, loss_ce: 0.006339
iteration 11426 : loss : 0.024504, loss_ce: 0.009103
iteration 11427 : loss : 0.026778, loss_ce: 0.013691
iteration 11428 : loss : 0.076104, loss_ce: 0.005986
iteration 11429 : loss : 0.026327, loss_ce: 0.007332
iteration 11430 : loss : 0.027329, loss_ce: 0.013645
iteration 11431 : loss : 0.024025, loss_ce: 0.005502
iteration 11432 : loss : 0.077344, loss_ce: 0.002740
iteration 11433 : loss : 0.026941, loss_ce: 0.012371
iteration 11434 : loss : 0.020402, loss_ce: 0.008927
iteration 11435 : loss : 0.077115, loss_ce: 0.008551
iteration 11436 : loss : 0.025862, loss_ce: 0.008802
iteration 11437 : loss : 0.024189, loss_ce: 0.012773
iteration 11438 : loss : 0.019034, loss_ce: 0.005587
iteration 11439 : loss : 0.081307, loss_ce: 0.013067
 62%|████████████████▌          | 123/200 [2:06:19<1:19:01, 61.58s/it]iteration 11440 : loss : 0.024095, loss_ce: 0.009044
iteration 11441 : loss : 0.025498, loss_ce: 0.010497
iteration 11442 : loss : 0.021543, loss_ce: 0.006549
iteration 11443 : loss : 0.025567, loss_ce: 0.007931
iteration 11444 : loss : 0.077162, loss_ce: 0.009299
iteration 11445 : loss : 0.026598, loss_ce: 0.011832
iteration 11446 : loss : 0.025738, loss_ce: 0.007050
iteration 11447 : loss : 0.075185, loss_ce: 0.004485
iteration 11448 : loss : 0.022391, loss_ce: 0.008024
iteration 11449 : loss : 0.025887, loss_ce: 0.009715
iteration 11450 : loss : 0.029402, loss_ce: 0.009717
iteration 11451 : loss : 0.031274, loss_ce: 0.007388
iteration 11452 : loss : 0.036382, loss_ce: 0.003908
iteration 11453 : loss : 0.021755, loss_ce: 0.008046
iteration 11454 : loss : 0.022564, loss_ce: 0.010459
iteration 11455 : loss : 0.023635, loss_ce: 0.009432
iteration 11456 : loss : 0.026265, loss_ce: 0.010435
iteration 11457 : loss : 0.025988, loss_ce: 0.009287
iteration 11458 : loss : 0.072577, loss_ce: 0.007259
iteration 11459 : loss : 0.022191, loss_ce: 0.006890
iteration 11460 : loss : 0.021282, loss_ce: 0.006699
iteration 11461 : loss : 0.077678, loss_ce: 0.007561
iteration 11462 : loss : 0.075003, loss_ce: 0.005649
iteration 11463 : loss : 0.024698, loss_ce: 0.008153
iteration 11464 : loss : 0.025875, loss_ce: 0.005037
iteration 11465 : loss : 0.021330, loss_ce: 0.006094
iteration 11466 : loss : 0.021335, loss_ce: 0.007389
iteration 11467 : loss : 0.021869, loss_ce: 0.003371
iteration 11468 : loss : 0.020351, loss_ce: 0.006830
iteration 11469 : loss : 0.025770, loss_ce: 0.013559
iteration 11470 : loss : 0.023868, loss_ce: 0.003106
iteration 11471 : loss : 0.030976, loss_ce: 0.009501
iteration 11472 : loss : 0.032824, loss_ce: 0.010171
iteration 11473 : loss : 0.022731, loss_ce: 0.003890
iteration 11474 : loss : 0.022092, loss_ce: 0.006399
iteration 11475 : loss : 0.026739, loss_ce: 0.012301
iteration 11476 : loss : 0.023214, loss_ce: 0.009768
iteration 11477 : loss : 0.030514, loss_ce: 0.009906
iteration 11478 : loss : 0.023283, loss_ce: 0.008668
iteration 11479 : loss : 0.031572, loss_ce: 0.009490
iteration 11480 : loss : 0.023747, loss_ce: 0.008721
iteration 11481 : loss : 0.024439, loss_ce: 0.008614
iteration 11482 : loss : 0.074618, loss_ce: 0.003271
iteration 11483 : loss : 0.020617, loss_ce: 0.007158
iteration 11484 : loss : 0.021453, loss_ce: 0.007388
iteration 11485 : loss : 0.084217, loss_ce: 0.005842
iteration 11486 : loss : 0.026490, loss_ce: 0.010571
iteration 11487 : loss : 0.019048, loss_ce: 0.003977
iteration 11488 : loss : 0.022089, loss_ce: 0.009134
iteration 11489 : loss : 0.022569, loss_ce: 0.007950
iteration 11490 : loss : 0.023112, loss_ce: 0.012489
iteration 11491 : loss : 0.021839, loss_ce: 0.006162
iteration 11492 : loss : 0.026395, loss_ce: 0.009949
iteration 11493 : loss : 0.024351, loss_ce: 0.010273
iteration 11494 : loss : 0.029066, loss_ce: 0.010012
iteration 11495 : loss : 0.033883, loss_ce: 0.007280
iteration 11496 : loss : 0.026426, loss_ce: 0.009934
iteration 11497 : loss : 0.027775, loss_ce: 0.012668
iteration 11498 : loss : 0.026468, loss_ce: 0.009992
iteration 11499 : loss : 0.021910, loss_ce: 0.005266
iteration 11500 : loss : 0.019801, loss_ce: 0.006114
iteration 11501 : loss : 0.018619, loss_ce: 0.005286
iteration 11502 : loss : 0.027434, loss_ce: 0.008652
iteration 11503 : loss : 0.025083, loss_ce: 0.010808
iteration 11504 : loss : 0.028943, loss_ce: 0.011299
iteration 11505 : loss : 0.021660, loss_ce: 0.005780
iteration 11506 : loss : 0.027809, loss_ce: 0.007048
iteration 11507 : loss : 0.026244, loss_ce: 0.006339
iteration 11508 : loss : 0.023474, loss_ce: 0.005641
iteration 11509 : loss : 0.078696, loss_ce: 0.006173
iteration 11510 : loss : 0.022207, loss_ce: 0.007295
iteration 11511 : loss : 0.028797, loss_ce: 0.012547
iteration 11512 : loss : 0.027259, loss_ce: 0.009487
iteration 11513 : loss : 0.023680, loss_ce: 0.004845
iteration 11514 : loss : 0.024281, loss_ce: 0.009579
iteration 11515 : loss : 0.028176, loss_ce: 0.013463
iteration 11516 : loss : 0.035508, loss_ce: 0.007742
iteration 11517 : loss : 0.028198, loss_ce: 0.008860
iteration 11518 : loss : 0.025614, loss_ce: 0.009988
iteration 11519 : loss : 0.025021, loss_ce: 0.008465
iteration 11520 : loss : 0.029213, loss_ce: 0.009257
iteration 11521 : loss : 0.025745, loss_ce: 0.008576
iteration 11522 : loss : 0.030211, loss_ce: 0.010806
iteration 11523 : loss : 0.033336, loss_ce: 0.011184
iteration 11524 : loss : 0.018996, loss_ce: 0.006037
iteration 11525 : loss : 0.022313, loss_ce: 0.008567
iteration 11526 : loss : 0.023467, loss_ce: 0.009723
iteration 11527 : loss : 0.025721, loss_ce: 0.010351
iteration 11528 : loss : 0.031211, loss_ce: 0.008410
iteration 11529 : loss : 0.023575, loss_ce: 0.009715
iteration 11530 : loss : 0.026355, loss_ce: 0.009141
iteration 11531 : loss : 0.025782, loss_ce: 0.008426
iteration 11532 : loss : 0.129701, loss_ce: 0.009510
 62%|████████████████▋          | 124/200 [2:07:20<1:17:58, 61.56s/it]iteration 11533 : loss : 0.036150, loss_ce: 0.005515
iteration 11534 : loss : 0.025279, loss_ce: 0.009079
iteration 11535 : loss : 0.025067, loss_ce: 0.010025
iteration 11536 : loss : 0.026687, loss_ce: 0.009240
iteration 11537 : loss : 0.024027, loss_ce: 0.007302
iteration 11538 : loss : 0.019406, loss_ce: 0.004916
iteration 11539 : loss : 0.026811, loss_ce: 0.010139
iteration 11540 : loss : 0.023930, loss_ce: 0.010526
iteration 11541 : loss : 0.022352, loss_ce: 0.007948
iteration 11542 : loss : 0.072349, loss_ce: 0.002639
iteration 11543 : loss : 0.020970, loss_ce: 0.007401
iteration 11544 : loss : 0.029170, loss_ce: 0.009499
iteration 11545 : loss : 0.027921, loss_ce: 0.008750
iteration 11546 : loss : 0.020365, loss_ce: 0.006304
iteration 11547 : loss : 0.024170, loss_ce: 0.009240
iteration 11548 : loss : 0.024367, loss_ce: 0.010121
iteration 11549 : loss : 0.024130, loss_ce: 0.008550
iteration 11550 : loss : 0.023148, loss_ce: 0.006412
iteration 11551 : loss : 0.020756, loss_ce: 0.009295
iteration 11552 : loss : 0.021946, loss_ce: 0.005544
iteration 11553 : loss : 0.022472, loss_ce: 0.010666
iteration 11554 : loss : 0.028462, loss_ce: 0.007451
iteration 11555 : loss : 0.024637, loss_ce: 0.008090
iteration 11556 : loss : 0.029197, loss_ce: 0.008243
iteration 11557 : loss : 0.024237, loss_ce: 0.008246
iteration 11558 : loss : 0.019361, loss_ce: 0.010032
iteration 11559 : loss : 0.020349, loss_ce: 0.007084
iteration 11560 : loss : 0.023826, loss_ce: 0.007139
iteration 11561 : loss : 0.076855, loss_ce: 0.006858
iteration 11562 : loss : 0.021401, loss_ce: 0.010813
iteration 11563 : loss : 0.021611, loss_ce: 0.004296
iteration 11564 : loss : 0.024364, loss_ce: 0.007488
iteration 11565 : loss : 0.025412, loss_ce: 0.009037
iteration 11566 : loss : 0.028766, loss_ce: 0.011821
iteration 11567 : loss : 0.027901, loss_ce: 0.012954
iteration 11568 : loss : 0.020594, loss_ce: 0.007475
iteration 11569 : loss : 0.026267, loss_ce: 0.010583
iteration 11570 : loss : 0.022831, loss_ce: 0.007756
iteration 11571 : loss : 0.023927, loss_ce: 0.009962
iteration 11572 : loss : 0.028368, loss_ce: 0.007444
iteration 11573 : loss : 0.027148, loss_ce: 0.005351
iteration 11574 : loss : 0.028725, loss_ce: 0.010190
iteration 11575 : loss : 0.024072, loss_ce: 0.006974
iteration 11576 : loss : 0.023038, loss_ce: 0.005831
iteration 11577 : loss : 0.025329, loss_ce: 0.009920
iteration 11578 : loss : 0.078321, loss_ce: 0.011135
iteration 11579 : loss : 0.019412, loss_ce: 0.007441
iteration 11580 : loss : 0.023206, loss_ce: 0.009032
iteration 11581 : loss : 0.019866, loss_ce: 0.008808
iteration 11582 : loss : 0.031277, loss_ce: 0.007624
iteration 11583 : loss : 0.034661, loss_ce: 0.010773
iteration 11584 : loss : 0.075336, loss_ce: 0.006739
iteration 11585 : loss : 0.232417, loss_ce: 0.003755
iteration 11586 : loss : 0.020937, loss_ce: 0.006994
iteration 11587 : loss : 0.078329, loss_ce: 0.005983
iteration 11588 : loss : 0.025951, loss_ce: 0.006587
iteration 11589 : loss : 0.018740, loss_ce: 0.006929
iteration 11590 : loss : 0.026702, loss_ce: 0.007022
iteration 11591 : loss : 0.025342, loss_ce: 0.009108
iteration 11592 : loss : 0.022413, loss_ce: 0.008659
iteration 11593 : loss : 0.029214, loss_ce: 0.012180
iteration 11594 : loss : 0.035354, loss_ce: 0.007600
iteration 11595 : loss : 0.026363, loss_ce: 0.010798
iteration 11596 : loss : 0.023594, loss_ce: 0.008759
iteration 11597 : loss : 0.023433, loss_ce: 0.008117
iteration 11598 : loss : 0.022812, loss_ce: 0.011181
iteration 11599 : loss : 0.021305, loss_ce: 0.008389
iteration 11600 : loss : 0.024509, loss_ce: 0.007554
iteration 11601 : loss : 0.024569, loss_ce: 0.010676
iteration 11602 : loss : 0.020166, loss_ce: 0.005802
iteration 11603 : loss : 0.023137, loss_ce: 0.005198
iteration 11604 : loss : 0.023744, loss_ce: 0.008955
iteration 11605 : loss : 0.026918, loss_ce: 0.010421
iteration 11606 : loss : 0.054234, loss_ce: 0.006469
iteration 11607 : loss : 0.026963, loss_ce: 0.009461
iteration 11608 : loss : 0.024552, loss_ce: 0.008571
iteration 11609 : loss : 0.027864, loss_ce: 0.007179
iteration 11610 : loss : 0.023771, loss_ce: 0.006066
iteration 11611 : loss : 0.025866, loss_ce: 0.009265
iteration 11612 : loss : 0.025686, loss_ce: 0.008952
iteration 11613 : loss : 0.023691, loss_ce: 0.008872
iteration 11614 : loss : 0.023264, loss_ce: 0.008172
iteration 11615 : loss : 0.030670, loss_ce: 0.011207
iteration 11616 : loss : 0.024421, loss_ce: 0.007302
iteration 11617 : loss : 0.027068, loss_ce: 0.009201
iteration 11618 : loss : 0.074733, loss_ce: 0.004059
iteration 11619 : loss : 0.023284, loss_ce: 0.006551
iteration 11620 : loss : 0.023063, loss_ce: 0.004560
iteration 11621 : loss : 0.031999, loss_ce: 0.011573
iteration 11622 : loss : 0.024222, loss_ce: 0.007076
iteration 11623 : loss : 0.035591, loss_ce: 0.014716
iteration 11624 : loss : 0.024411, loss_ce: 0.011234
iteration 11625 : loss : 0.238920, loss_ce: 0.013956
 62%|████████████████▉          | 125/200 [2:08:22<1:16:59, 61.59s/it]iteration 11626 : loss : 0.026574, loss_ce: 0.005116
iteration 11627 : loss : 0.031993, loss_ce: 0.016746
iteration 11628 : loss : 0.075841, loss_ce: 0.006245
iteration 11629 : loss : 0.026399, loss_ce: 0.008852
iteration 11630 : loss : 0.025134, loss_ce: 0.009794
iteration 11631 : loss : 0.023724, loss_ce: 0.008317
iteration 11632 : loss : 0.029012, loss_ce: 0.015744
iteration 11633 : loss : 0.023728, loss_ce: 0.005594
iteration 11634 : loss : 0.028347, loss_ce: 0.009756
iteration 11635 : loss : 0.025541, loss_ce: 0.012742
iteration 11636 : loss : 0.025344, loss_ce: 0.007685
iteration 11637 : loss : 0.022163, loss_ce: 0.007095
iteration 11638 : loss : 0.027814, loss_ce: 0.011879
iteration 11639 : loss : 0.028438, loss_ce: 0.008651
iteration 11640 : loss : 0.020846, loss_ce: 0.006036
iteration 11641 : loss : 0.022246, loss_ce: 0.009013
iteration 11642 : loss : 0.023770, loss_ce: 0.006215
iteration 11643 : loss : 0.026961, loss_ce: 0.010154
iteration 11644 : loss : 0.023635, loss_ce: 0.008747
iteration 11645 : loss : 0.023233, loss_ce: 0.008212
iteration 11646 : loss : 0.023628, loss_ce: 0.012683
iteration 11647 : loss : 0.032925, loss_ce: 0.008603
iteration 11648 : loss : 0.063211, loss_ce: 0.005564
iteration 11649 : loss : 0.023462, loss_ce: 0.008979
iteration 11650 : loss : 0.021843, loss_ce: 0.009655
iteration 11651 : loss : 0.032069, loss_ce: 0.014578
iteration 11652 : loss : 0.022653, loss_ce: 0.006851
iteration 11653 : loss : 0.032731, loss_ce: 0.011897
iteration 11654 : loss : 0.083755, loss_ce: 0.012653
iteration 11655 : loss : 0.033197, loss_ce: 0.013657
iteration 11656 : loss : 0.024849, loss_ce: 0.011335
iteration 11657 : loss : 0.030041, loss_ce: 0.007918
iteration 11658 : loss : 0.030673, loss_ce: 0.007907
iteration 11659 : loss : 0.026636, loss_ce: 0.010331
iteration 11660 : loss : 0.081181, loss_ce: 0.008819
iteration 11661 : loss : 0.032394, loss_ce: 0.013386
iteration 11662 : loss : 0.023578, loss_ce: 0.008802
iteration 11663 : loss : 0.032769, loss_ce: 0.015324
iteration 11664 : loss : 0.030354, loss_ce: 0.009593
iteration 11665 : loss : 0.027922, loss_ce: 0.009331
iteration 11666 : loss : 0.032525, loss_ce: 0.011861
iteration 11667 : loss : 0.078528, loss_ce: 0.009526
iteration 11668 : loss : 0.030427, loss_ce: 0.012219
iteration 11669 : loss : 0.025839, loss_ce: 0.009737
iteration 11670 : loss : 0.030439, loss_ce: 0.013707
iteration 11671 : loss : 0.030095, loss_ce: 0.006437
iteration 11672 : loss : 0.025485, loss_ce: 0.011104
iteration 11673 : loss : 0.025097, loss_ce: 0.012045
iteration 11674 : loss : 0.030466, loss_ce: 0.011385
iteration 11675 : loss : 0.028444, loss_ce: 0.012856
iteration 11676 : loss : 0.024088, loss_ce: 0.006528
iteration 11677 : loss : 0.022448, loss_ce: 0.009289
iteration 11678 : loss : 0.023057, loss_ce: 0.009078
iteration 11679 : loss : 0.025311, loss_ce: 0.010743
iteration 11680 : loss : 0.029828, loss_ce: 0.006623
iteration 11681 : loss : 0.024247, loss_ce: 0.007693
iteration 11682 : loss : 0.031725, loss_ce: 0.005650
iteration 11683 : loss : 0.022623, loss_ce: 0.007219
iteration 11684 : loss : 0.032484, loss_ce: 0.008178
iteration 11685 : loss : 0.037592, loss_ce: 0.005853
iteration 11686 : loss : 0.024030, loss_ce: 0.008809
iteration 11687 : loss : 0.027279, loss_ce: 0.007246
iteration 11688 : loss : 0.023405, loss_ce: 0.008559
iteration 11689 : loss : 0.032123, loss_ce: 0.014581
iteration 11690 : loss : 0.022843, loss_ce: 0.005716
iteration 11691 : loss : 0.021943, loss_ce: 0.007485
iteration 11692 : loss : 0.029549, loss_ce: 0.010413
iteration 11693 : loss : 0.030258, loss_ce: 0.010296
iteration 11694 : loss : 0.023069, loss_ce: 0.006903
iteration 11695 : loss : 0.026731, loss_ce: 0.006883
iteration 11696 : loss : 0.019556, loss_ce: 0.006177
iteration 11697 : loss : 0.034116, loss_ce: 0.008372
iteration 11698 : loss : 0.022882, loss_ce: 0.006915
iteration 11699 : loss : 0.026927, loss_ce: 0.007479
iteration 11700 : loss : 0.023726, loss_ce: 0.006949
iteration 11701 : loss : 0.023600, loss_ce: 0.005182
iteration 11702 : loss : 0.028854, loss_ce: 0.010804
iteration 11703 : loss : 0.073252, loss_ce: 0.007241
iteration 11704 : loss : 0.080850, loss_ce: 0.007076
iteration 11705 : loss : 0.030466, loss_ce: 0.010977
iteration 11706 : loss : 0.077346, loss_ce: 0.007102
iteration 11707 : loss : 0.026633, loss_ce: 0.008887
iteration 11708 : loss : 0.026892, loss_ce: 0.010805
iteration 11709 : loss : 0.024797, loss_ce: 0.008799
iteration 11710 : loss : 0.021663, loss_ce: 0.008576
iteration 11711 : loss : 0.025316, loss_ce: 0.010588
iteration 11712 : loss : 0.030000, loss_ce: 0.005122
iteration 11713 : loss : 0.075482, loss_ce: 0.006544
iteration 11714 : loss : 0.024388, loss_ce: 0.007593
iteration 11715 : loss : 0.025077, loss_ce: 0.008342
iteration 11716 : loss : 0.026096, loss_ce: 0.011135
iteration 11717 : loss : 0.023352, loss_ce: 0.011204
iteration 11718 : loss : 0.032416, loss_ce: 0.020212
 63%|█████████████████          | 126/200 [2:09:23<1:15:56, 61.57s/it]iteration 11719 : loss : 0.036255, loss_ce: 0.007272
iteration 11720 : loss : 0.021890, loss_ce: 0.010061
iteration 11721 : loss : 0.027567, loss_ce: 0.010266
iteration 11722 : loss : 0.019319, loss_ce: 0.005248
iteration 11723 : loss : 0.029802, loss_ce: 0.012331
iteration 11724 : loss : 0.021962, loss_ce: 0.007849
iteration 11725 : loss : 0.024149, loss_ce: 0.007266
iteration 11726 : loss : 0.022897, loss_ce: 0.009517
iteration 11727 : loss : 0.025578, loss_ce: 0.008032
iteration 11728 : loss : 0.023448, loss_ce: 0.007178
iteration 11729 : loss : 0.027093, loss_ce: 0.008091
iteration 11730 : loss : 0.024935, loss_ce: 0.006399
iteration 11731 : loss : 0.025106, loss_ce: 0.007610
iteration 11732 : loss : 0.027020, loss_ce: 0.009140
iteration 11733 : loss : 0.031326, loss_ce: 0.010648
iteration 11734 : loss : 0.023604, loss_ce: 0.009258
iteration 11735 : loss : 0.024720, loss_ce: 0.008492
iteration 11736 : loss : 0.028055, loss_ce: 0.006765
iteration 11737 : loss : 0.023728, loss_ce: 0.007190
iteration 11738 : loss : 0.029321, loss_ce: 0.006931
iteration 11739 : loss : 0.078644, loss_ce: 0.006697
iteration 11740 : loss : 0.022699, loss_ce: 0.005116
iteration 11741 : loss : 0.025260, loss_ce: 0.008785
iteration 11742 : loss : 0.030460, loss_ce: 0.007425
iteration 11743 : loss : 0.028240, loss_ce: 0.012087
iteration 11744 : loss : 0.026655, loss_ce: 0.011190
iteration 11745 : loss : 0.025677, loss_ce: 0.007623
iteration 11746 : loss : 0.020642, loss_ce: 0.007152
iteration 11747 : loss : 0.026502, loss_ce: 0.008119
iteration 11748 : loss : 0.024723, loss_ce: 0.007486
iteration 11749 : loss : 0.021016, loss_ce: 0.008908
iteration 11750 : loss : 0.022920, loss_ce: 0.007786
iteration 11751 : loss : 0.020947, loss_ce: 0.009232
iteration 11752 : loss : 0.021571, loss_ce: 0.005152
iteration 11753 : loss : 0.031515, loss_ce: 0.007683
iteration 11754 : loss : 0.028363, loss_ce: 0.008101
iteration 11755 : loss : 0.027125, loss_ce: 0.012599
iteration 11756 : loss : 0.027460, loss_ce: 0.009649
iteration 11757 : loss : 0.020444, loss_ce: 0.005803
iteration 11758 : loss : 0.022561, loss_ce: 0.010431
iteration 11759 : loss : 0.024900, loss_ce: 0.007411
iteration 11760 : loss : 0.027807, loss_ce: 0.005658
iteration 11761 : loss : 0.075114, loss_ce: 0.004611
iteration 11762 : loss : 0.020652, loss_ce: 0.006952
iteration 11763 : loss : 0.029540, loss_ce: 0.008109
iteration 11764 : loss : 0.024996, loss_ce: 0.008235
iteration 11765 : loss : 0.021829, loss_ce: 0.009366
iteration 11766 : loss : 0.023000, loss_ce: 0.009783
iteration 11767 : loss : 0.025503, loss_ce: 0.011243
iteration 11768 : loss : 0.026361, loss_ce: 0.013500
iteration 11769 : loss : 0.023127, loss_ce: 0.011304
iteration 11770 : loss : 0.024700, loss_ce: 0.009294
iteration 11771 : loss : 0.025982, loss_ce: 0.013110
iteration 11772 : loss : 0.024464, loss_ce: 0.009508
iteration 11773 : loss : 0.021262, loss_ce: 0.007911
iteration 11774 : loss : 0.025542, loss_ce: 0.009221
iteration 11775 : loss : 0.023254, loss_ce: 0.011596
iteration 11776 : loss : 0.035321, loss_ce: 0.008155
iteration 11777 : loss : 0.016353, loss_ce: 0.004273
iteration 11778 : loss : 0.025226, loss_ce: 0.004765
iteration 11779 : loss : 0.022776, loss_ce: 0.007586
iteration 11780 : loss : 0.074972, loss_ce: 0.006934
iteration 11781 : loss : 0.022257, loss_ce: 0.004925
iteration 11782 : loss : 0.026590, loss_ce: 0.013356
iteration 11783 : loss : 0.026263, loss_ce: 0.011908
iteration 11784 : loss : 0.026987, loss_ce: 0.014096
iteration 11785 : loss : 0.072852, loss_ce: 0.005205
iteration 11786 : loss : 0.024549, loss_ce: 0.006437
iteration 11787 : loss : 0.076916, loss_ce: 0.004472
iteration 11788 : loss : 0.072853, loss_ce: 0.003234
iteration 11789 : loss : 0.025096, loss_ce: 0.008457
iteration 11790 : loss : 0.075603, loss_ce: 0.008742
iteration 11791 : loss : 0.074651, loss_ce: 0.003946
iteration 11792 : loss : 0.024052, loss_ce: 0.009420
iteration 11793 : loss : 0.046208, loss_ce: 0.005190
iteration 11794 : loss : 0.024718, loss_ce: 0.010329
iteration 11795 : loss : 0.039304, loss_ce: 0.006915
iteration 11796 : loss : 0.028203, loss_ce: 0.013826
iteration 11797 : loss : 0.030531, loss_ce: 0.005357
iteration 11798 : loss : 0.026958, loss_ce: 0.010404
iteration 11799 : loss : 0.026354, loss_ce: 0.010596
iteration 11800 : loss : 0.027706, loss_ce: 0.010776
iteration 11801 : loss : 0.028517, loss_ce: 0.005813
iteration 11802 : loss : 0.029746, loss_ce: 0.011766
iteration 11803 : loss : 0.023932, loss_ce: 0.006599
iteration 11804 : loss : 0.036698, loss_ce: 0.011394
iteration 11805 : loss : 0.052629, loss_ce: 0.006909
iteration 11806 : loss : 0.023179, loss_ce: 0.010140
iteration 11807 : loss : 0.026973, loss_ce: 0.011897
iteration 11808 : loss : 0.024813, loss_ce: 0.006520
iteration 11809 : loss : 0.028474, loss_ce: 0.008741
iteration 11810 : loss : 0.025257, loss_ce: 0.009147
iteration 11811 : loss : 0.150891, loss_ce: 0.007863
 64%|█████████████████▏         | 127/200 [2:10:25<1:14:57, 61.61s/it]iteration 11812 : loss : 0.029940, loss_ce: 0.006423
iteration 11813 : loss : 0.050998, loss_ce: 0.018524
iteration 11814 : loss : 0.134967, loss_ce: 0.011332
iteration 11815 : loss : 0.062289, loss_ce: 0.022896
iteration 11816 : loss : 0.032198, loss_ce: 0.013763
iteration 11817 : loss : 0.027162, loss_ce: 0.013059
iteration 11818 : loss : 0.034844, loss_ce: 0.011306
iteration 11819 : loss : 0.026366, loss_ce: 0.010461
iteration 11820 : loss : 0.030050, loss_ce: 0.010403
iteration 11821 : loss : 0.029682, loss_ce: 0.008779
iteration 11822 : loss : 0.025173, loss_ce: 0.010307
iteration 11823 : loss : 0.027370, loss_ce: 0.008342
iteration 11824 : loss : 0.027828, loss_ce: 0.009744
iteration 11825 : loss : 0.028107, loss_ce: 0.009202
iteration 11826 : loss : 0.024486, loss_ce: 0.008831
iteration 11827 : loss : 0.029184, loss_ce: 0.013651
iteration 11828 : loss : 0.030750, loss_ce: 0.011981
iteration 11829 : loss : 0.025170, loss_ce: 0.008088
iteration 11830 : loss : 0.029332, loss_ce: 0.008435
iteration 11831 : loss : 0.025234, loss_ce: 0.008642
iteration 11832 : loss : 0.026197, loss_ce: 0.011498
iteration 11833 : loss : 0.023255, loss_ce: 0.006353
iteration 11834 : loss : 0.030873, loss_ce: 0.010048
iteration 11835 : loss : 0.029709, loss_ce: 0.010355
iteration 11836 : loss : 0.075093, loss_ce: 0.005846
iteration 11837 : loss : 0.026531, loss_ce: 0.013851
iteration 11838 : loss : 0.027140, loss_ce: 0.008437
iteration 11839 : loss : 0.029503, loss_ce: 0.010830
iteration 11840 : loss : 0.024923, loss_ce: 0.006875
iteration 11841 : loss : 0.022739, loss_ce: 0.008628
iteration 11842 : loss : 0.023636, loss_ce: 0.007850
iteration 11843 : loss : 0.030736, loss_ce: 0.003781
iteration 11844 : loss : 0.027988, loss_ce: 0.006296
iteration 11845 : loss : 0.023227, loss_ce: 0.009593
iteration 11846 : loss : 0.025767, loss_ce: 0.006922
iteration 11847 : loss : 0.028813, loss_ce: 0.009994
iteration 11848 : loss : 0.025308, loss_ce: 0.005260
iteration 11849 : loss : 0.024866, loss_ce: 0.007480
iteration 11850 : loss : 0.029419, loss_ce: 0.009116
iteration 11851 : loss : 0.023108, loss_ce: 0.007687
iteration 11852 : loss : 0.028009, loss_ce: 0.007760
iteration 11853 : loss : 0.021382, loss_ce: 0.006278
iteration 11854 : loss : 0.026571, loss_ce: 0.009409
iteration 11855 : loss : 0.024116, loss_ce: 0.009106
iteration 11856 : loss : 0.029029, loss_ce: 0.008735
iteration 11857 : loss : 0.025639, loss_ce: 0.008113
iteration 11858 : loss : 0.026261, loss_ce: 0.010314
iteration 11859 : loss : 0.032099, loss_ce: 0.005137
iteration 11860 : loss : 0.026129, loss_ce: 0.007911
iteration 11861 : loss : 0.021967, loss_ce: 0.009412
iteration 11862 : loss : 0.026196, loss_ce: 0.010666
iteration 11863 : loss : 0.026003, loss_ce: 0.011522
iteration 11864 : loss : 0.073618, loss_ce: 0.007590
iteration 11865 : loss : 0.025198, loss_ce: 0.010893
iteration 11866 : loss : 0.021633, loss_ce: 0.007579
iteration 11867 : loss : 0.026371, loss_ce: 0.008027
iteration 11868 : loss : 0.020594, loss_ce: 0.007309
iteration 11869 : loss : 0.022712, loss_ce: 0.008587
iteration 11870 : loss : 0.074345, loss_ce: 0.007198
iteration 11871 : loss : 0.023274, loss_ce: 0.009635
iteration 11872 : loss : 0.019135, loss_ce: 0.006498
iteration 11873 : loss : 0.024565, loss_ce: 0.005470
iteration 11874 : loss : 0.029198, loss_ce: 0.008013
iteration 11875 : loss : 0.081586, loss_ce: 0.005858
iteration 11876 : loss : 0.025709, loss_ce: 0.008349
iteration 11877 : loss : 0.023815, loss_ce: 0.009239
iteration 11878 : loss : 0.028762, loss_ce: 0.009740
iteration 11879 : loss : 0.034612, loss_ce: 0.005981
iteration 11880 : loss : 0.078854, loss_ce: 0.013091
iteration 11881 : loss : 0.023296, loss_ce: 0.005037
iteration 11882 : loss : 0.020935, loss_ce: 0.005782
iteration 11883 : loss : 0.025896, loss_ce: 0.011463
iteration 11884 : loss : 0.025640, loss_ce: 0.006793
iteration 11885 : loss : 0.021272, loss_ce: 0.008207
iteration 11886 : loss : 0.022812, loss_ce: 0.010255
iteration 11887 : loss : 0.076756, loss_ce: 0.006674
iteration 11888 : loss : 0.029024, loss_ce: 0.007673
iteration 11889 : loss : 0.025251, loss_ce: 0.012285
iteration 11890 : loss : 0.030321, loss_ce: 0.012777
iteration 11891 : loss : 0.042165, loss_ce: 0.007455
iteration 11892 : loss : 0.023848, loss_ce: 0.006284
iteration 11893 : loss : 0.025253, loss_ce: 0.009272
iteration 11894 : loss : 0.029271, loss_ce: 0.008523
iteration 11895 : loss : 0.026819, loss_ce: 0.011272
iteration 11896 : loss : 0.024355, loss_ce: 0.008515
iteration 11897 : loss : 0.027901, loss_ce: 0.010407
iteration 11898 : loss : 0.032123, loss_ce: 0.010919
iteration 11899 : loss : 0.023401, loss_ce: 0.009728
iteration 11900 : loss : 0.024587, loss_ce: 0.012518
iteration 11901 : loss : 0.025446, loss_ce: 0.010816
iteration 11902 : loss : 0.027545, loss_ce: 0.010109
iteration 11903 : loss : 0.022898, loss_ce: 0.009604
iteration 11904 : loss : 0.131844, loss_ce: 0.010590
 64%|█████████████████▎         | 128/200 [2:11:27<1:13:57, 61.63s/it]iteration 11905 : loss : 0.074222, loss_ce: 0.006740
iteration 11906 : loss : 0.031696, loss_ce: 0.012510
iteration 11907 : loss : 0.022953, loss_ce: 0.009031
iteration 11908 : loss : 0.026348, loss_ce: 0.012234
iteration 11909 : loss : 0.026239, loss_ce: 0.009286
iteration 11910 : loss : 0.020407, loss_ce: 0.004746
iteration 11911 : loss : 0.078215, loss_ce: 0.005446
iteration 11912 : loss : 0.039128, loss_ce: 0.007458
iteration 11913 : loss : 0.023958, loss_ce: 0.006905
iteration 11914 : loss : 0.020488, loss_ce: 0.005720
iteration 11915 : loss : 0.025893, loss_ce: 0.009552
iteration 11916 : loss : 0.022177, loss_ce: 0.006852
iteration 11917 : loss : 0.028225, loss_ce: 0.011270
iteration 11918 : loss : 0.024114, loss_ce: 0.012121
iteration 11919 : loss : 0.023818, loss_ce: 0.009329
iteration 11920 : loss : 0.024414, loss_ce: 0.008951
iteration 11921 : loss : 0.026673, loss_ce: 0.005525
iteration 11922 : loss : 0.073339, loss_ce: 0.012131
iteration 11923 : loss : 0.020622, loss_ce: 0.006958
iteration 11924 : loss : 0.043450, loss_ce: 0.006224
iteration 11925 : loss : 0.024192, loss_ce: 0.009413
iteration 11926 : loss : 0.021859, loss_ce: 0.006191
iteration 11927 : loss : 0.027084, loss_ce: 0.007914
iteration 11928 : loss : 0.026480, loss_ce: 0.006810
iteration 11929 : loss : 0.024182, loss_ce: 0.008985
iteration 11930 : loss : 0.024277, loss_ce: 0.012022
iteration 11931 : loss : 0.026096, loss_ce: 0.006833
iteration 11932 : loss : 0.026260, loss_ce: 0.007300
iteration 11933 : loss : 0.023003, loss_ce: 0.006339
iteration 11934 : loss : 0.025438, loss_ce: 0.009153
iteration 11935 : loss : 0.023736, loss_ce: 0.006013
iteration 11936 : loss : 0.022517, loss_ce: 0.009910
iteration 11937 : loss : 0.023942, loss_ce: 0.007828
iteration 11938 : loss : 0.025630, loss_ce: 0.009699
iteration 11939 : loss : 0.023212, loss_ce: 0.009321
iteration 11940 : loss : 0.026492, loss_ce: 0.010633
iteration 11941 : loss : 0.069686, loss_ce: 0.009666
iteration 11942 : loss : 0.025790, loss_ce: 0.014293
iteration 11943 : loss : 0.027316, loss_ce: 0.010285
iteration 11944 : loss : 0.078345, loss_ce: 0.007014
iteration 11945 : loss : 0.026421, loss_ce: 0.010321
iteration 11946 : loss : 0.027347, loss_ce: 0.007351
iteration 11947 : loss : 0.027890, loss_ce: 0.013755
iteration 11948 : loss : 0.024825, loss_ce: 0.010405
iteration 11949 : loss : 0.024812, loss_ce: 0.010145
iteration 11950 : loss : 0.022685, loss_ce: 0.006600
iteration 11951 : loss : 0.027762, loss_ce: 0.010085
iteration 11952 : loss : 0.019405, loss_ce: 0.007175
iteration 11953 : loss : 0.029175, loss_ce: 0.012578
iteration 11954 : loss : 0.024826, loss_ce: 0.009716
iteration 11955 : loss : 0.024784, loss_ce: 0.006046
iteration 11956 : loss : 0.026012, loss_ce: 0.007523
iteration 11957 : loss : 0.083109, loss_ce: 0.006490
iteration 11958 : loss : 0.026381, loss_ce: 0.007026
iteration 11959 : loss : 0.019949, loss_ce: 0.007890
iteration 11960 : loss : 0.021386, loss_ce: 0.007394
iteration 11961 : loss : 0.022046, loss_ce: 0.010108
iteration 11962 : loss : 0.027411, loss_ce: 0.007486
iteration 11963 : loss : 0.023773, loss_ce: 0.009612
iteration 11964 : loss : 0.032110, loss_ce: 0.008959
iteration 11965 : loss : 0.080655, loss_ce: 0.003387
iteration 11966 : loss : 0.044752, loss_ce: 0.006094
iteration 11967 : loss : 0.028971, loss_ce: 0.007651
iteration 11968 : loss : 0.030715, loss_ce: 0.006147
iteration 11969 : loss : 0.022860, loss_ce: 0.008249
iteration 11970 : loss : 0.022789, loss_ce: 0.008175
iteration 11971 : loss : 0.026026, loss_ce: 0.009113
iteration 11972 : loss : 0.021771, loss_ce: 0.008575
iteration 11973 : loss : 0.024953, loss_ce: 0.010329
iteration 11974 : loss : 0.021702, loss_ce: 0.007623
iteration 11975 : loss : 0.083275, loss_ce: 0.005201
iteration 11976 : loss : 0.021737, loss_ce: 0.006434
iteration 11977 : loss : 0.019071, loss_ce: 0.005126
iteration 11978 : loss : 0.024735, loss_ce: 0.009579
iteration 11979 : loss : 0.023178, loss_ce: 0.005723
iteration 11980 : loss : 0.025585, loss_ce: 0.008982
iteration 11981 : loss : 0.021227, loss_ce: 0.007938
iteration 11982 : loss : 0.026408, loss_ce: 0.010964
iteration 11983 : loss : 0.024621, loss_ce: 0.010716
iteration 11984 : loss : 0.026991, loss_ce: 0.008007
iteration 11985 : loss : 0.022027, loss_ce: 0.006874
iteration 11986 : loss : 0.027399, loss_ce: 0.009607
iteration 11987 : loss : 0.025771, loss_ce: 0.012254
iteration 11988 : loss : 0.024701, loss_ce: 0.008496
iteration 11989 : loss : 0.030495, loss_ce: 0.007954
iteration 11990 : loss : 0.027352, loss_ce: 0.006524
iteration 11991 : loss : 0.022403, loss_ce: 0.007296
iteration 11992 : loss : 0.022453, loss_ce: 0.010136
iteration 11993 : loss : 0.031546, loss_ce: 0.008511
iteration 11994 : loss : 0.020169, loss_ce: 0.005948
iteration 11995 : loss : 0.027977, loss_ce: 0.011841
iteration 11996 : loss : 0.020745, loss_ce: 0.005825
iteration 11997 : loss : 0.035082, loss_ce: 0.014499
 64%|█████████████████▍         | 129/200 [2:12:22<1:10:31, 59.59s/it]iteration 11998 : loss : 0.022757, loss_ce: 0.006565
iteration 11999 : loss : 0.024719, loss_ce: 0.009380
iteration 12000 : loss : 0.023972, loss_ce: 0.006527
iteration 12001 : loss : 0.021943, loss_ce: 0.008545
iteration 12002 : loss : 0.022256, loss_ce: 0.006938
iteration 12003 : loss : 0.024535, loss_ce: 0.009723
iteration 12004 : loss : 0.035661, loss_ce: 0.005298
iteration 12005 : loss : 0.021702, loss_ce: 0.004720
iteration 12006 : loss : 0.026170, loss_ce: 0.011090
iteration 12007 : loss : 0.024541, loss_ce: 0.011632
iteration 12008 : loss : 0.030351, loss_ce: 0.006290
iteration 12009 : loss : 0.027778, loss_ce: 0.006874
iteration 12010 : loss : 0.022795, loss_ce: 0.008455
iteration 12011 : loss : 0.021769, loss_ce: 0.007292
iteration 12012 : loss : 0.023301, loss_ce: 0.009499
iteration 12013 : loss : 0.028989, loss_ce: 0.011839
iteration 12014 : loss : 0.024010, loss_ce: 0.008944
iteration 12015 : loss : 0.024794, loss_ce: 0.008985
iteration 12016 : loss : 0.019166, loss_ce: 0.009315
iteration 12017 : loss : 0.025687, loss_ce: 0.008872
iteration 12018 : loss : 0.073967, loss_ce: 0.004984
iteration 12019 : loss : 0.019027, loss_ce: 0.007278
iteration 12020 : loss : 0.023906, loss_ce: 0.007091
iteration 12021 : loss : 0.025476, loss_ce: 0.008556
iteration 12022 : loss : 0.074326, loss_ce: 0.007170
iteration 12023 : loss : 0.024464, loss_ce: 0.009525
iteration 12024 : loss : 0.021013, loss_ce: 0.005698
iteration 12025 : loss : 0.022353, loss_ce: 0.007689
iteration 12026 : loss : 0.023478, loss_ce: 0.009419
iteration 12027 : loss : 0.025415, loss_ce: 0.009750
iteration 12028 : loss : 0.024917, loss_ce: 0.010899
iteration 12029 : loss : 0.022351, loss_ce: 0.009344
iteration 12030 : loss : 0.048177, loss_ce: 0.008069
iteration 12031 : loss : 0.022212, loss_ce: 0.005896
iteration 12032 : loss : 0.026166, loss_ce: 0.011101
iteration 12033 : loss : 0.073981, loss_ce: 0.004106
iteration 12034 : loss : 0.021878, loss_ce: 0.008242
iteration 12035 : loss : 0.026180, loss_ce: 0.010032
iteration 12036 : loss : 0.025594, loss_ce: 0.009183
iteration 12037 : loss : 0.027040, loss_ce: 0.009800
iteration 12038 : loss : 0.026133, loss_ce: 0.006170
iteration 12039 : loss : 0.028972, loss_ce: 0.005902
iteration 12040 : loss : 0.022836, loss_ce: 0.006201
iteration 12041 : loss : 0.029279, loss_ce: 0.006325
iteration 12042 : loss : 0.027599, loss_ce: 0.006274
iteration 12043 : loss : 0.023674, loss_ce: 0.011046
iteration 12044 : loss : 0.024036, loss_ce: 0.010668
iteration 12045 : loss : 0.025578, loss_ce: 0.007269
iteration 12046 : loss : 0.024828, loss_ce: 0.009148
iteration 12047 : loss : 0.021530, loss_ce: 0.008167
iteration 12048 : loss : 0.025228, loss_ce: 0.010971
iteration 12049 : loss : 0.026073, loss_ce: 0.007740
iteration 12050 : loss : 0.026580, loss_ce: 0.009695
iteration 12051 : loss : 0.035618, loss_ce: 0.009344
iteration 12052 : loss : 0.023519, loss_ce: 0.011284
iteration 12053 : loss : 0.023830, loss_ce: 0.006513
iteration 12054 : loss : 0.025654, loss_ce: 0.011490
iteration 12055 : loss : 0.023310, loss_ce: 0.011496
iteration 12056 : loss : 0.022038, loss_ce: 0.007652
iteration 12057 : loss : 0.023649, loss_ce: 0.010661
iteration 12058 : loss : 0.024090, loss_ce: 0.008693
iteration 12059 : loss : 0.027387, loss_ce: 0.008958
iteration 12060 : loss : 0.025641, loss_ce: 0.009329
iteration 12061 : loss : 0.022843, loss_ce: 0.005347
iteration 12062 : loss : 0.076173, loss_ce: 0.005729
iteration 12063 : loss : 0.021794, loss_ce: 0.009904
iteration 12064 : loss : 0.021975, loss_ce: 0.007355
iteration 12065 : loss : 0.022886, loss_ce: 0.009176
iteration 12066 : loss : 0.025484, loss_ce: 0.004809
iteration 12067 : loss : 0.073778, loss_ce: 0.006032
iteration 12068 : loss : 0.021157, loss_ce: 0.006544
iteration 12069 : loss : 0.024724, loss_ce: 0.009741
iteration 12070 : loss : 0.023502, loss_ce: 0.006578
iteration 12071 : loss : 0.025613, loss_ce: 0.011286
iteration 12072 : loss : 0.023297, loss_ce: 0.006366
iteration 12073 : loss : 0.021829, loss_ce: 0.007409
iteration 12074 : loss : 0.019376, loss_ce: 0.007126
iteration 12075 : loss : 0.026038, loss_ce: 0.004380
iteration 12076 : loss : 0.039870, loss_ce: 0.010891
iteration 12077 : loss : 0.024405, loss_ce: 0.006686
iteration 12078 : loss : 0.021247, loss_ce: 0.007375
iteration 12079 : loss : 0.074268, loss_ce: 0.005614
iteration 12080 : loss : 0.021344, loss_ce: 0.008085
iteration 12081 : loss : 0.028802, loss_ce: 0.009217
iteration 12082 : loss : 0.032699, loss_ce: 0.006528
iteration 12083 : loss : 0.020872, loss_ce: 0.007767
iteration 12084 : loss : 0.025472, loss_ce: 0.007534
iteration 12085 : loss : 0.021621, loss_ce: 0.007410
iteration 12086 : loss : 0.032442, loss_ce: 0.014338
iteration 12087 : loss : 0.027530, loss_ce: 0.008242
iteration 12088 : loss : 0.040158, loss_ce: 0.010523
iteration 12089 : loss : 0.021802, loss_ce: 0.006641
iteration 12090 : loss : 0.283929, loss_ce: 0.005407
 65%|█████████████████▌         | 130/200 [2:13:16<1:07:46, 58.09s/it]iteration 12091 : loss : 0.021138, loss_ce: 0.003631
iteration 12092 : loss : 0.021116, loss_ce: 0.005538
iteration 12093 : loss : 0.024402, loss_ce: 0.012005
iteration 12094 : loss : 0.021733, loss_ce: 0.009254
iteration 12095 : loss : 0.028096, loss_ce: 0.005070
iteration 12096 : loss : 0.075931, loss_ce: 0.008371
iteration 12097 : loss : 0.024519, loss_ce: 0.008288
iteration 12098 : loss : 0.025974, loss_ce: 0.007962
iteration 12099 : loss : 0.024676, loss_ce: 0.007655
iteration 12100 : loss : 0.022360, loss_ce: 0.007306
iteration 12101 : loss : 0.019029, loss_ce: 0.006426
iteration 12102 : loss : 0.027525, loss_ce: 0.007556
iteration 12103 : loss : 0.029446, loss_ce: 0.004553
iteration 12104 : loss : 0.022381, loss_ce: 0.007950
iteration 12105 : loss : 0.023978, loss_ce: 0.007807
iteration 12106 : loss : 0.024878, loss_ce: 0.008220
iteration 12107 : loss : 0.024132, loss_ce: 0.011210
iteration 12108 : loss : 0.034562, loss_ce: 0.007650
iteration 12109 : loss : 0.020455, loss_ce: 0.007323
iteration 12110 : loss : 0.023426, loss_ce: 0.008105
iteration 12111 : loss : 0.025594, loss_ce: 0.010523
iteration 12112 : loss : 0.032052, loss_ce: 0.008380
iteration 12113 : loss : 0.025111, loss_ce: 0.008761
iteration 12114 : loss : 0.024954, loss_ce: 0.007872
iteration 12115 : loss : 0.047049, loss_ce: 0.006278
iteration 12116 : loss : 0.019391, loss_ce: 0.007424
iteration 12117 : loss : 0.019871, loss_ce: 0.007505
iteration 12118 : loss : 0.020606, loss_ce: 0.004838
iteration 12119 : loss : 0.028229, loss_ce: 0.012555
iteration 12120 : loss : 0.027291, loss_ce: 0.009610
iteration 12121 : loss : 0.074682, loss_ce: 0.005373
iteration 12122 : loss : 0.027078, loss_ce: 0.011020
iteration 12123 : loss : 0.076925, loss_ce: 0.009401
iteration 12124 : loss : 0.025384, loss_ce: 0.009489
iteration 12125 : loss : 0.023131, loss_ce: 0.007925
iteration 12126 : loss : 0.024568, loss_ce: 0.009659
iteration 12127 : loss : 0.022369, loss_ce: 0.005374
iteration 12128 : loss : 0.031511, loss_ce: 0.008036
iteration 12129 : loss : 0.030448, loss_ce: 0.014020
iteration 12130 : loss : 0.024378, loss_ce: 0.008458
iteration 12131 : loss : 0.031506, loss_ce: 0.009526
iteration 12132 : loss : 0.025168, loss_ce: 0.010759
iteration 12133 : loss : 0.023850, loss_ce: 0.006361
iteration 12134 : loss : 0.023442, loss_ce: 0.005507
iteration 12135 : loss : 0.023281, loss_ce: 0.006490
iteration 12136 : loss : 0.027075, loss_ce: 0.007709
iteration 12137 : loss : 0.022557, loss_ce: 0.008294
iteration 12138 : loss : 0.030879, loss_ce: 0.009618
iteration 12139 : loss : 0.023794, loss_ce: 0.007063
iteration 12140 : loss : 0.076744, loss_ce: 0.004344
iteration 12141 : loss : 0.082764, loss_ce: 0.005271
iteration 12142 : loss : 0.024383, loss_ce: 0.010079
iteration 12143 : loss : 0.028656, loss_ce: 0.008478
iteration 12144 : loss : 0.027352, loss_ce: 0.009184
iteration 12145 : loss : 0.026349, loss_ce: 0.008673
iteration 12146 : loss : 0.024666, loss_ce: 0.011340
iteration 12147 : loss : 0.024797, loss_ce: 0.008225
iteration 12148 : loss : 0.038254, loss_ce: 0.010544
iteration 12149 : loss : 0.024711, loss_ce: 0.010224
iteration 12150 : loss : 0.024236, loss_ce: 0.012500
iteration 12151 : loss : 0.028108, loss_ce: 0.011392
iteration 12152 : loss : 0.023387, loss_ce: 0.008576
iteration 12153 : loss : 0.026283, loss_ce: 0.009638
iteration 12154 : loss : 0.027755, loss_ce: 0.013436
iteration 12155 : loss : 0.022700, loss_ce: 0.008266
iteration 12156 : loss : 0.022308, loss_ce: 0.007251
iteration 12157 : loss : 0.041887, loss_ce: 0.005901
iteration 12158 : loss : 0.022418, loss_ce: 0.006935
iteration 12159 : loss : 0.029514, loss_ce: 0.008926
iteration 12160 : loss : 0.022325, loss_ce: 0.009000
iteration 12161 : loss : 0.049143, loss_ce: 0.013780
iteration 12162 : loss : 0.075921, loss_ce: 0.008121
iteration 12163 : loss : 0.025998, loss_ce: 0.007209
iteration 12164 : loss : 0.022778, loss_ce: 0.006762
iteration 12165 : loss : 0.023260, loss_ce: 0.008273
iteration 12166 : loss : 0.024539, loss_ce: 0.010030
iteration 12167 : loss : 0.024932, loss_ce: 0.009103
iteration 12168 : loss : 0.026996, loss_ce: 0.008808
iteration 12169 : loss : 0.026164, loss_ce: 0.008894
iteration 12170 : loss : 0.081055, loss_ce: 0.003629
iteration 12171 : loss : 0.021683, loss_ce: 0.007801
iteration 12172 : loss : 0.028836, loss_ce: 0.007893
iteration 12173 : loss : 0.024896, loss_ce: 0.002785
iteration 12174 : loss : 0.025380, loss_ce: 0.009818
iteration 12175 : loss : 0.025844, loss_ce: 0.010918
iteration 12176 : loss : 0.027708, loss_ce: 0.011582
iteration 12177 : loss : 0.032941, loss_ce: 0.007921
iteration 12178 : loss : 0.049720, loss_ce: 0.005700
iteration 12179 : loss : 0.024380, loss_ce: 0.007927
iteration 12180 : loss : 0.075901, loss_ce: 0.009510
iteration 12181 : loss : 0.026185, loss_ce: 0.009439
iteration 12182 : loss : 0.018074, loss_ce: 0.007142
iteration 12183 : loss : 0.387838, loss_ce: 0.000524
 66%|█████████████████▋         | 131/200 [2:14:10<1:05:31, 56.97s/it]iteration 12184 : loss : 0.025529, loss_ce: 0.010196
iteration 12185 : loss : 0.040390, loss_ce: 0.010702
iteration 12186 : loss : 0.025509, loss_ce: 0.008538
iteration 12187 : loss : 0.020849, loss_ce: 0.006159
iteration 12188 : loss : 0.023241, loss_ce: 0.006238
iteration 12189 : loss : 0.026825, loss_ce: 0.007402
iteration 12190 : loss : 0.028617, loss_ce: 0.005864
iteration 12191 : loss : 0.020252, loss_ce: 0.005184
iteration 12192 : loss : 0.028890, loss_ce: 0.011350
iteration 12193 : loss : 0.076075, loss_ce: 0.009101
iteration 12194 : loss : 0.024637, loss_ce: 0.008028
iteration 12195 : loss : 0.021322, loss_ce: 0.006006
iteration 12196 : loss : 0.029333, loss_ce: 0.008186
iteration 12197 : loss : 0.022250, loss_ce: 0.011100
iteration 12198 : loss : 0.022949, loss_ce: 0.009850
iteration 12199 : loss : 0.023669, loss_ce: 0.009409
iteration 12200 : loss : 0.036407, loss_ce: 0.006559
iteration 12201 : loss : 0.034784, loss_ce: 0.004833
iteration 12202 : loss : 0.024280, loss_ce: 0.008703
iteration 12203 : loss : 0.024638, loss_ce: 0.006633
iteration 12204 : loss : 0.022544, loss_ce: 0.007132
iteration 12205 : loss : 0.025650, loss_ce: 0.008649
iteration 12206 : loss : 0.028108, loss_ce: 0.013385
iteration 12207 : loss : 0.023336, loss_ce: 0.006573
iteration 12208 : loss : 0.029273, loss_ce: 0.010412
iteration 12209 : loss : 0.025325, loss_ce: 0.011922
iteration 12210 : loss : 0.025341, loss_ce: 0.007917
iteration 12211 : loss : 0.026919, loss_ce: 0.004833
iteration 12212 : loss : 0.023127, loss_ce: 0.011568
iteration 12213 : loss : 0.027990, loss_ce: 0.011029
iteration 12214 : loss : 0.073716, loss_ce: 0.007149
iteration 12215 : loss : 0.020143, loss_ce: 0.006062
iteration 12216 : loss : 0.019994, loss_ce: 0.005173
iteration 12217 : loss : 0.026143, loss_ce: 0.005438
iteration 12218 : loss : 0.026295, loss_ce: 0.012940
iteration 12219 : loss : 0.024556, loss_ce: 0.008697
iteration 12220 : loss : 0.022927, loss_ce: 0.010088
iteration 12221 : loss : 0.033518, loss_ce: 0.009505
iteration 12222 : loss : 0.021895, loss_ce: 0.010204
iteration 12223 : loss : 0.022387, loss_ce: 0.007740
iteration 12224 : loss : 0.030077, loss_ce: 0.008246
iteration 12225 : loss : 0.025446, loss_ce: 0.010731
iteration 12226 : loss : 0.037296, loss_ce: 0.006312
iteration 12227 : loss : 0.078474, loss_ce: 0.004284
iteration 12228 : loss : 0.020558, loss_ce: 0.005632
iteration 12229 : loss : 0.023536, loss_ce: 0.010830
iteration 12230 : loss : 0.032734, loss_ce: 0.010511
iteration 12231 : loss : 0.021048, loss_ce: 0.005978
iteration 12232 : loss : 0.027365, loss_ce: 0.005380
iteration 12233 : loss : 0.021485, loss_ce: 0.009111
iteration 12234 : loss : 0.026410, loss_ce: 0.005735
iteration 12235 : loss : 0.020420, loss_ce: 0.009773
iteration 12236 : loss : 0.021856, loss_ce: 0.007874
iteration 12237 : loss : 0.028327, loss_ce: 0.011599
iteration 12238 : loss : 0.023480, loss_ce: 0.008151
iteration 12239 : loss : 0.023938, loss_ce: 0.008634
iteration 12240 : loss : 0.026565, loss_ce: 0.010407
iteration 12241 : loss : 0.031567, loss_ce: 0.009932
iteration 12242 : loss : 0.023278, loss_ce: 0.006205
iteration 12243 : loss : 0.024277, loss_ce: 0.011746
iteration 12244 : loss : 0.023228, loss_ce: 0.010421
iteration 12245 : loss : 0.025187, loss_ce: 0.007402
iteration 12246 : loss : 0.023054, loss_ce: 0.010810
iteration 12247 : loss : 0.072647, loss_ce: 0.004200
iteration 12248 : loss : 0.026827, loss_ce: 0.013738
iteration 12249 : loss : 0.027631, loss_ce: 0.006568
iteration 12250 : loss : 0.019833, loss_ce: 0.006023
iteration 12251 : loss : 0.071208, loss_ce: 0.007845
iteration 12252 : loss : 0.025459, loss_ce: 0.009585
iteration 12253 : loss : 0.022845, loss_ce: 0.007626
iteration 12254 : loss : 0.023093, loss_ce: 0.007984
iteration 12255 : loss : 0.024955, loss_ce: 0.005224
iteration 12256 : loss : 0.022170, loss_ce: 0.009730
iteration 12257 : loss : 0.023465, loss_ce: 0.010966
iteration 12258 : loss : 0.028976, loss_ce: 0.010695
iteration 12259 : loss : 0.024943, loss_ce: 0.012684
iteration 12260 : loss : 0.076633, loss_ce: 0.006655
iteration 12261 : loss : 0.028224, loss_ce: 0.004685
iteration 12262 : loss : 0.073571, loss_ce: 0.005343
iteration 12263 : loss : 0.038190, loss_ce: 0.009003
iteration 12264 : loss : 0.024193, loss_ce: 0.005556
iteration 12265 : loss : 0.023233, loss_ce: 0.007026
iteration 12266 : loss : 0.026618, loss_ce: 0.012313
iteration 12267 : loss : 0.023098, loss_ce: 0.006478
iteration 12268 : loss : 0.024402, loss_ce: 0.009146
iteration 12269 : loss : 0.021716, loss_ce: 0.006549
iteration 12270 : loss : 0.027031, loss_ce: 0.009827
iteration 12271 : loss : 0.028977, loss_ce: 0.010115
iteration 12272 : loss : 0.023736, loss_ce: 0.010323
iteration 12273 : loss : 0.031172, loss_ce: 0.007773
iteration 12274 : loss : 0.023806, loss_ce: 0.006498
iteration 12275 : loss : 0.031840, loss_ce: 0.005986
iteration 12276 : loss : 0.185376, loss_ce: 0.005465
 66%|█████████████████▊         | 132/200 [2:15:05<1:03:41, 56.20s/it]iteration 12277 : loss : 0.023414, loss_ce: 0.007193
iteration 12278 : loss : 0.022179, loss_ce: 0.007676
iteration 12279 : loss : 0.028518, loss_ce: 0.005799
iteration 12280 : loss : 0.023029, loss_ce: 0.008328
iteration 12281 : loss : 0.086469, loss_ce: 0.005857
iteration 12282 : loss : 0.029879, loss_ce: 0.009624
iteration 12283 : loss : 0.032013, loss_ce: 0.007828
iteration 12284 : loss : 0.029150, loss_ce: 0.008885
iteration 12285 : loss : 0.020628, loss_ce: 0.006646
iteration 12286 : loss : 0.022271, loss_ce: 0.006857
iteration 12287 : loss : 0.027124, loss_ce: 0.009202
iteration 12288 : loss : 0.028114, loss_ce: 0.009113
iteration 12289 : loss : 0.075431, loss_ce: 0.008561
iteration 12290 : loss : 0.023771, loss_ce: 0.009968
iteration 12291 : loss : 0.028975, loss_ce: 0.012895
iteration 12292 : loss : 0.023550, loss_ce: 0.008354
iteration 12293 : loss : 0.024277, loss_ce: 0.008291
iteration 12294 : loss : 0.024320, loss_ce: 0.009767
iteration 12295 : loss : 0.021848, loss_ce: 0.004957
iteration 12296 : loss : 0.019279, loss_ce: 0.008280
iteration 12297 : loss : 0.077751, loss_ce: 0.009297
iteration 12298 : loss : 0.016468, loss_ce: 0.004456
iteration 12299 : loss : 0.070370, loss_ce: 0.005313
iteration 12300 : loss : 0.023951, loss_ce: 0.008270
iteration 12301 : loss : 0.026978, loss_ce: 0.006118
iteration 12302 : loss : 0.026743, loss_ce: 0.010007
iteration 12303 : loss : 0.027951, loss_ce: 0.008436
iteration 12304 : loss : 0.030199, loss_ce: 0.007571
iteration 12305 : loss : 0.026674, loss_ce: 0.008266
iteration 12306 : loss : 0.023389, loss_ce: 0.011601
iteration 12307 : loss : 0.023797, loss_ce: 0.010043
iteration 12308 : loss : 0.024082, loss_ce: 0.007462
iteration 12309 : loss : 0.033714, loss_ce: 0.005813
iteration 12310 : loss : 0.025643, loss_ce: 0.005997
iteration 12311 : loss : 0.023506, loss_ce: 0.006352
iteration 12312 : loss : 0.023239, loss_ce: 0.006124
iteration 12313 : loss : 0.032691, loss_ce: 0.008309
iteration 12314 : loss : 0.022247, loss_ce: 0.009202
iteration 12315 : loss : 0.077449, loss_ce: 0.007093
iteration 12316 : loss : 0.031460, loss_ce: 0.012045
iteration 12317 : loss : 0.024446, loss_ce: 0.009411
iteration 12318 : loss : 0.023263, loss_ce: 0.006310
iteration 12319 : loss : 0.036453, loss_ce: 0.008498
iteration 12320 : loss : 0.023413, loss_ce: 0.006358
iteration 12321 : loss : 0.032655, loss_ce: 0.006619
iteration 12322 : loss : 0.023514, loss_ce: 0.010997
iteration 12323 : loss : 0.024842, loss_ce: 0.011383
iteration 12324 : loss : 0.023214, loss_ce: 0.009224
iteration 12325 : loss : 0.029704, loss_ce: 0.006410
iteration 12326 : loss : 0.024669, loss_ce: 0.006975
iteration 12327 : loss : 0.025730, loss_ce: 0.006840
iteration 12328 : loss : 0.024280, loss_ce: 0.008636
iteration 12329 : loss : 0.025371, loss_ce: 0.006762
iteration 12330 : loss : 0.026743, loss_ce: 0.011551
iteration 12331 : loss : 0.025071, loss_ce: 0.007941
iteration 12332 : loss : 0.022386, loss_ce: 0.005568
iteration 12333 : loss : 0.025271, loss_ce: 0.007756
iteration 12334 : loss : 0.021216, loss_ce: 0.007614
iteration 12335 : loss : 0.021260, loss_ce: 0.007119
iteration 12336 : loss : 0.019856, loss_ce: 0.008296
iteration 12337 : loss : 0.023578, loss_ce: 0.007851
iteration 12338 : loss : 0.022258, loss_ce: 0.009903
iteration 12339 : loss : 0.022926, loss_ce: 0.008473
iteration 12340 : loss : 0.024478, loss_ce: 0.009251
iteration 12341 : loss : 0.025218, loss_ce: 0.010688
iteration 12342 : loss : 0.023750, loss_ce: 0.009863
iteration 12343 : loss : 0.023153, loss_ce: 0.010279
iteration 12344 : loss : 0.021337, loss_ce: 0.004822
iteration 12345 : loss : 0.021100, loss_ce: 0.008206
iteration 12346 : loss : 0.020453, loss_ce: 0.007153
iteration 12347 : loss : 0.026163, loss_ce: 0.009976
iteration 12348 : loss : 0.022544, loss_ce: 0.008889
iteration 12349 : loss : 0.033938, loss_ce: 0.008023
iteration 12350 : loss : 0.022688, loss_ce: 0.006068
iteration 12351 : loss : 0.032685, loss_ce: 0.004338
iteration 12352 : loss : 0.024126, loss_ce: 0.010612
iteration 12353 : loss : 0.077922, loss_ce: 0.005216
iteration 12354 : loss : 0.018879, loss_ce: 0.006434
iteration 12355 : loss : 0.023435, loss_ce: 0.008555
iteration 12356 : loss : 0.023151, loss_ce: 0.010273
iteration 12357 : loss : 0.027620, loss_ce: 0.008258
iteration 12358 : loss : 0.058780, loss_ce: 0.008406
iteration 12359 : loss : 0.029403, loss_ce: 0.012409
iteration 12360 : loss : 0.026546, loss_ce: 0.013576
iteration 12361 : loss : 0.023627, loss_ce: 0.006754
iteration 12362 : loss : 0.028418, loss_ce: 0.009415
iteration 12363 : loss : 0.029657, loss_ce: 0.013710
iteration 12364 : loss : 0.023937, loss_ce: 0.009081
iteration 12365 : loss : 0.027614, loss_ce: 0.008278
iteration 12366 : loss : 0.025763, loss_ce: 0.009425
iteration 12367 : loss : 0.021678, loss_ce: 0.010498
iteration 12368 : loss : 0.021598, loss_ce: 0.007532
iteration 12369 : loss : 0.150687, loss_ce: 0.014875
 66%|█████████████████▉         | 133/200 [2:15:59<1:02:09, 55.66s/it]iteration 12370 : loss : 0.020732, loss_ce: 0.005507
iteration 12371 : loss : 0.024707, loss_ce: 0.008194
iteration 12372 : loss : 0.020058, loss_ce: 0.007344
iteration 12373 : loss : 0.023745, loss_ce: 0.010027
iteration 12374 : loss : 0.076398, loss_ce: 0.006807
iteration 12375 : loss : 0.018999, loss_ce: 0.006361
iteration 12376 : loss : 0.021976, loss_ce: 0.011522
iteration 12377 : loss : 0.023691, loss_ce: 0.008605
iteration 12378 : loss : 0.023662, loss_ce: 0.009752
iteration 12379 : loss : 0.020271, loss_ce: 0.006559
iteration 12380 : loss : 0.074815, loss_ce: 0.006871
iteration 12381 : loss : 0.027124, loss_ce: 0.007940
iteration 12382 : loss : 0.027061, loss_ce: 0.010009
iteration 12383 : loss : 0.018773, loss_ce: 0.004503
iteration 12384 : loss : 0.028983, loss_ce: 0.013889
iteration 12385 : loss : 0.025533, loss_ce: 0.010959
iteration 12386 : loss : 0.025416, loss_ce: 0.011677
iteration 12387 : loss : 0.018110, loss_ce: 0.005481
iteration 12388 : loss : 0.023237, loss_ce: 0.007925
iteration 12389 : loss : 0.024670, loss_ce: 0.006420
iteration 12390 : loss : 0.021878, loss_ce: 0.007327
iteration 12391 : loss : 0.022933, loss_ce: 0.011065
iteration 12392 : loss : 0.018935, loss_ce: 0.004639
iteration 12393 : loss : 0.075730, loss_ce: 0.010113
iteration 12394 : loss : 0.027423, loss_ce: 0.005930
iteration 12395 : loss : 0.027038, loss_ce: 0.007364
iteration 12396 : loss : 0.023099, loss_ce: 0.005457
iteration 12397 : loss : 0.023623, loss_ce: 0.007285
iteration 12398 : loss : 0.024149, loss_ce: 0.011741
iteration 12399 : loss : 0.028810, loss_ce: 0.007518
iteration 12400 : loss : 0.024195, loss_ce: 0.004518
iteration 12401 : loss : 0.022714, loss_ce: 0.007447
iteration 12402 : loss : 0.022993, loss_ce: 0.006255
iteration 12403 : loss : 0.025096, loss_ce: 0.010704
iteration 12404 : loss : 0.024678, loss_ce: 0.004535
iteration 12405 : loss : 0.024520, loss_ce: 0.007060
iteration 12406 : loss : 0.025968, loss_ce: 0.006942
iteration 12407 : loss : 0.018488, loss_ce: 0.005746
iteration 12408 : loss : 0.028438, loss_ce: 0.007845
iteration 12409 : loss : 0.033060, loss_ce: 0.005850
iteration 12410 : loss : 0.023160, loss_ce: 0.006771
iteration 12411 : loss : 0.034136, loss_ce: 0.006739
iteration 12412 : loss : 0.080362, loss_ce: 0.005122
iteration 12413 : loss : 0.026267, loss_ce: 0.009607
iteration 12414 : loss : 0.122672, loss_ce: 0.004060
iteration 12415 : loss : 0.032092, loss_ce: 0.008136
iteration 12416 : loss : 0.025076, loss_ce: 0.007602
iteration 12417 : loss : 0.022371, loss_ce: 0.006590
iteration 12418 : loss : 0.028174, loss_ce: 0.013388
iteration 12419 : loss : 0.030074, loss_ce: 0.005148
iteration 12420 : loss : 0.028531, loss_ce: 0.013360
iteration 12421 : loss : 0.028245, loss_ce: 0.007757
iteration 12422 : loss : 0.030470, loss_ce: 0.004640
iteration 12423 : loss : 0.024117, loss_ce: 0.011467
iteration 12424 : loss : 0.020639, loss_ce: 0.008736
iteration 12425 : loss : 0.025928, loss_ce: 0.007582
iteration 12426 : loss : 0.027151, loss_ce: 0.004818
iteration 12427 : loss : 0.024242, loss_ce: 0.008762
iteration 12428 : loss : 0.036279, loss_ce: 0.006246
iteration 12429 : loss : 0.025432, loss_ce: 0.012573
iteration 12430 : loss : 0.025757, loss_ce: 0.012674
iteration 12431 : loss : 0.022637, loss_ce: 0.010370
iteration 12432 : loss : 0.024298, loss_ce: 0.010149
iteration 12433 : loss : 0.026785, loss_ce: 0.007262
iteration 12434 : loss : 0.020860, loss_ce: 0.008399
iteration 12435 : loss : 0.125880, loss_ce: 0.002009
iteration 12436 : loss : 0.025313, loss_ce: 0.011962
iteration 12437 : loss : 0.024448, loss_ce: 0.003854
iteration 12438 : loss : 0.028930, loss_ce: 0.009889
iteration 12439 : loss : 0.027950, loss_ce: 0.012414
iteration 12440 : loss : 0.024092, loss_ce: 0.006004
iteration 12441 : loss : 0.022572, loss_ce: 0.009731
iteration 12442 : loss : 0.027159, loss_ce: 0.013191
iteration 12443 : loss : 0.022440, loss_ce: 0.008230
iteration 12444 : loss : 0.025253, loss_ce: 0.009379
iteration 12445 : loss : 0.022692, loss_ce: 0.005634
iteration 12446 : loss : 0.025548, loss_ce: 0.011540
iteration 12447 : loss : 0.024200, loss_ce: 0.009437
iteration 12448 : loss : 0.023939, loss_ce: 0.009480
iteration 12449 : loss : 0.030124, loss_ce: 0.011266
iteration 12450 : loss : 0.023958, loss_ce: 0.009129
iteration 12451 : loss : 0.075715, loss_ce: 0.008575
iteration 12452 : loss : 0.076867, loss_ce: 0.007164
iteration 12453 : loss : 0.022615, loss_ce: 0.008230
iteration 12454 : loss : 0.025743, loss_ce: 0.014601
iteration 12455 : loss : 0.024758, loss_ce: 0.009907
iteration 12456 : loss : 0.020636, loss_ce: 0.006778
iteration 12457 : loss : 0.021787, loss_ce: 0.010023
iteration 12458 : loss : 0.021153, loss_ce: 0.006814
iteration 12459 : loss : 0.026916, loss_ce: 0.011376
iteration 12460 : loss : 0.023227, loss_ce: 0.009707
iteration 12461 : loss : 0.025342, loss_ce: 0.010508
iteration 12462 : loss : 0.128765, loss_ce: 0.012250
 67%|██████████████████         | 134/200 [2:16:54<1:00:47, 55.26s/it]iteration 12463 : loss : 0.022358, loss_ce: 0.007933
iteration 12464 : loss : 0.018969, loss_ce: 0.006057
iteration 12465 : loss : 0.021790, loss_ce: 0.009166
iteration 12466 : loss : 0.023951, loss_ce: 0.012114
iteration 12467 : loss : 0.031885, loss_ce: 0.008405
iteration 12468 : loss : 0.029776, loss_ce: 0.006952
iteration 12469 : loss : 0.025258, loss_ce: 0.009960
iteration 12470 : loss : 0.024735, loss_ce: 0.005482
iteration 12471 : loss : 0.075057, loss_ce: 0.004643
iteration 12472 : loss : 0.025578, loss_ce: 0.009918
iteration 12473 : loss : 0.023765, loss_ce: 0.008848
iteration 12474 : loss : 0.021049, loss_ce: 0.010001
iteration 12475 : loss : 0.023462, loss_ce: 0.011484
iteration 12476 : loss : 0.021745, loss_ce: 0.003835
iteration 12477 : loss : 0.026786, loss_ce: 0.011057
iteration 12478 : loss : 0.021737, loss_ce: 0.008675
iteration 12479 : loss : 0.021589, loss_ce: 0.008562
iteration 12480 : loss : 0.020102, loss_ce: 0.006586
iteration 12481 : loss : 0.019226, loss_ce: 0.006280
iteration 12482 : loss : 0.022533, loss_ce: 0.007003
iteration 12483 : loss : 0.020055, loss_ce: 0.008762
iteration 12484 : loss : 0.023453, loss_ce: 0.007629
iteration 12485 : loss : 0.025547, loss_ce: 0.010086
iteration 12486 : loss : 0.025305, loss_ce: 0.008396
iteration 12487 : loss : 0.023987, loss_ce: 0.007736
iteration 12488 : loss : 0.023812, loss_ce: 0.007207
iteration 12489 : loss : 0.025755, loss_ce: 0.008169
iteration 12490 : loss : 0.024486, loss_ce: 0.009281
iteration 12491 : loss : 0.077431, loss_ce: 0.008182
iteration 12492 : loss : 0.022954, loss_ce: 0.007480
iteration 12493 : loss : 0.021865, loss_ce: 0.008473
iteration 12494 : loss : 0.020989, loss_ce: 0.007846
iteration 12495 : loss : 0.022348, loss_ce: 0.009333
iteration 12496 : loss : 0.019158, loss_ce: 0.009261
iteration 12497 : loss : 0.020024, loss_ce: 0.007016
iteration 12498 : loss : 0.030534, loss_ce: 0.008760
iteration 12499 : loss : 0.021010, loss_ce: 0.006133
iteration 12500 : loss : 0.024695, loss_ce: 0.006818
iteration 12501 : loss : 0.023138, loss_ce: 0.007957
iteration 12502 : loss : 0.025265, loss_ce: 0.006475
iteration 12503 : loss : 0.023229, loss_ce: 0.006799
iteration 12504 : loss : 0.074741, loss_ce: 0.006914
iteration 12505 : loss : 0.028149, loss_ce: 0.011461
iteration 12506 : loss : 0.020088, loss_ce: 0.009165
iteration 12507 : loss : 0.073107, loss_ce: 0.006027
iteration 12508 : loss : 0.026667, loss_ce: 0.009414
iteration 12509 : loss : 0.022807, loss_ce: 0.009441
iteration 12510 : loss : 0.027154, loss_ce: 0.006237
iteration 12511 : loss : 0.016794, loss_ce: 0.005144
iteration 12512 : loss : 0.023892, loss_ce: 0.008623
iteration 12513 : loss : 0.025193, loss_ce: 0.008377
iteration 12514 : loss : 0.032295, loss_ce: 0.007997
iteration 12515 : loss : 0.024562, loss_ce: 0.008945
iteration 12516 : loss : 0.021017, loss_ce: 0.008044
iteration 12517 : loss : 0.026366, loss_ce: 0.007578
iteration 12518 : loss : 0.078405, loss_ce: 0.009153
iteration 12519 : loss : 0.025403, loss_ce: 0.009556
iteration 12520 : loss : 0.033822, loss_ce: 0.010746
iteration 12521 : loss : 0.026911, loss_ce: 0.006196
iteration 12522 : loss : 0.031403, loss_ce: 0.007415
iteration 12523 : loss : 0.023659, loss_ce: 0.008458
iteration 12524 : loss : 0.021923, loss_ce: 0.005908
iteration 12525 : loss : 0.029312, loss_ce: 0.010331
iteration 12526 : loss : 0.023905, loss_ce: 0.006009
iteration 12527 : loss : 0.027176, loss_ce: 0.005623
iteration 12528 : loss : 0.021739, loss_ce: 0.006322
iteration 12529 : loss : 0.024184, loss_ce: 0.011358
iteration 12530 : loss : 0.079387, loss_ce: 0.009123
iteration 12531 : loss : 0.022499, loss_ce: 0.007823
iteration 12532 : loss : 0.023013, loss_ce: 0.010897
iteration 12533 : loss : 0.075069, loss_ce: 0.005594
iteration 12534 : loss : 0.019978, loss_ce: 0.005950
iteration 12535 : loss : 0.021222, loss_ce: 0.005418
iteration 12536 : loss : 0.023755, loss_ce: 0.008155
iteration 12537 : loss : 0.020646, loss_ce: 0.008555
iteration 12538 : loss : 0.027614, loss_ce: 0.009499
iteration 12539 : loss : 0.022419, loss_ce: 0.005748
iteration 12540 : loss : 0.027696, loss_ce: 0.005752
iteration 12541 : loss : 0.022397, loss_ce: 0.008973
iteration 12542 : loss : 0.020969, loss_ce: 0.007782
iteration 12543 : loss : 0.029310, loss_ce: 0.007130
iteration 12544 : loss : 0.019026, loss_ce: 0.007079
iteration 12545 : loss : 0.027414, loss_ce: 0.010298
iteration 12546 : loss : 0.032197, loss_ce: 0.010264
iteration 12547 : loss : 0.025197, loss_ce: 0.005145
iteration 12548 : loss : 0.024948, loss_ce: 0.009981
iteration 12549 : loss : 0.025499, loss_ce: 0.009464
iteration 12550 : loss : 0.022446, loss_ce: 0.007170
iteration 12551 : loss : 0.023425, loss_ce: 0.010680
iteration 12552 : loss : 0.021591, loss_ce: 0.006981
iteration 12553 : loss : 0.076682, loss_ce: 0.008284
iteration 12554 : loss : 0.025146, loss_ce: 0.008991
iteration 12555 : loss : 0.086251, loss_ce: 0.015154
 68%|███████████████████▌         | 135/200 [2:17:48<59:39, 55.06s/it]iteration 12556 : loss : 0.029283, loss_ce: 0.009490
iteration 12557 : loss : 0.026271, loss_ce: 0.013112
iteration 12558 : loss : 0.023868, loss_ce: 0.006434
iteration 12559 : loss : 0.024052, loss_ce: 0.011834
iteration 12560 : loss : 0.025632, loss_ce: 0.010348
iteration 12561 : loss : 0.024708, loss_ce: 0.011362
iteration 12562 : loss : 0.023544, loss_ce: 0.008946
iteration 12563 : loss : 0.024314, loss_ce: 0.008345
iteration 12564 : loss : 0.076767, loss_ce: 0.009036
iteration 12565 : loss : 0.025853, loss_ce: 0.010026
iteration 12566 : loss : 0.027837, loss_ce: 0.011101
iteration 12567 : loss : 0.024865, loss_ce: 0.006816
iteration 12568 : loss : 0.019844, loss_ce: 0.007377
iteration 12569 : loss : 0.023055, loss_ce: 0.007212
iteration 12570 : loss : 0.029911, loss_ce: 0.005535
iteration 12571 : loss : 0.023238, loss_ce: 0.005124
iteration 12572 : loss : 0.023355, loss_ce: 0.008734
iteration 12573 : loss : 0.024000, loss_ce: 0.007781
iteration 12574 : loss : 0.019968, loss_ce: 0.008381
iteration 12575 : loss : 0.024056, loss_ce: 0.009268
iteration 12576 : loss : 0.023333, loss_ce: 0.009670
iteration 12577 : loss : 0.024408, loss_ce: 0.005378
iteration 12578 : loss : 0.024533, loss_ce: 0.007819
iteration 12579 : loss : 0.022408, loss_ce: 0.010096
iteration 12580 : loss : 0.034632, loss_ce: 0.006282
iteration 12581 : loss : 0.020339, loss_ce: 0.008462
iteration 12582 : loss : 0.021446, loss_ce: 0.009260
iteration 12583 : loss : 0.072603, loss_ce: 0.007142
iteration 12584 : loss : 0.073629, loss_ce: 0.003254
iteration 12585 : loss : 0.020921, loss_ce: 0.010406
iteration 12586 : loss : 0.020343, loss_ce: 0.008293
iteration 12587 : loss : 0.020232, loss_ce: 0.005349
iteration 12588 : loss : 0.020335, loss_ce: 0.007523
iteration 12589 : loss : 0.022677, loss_ce: 0.007432
iteration 12590 : loss : 0.024370, loss_ce: 0.010306
iteration 12591 : loss : 0.074067, loss_ce: 0.006152
iteration 12592 : loss : 0.024676, loss_ce: 0.006398
iteration 12593 : loss : 0.025173, loss_ce: 0.010352
iteration 12594 : loss : 0.022214, loss_ce: 0.007583
iteration 12595 : loss : 0.025647, loss_ce: 0.009644
iteration 12596 : loss : 0.020688, loss_ce: 0.005126
iteration 12597 : loss : 0.022610, loss_ce: 0.008262
iteration 12598 : loss : 0.022624, loss_ce: 0.010091
iteration 12599 : loss : 0.021363, loss_ce: 0.007128
iteration 12600 : loss : 0.022490, loss_ce: 0.009596
iteration 12601 : loss : 0.029370, loss_ce: 0.006070
iteration 12602 : loss : 0.022231, loss_ce: 0.007550
iteration 12603 : loss : 0.024741, loss_ce: 0.006369
iteration 12604 : loss : 0.023168, loss_ce: 0.006226
iteration 12605 : loss : 0.030260, loss_ce: 0.005411
iteration 12606 : loss : 0.025916, loss_ce: 0.009041
iteration 12607 : loss : 0.022535, loss_ce: 0.007608
iteration 12608 : loss : 0.019221, loss_ce: 0.005296
iteration 12609 : loss : 0.025443, loss_ce: 0.012405
iteration 12610 : loss : 0.020938, loss_ce: 0.006113
iteration 12611 : loss : 0.030533, loss_ce: 0.008236
iteration 12612 : loss : 0.025032, loss_ce: 0.005163
iteration 12613 : loss : 0.027846, loss_ce: 0.006267
iteration 12614 : loss : 0.021584, loss_ce: 0.010007
iteration 12615 : loss : 0.018271, loss_ce: 0.003255
iteration 12616 : loss : 0.023708, loss_ce: 0.009035
iteration 12617 : loss : 0.075775, loss_ce: 0.007392
iteration 12618 : loss : 0.076336, loss_ce: 0.004261
iteration 12619 : loss : 0.023684, loss_ce: 0.007469
iteration 12620 : loss : 0.024984, loss_ce: 0.009896
iteration 12621 : loss : 0.028684, loss_ce: 0.007714
iteration 12622 : loss : 0.022857, loss_ce: 0.008826
iteration 12623 : loss : 0.022385, loss_ce: 0.007636
iteration 12624 : loss : 0.030689, loss_ce: 0.004907
iteration 12625 : loss : 0.020299, loss_ce: 0.007952
iteration 12626 : loss : 0.023873, loss_ce: 0.009136
iteration 12627 : loss : 0.023990, loss_ce: 0.009506
iteration 12628 : loss : 0.028558, loss_ce: 0.006380
iteration 12629 : loss : 0.021663, loss_ce: 0.006242
iteration 12630 : loss : 0.024801, loss_ce: 0.013679
iteration 12631 : loss : 0.027735, loss_ce: 0.009080
iteration 12632 : loss : 0.024625, loss_ce: 0.012208
iteration 12633 : loss : 0.035955, loss_ce: 0.004698
iteration 12634 : loss : 0.021252, loss_ce: 0.008931
iteration 12635 : loss : 0.022955, loss_ce: 0.007918
iteration 12636 : loss : 0.028705, loss_ce: 0.010349
iteration 12637 : loss : 0.022965, loss_ce: 0.008469
iteration 12638 : loss : 0.023517, loss_ce: 0.010384
iteration 12639 : loss : 0.023956, loss_ce: 0.008251
iteration 12640 : loss : 0.026189, loss_ce: 0.007359
iteration 12641 : loss : 0.020360, loss_ce: 0.006028
iteration 12642 : loss : 0.027546, loss_ce: 0.011204
iteration 12643 : loss : 0.031044, loss_ce: 0.008819
iteration 12644 : loss : 0.023081, loss_ce: 0.008276
iteration 12645 : loss : 0.019713, loss_ce: 0.003625
iteration 12646 : loss : 0.024568, loss_ce: 0.011778
iteration 12647 : loss : 0.022560, loss_ce: 0.003191
iteration 12648 : loss : 0.392030, loss_ce: 0.002555
 68%|███████████████████▋         | 136/200 [2:18:43<58:30, 54.85s/it]iteration 12649 : loss : 0.020998, loss_ce: 0.005531
iteration 12650 : loss : 0.023761, loss_ce: 0.008392
iteration 12651 : loss : 0.022499, loss_ce: 0.008600
iteration 12652 : loss : 0.029359, loss_ce: 0.008809
iteration 12653 : loss : 0.027441, loss_ce: 0.011573
iteration 12654 : loss : 0.020580, loss_ce: 0.006908
iteration 12655 : loss : 0.026982, loss_ce: 0.007304
iteration 12656 : loss : 0.019956, loss_ce: 0.006082
iteration 12657 : loss : 0.022587, loss_ce: 0.009921
iteration 12658 : loss : 0.023866, loss_ce: 0.006300
iteration 12659 : loss : 0.024842, loss_ce: 0.010093
iteration 12660 : loss : 0.020845, loss_ce: 0.006144
iteration 12661 : loss : 0.028750, loss_ce: 0.009687
iteration 12662 : loss : 0.020584, loss_ce: 0.008688
iteration 12663 : loss : 0.025772, loss_ce: 0.014312
iteration 12664 : loss : 0.022533, loss_ce: 0.008358
iteration 12665 : loss : 0.023869, loss_ce: 0.006684
iteration 12666 : loss : 0.029771, loss_ce: 0.007153
iteration 12667 : loss : 0.023376, loss_ce: 0.007113
iteration 12668 : loss : 0.029980, loss_ce: 0.005729
iteration 12669 : loss : 0.019507, loss_ce: 0.006311
iteration 12670 : loss : 0.023921, loss_ce: 0.007492
iteration 12671 : loss : 0.020105, loss_ce: 0.004505
iteration 12672 : loss : 0.024987, loss_ce: 0.007940
iteration 12673 : loss : 0.028334, loss_ce: 0.012339
iteration 12674 : loss : 0.024766, loss_ce: 0.005984
iteration 12675 : loss : 0.023594, loss_ce: 0.007756
iteration 12676 : loss : 0.026643, loss_ce: 0.011579
iteration 12677 : loss : 0.021993, loss_ce: 0.005571
iteration 12678 : loss : 0.023984, loss_ce: 0.009504
iteration 12679 : loss : 0.022525, loss_ce: 0.008172
iteration 12680 : loss : 0.023658, loss_ce: 0.009817
iteration 12681 : loss : 0.018851, loss_ce: 0.006702
iteration 12682 : loss : 0.025482, loss_ce: 0.010441
iteration 12683 : loss : 0.025623, loss_ce: 0.011692
iteration 12684 : loss : 0.024529, loss_ce: 0.007112
iteration 12685 : loss : 0.025557, loss_ce: 0.009950
iteration 12686 : loss : 0.024797, loss_ce: 0.007584
iteration 12687 : loss : 0.020967, loss_ce: 0.008337
iteration 12688 : loss : 0.028053, loss_ce: 0.011765
iteration 12689 : loss : 0.023249, loss_ce: 0.007212
iteration 12690 : loss : 0.025466, loss_ce: 0.006042
iteration 12691 : loss : 0.021714, loss_ce: 0.006966
iteration 12692 : loss : 0.026268, loss_ce: 0.007145
iteration 12693 : loss : 0.027327, loss_ce: 0.008255
iteration 12694 : loss : 0.020894, loss_ce: 0.005488
iteration 12695 : loss : 0.022532, loss_ce: 0.004711
iteration 12696 : loss : 0.023577, loss_ce: 0.007991
iteration 12697 : loss : 0.025009, loss_ce: 0.009068
iteration 12698 : loss : 0.024782, loss_ce: 0.008213
iteration 12699 : loss : 0.024274, loss_ce: 0.007610
iteration 12700 : loss : 0.022767, loss_ce: 0.008115
iteration 12701 : loss : 0.021802, loss_ce: 0.008723
iteration 12702 : loss : 0.019546, loss_ce: 0.007652
iteration 12703 : loss : 0.024862, loss_ce: 0.012443
iteration 12704 : loss : 0.021044, loss_ce: 0.005401
iteration 12705 : loss : 0.028065, loss_ce: 0.006142
iteration 12706 : loss : 0.022347, loss_ce: 0.006921
iteration 12707 : loss : 0.024847, loss_ce: 0.008656
iteration 12708 : loss : 0.022780, loss_ce: 0.007818
iteration 12709 : loss : 0.129772, loss_ce: 0.006371
iteration 12710 : loss : 0.031893, loss_ce: 0.007250
iteration 12711 : loss : 0.024298, loss_ce: 0.006666
iteration 12712 : loss : 0.025879, loss_ce: 0.011840
iteration 12713 : loss : 0.026183, loss_ce: 0.012662
iteration 12714 : loss : 0.023928, loss_ce: 0.011663
iteration 12715 : loss : 0.019937, loss_ce: 0.004590
iteration 12716 : loss : 0.022419, loss_ce: 0.007647
iteration 12717 : loss : 0.025372, loss_ce: 0.011961
iteration 12718 : loss : 0.021526, loss_ce: 0.009078
iteration 12719 : loss : 0.022219, loss_ce: 0.008719
iteration 12720 : loss : 0.025882, loss_ce: 0.010528
iteration 12721 : loss : 0.019464, loss_ce: 0.005760
iteration 12722 : loss : 0.072558, loss_ce: 0.004658
iteration 12723 : loss : 0.020733, loss_ce: 0.004740
iteration 12724 : loss : 0.017848, loss_ce: 0.006887
iteration 12725 : loss : 0.076237, loss_ce: 0.005229
iteration 12726 : loss : 0.020060, loss_ce: 0.005557
iteration 12727 : loss : 0.074825, loss_ce: 0.007683
iteration 12728 : loss : 0.073408, loss_ce: 0.005022
iteration 12729 : loss : 0.020891, loss_ce: 0.007999
iteration 12730 : loss : 0.075048, loss_ce: 0.004645
iteration 12731 : loss : 0.075345, loss_ce: 0.008360
iteration 12732 : loss : 0.022602, loss_ce: 0.009757
iteration 12733 : loss : 0.023089, loss_ce: 0.007653
iteration 12734 : loss : 0.022326, loss_ce: 0.007198
iteration 12735 : loss : 0.072828, loss_ce: 0.005645
iteration 12736 : loss : 0.021337, loss_ce: 0.007771
iteration 12737 : loss : 0.020998, loss_ce: 0.006387
iteration 12738 : loss : 0.029756, loss_ce: 0.013243
iteration 12739 : loss : 0.023116, loss_ce: 0.010436
iteration 12740 : loss : 0.023237, loss_ce: 0.007580
iteration 12741 : loss : 0.143049, loss_ce: 0.028708
 68%|███████████████████▊         | 137/200 [2:19:37<57:27, 54.72s/it]iteration 12742 : loss : 0.024342, loss_ce: 0.005960
iteration 12743 : loss : 0.024352, loss_ce: 0.009829
iteration 12744 : loss : 0.079505, loss_ce: 0.005682
iteration 12745 : loss : 0.024208, loss_ce: 0.006356
iteration 12746 : loss : 0.018956, loss_ce: 0.005240
iteration 12747 : loss : 0.075938, loss_ce: 0.007152
iteration 12748 : loss : 0.021367, loss_ce: 0.010198
iteration 12749 : loss : 0.045178, loss_ce: 0.007635
iteration 12750 : loss : 0.023342, loss_ce: 0.005947
iteration 12751 : loss : 0.017854, loss_ce: 0.006489
iteration 12752 : loss : 0.076250, loss_ce: 0.004476
iteration 12753 : loss : 0.024551, loss_ce: 0.008545
iteration 12754 : loss : 0.021191, loss_ce: 0.005641
iteration 12755 : loss : 0.025730, loss_ce: 0.009163
iteration 12756 : loss : 0.025065, loss_ce: 0.008710
iteration 12757 : loss : 0.026659, loss_ce: 0.010579
iteration 12758 : loss : 0.036241, loss_ce: 0.008890
iteration 12759 : loss : 0.022568, loss_ce: 0.006199
iteration 12760 : loss : 0.024839, loss_ce: 0.011462
iteration 12761 : loss : 0.020396, loss_ce: 0.008356
iteration 12762 : loss : 0.024710, loss_ce: 0.011763
iteration 12763 : loss : 0.032075, loss_ce: 0.008877
iteration 12764 : loss : 0.029166, loss_ce: 0.008912
iteration 12765 : loss : 0.021379, loss_ce: 0.006457
iteration 12766 : loss : 0.021532, loss_ce: 0.007398
iteration 12767 : loss : 0.029483, loss_ce: 0.008879
iteration 12768 : loss : 0.076308, loss_ce: 0.007302
iteration 12769 : loss : 0.078962, loss_ce: 0.005667
iteration 12770 : loss : 0.024033, loss_ce: 0.008970
iteration 12771 : loss : 0.025358, loss_ce: 0.012055
iteration 12772 : loss : 0.021110, loss_ce: 0.008370
iteration 12773 : loss : 0.024420, loss_ce: 0.008654
iteration 12774 : loss : 0.022748, loss_ce: 0.006802
iteration 12775 : loss : 0.020167, loss_ce: 0.008621
iteration 12776 : loss : 0.027853, loss_ce: 0.011302
iteration 12777 : loss : 0.025406, loss_ce: 0.009671
iteration 12778 : loss : 0.028737, loss_ce: 0.010422
iteration 12779 : loss : 0.076722, loss_ce: 0.004948
iteration 12780 : loss : 0.075064, loss_ce: 0.006849
iteration 12781 : loss : 0.021924, loss_ce: 0.009010
iteration 12782 : loss : 0.020173, loss_ce: 0.007059
iteration 12783 : loss : 0.020194, loss_ce: 0.006241
iteration 12784 : loss : 0.022484, loss_ce: 0.008883
iteration 12785 : loss : 0.025708, loss_ce: 0.010087
iteration 12786 : loss : 0.023288, loss_ce: 0.009657
iteration 12787 : loss : 0.020501, loss_ce: 0.006015
iteration 12788 : loss : 0.021409, loss_ce: 0.006316
iteration 12789 : loss : 0.023098, loss_ce: 0.007445
iteration 12790 : loss : 0.031999, loss_ce: 0.010982
iteration 12791 : loss : 0.024747, loss_ce: 0.008013
iteration 12792 : loss : 0.022964, loss_ce: 0.006482
iteration 12793 : loss : 0.027658, loss_ce: 0.007947
iteration 12794 : loss : 0.027053, loss_ce: 0.009868
iteration 12795 : loss : 0.023760, loss_ce: 0.008132
iteration 12796 : loss : 0.022364, loss_ce: 0.004904
iteration 12797 : loss : 0.023439, loss_ce: 0.007813
iteration 12798 : loss : 0.022727, loss_ce: 0.009485
iteration 12799 : loss : 0.025830, loss_ce: 0.008493
iteration 12800 : loss : 0.020428, loss_ce: 0.005923
iteration 12801 : loss : 0.022024, loss_ce: 0.008526
iteration 12802 : loss : 0.022899, loss_ce: 0.005841
iteration 12803 : loss : 0.030290, loss_ce: 0.008679
iteration 12804 : loss : 0.023446, loss_ce: 0.009493
iteration 12805 : loss : 0.022894, loss_ce: 0.005549
iteration 12806 : loss : 0.028903, loss_ce: 0.010161
iteration 12807 : loss : 0.075835, loss_ce: 0.005645
iteration 12808 : loss : 0.023307, loss_ce: 0.009902
iteration 12809 : loss : 0.032159, loss_ce: 0.006083
iteration 12810 : loss : 0.026204, loss_ce: 0.009564
iteration 12811 : loss : 0.025016, loss_ce: 0.005309
iteration 12812 : loss : 0.020438, loss_ce: 0.011357
iteration 12813 : loss : 0.023927, loss_ce: 0.009646
iteration 12814 : loss : 0.073139, loss_ce: 0.007881
iteration 12815 : loss : 0.019893, loss_ce: 0.005988
iteration 12816 : loss : 0.023253, loss_ce: 0.010572
iteration 12817 : loss : 0.021374, loss_ce: 0.006339
iteration 12818 : loss : 0.031306, loss_ce: 0.008892
iteration 12819 : loss : 0.023974, loss_ce: 0.008895
iteration 12820 : loss : 0.034726, loss_ce: 0.011247
iteration 12821 : loss : 0.017983, loss_ce: 0.007452
iteration 12822 : loss : 0.025006, loss_ce: 0.007258
iteration 12823 : loss : 0.022754, loss_ce: 0.006356
iteration 12824 : loss : 0.028934, loss_ce: 0.007390
iteration 12825 : loss : 0.020237, loss_ce: 0.006892
iteration 12826 : loss : 0.024057, loss_ce: 0.006074
iteration 12827 : loss : 0.026119, loss_ce: 0.008092
iteration 12828 : loss : 0.030002, loss_ce: 0.007461
iteration 12829 : loss : 0.020472, loss_ce: 0.009758
iteration 12830 : loss : 0.026012, loss_ce: 0.011265
iteration 12831 : loss : 0.020538, loss_ce: 0.007302
iteration 12832 : loss : 0.023928, loss_ce: 0.008259
iteration 12833 : loss : 0.021821, loss_ce: 0.007999
iteration 12834 : loss : 0.125083, loss_ce: 0.009268
 69%|████████████████████         | 138/200 [2:20:31<56:27, 54.63s/it]iteration 12835 : loss : 0.073282, loss_ce: 0.006079
iteration 12836 : loss : 0.025823, loss_ce: 0.007868
iteration 12837 : loss : 0.025499, loss_ce: 0.006231
iteration 12838 : loss : 0.020398, loss_ce: 0.007070
iteration 12839 : loss : 0.026936, loss_ce: 0.007644
iteration 12840 : loss : 0.025748, loss_ce: 0.009662
iteration 12841 : loss : 0.020854, loss_ce: 0.008812
iteration 12842 : loss : 0.023644, loss_ce: 0.007098
iteration 12843 : loss : 0.025131, loss_ce: 0.009066
iteration 12844 : loss : 0.024357, loss_ce: 0.010343
iteration 12845 : loss : 0.021627, loss_ce: 0.007738
iteration 12846 : loss : 0.023292, loss_ce: 0.009798
iteration 12847 : loss : 0.040990, loss_ce: 0.006957
iteration 12848 : loss : 0.073357, loss_ce: 0.004826
iteration 12849 : loss : 0.022986, loss_ce: 0.007274
iteration 12850 : loss : 0.020221, loss_ce: 0.004531
iteration 12851 : loss : 0.027978, loss_ce: 0.010699
iteration 12852 : loss : 0.024652, loss_ce: 0.011990
iteration 12853 : loss : 0.030340, loss_ce: 0.005383
iteration 12854 : loss : 0.019024, loss_ce: 0.008468
iteration 12855 : loss : 0.023188, loss_ce: 0.005905
iteration 12856 : loss : 0.020588, loss_ce: 0.007238
iteration 12857 : loss : 0.078272, loss_ce: 0.007551
iteration 12858 : loss : 0.023958, loss_ce: 0.009746
iteration 12859 : loss : 0.031785, loss_ce: 0.006654
iteration 12860 : loss : 0.026604, loss_ce: 0.005593
iteration 12861 : loss : 0.022276, loss_ce: 0.007055
iteration 12862 : loss : 0.034114, loss_ce: 0.007856
iteration 12863 : loss : 0.076399, loss_ce: 0.010822
iteration 12864 : loss : 0.024206, loss_ce: 0.007308
iteration 12865 : loss : 0.020035, loss_ce: 0.010417
iteration 12866 : loss : 0.029166, loss_ce: 0.011890
iteration 12867 : loss : 0.083313, loss_ce: 0.007242
iteration 12868 : loss : 0.073448, loss_ce: 0.006752
iteration 12869 : loss : 0.023704, loss_ce: 0.006777
iteration 12870 : loss : 0.024721, loss_ce: 0.009478
iteration 12871 : loss : 0.073247, loss_ce: 0.005295
iteration 12872 : loss : 0.024453, loss_ce: 0.007319
iteration 12873 : loss : 0.021360, loss_ce: 0.007808
iteration 12874 : loss : 0.028384, loss_ce: 0.008922
iteration 12875 : loss : 0.025454, loss_ce: 0.005682
iteration 12876 : loss : 0.023222, loss_ce: 0.005110
iteration 12877 : loss : 0.024768, loss_ce: 0.007979
iteration 12878 : loss : 0.024479, loss_ce: 0.008650
iteration 12879 : loss : 0.020730, loss_ce: 0.006929
iteration 12880 : loss : 0.018398, loss_ce: 0.007311
iteration 12881 : loss : 0.027085, loss_ce: 0.010211
iteration 12882 : loss : 0.023264, loss_ce: 0.008297
iteration 12883 : loss : 0.075895, loss_ce: 0.005897
iteration 12884 : loss : 0.020763, loss_ce: 0.005891
iteration 12885 : loss : 0.023187, loss_ce: 0.007790
iteration 12886 : loss : 0.020952, loss_ce: 0.008239
iteration 12887 : loss : 0.025348, loss_ce: 0.009293
iteration 12888 : loss : 0.022382, loss_ce: 0.006079
iteration 12889 : loss : 0.022225, loss_ce: 0.008874
iteration 12890 : loss : 0.024094, loss_ce: 0.008832
iteration 12891 : loss : 0.025178, loss_ce: 0.006982
iteration 12892 : loss : 0.028310, loss_ce: 0.008225
iteration 12893 : loss : 0.021765, loss_ce: 0.008133
iteration 12894 : loss : 0.023787, loss_ce: 0.009816
iteration 12895 : loss : 0.025282, loss_ce: 0.007883
iteration 12896 : loss : 0.022048, loss_ce: 0.006970
iteration 12897 : loss : 0.030674, loss_ce: 0.010789
iteration 12898 : loss : 0.023406, loss_ce: 0.012427
iteration 12899 : loss : 0.026294, loss_ce: 0.011966
iteration 12900 : loss : 0.024299, loss_ce: 0.007302
iteration 12901 : loss : 0.026762, loss_ce: 0.011531
iteration 12902 : loss : 0.021706, loss_ce: 0.005569
iteration 12903 : loss : 0.024714, loss_ce: 0.009193
iteration 12904 : loss : 0.058329, loss_ce: 0.008719
iteration 12905 : loss : 0.026344, loss_ce: 0.011524
iteration 12906 : loss : 0.020920, loss_ce: 0.007504
iteration 12907 : loss : 0.026492, loss_ce: 0.008807
iteration 12908 : loss : 0.030165, loss_ce: 0.009733
iteration 12909 : loss : 0.024059, loss_ce: 0.009303
iteration 12910 : loss : 0.022537, loss_ce: 0.007145
iteration 12911 : loss : 0.016553, loss_ce: 0.004412
iteration 12912 : loss : 0.023431, loss_ce: 0.008495
iteration 12913 : loss : 0.019357, loss_ce: 0.006618
iteration 12914 : loss : 0.027146, loss_ce: 0.010013
iteration 12915 : loss : 0.025991, loss_ce: 0.008255
iteration 12916 : loss : 0.025275, loss_ce: 0.011536
iteration 12917 : loss : 0.022801, loss_ce: 0.008245
iteration 12918 : loss : 0.020525, loss_ce: 0.006273
iteration 12919 : loss : 0.019202, loss_ce: 0.006157
iteration 12920 : loss : 0.023476, loss_ce: 0.010240
iteration 12921 : loss : 0.026114, loss_ce: 0.010188
iteration 12922 : loss : 0.023977, loss_ce: 0.009106
iteration 12923 : loss : 0.021670, loss_ce: 0.004429
iteration 12924 : loss : 0.035940, loss_ce: 0.007636
iteration 12925 : loss : 0.023126, loss_ce: 0.006709
iteration 12926 : loss : 0.020871, loss_ce: 0.005764
iteration 12927 : loss : 0.071014, loss_ce: 0.013642
 70%|████████████████████▏        | 139/200 [2:21:26<55:29, 54.58s/it]iteration 12928 : loss : 0.018458, loss_ce: 0.007139
iteration 12929 : loss : 0.026955, loss_ce: 0.011706
iteration 12930 : loss : 0.023588, loss_ce: 0.003666
iteration 12931 : loss : 0.020043, loss_ce: 0.006861
iteration 12932 : loss : 0.022200, loss_ce: 0.008575
iteration 12933 : loss : 0.020248, loss_ce: 0.008070
iteration 12934 : loss : 0.025140, loss_ce: 0.010897
iteration 12935 : loss : 0.021710, loss_ce: 0.008892
iteration 12936 : loss : 0.024175, loss_ce: 0.010783
iteration 12937 : loss : 0.027392, loss_ce: 0.008469
iteration 12938 : loss : 0.023051, loss_ce: 0.008237
iteration 12939 : loss : 0.025026, loss_ce: 0.008548
iteration 12940 : loss : 0.033296, loss_ce: 0.010402
iteration 12941 : loss : 0.032704, loss_ce: 0.013127
iteration 12942 : loss : 0.023180, loss_ce: 0.011035
iteration 12943 : loss : 0.025110, loss_ce: 0.008611
iteration 12944 : loss : 0.023502, loss_ce: 0.009007
iteration 12945 : loss : 0.022478, loss_ce: 0.006893
iteration 12946 : loss : 0.033543, loss_ce: 0.008705
iteration 12947 : loss : 0.020062, loss_ce: 0.005765
iteration 12948 : loss : 0.026340, loss_ce: 0.007128
iteration 12949 : loss : 0.022559, loss_ce: 0.006996
iteration 12950 : loss : 0.023394, loss_ce: 0.007977
iteration 12951 : loss : 0.018787, loss_ce: 0.006180
iteration 12952 : loss : 0.025271, loss_ce: 0.006505
iteration 12953 : loss : 0.020741, loss_ce: 0.007686
iteration 12954 : loss : 0.027417, loss_ce: 0.013265
iteration 12955 : loss : 0.075158, loss_ce: 0.008153
iteration 12956 : loss : 0.027448, loss_ce: 0.012811
iteration 12957 : loss : 0.025829, loss_ce: 0.012004
iteration 12958 : loss : 0.075366, loss_ce: 0.008024
iteration 12959 : loss : 0.026571, loss_ce: 0.008684
iteration 12960 : loss : 0.023996, loss_ce: 0.008065
iteration 12961 : loss : 0.019568, loss_ce: 0.005740
iteration 12962 : loss : 0.030970, loss_ce: 0.012643
iteration 12963 : loss : 0.075442, loss_ce: 0.008854
iteration 12964 : loss : 0.025246, loss_ce: 0.005989
iteration 12965 : loss : 0.028628, loss_ce: 0.007422
iteration 12966 : loss : 0.023849, loss_ce: 0.007837
iteration 12967 : loss : 0.026781, loss_ce: 0.008359
iteration 12968 : loss : 0.020922, loss_ce: 0.006716
iteration 12969 : loss : 0.023848, loss_ce: 0.008508
iteration 12970 : loss : 0.023725, loss_ce: 0.005788
iteration 12971 : loss : 0.025501, loss_ce: 0.005923
iteration 12972 : loss : 0.023375, loss_ce: 0.006042
iteration 12973 : loss : 0.026862, loss_ce: 0.008983
iteration 12974 : loss : 0.029584, loss_ce: 0.003824
iteration 12975 : loss : 0.027955, loss_ce: 0.009853
iteration 12976 : loss : 0.026532, loss_ce: 0.008655
iteration 12977 : loss : 0.022300, loss_ce: 0.008475
iteration 12978 : loss : 0.032339, loss_ce: 0.006118
iteration 12979 : loss : 0.022312, loss_ce: 0.008579
iteration 12980 : loss : 0.023869, loss_ce: 0.007488
iteration 12981 : loss : 0.028353, loss_ce: 0.009041
iteration 12982 : loss : 0.073251, loss_ce: 0.003426
iteration 12983 : loss : 0.021895, loss_ce: 0.007591
iteration 12984 : loss : 0.024135, loss_ce: 0.009375
iteration 12985 : loss : 0.023797, loss_ce: 0.011400
iteration 12986 : loss : 0.055930, loss_ce: 0.007006
iteration 12987 : loss : 0.022255, loss_ce: 0.008802
iteration 12988 : loss : 0.072453, loss_ce: 0.004908
iteration 12989 : loss : 0.024728, loss_ce: 0.008725
iteration 12990 : loss : 0.023789, loss_ce: 0.007717
iteration 12991 : loss : 0.022447, loss_ce: 0.007768
iteration 12992 : loss : 0.029421, loss_ce: 0.008913
iteration 12993 : loss : 0.025519, loss_ce: 0.009462
iteration 12994 : loss : 0.026433, loss_ce: 0.005530
iteration 12995 : loss : 0.026595, loss_ce: 0.010693
iteration 12996 : loss : 0.026806, loss_ce: 0.005709
iteration 12997 : loss : 0.024311, loss_ce: 0.011354
iteration 12998 : loss : 0.022577, loss_ce: 0.007541
iteration 12999 : loss : 0.028455, loss_ce: 0.007923
iteration 13000 : loss : 0.023462, loss_ce: 0.010103
iteration 13001 : loss : 0.024593, loss_ce: 0.012016
iteration 13002 : loss : 0.040203, loss_ce: 0.009864
iteration 13003 : loss : 0.076380, loss_ce: 0.007652
iteration 13004 : loss : 0.020583, loss_ce: 0.005897
iteration 13005 : loss : 0.025596, loss_ce: 0.009324
iteration 13006 : loss : 0.021173, loss_ce: 0.005049
iteration 13007 : loss : 0.024818, loss_ce: 0.009502
iteration 13008 : loss : 0.026751, loss_ce: 0.008246
iteration 13009 : loss : 0.026893, loss_ce: 0.008494
iteration 13010 : loss : 0.024334, loss_ce: 0.010001
iteration 13011 : loss : 0.024205, loss_ce: 0.011214
iteration 13012 : loss : 0.029026, loss_ce: 0.004454
iteration 13013 : loss : 0.021365, loss_ce: 0.009493
iteration 13014 : loss : 0.023901, loss_ce: 0.009284
iteration 13015 : loss : 0.022378, loss_ce: 0.006289
iteration 13016 : loss : 0.029596, loss_ce: 0.009932
iteration 13017 : loss : 0.033512, loss_ce: 0.010161
iteration 13018 : loss : 0.026602, loss_ce: 0.005180
iteration 13019 : loss : 0.022059, loss_ce: 0.006470
iteration 13020 : loss : 0.138978, loss_ce: 0.014337
 70%|████████████████████▎        | 140/200 [2:22:20<54:31, 54.53s/it]iteration 13021 : loss : 0.022007, loss_ce: 0.006589
iteration 13022 : loss : 0.024314, loss_ce: 0.009986
iteration 13023 : loss : 0.024398, loss_ce: 0.012924
iteration 13024 : loss : 0.019343, loss_ce: 0.003672
iteration 13025 : loss : 0.027621, loss_ce: 0.006613
iteration 13026 : loss : 0.025211, loss_ce: 0.007946
iteration 13027 : loss : 0.031326, loss_ce: 0.007863
iteration 13028 : loss : 0.020473, loss_ce: 0.009024
iteration 13029 : loss : 0.030892, loss_ce: 0.011915
iteration 13030 : loss : 0.021332, loss_ce: 0.006014
iteration 13031 : loss : 0.019812, loss_ce: 0.007744
iteration 13032 : loss : 0.029944, loss_ce: 0.011962
iteration 13033 : loss : 0.027566, loss_ce: 0.008372
iteration 13034 : loss : 0.027147, loss_ce: 0.007937
iteration 13035 : loss : 0.026343, loss_ce: 0.011735
iteration 13036 : loss : 0.022266, loss_ce: 0.005034
iteration 13037 : loss : 0.023084, loss_ce: 0.009779
iteration 13038 : loss : 0.024713, loss_ce: 0.006492
iteration 13039 : loss : 0.018386, loss_ce: 0.008328
iteration 13040 : loss : 0.023088, loss_ce: 0.007861
iteration 13041 : loss : 0.020482, loss_ce: 0.002702
iteration 13042 : loss : 0.025860, loss_ce: 0.011711
iteration 13043 : loss : 0.022308, loss_ce: 0.009463
iteration 13044 : loss : 0.024840, loss_ce: 0.008141
iteration 13045 : loss : 0.022742, loss_ce: 0.008802
iteration 13046 : loss : 0.018234, loss_ce: 0.006418
iteration 13047 : loss : 0.021484, loss_ce: 0.007082
iteration 13048 : loss : 0.021019, loss_ce: 0.008663
iteration 13049 : loss : 0.026693, loss_ce: 0.008223
iteration 13050 : loss : 0.022734, loss_ce: 0.010250
iteration 13051 : loss : 0.022734, loss_ce: 0.008261
iteration 13052 : loss : 0.028732, loss_ce: 0.007178
iteration 13053 : loss : 0.021152, loss_ce: 0.005702
iteration 13054 : loss : 0.025812, loss_ce: 0.007778
iteration 13055 : loss : 0.024297, loss_ce: 0.007643
iteration 13056 : loss : 0.024223, loss_ce: 0.007361
iteration 13057 : loss : 0.019905, loss_ce: 0.008893
iteration 13058 : loss : 0.026129, loss_ce: 0.010792
iteration 13059 : loss : 0.077292, loss_ce: 0.007303
iteration 13060 : loss : 0.025533, loss_ce: 0.008331
iteration 13061 : loss : 0.022086, loss_ce: 0.009109
iteration 13062 : loss : 0.024776, loss_ce: 0.009102
iteration 13063 : loss : 0.025520, loss_ce: 0.005476
iteration 13064 : loss : 0.021496, loss_ce: 0.007675
iteration 13065 : loss : 0.038067, loss_ce: 0.007620
iteration 13066 : loss : 0.020850, loss_ce: 0.007148
iteration 13067 : loss : 0.023297, loss_ce: 0.009917
iteration 13068 : loss : 0.021528, loss_ce: 0.009248
iteration 13069 : loss : 0.020786, loss_ce: 0.006839
iteration 13070 : loss : 0.028229, loss_ce: 0.009273
iteration 13071 : loss : 0.020293, loss_ce: 0.007671
iteration 13072 : loss : 0.072231, loss_ce: 0.005584
iteration 13073 : loss : 0.020120, loss_ce: 0.007202
iteration 13074 : loss : 0.021706, loss_ce: 0.005786
iteration 13075 : loss : 0.023344, loss_ce: 0.005984
iteration 13076 : loss : 0.025476, loss_ce: 0.007942
iteration 13077 : loss : 0.022363, loss_ce: 0.006250
iteration 13078 : loss : 0.031892, loss_ce: 0.010551
iteration 13079 : loss : 0.025658, loss_ce: 0.006593
iteration 13080 : loss : 0.024480, loss_ce: 0.007145
iteration 13081 : loss : 0.019531, loss_ce: 0.007252
iteration 13082 : loss : 0.023491, loss_ce: 0.009753
iteration 13083 : loss : 0.026737, loss_ce: 0.010555
iteration 13084 : loss : 0.022312, loss_ce: 0.007863
iteration 13085 : loss : 0.029870, loss_ce: 0.009856
iteration 13086 : loss : 0.025502, loss_ce: 0.008241
iteration 13087 : loss : 0.025355, loss_ce: 0.008071
iteration 13088 : loss : 0.021406, loss_ce: 0.007974
iteration 13089 : loss : 0.022992, loss_ce: 0.007344
iteration 13090 : loss : 0.027039, loss_ce: 0.008916
iteration 13091 : loss : 0.027033, loss_ce: 0.008531
iteration 13092 : loss : 0.021612, loss_ce: 0.007047
iteration 13093 : loss : 0.023082, loss_ce: 0.009127
iteration 13094 : loss : 0.025121, loss_ce: 0.012098
iteration 13095 : loss : 0.076600, loss_ce: 0.006756
iteration 13096 : loss : 0.024114, loss_ce: 0.008302
iteration 13097 : loss : 0.030231, loss_ce: 0.006017
iteration 13098 : loss : 0.020658, loss_ce: 0.005820
iteration 13099 : loss : 0.020619, loss_ce: 0.005463
iteration 13100 : loss : 0.019551, loss_ce: 0.006215
iteration 13101 : loss : 0.023942, loss_ce: 0.008691
iteration 13102 : loss : 0.073471, loss_ce: 0.007232
iteration 13103 : loss : 0.073109, loss_ce: 0.005708
iteration 13104 : loss : 0.020538, loss_ce: 0.009584
iteration 13105 : loss : 0.022693, loss_ce: 0.007607
iteration 13106 : loss : 0.019001, loss_ce: 0.006418
iteration 13107 : loss : 0.078950, loss_ce: 0.006617
iteration 13108 : loss : 0.028318, loss_ce: 0.008133
iteration 13109 : loss : 0.023627, loss_ce: 0.005328
iteration 13110 : loss : 0.074247, loss_ce: 0.011145
iteration 13111 : loss : 0.021118, loss_ce: 0.009899
iteration 13112 : loss : 0.021710, loss_ce: 0.010579
iteration 13113 : loss : 0.231952, loss_ce: 0.005204
 70%|████████████████████▍        | 141/200 [2:23:15<53:34, 54.48s/it]iteration 13114 : loss : 0.019578, loss_ce: 0.007423
iteration 13115 : loss : 0.023984, loss_ce: 0.010676
iteration 13116 : loss : 0.022097, loss_ce: 0.007729
iteration 13117 : loss : 0.023477, loss_ce: 0.005434
iteration 13118 : loss : 0.023170, loss_ce: 0.009534
iteration 13119 : loss : 0.024797, loss_ce: 0.007552
iteration 13120 : loss : 0.022959, loss_ce: 0.008936
iteration 13121 : loss : 0.020156, loss_ce: 0.004720
iteration 13122 : loss : 0.022806, loss_ce: 0.004764
iteration 13123 : loss : 0.025075, loss_ce: 0.006923
iteration 13124 : loss : 0.020430, loss_ce: 0.007123
iteration 13125 : loss : 0.073353, loss_ce: 0.006398
iteration 13126 : loss : 0.023788, loss_ce: 0.007895
iteration 13127 : loss : 0.021636, loss_ce: 0.008190
iteration 13128 : loss : 0.072251, loss_ce: 0.006133
iteration 13129 : loss : 0.024775, loss_ce: 0.009245
iteration 13130 : loss : 0.076286, loss_ce: 0.009430
iteration 13131 : loss : 0.028082, loss_ce: 0.010087
iteration 13132 : loss : 0.018668, loss_ce: 0.002973
iteration 13133 : loss : 0.026062, loss_ce: 0.006632
iteration 13134 : loss : 0.020719, loss_ce: 0.007867
iteration 13135 : loss : 0.022151, loss_ce: 0.008589
iteration 13136 : loss : 0.043351, loss_ce: 0.009955
iteration 13137 : loss : 0.024453, loss_ce: 0.008901
iteration 13138 : loss : 0.028833, loss_ce: 0.009663
iteration 13139 : loss : 0.025208, loss_ce: 0.008698
iteration 13140 : loss : 0.020717, loss_ce: 0.006382
iteration 13141 : loss : 0.024458, loss_ce: 0.007166
iteration 13142 : loss : 0.021212, loss_ce: 0.006614
iteration 13143 : loss : 0.025573, loss_ce: 0.004968
iteration 13144 : loss : 0.033997, loss_ce: 0.007909
iteration 13145 : loss : 0.021097, loss_ce: 0.006839
iteration 13146 : loss : 0.020155, loss_ce: 0.009370
iteration 13147 : loss : 0.019656, loss_ce: 0.008005
iteration 13148 : loss : 0.026478, loss_ce: 0.008944
iteration 13149 : loss : 0.026450, loss_ce: 0.006079
iteration 13150 : loss : 0.020976, loss_ce: 0.008742
iteration 13151 : loss : 0.024843, loss_ce: 0.012952
iteration 13152 : loss : 0.028363, loss_ce: 0.009397
iteration 13153 : loss : 0.021220, loss_ce: 0.008084
iteration 13154 : loss : 0.021825, loss_ce: 0.008320
iteration 13155 : loss : 0.026321, loss_ce: 0.007660
iteration 13156 : loss : 0.022406, loss_ce: 0.005680
iteration 13157 : loss : 0.018840, loss_ce: 0.006047
iteration 13158 : loss : 0.025884, loss_ce: 0.008053
iteration 13159 : loss : 0.022503, loss_ce: 0.008164
iteration 13160 : loss : 0.029120, loss_ce: 0.007463
iteration 13161 : loss : 0.023471, loss_ce: 0.009555
iteration 13162 : loss : 0.026189, loss_ce: 0.007719
iteration 13163 : loss : 0.037052, loss_ce: 0.006037
iteration 13164 : loss : 0.023630, loss_ce: 0.011500
iteration 13165 : loss : 0.023400, loss_ce: 0.008215
iteration 13166 : loss : 0.024645, loss_ce: 0.006908
iteration 13167 : loss : 0.024272, loss_ce: 0.008713
iteration 13168 : loss : 0.024178, loss_ce: 0.012782
iteration 13169 : loss : 0.060484, loss_ce: 0.009656
iteration 13170 : loss : 0.074541, loss_ce: 0.005995
iteration 13171 : loss : 0.021875, loss_ce: 0.004919
iteration 13172 : loss : 0.021113, loss_ce: 0.007129
iteration 13173 : loss : 0.082424, loss_ce: 0.006837
iteration 13174 : loss : 0.036091, loss_ce: 0.012220
iteration 13175 : loss : 0.027081, loss_ce: 0.010554
iteration 13176 : loss : 0.023881, loss_ce: 0.012275
iteration 13177 : loss : 0.022419, loss_ce: 0.007275
iteration 13178 : loss : 0.027123, loss_ce: 0.010907
iteration 13179 : loss : 0.023729, loss_ce: 0.011594
iteration 13180 : loss : 0.075312, loss_ce: 0.007435
iteration 13181 : loss : 0.022726, loss_ce: 0.010044
iteration 13182 : loss : 0.026922, loss_ce: 0.004759
iteration 13183 : loss : 0.022909, loss_ce: 0.005417
iteration 13184 : loss : 0.022551, loss_ce: 0.009417
iteration 13185 : loss : 0.024356, loss_ce: 0.009341
iteration 13186 : loss : 0.026216, loss_ce: 0.010772
iteration 13187 : loss : 0.018658, loss_ce: 0.004956
iteration 13188 : loss : 0.025567, loss_ce: 0.008855
iteration 13189 : loss : 0.021553, loss_ce: 0.007900
iteration 13190 : loss : 0.020267, loss_ce: 0.007523
iteration 13191 : loss : 0.019226, loss_ce: 0.006107
iteration 13192 : loss : 0.026122, loss_ce: 0.008587
iteration 13193 : loss : 0.019530, loss_ce: 0.007024
iteration 13194 : loss : 0.022555, loss_ce: 0.009256
iteration 13195 : loss : 0.027234, loss_ce: 0.009215
iteration 13196 : loss : 0.028892, loss_ce: 0.008485
iteration 13197 : loss : 0.032990, loss_ce: 0.005315
iteration 13198 : loss : 0.021570, loss_ce: 0.006393
iteration 13199 : loss : 0.029162, loss_ce: 0.010652
iteration 13200 : loss : 0.023065, loss_ce: 0.008166
iteration 13201 : loss : 0.072825, loss_ce: 0.004366
iteration 13202 : loss : 0.024904, loss_ce: 0.007994
iteration 13203 : loss : 0.020576, loss_ce: 0.008822
iteration 13204 : loss : 0.025432, loss_ce: 0.006221
iteration 13205 : loss : 0.022306, loss_ce: 0.004803
iteration 13206 : loss : 0.035880, loss_ce: 0.026115
 71%|████████████████████▌        | 142/200 [2:24:09<52:39, 54.48s/it]iteration 13207 : loss : 0.024698, loss_ce: 0.013531
iteration 13208 : loss : 0.023708, loss_ce: 0.010541
iteration 13209 : loss : 0.035324, loss_ce: 0.007964
iteration 13210 : loss : 0.072795, loss_ce: 0.010098
iteration 13211 : loss : 0.021118, loss_ce: 0.008966
iteration 13212 : loss : 0.034899, loss_ce: 0.010301
iteration 13213 : loss : 0.025077, loss_ce: 0.008035
iteration 13214 : loss : 0.028068, loss_ce: 0.007149
iteration 13215 : loss : 0.021703, loss_ce: 0.007212
iteration 13216 : loss : 0.077219, loss_ce: 0.005740
iteration 13217 : loss : 0.020970, loss_ce: 0.006452
iteration 13218 : loss : 0.028374, loss_ce: 0.008712
iteration 13219 : loss : 0.019226, loss_ce: 0.003885
iteration 13220 : loss : 0.025335, loss_ce: 0.010677
iteration 13221 : loss : 0.021084, loss_ce: 0.005963
iteration 13222 : loss : 0.024914, loss_ce: 0.008292
iteration 13223 : loss : 0.026748, loss_ce: 0.011803
iteration 13224 : loss : 0.027681, loss_ce: 0.005221
iteration 13225 : loss : 0.023205, loss_ce: 0.006016
iteration 13226 : loss : 0.025732, loss_ce: 0.010053
iteration 13227 : loss : 0.021069, loss_ce: 0.005382
iteration 13228 : loss : 0.075182, loss_ce: 0.007911
iteration 13229 : loss : 0.023819, loss_ce: 0.008905
iteration 13230 : loss : 0.074918, loss_ce: 0.007686
iteration 13231 : loss : 0.023552, loss_ce: 0.009288
iteration 13232 : loss : 0.027284, loss_ce: 0.010434
iteration 13233 : loss : 0.022591, loss_ce: 0.007723
iteration 13234 : loss : 0.020673, loss_ce: 0.003953
iteration 13235 : loss : 0.025339, loss_ce: 0.012561
iteration 13236 : loss : 0.027951, loss_ce: 0.009746
iteration 13237 : loss : 0.021977, loss_ce: 0.005616
iteration 13238 : loss : 0.025814, loss_ce: 0.010094
iteration 13239 : loss : 0.024476, loss_ce: 0.012161
iteration 13240 : loss : 0.022789, loss_ce: 0.009298
iteration 13241 : loss : 0.031541, loss_ce: 0.004589
iteration 13242 : loss : 0.022420, loss_ce: 0.006180
iteration 13243 : loss : 0.022052, loss_ce: 0.008039
iteration 13244 : loss : 0.028906, loss_ce: 0.010848
iteration 13245 : loss : 0.024053, loss_ce: 0.007142
iteration 13246 : loss : 0.024521, loss_ce: 0.009565
iteration 13247 : loss : 0.022733, loss_ce: 0.007202
iteration 13248 : loss : 0.075062, loss_ce: 0.009435
iteration 13249 : loss : 0.087288, loss_ce: 0.007848
iteration 13250 : loss : 0.021892, loss_ce: 0.007643
iteration 13251 : loss : 0.022720, loss_ce: 0.007105
iteration 13252 : loss : 0.022929, loss_ce: 0.004655
iteration 13253 : loss : 0.022654, loss_ce: 0.006889
iteration 13254 : loss : 0.022213, loss_ce: 0.009829
iteration 13255 : loss : 0.024344, loss_ce: 0.005098
iteration 13256 : loss : 0.025331, loss_ce: 0.008101
iteration 13257 : loss : 0.021820, loss_ce: 0.006385
iteration 13258 : loss : 0.023117, loss_ce: 0.007758
iteration 13259 : loss : 0.020449, loss_ce: 0.008643
iteration 13260 : loss : 0.019522, loss_ce: 0.006475
iteration 13261 : loss : 0.020496, loss_ce: 0.007546
iteration 13262 : loss : 0.024530, loss_ce: 0.005269
iteration 13263 : loss : 0.024510, loss_ce: 0.006887
iteration 13264 : loss : 0.020223, loss_ce: 0.006507
iteration 13265 : loss : 0.023556, loss_ce: 0.007579
iteration 13266 : loss : 0.031581, loss_ce: 0.005379
iteration 13267 : loss : 0.028639, loss_ce: 0.011303
iteration 13268 : loss : 0.022831, loss_ce: 0.005683
iteration 13269 : loss : 0.078602, loss_ce: 0.004947
iteration 13270 : loss : 0.076847, loss_ce: 0.006565
iteration 13271 : loss : 0.020370, loss_ce: 0.006371
iteration 13272 : loss : 0.020938, loss_ce: 0.007211
iteration 13273 : loss : 0.018759, loss_ce: 0.008304
iteration 13274 : loss : 0.023168, loss_ce: 0.008519
iteration 13275 : loss : 0.028466, loss_ce: 0.009943
iteration 13276 : loss : 0.024287, loss_ce: 0.010708
iteration 13277 : loss : 0.027863, loss_ce: 0.005522
iteration 13278 : loss : 0.020027, loss_ce: 0.007381
iteration 13279 : loss : 0.022885, loss_ce: 0.008666
iteration 13280 : loss : 0.026672, loss_ce: 0.005423
iteration 13281 : loss : 0.022541, loss_ce: 0.009010
iteration 13282 : loss : 0.024572, loss_ce: 0.007033
iteration 13283 : loss : 0.021722, loss_ce: 0.009245
iteration 13284 : loss : 0.022648, loss_ce: 0.008806
iteration 13285 : loss : 0.023073, loss_ce: 0.008622
iteration 13286 : loss : 0.020181, loss_ce: 0.004887
iteration 13287 : loss : 0.020996, loss_ce: 0.008051
iteration 13288 : loss : 0.022320, loss_ce: 0.009887
iteration 13289 : loss : 0.024008, loss_ce: 0.009168
iteration 13290 : loss : 0.033303, loss_ce: 0.008001
iteration 13291 : loss : 0.024190, loss_ce: 0.007332
iteration 13292 : loss : 0.024457, loss_ce: 0.008517
iteration 13293 : loss : 0.030253, loss_ce: 0.009193
iteration 13294 : loss : 0.026738, loss_ce: 0.009594
iteration 13295 : loss : 0.024308, loss_ce: 0.010076
iteration 13296 : loss : 0.019584, loss_ce: 0.006686
iteration 13297 : loss : 0.021188, loss_ce: 0.007301
iteration 13298 : loss : 0.019584, loss_ce: 0.007689
iteration 13299 : loss : 0.336575, loss_ce: 0.003948
 72%|████████████████████▋        | 143/200 [2:25:03<51:43, 54.45s/it]iteration 13300 : loss : 0.024963, loss_ce: 0.008167
iteration 13301 : loss : 0.022060, loss_ce: 0.008058
iteration 13302 : loss : 0.025719, loss_ce: 0.006840
iteration 13303 : loss : 0.021860, loss_ce: 0.007056
iteration 13304 : loss : 0.023327, loss_ce: 0.010895
iteration 13305 : loss : 0.026669, loss_ce: 0.006297
iteration 13306 : loss : 0.022373, loss_ce: 0.007346
iteration 13307 : loss : 0.020199, loss_ce: 0.008545
iteration 13308 : loss : 0.021714, loss_ce: 0.007130
iteration 13309 : loss : 0.022695, loss_ce: 0.006714
iteration 13310 : loss : 0.022215, loss_ce: 0.010970
iteration 13311 : loss : 0.019568, loss_ce: 0.006543
iteration 13312 : loss : 0.021014, loss_ce: 0.007871
iteration 13313 : loss : 0.040257, loss_ce: 0.005408
iteration 13314 : loss : 0.025103, loss_ce: 0.006812
iteration 13315 : loss : 0.024270, loss_ce: 0.007384
iteration 13316 : loss : 0.028101, loss_ce: 0.005921
iteration 13317 : loss : 0.026189, loss_ce: 0.012367
iteration 13318 : loss : 0.021292, loss_ce: 0.007232
iteration 13319 : loss : 0.021529, loss_ce: 0.007694
iteration 13320 : loss : 0.024067, loss_ce: 0.011478
iteration 13321 : loss : 0.027814, loss_ce: 0.007862
iteration 13322 : loss : 0.019117, loss_ce: 0.005752
iteration 13323 : loss : 0.029762, loss_ce: 0.006929
iteration 13324 : loss : 0.024345, loss_ce: 0.006195
iteration 13325 : loss : 0.021483, loss_ce: 0.009020
iteration 13326 : loss : 0.020847, loss_ce: 0.009450
iteration 13327 : loss : 0.027570, loss_ce: 0.011823
iteration 13328 : loss : 0.022722, loss_ce: 0.007137
iteration 13329 : loss : 0.020626, loss_ce: 0.008060
iteration 13330 : loss : 0.025215, loss_ce: 0.011477
iteration 13331 : loss : 0.022013, loss_ce: 0.009250
iteration 13332 : loss : 0.027843, loss_ce: 0.005541
iteration 13333 : loss : 0.023528, loss_ce: 0.011635
iteration 13334 : loss : 0.022343, loss_ce: 0.007592
iteration 13335 : loss : 0.026443, loss_ce: 0.005959
iteration 13336 : loss : 0.019153, loss_ce: 0.003675
iteration 13337 : loss : 0.033402, loss_ce: 0.007411
iteration 13338 : loss : 0.025842, loss_ce: 0.008180
iteration 13339 : loss : 0.023612, loss_ce: 0.002870
iteration 13340 : loss : 0.027951, loss_ce: 0.011951
iteration 13341 : loss : 0.021591, loss_ce: 0.008176
iteration 13342 : loss : 0.021690, loss_ce: 0.005763
iteration 13343 : loss : 0.025565, loss_ce: 0.005930
iteration 13344 : loss : 0.028777, loss_ce: 0.007406
iteration 13345 : loss : 0.020835, loss_ce: 0.007297
iteration 13346 : loss : 0.079123, loss_ce: 0.008772
iteration 13347 : loss : 0.020357, loss_ce: 0.008115
iteration 13348 : loss : 0.025242, loss_ce: 0.009638
iteration 13349 : loss : 0.024485, loss_ce: 0.008368
iteration 13350 : loss : 0.031503, loss_ce: 0.008323
iteration 13351 : loss : 0.021833, loss_ce: 0.006539
iteration 13352 : loss : 0.026975, loss_ce: 0.009044
iteration 13353 : loss : 0.076285, loss_ce: 0.004174
iteration 13354 : loss : 0.020569, loss_ce: 0.004400
iteration 13355 : loss : 0.022270, loss_ce: 0.009411
iteration 13356 : loss : 0.023797, loss_ce: 0.012171
iteration 13357 : loss : 0.027780, loss_ce: 0.008303
iteration 13358 : loss : 0.025126, loss_ce: 0.006777
iteration 13359 : loss : 0.021921, loss_ce: 0.009117
iteration 13360 : loss : 0.023982, loss_ce: 0.010562
iteration 13361 : loss : 0.028917, loss_ce: 0.013363
iteration 13362 : loss : 0.024728, loss_ce: 0.008625
iteration 13363 : loss : 0.025881, loss_ce: 0.006705
iteration 13364 : loss : 0.025516, loss_ce: 0.011723
iteration 13365 : loss : 0.073538, loss_ce: 0.004397
iteration 13366 : loss : 0.021993, loss_ce: 0.007593
iteration 13367 : loss : 0.025034, loss_ce: 0.012927
iteration 13368 : loss : 0.023145, loss_ce: 0.008000
iteration 13369 : loss : 0.024619, loss_ce: 0.009582
iteration 13370 : loss : 0.023131, loss_ce: 0.010262
iteration 13371 : loss : 0.021956, loss_ce: 0.006724
iteration 13372 : loss : 0.073067, loss_ce: 0.006411
iteration 13373 : loss : 0.021843, loss_ce: 0.007651
iteration 13374 : loss : 0.024343, loss_ce: 0.011471
iteration 13375 : loss : 0.022212, loss_ce: 0.010377
iteration 13376 : loss : 0.024166, loss_ce: 0.004232
iteration 13377 : loss : 0.022731, loss_ce: 0.006585
iteration 13378 : loss : 0.027557, loss_ce: 0.004571
iteration 13379 : loss : 0.022286, loss_ce: 0.005605
iteration 13380 : loss : 0.027103, loss_ce: 0.008365
iteration 13381 : loss : 0.021010, loss_ce: 0.009536
iteration 13382 : loss : 0.021743, loss_ce: 0.004236
iteration 13383 : loss : 0.029325, loss_ce: 0.009776
iteration 13384 : loss : 0.025718, loss_ce: 0.008530
iteration 13385 : loss : 0.020923, loss_ce: 0.008054
iteration 13386 : loss : 0.026535, loss_ce: 0.011458
iteration 13387 : loss : 0.025476, loss_ce: 0.006619
iteration 13388 : loss : 0.019080, loss_ce: 0.005475
iteration 13389 : loss : 0.075619, loss_ce: 0.005267
iteration 13390 : loss : 0.023649, loss_ce: 0.008582
iteration 13391 : loss : 0.176768, loss_ce: 0.004410
iteration 13392 : loss : 0.229997, loss_ce: 0.002676
 72%|████████████████████▉        | 144/200 [2:25:58<50:49, 54.46s/it]iteration 13393 : loss : 0.016432, loss_ce: 0.005463
iteration 13394 : loss : 0.028590, loss_ce: 0.007841
iteration 13395 : loss : 0.024474, loss_ce: 0.006541
iteration 13396 : loss : 0.025030, loss_ce: 0.006331
iteration 13397 : loss : 0.025287, loss_ce: 0.009129
iteration 13398 : loss : 0.021294, loss_ce: 0.008104
iteration 13399 : loss : 0.027780, loss_ce: 0.009674
iteration 13400 : loss : 0.024574, loss_ce: 0.005748
iteration 13401 : loss : 0.019227, loss_ce: 0.006828
iteration 13402 : loss : 0.022444, loss_ce: 0.008900
iteration 13403 : loss : 0.026690, loss_ce: 0.007483
iteration 13404 : loss : 0.074299, loss_ce: 0.006385
iteration 13405 : loss : 0.025222, loss_ce: 0.007719
iteration 13406 : loss : 0.021100, loss_ce: 0.006426
iteration 13407 : loss : 0.023102, loss_ce: 0.007276
iteration 13408 : loss : 0.028169, loss_ce: 0.006169
iteration 13409 : loss : 0.022006, loss_ce: 0.008956
iteration 13410 : loss : 0.026543, loss_ce: 0.010713
iteration 13411 : loss : 0.027064, loss_ce: 0.006123
iteration 13412 : loss : 0.021100, loss_ce: 0.007817
iteration 13413 : loss : 0.020701, loss_ce: 0.009165
iteration 13414 : loss : 0.022070, loss_ce: 0.007229
iteration 13415 : loss : 0.022056, loss_ce: 0.007018
iteration 13416 : loss : 0.025214, loss_ce: 0.012413
iteration 13417 : loss : 0.079248, loss_ce: 0.008288
iteration 13418 : loss : 0.024898, loss_ce: 0.005273
iteration 13419 : loss : 0.023112, loss_ce: 0.009433
iteration 13420 : loss : 0.020817, loss_ce: 0.007795
iteration 13421 : loss : 0.074835, loss_ce: 0.005537
iteration 13422 : loss : 0.022673, loss_ce: 0.005226
iteration 13423 : loss : 0.022740, loss_ce: 0.007962
iteration 13424 : loss : 0.026164, loss_ce: 0.013486
iteration 13425 : loss : 0.018641, loss_ce: 0.003008
iteration 13426 : loss : 0.023671, loss_ce: 0.008698
iteration 13427 : loss : 0.023778, loss_ce: 0.010217
iteration 13428 : loss : 0.025119, loss_ce: 0.008844
iteration 13429 : loss : 0.026177, loss_ce: 0.010479
iteration 13430 : loss : 0.027754, loss_ce: 0.008272
iteration 13431 : loss : 0.078789, loss_ce: 0.009555
iteration 13432 : loss : 0.022034, loss_ce: 0.003845
iteration 13433 : loss : 0.023760, loss_ce: 0.007647
iteration 13434 : loss : 0.023982, loss_ce: 0.006952
iteration 13435 : loss : 0.025309, loss_ce: 0.010270
iteration 13436 : loss : 0.020094, loss_ce: 0.004281
iteration 13437 : loss : 0.022554, loss_ce: 0.006896
iteration 13438 : loss : 0.020598, loss_ce: 0.006480
iteration 13439 : loss : 0.022546, loss_ce: 0.006107
iteration 13440 : loss : 0.021702, loss_ce: 0.010195
iteration 13441 : loss : 0.024052, loss_ce: 0.009073
iteration 13442 : loss : 0.026161, loss_ce: 0.005748
iteration 13443 : loss : 0.024076, loss_ce: 0.009235
iteration 13444 : loss : 0.024629, loss_ce: 0.009869
iteration 13445 : loss : 0.026332, loss_ce: 0.011977
iteration 13446 : loss : 0.023075, loss_ce: 0.009345
iteration 13447 : loss : 0.020991, loss_ce: 0.009835
iteration 13448 : loss : 0.024996, loss_ce: 0.007697
iteration 13449 : loss : 0.025663, loss_ce: 0.013735
iteration 13450 : loss : 0.023414, loss_ce: 0.009095
iteration 13451 : loss : 0.043431, loss_ce: 0.007750
iteration 13452 : loss : 0.077923, loss_ce: 0.004998
iteration 13453 : loss : 0.025594, loss_ce: 0.008307
iteration 13454 : loss : 0.024213, loss_ce: 0.010844
iteration 13455 : loss : 0.026377, loss_ce: 0.012409
iteration 13456 : loss : 0.127009, loss_ce: 0.005324
iteration 13457 : loss : 0.027407, loss_ce: 0.008486
iteration 13458 : loss : 0.028032, loss_ce: 0.007791
iteration 13459 : loss : 0.022657, loss_ce: 0.009677
iteration 13460 : loss : 0.024794, loss_ce: 0.010974
iteration 13461 : loss : 0.024501, loss_ce: 0.011193
iteration 13462 : loss : 0.022952, loss_ce: 0.007676
iteration 13463 : loss : 0.025238, loss_ce: 0.011685
iteration 13464 : loss : 0.018623, loss_ce: 0.005157
iteration 13465 : loss : 0.077623, loss_ce: 0.006930
iteration 13466 : loss : 0.020641, loss_ce: 0.007618
iteration 13467 : loss : 0.023867, loss_ce: 0.005827
iteration 13468 : loss : 0.022671, loss_ce: 0.006637
iteration 13469 : loss : 0.021028, loss_ce: 0.005842
iteration 13470 : loss : 0.024266, loss_ce: 0.008547
iteration 13471 : loss : 0.033313, loss_ce: 0.008293
iteration 13472 : loss : 0.037154, loss_ce: 0.007603
iteration 13473 : loss : 0.025657, loss_ce: 0.008337
iteration 13474 : loss : 0.025396, loss_ce: 0.010850
iteration 13475 : loss : 0.025135, loss_ce: 0.003358
iteration 13476 : loss : 0.020298, loss_ce: 0.008527
iteration 13477 : loss : 0.024080, loss_ce: 0.012817
iteration 13478 : loss : 0.085633, loss_ce: 0.005978
iteration 13479 : loss : 0.021218, loss_ce: 0.005939
iteration 13480 : loss : 0.073707, loss_ce: 0.008727
iteration 13481 : loss : 0.025355, loss_ce: 0.006903
iteration 13482 : loss : 0.023832, loss_ce: 0.004113
iteration 13483 : loss : 0.023606, loss_ce: 0.006720
iteration 13484 : loss : 0.020975, loss_ce: 0.008312
iteration 13485 : loss : 0.281063, loss_ce: 0.003815
 72%|█████████████████████        | 145/200 [2:26:53<49:59, 54.53s/it]iteration 13486 : loss : 0.023359, loss_ce: 0.009116
iteration 13487 : loss : 0.022308, loss_ce: 0.008704
iteration 13488 : loss : 0.024443, loss_ce: 0.011423
iteration 13489 : loss : 0.022029, loss_ce: 0.008905
iteration 13490 : loss : 0.033979, loss_ce: 0.009933
iteration 13491 : loss : 0.026743, loss_ce: 0.009205
iteration 13492 : loss : 0.025737, loss_ce: 0.010227
iteration 13493 : loss : 0.023694, loss_ce: 0.008702
iteration 13494 : loss : 0.017716, loss_ce: 0.005502
iteration 13495 : loss : 0.025479, loss_ce: 0.010539
iteration 13496 : loss : 0.022477, loss_ce: 0.008935
iteration 13497 : loss : 0.028736, loss_ce: 0.007618
iteration 13498 : loss : 0.026548, loss_ce: 0.009902
iteration 13499 : loss : 0.022817, loss_ce: 0.008555
iteration 13500 : loss : 0.035656, loss_ce: 0.008762
iteration 13501 : loss : 0.026447, loss_ce: 0.006916
iteration 13502 : loss : 0.026667, loss_ce: 0.010988
iteration 13503 : loss : 0.019990, loss_ce: 0.007997
iteration 13504 : loss : 0.023890, loss_ce: 0.008495
iteration 13505 : loss : 0.022101, loss_ce: 0.006252
iteration 13506 : loss : 0.020340, loss_ce: 0.004164
iteration 13507 : loss : 0.020202, loss_ce: 0.006265
iteration 13508 : loss : 0.023826, loss_ce: 0.009120
iteration 13509 : loss : 0.026298, loss_ce: 0.007765
iteration 13510 : loss : 0.075141, loss_ce: 0.005096
iteration 13511 : loss : 0.023631, loss_ce: 0.009034
iteration 13512 : loss : 0.073836, loss_ce: 0.006580
iteration 13513 : loss : 0.025827, loss_ce: 0.006681
iteration 13514 : loss : 0.026033, loss_ce: 0.009676
iteration 13515 : loss : 0.022763, loss_ce: 0.008831
iteration 13516 : loss : 0.022596, loss_ce: 0.006205
iteration 13517 : loss : 0.018747, loss_ce: 0.008121
iteration 13518 : loss : 0.023607, loss_ce: 0.010584
iteration 13519 : loss : 0.026995, loss_ce: 0.009691
iteration 13520 : loss : 0.021970, loss_ce: 0.008027
iteration 13521 : loss : 0.022342, loss_ce: 0.009151
iteration 13522 : loss : 0.023397, loss_ce: 0.005008
iteration 13523 : loss : 0.023734, loss_ce: 0.008849
iteration 13524 : loss : 0.025251, loss_ce: 0.008836
iteration 13525 : loss : 0.048348, loss_ce: 0.006089
iteration 13526 : loss : 0.021002, loss_ce: 0.010802
iteration 13527 : loss : 0.021148, loss_ce: 0.005792
iteration 13528 : loss : 0.023169, loss_ce: 0.009083
iteration 13529 : loss : 0.024411, loss_ce: 0.007407
iteration 13530 : loss : 0.027444, loss_ce: 0.008609
iteration 13531 : loss : 0.025471, loss_ce: 0.007475
iteration 13532 : loss : 0.026914, loss_ce: 0.006291
iteration 13533 : loss : 0.022172, loss_ce: 0.011572
iteration 13534 : loss : 0.022788, loss_ce: 0.009088
iteration 13535 : loss : 0.023827, loss_ce: 0.009994
iteration 13536 : loss : 0.025707, loss_ce: 0.009211
iteration 13537 : loss : 0.031512, loss_ce: 0.007095
iteration 13538 : loss : 0.022027, loss_ce: 0.006651
iteration 13539 : loss : 0.020701, loss_ce: 0.006699
iteration 13540 : loss : 0.023535, loss_ce: 0.007090
iteration 13541 : loss : 0.025269, loss_ce: 0.007692
iteration 13542 : loss : 0.020163, loss_ce: 0.008558
iteration 13543 : loss : 0.021841, loss_ce: 0.008854
iteration 13544 : loss : 0.022938, loss_ce: 0.005916
iteration 13545 : loss : 0.025893, loss_ce: 0.011431
iteration 13546 : loss : 0.023904, loss_ce: 0.007092
iteration 13547 : loss : 0.074700, loss_ce: 0.005767
iteration 13548 : loss : 0.023375, loss_ce: 0.007896
iteration 13549 : loss : 0.022732, loss_ce: 0.009211
iteration 13550 : loss : 0.035546, loss_ce: 0.004225
iteration 13551 : loss : 0.028420, loss_ce: 0.008656
iteration 13552 : loss : 0.025347, loss_ce: 0.011087
iteration 13553 : loss : 0.024060, loss_ce: 0.009683
iteration 13554 : loss : 0.020450, loss_ce: 0.006497
iteration 13555 : loss : 0.026244, loss_ce: 0.009133
iteration 13556 : loss : 0.026024, loss_ce: 0.006544
iteration 13557 : loss : 0.018329, loss_ce: 0.006294
iteration 13558 : loss : 0.079347, loss_ce: 0.007379
iteration 13559 : loss : 0.021692, loss_ce: 0.010005
iteration 13560 : loss : 0.022725, loss_ce: 0.008337
iteration 13561 : loss : 0.027027, loss_ce: 0.005897
iteration 13562 : loss : 0.026181, loss_ce: 0.005451
iteration 13563 : loss : 0.023630, loss_ce: 0.007676
iteration 13564 : loss : 0.023847, loss_ce: 0.004689
iteration 13565 : loss : 0.021043, loss_ce: 0.008049
iteration 13566 : loss : 0.024059, loss_ce: 0.008934
iteration 13567 : loss : 0.022228, loss_ce: 0.006815
iteration 13568 : loss : 0.076651, loss_ce: 0.004508
iteration 13569 : loss : 0.024186, loss_ce: 0.011286
iteration 13570 : loss : 0.027346, loss_ce: 0.008030
iteration 13571 : loss : 0.023009, loss_ce: 0.007360
iteration 13572 : loss : 0.020850, loss_ce: 0.004997
iteration 13573 : loss : 0.019328, loss_ce: 0.007043
iteration 13574 : loss : 0.030352, loss_ce: 0.010532
iteration 13575 : loss : 0.020280, loss_ce: 0.009081
iteration 13576 : loss : 0.027128, loss_ce: 0.008754
iteration 13577 : loss : 0.081294, loss_ce: 0.002078
iteration 13578 : loss : 0.130435, loss_ce: 0.004601
 73%|█████████████████████▏       | 146/200 [2:27:47<49:02, 54.50s/it]iteration 13579 : loss : 0.024321, loss_ce: 0.006999
iteration 13580 : loss : 0.022287, loss_ce: 0.007599
iteration 13581 : loss : 0.022668, loss_ce: 0.007238
iteration 13582 : loss : 0.019802, loss_ce: 0.005594
iteration 13583 : loss : 0.021694, loss_ce: 0.006360
iteration 13584 : loss : 0.070688, loss_ce: 0.003341
iteration 13585 : loss : 0.024046, loss_ce: 0.008626
iteration 13586 : loss : 0.072084, loss_ce: 0.005804
iteration 13587 : loss : 0.025471, loss_ce: 0.008880
iteration 13588 : loss : 0.024449, loss_ce: 0.007580
iteration 13589 : loss : 0.023651, loss_ce: 0.006731
iteration 13590 : loss : 0.019860, loss_ce: 0.006684
iteration 13591 : loss : 0.022338, loss_ce: 0.007260
iteration 13592 : loss : 0.019326, loss_ce: 0.004715
iteration 13593 : loss : 0.024143, loss_ce: 0.010419
iteration 13594 : loss : 0.021258, loss_ce: 0.009563
iteration 13595 : loss : 0.024518, loss_ce: 0.007031
iteration 13596 : loss : 0.044146, loss_ce: 0.009698
iteration 13597 : loss : 0.023584, loss_ce: 0.009685
iteration 13598 : loss : 0.026008, loss_ce: 0.008175
iteration 13599 : loss : 0.019607, loss_ce: 0.005031
iteration 13600 : loss : 0.020086, loss_ce: 0.004236
iteration 13601 : loss : 0.019436, loss_ce: 0.004663
iteration 13602 : loss : 0.020946, loss_ce: 0.009445
iteration 13603 : loss : 0.023241, loss_ce: 0.006637
iteration 13604 : loss : 0.018576, loss_ce: 0.005987
iteration 13605 : loss : 0.020464, loss_ce: 0.006763
iteration 13606 : loss : 0.025151, loss_ce: 0.008769
iteration 13607 : loss : 0.025203, loss_ce: 0.010555
iteration 13608 : loss : 0.023137, loss_ce: 0.011793
iteration 13609 : loss : 0.025898, loss_ce: 0.006527
iteration 13610 : loss : 0.024838, loss_ce: 0.009484
iteration 13611 : loss : 0.022526, loss_ce: 0.009529
iteration 13612 : loss : 0.020329, loss_ce: 0.006892
iteration 13613 : loss : 0.022078, loss_ce: 0.008311
iteration 13614 : loss : 0.019214, loss_ce: 0.005107
iteration 13615 : loss : 0.026462, loss_ce: 0.009754
iteration 13616 : loss : 0.021155, loss_ce: 0.009006
iteration 13617 : loss : 0.030390, loss_ce: 0.007121
iteration 13618 : loss : 0.023643, loss_ce: 0.007435
iteration 13619 : loss : 0.025554, loss_ce: 0.010953
iteration 13620 : loss : 0.038853, loss_ce: 0.006425
iteration 13621 : loss : 0.025028, loss_ce: 0.012157
iteration 13622 : loss : 0.020740, loss_ce: 0.005153
iteration 13623 : loss : 0.024588, loss_ce: 0.011593
iteration 13624 : loss : 0.022820, loss_ce: 0.007040
iteration 13625 : loss : 0.024679, loss_ce: 0.006426
iteration 13626 : loss : 0.022295, loss_ce: 0.007519
iteration 13627 : loss : 0.023910, loss_ce: 0.007923
iteration 13628 : loss : 0.078353, loss_ce: 0.006697
iteration 13629 : loss : 0.031751, loss_ce: 0.010673
iteration 13630 : loss : 0.026073, loss_ce: 0.007803
iteration 13631 : loss : 0.023328, loss_ce: 0.009147
iteration 13632 : loss : 0.075008, loss_ce: 0.007174
iteration 13633 : loss : 0.023608, loss_ce: 0.010876
iteration 13634 : loss : 0.025906, loss_ce: 0.006902
iteration 13635 : loss : 0.026214, loss_ce: 0.007629
iteration 13636 : loss : 0.027402, loss_ce: 0.007432
iteration 13637 : loss : 0.024290, loss_ce: 0.005504
iteration 13638 : loss : 0.075760, loss_ce: 0.007575
iteration 13639 : loss : 0.024528, loss_ce: 0.010791
iteration 13640 : loss : 0.022895, loss_ce: 0.008765
iteration 13641 : loss : 0.024934, loss_ce: 0.009823
iteration 13642 : loss : 0.025271, loss_ce: 0.011221
iteration 13643 : loss : 0.077176, loss_ce: 0.007805
iteration 13644 : loss : 0.026222, loss_ce: 0.005591
iteration 13645 : loss : 0.018569, loss_ce: 0.007270
iteration 13646 : loss : 0.022144, loss_ce: 0.010239
iteration 13647 : loss : 0.021979, loss_ce: 0.007059
iteration 13648 : loss : 0.027543, loss_ce: 0.011150
iteration 13649 : loss : 0.026835, loss_ce: 0.009758
iteration 13650 : loss : 0.021942, loss_ce: 0.008459
iteration 13651 : loss : 0.019958, loss_ce: 0.005555
iteration 13652 : loss : 0.022250, loss_ce: 0.008992
iteration 13653 : loss : 0.025545, loss_ce: 0.009863
iteration 13654 : loss : 0.021372, loss_ce: 0.005416
iteration 13655 : loss : 0.020844, loss_ce: 0.008383
iteration 13656 : loss : 0.020234, loss_ce: 0.008492
iteration 13657 : loss : 0.021369, loss_ce: 0.004905
iteration 13658 : loss : 0.076801, loss_ce: 0.006318
iteration 13659 : loss : 0.073447, loss_ce: 0.005540
iteration 13660 : loss : 0.027621, loss_ce: 0.010912
iteration 13661 : loss : 0.022067, loss_ce: 0.007497
iteration 13662 : loss : 0.076099, loss_ce: 0.007742
iteration 13663 : loss : 0.022347, loss_ce: 0.010867
iteration 13664 : loss : 0.024411, loss_ce: 0.010595
iteration 13665 : loss : 0.029991, loss_ce: 0.008029
iteration 13666 : loss : 0.022833, loss_ce: 0.011193
iteration 13667 : loss : 0.022779, loss_ce: 0.007926
iteration 13668 : loss : 0.025438, loss_ce: 0.010425
iteration 13669 : loss : 0.023133, loss_ce: 0.007203
iteration 13670 : loss : 0.020681, loss_ce: 0.008539
iteration 13671 : loss : 0.236176, loss_ce: 0.008112
 74%|█████████████████████▎       | 147/200 [2:28:42<48:07, 54.48s/it]iteration 13672 : loss : 0.026512, loss_ce: 0.006703
iteration 13673 : loss : 0.025737, loss_ce: 0.005466
iteration 13674 : loss : 0.023743, loss_ce: 0.008957
iteration 13675 : loss : 0.023546, loss_ce: 0.008791
iteration 13676 : loss : 0.018857, loss_ce: 0.006702
iteration 13677 : loss : 0.020661, loss_ce: 0.006841
iteration 13678 : loss : 0.020657, loss_ce: 0.006226
iteration 13679 : loss : 0.020682, loss_ce: 0.009059
iteration 13680 : loss : 0.021205, loss_ce: 0.008786
iteration 13681 : loss : 0.075360, loss_ce: 0.006169
iteration 13682 : loss : 0.024244, loss_ce: 0.010533
iteration 13683 : loss : 0.020951, loss_ce: 0.004558
iteration 13684 : loss : 0.073846, loss_ce: 0.005370
iteration 13685 : loss : 0.023166, loss_ce: 0.006304
iteration 13686 : loss : 0.024025, loss_ce: 0.008114
iteration 13687 : loss : 0.023632, loss_ce: 0.008544
iteration 13688 : loss : 0.019934, loss_ce: 0.008000
iteration 13689 : loss : 0.020750, loss_ce: 0.008122
iteration 13690 : loss : 0.023660, loss_ce: 0.006169
iteration 13691 : loss : 0.016896, loss_ce: 0.006369
iteration 13692 : loss : 0.020068, loss_ce: 0.006413
iteration 13693 : loss : 0.024611, loss_ce: 0.009449
iteration 13694 : loss : 0.025553, loss_ce: 0.012632
iteration 13695 : loss : 0.021853, loss_ce: 0.008284
iteration 13696 : loss : 0.022504, loss_ce: 0.010549
iteration 13697 : loss : 0.022147, loss_ce: 0.008562
iteration 13698 : loss : 0.020063, loss_ce: 0.006652
iteration 13699 : loss : 0.021101, loss_ce: 0.007404
iteration 13700 : loss : 0.021383, loss_ce: 0.008038
iteration 13701 : loss : 0.079454, loss_ce: 0.010893
iteration 13702 : loss : 0.020758, loss_ce: 0.008940
iteration 13703 : loss : 0.019815, loss_ce: 0.006576
iteration 13704 : loss : 0.028222, loss_ce: 0.005941
iteration 13705 : loss : 0.025514, loss_ce: 0.014863
iteration 13706 : loss : 0.025476, loss_ce: 0.009424
iteration 13707 : loss : 0.026287, loss_ce: 0.011126
iteration 13708 : loss : 0.023566, loss_ce: 0.010191
iteration 13709 : loss : 0.020874, loss_ce: 0.005200
iteration 13710 : loss : 0.024174, loss_ce: 0.009293
iteration 13711 : loss : 0.029180, loss_ce: 0.012043
iteration 13712 : loss : 0.025680, loss_ce: 0.012208
iteration 13713 : loss : 0.023975, loss_ce: 0.010491
iteration 13714 : loss : 0.028847, loss_ce: 0.006637
iteration 13715 : loss : 0.019865, loss_ce: 0.005832
iteration 13716 : loss : 0.115103, loss_ce: 0.003966
iteration 13717 : loss : 0.020359, loss_ce: 0.005658
iteration 13718 : loss : 0.073871, loss_ce: 0.004183
iteration 13719 : loss : 0.126041, loss_ce: 0.003395
iteration 13720 : loss : 0.022385, loss_ce: 0.008700
iteration 13721 : loss : 0.024395, loss_ce: 0.008986
iteration 13722 : loss : 0.027594, loss_ce: 0.008090
iteration 13723 : loss : 0.031241, loss_ce: 0.013336
iteration 13724 : loss : 0.030796, loss_ce: 0.007206
iteration 13725 : loss : 0.025683, loss_ce: 0.012728
iteration 13726 : loss : 0.026282, loss_ce: 0.005611
iteration 13727 : loss : 0.025493, loss_ce: 0.008345
iteration 13728 : loss : 0.022812, loss_ce: 0.008021
iteration 13729 : loss : 0.023149, loss_ce: 0.009868
iteration 13730 : loss : 0.025060, loss_ce: 0.009488
iteration 13731 : loss : 0.054967, loss_ce: 0.006059
iteration 13732 : loss : 0.020700, loss_ce: 0.005332
iteration 13733 : loss : 0.023357, loss_ce: 0.007015
iteration 13734 : loss : 0.029754, loss_ce: 0.008476
iteration 13735 : loss : 0.023794, loss_ce: 0.006526
iteration 13736 : loss : 0.021878, loss_ce: 0.007336
iteration 13737 : loss : 0.025267, loss_ce: 0.008792
iteration 13738 : loss : 0.022739, loss_ce: 0.008597
iteration 13739 : loss : 0.077537, loss_ce: 0.007277
iteration 13740 : loss : 0.024552, loss_ce: 0.008343
iteration 13741 : loss : 0.023814, loss_ce: 0.007737
iteration 13742 : loss : 0.024321, loss_ce: 0.008300
iteration 13743 : loss : 0.029447, loss_ce: 0.007368
iteration 13744 : loss : 0.024727, loss_ce: 0.008307
iteration 13745 : loss : 0.024595, loss_ce: 0.012935
iteration 13746 : loss : 0.022618, loss_ce: 0.007310
iteration 13747 : loss : 0.030633, loss_ce: 0.012646
iteration 13748 : loss : 0.027667, loss_ce: 0.008073
iteration 13749 : loss : 0.024007, loss_ce: 0.008726
iteration 13750 : loss : 0.023344, loss_ce: 0.008524
iteration 13751 : loss : 0.025088, loss_ce: 0.005687
iteration 13752 : loss : 0.072267, loss_ce: 0.003786
iteration 13753 : loss : 0.037246, loss_ce: 0.007517
iteration 13754 : loss : 0.027263, loss_ce: 0.013941
iteration 13755 : loss : 0.027088, loss_ce: 0.012177
iteration 13756 : loss : 0.028564, loss_ce: 0.002867
iteration 13757 : loss : 0.024372, loss_ce: 0.005557
iteration 13758 : loss : 0.024692, loss_ce: 0.008911
iteration 13759 : loss : 0.024782, loss_ce: 0.008090
iteration 13760 : loss : 0.073618, loss_ce: 0.003173
iteration 13761 : loss : 0.024425, loss_ce: 0.008601
iteration 13762 : loss : 0.022352, loss_ce: 0.005836
iteration 13763 : loss : 0.123333, loss_ce: 0.005707
iteration 13764 : loss : 0.188742, loss_ce: 0.018847
 74%|█████████████████████▍       | 148/200 [2:29:36<47:13, 54.48s/it]iteration 13765 : loss : 0.024534, loss_ce: 0.008851
iteration 13766 : loss : 0.018983, loss_ce: 0.005474
iteration 13767 : loss : 0.030392, loss_ce: 0.013762
iteration 13768 : loss : 0.057298, loss_ce: 0.004384
iteration 13769 : loss : 0.024410, loss_ce: 0.010419
iteration 13770 : loss : 0.025028, loss_ce: 0.008753
iteration 13771 : loss : 0.025786, loss_ce: 0.010643
iteration 13772 : loss : 0.074106, loss_ce: 0.006767
iteration 13773 : loss : 0.021789, loss_ce: 0.004546
iteration 13774 : loss : 0.030535, loss_ce: 0.008456
iteration 13775 : loss : 0.023249, loss_ce: 0.007477
iteration 13776 : loss : 0.024553, loss_ce: 0.008767
iteration 13777 : loss : 0.023244, loss_ce: 0.006307
iteration 13778 : loss : 0.023883, loss_ce: 0.010188
iteration 13779 : loss : 0.019535, loss_ce: 0.005662
iteration 13780 : loss : 0.048182, loss_ce: 0.008548
iteration 13781 : loss : 0.023006, loss_ce: 0.009550
iteration 13782 : loss : 0.026478, loss_ce: 0.008202
iteration 13783 : loss : 0.024157, loss_ce: 0.007619
iteration 13784 : loss : 0.028952, loss_ce: 0.012106
iteration 13785 : loss : 0.022690, loss_ce: 0.005305
iteration 13786 : loss : 0.021668, loss_ce: 0.005959
iteration 13787 : loss : 0.023905, loss_ce: 0.011069
iteration 13788 : loss : 0.021950, loss_ce: 0.005257
iteration 13789 : loss : 0.027755, loss_ce: 0.006247
iteration 13790 : loss : 0.021406, loss_ce: 0.004355
iteration 13791 : loss : 0.028394, loss_ce: 0.010083
iteration 13792 : loss : 0.024126, loss_ce: 0.010253
iteration 13793 : loss : 0.023050, loss_ce: 0.008600
iteration 13794 : loss : 0.022497, loss_ce: 0.008723
iteration 13795 : loss : 0.021240, loss_ce: 0.009207
iteration 13796 : loss : 0.027295, loss_ce: 0.010270
iteration 13797 : loss : 0.022279, loss_ce: 0.009295
iteration 13798 : loss : 0.023600, loss_ce: 0.005302
iteration 13799 : loss : 0.026999, loss_ce: 0.010539
iteration 13800 : loss : 0.022481, loss_ce: 0.006236
iteration 13801 : loss : 0.026270, loss_ce: 0.009700
iteration 13802 : loss : 0.022247, loss_ce: 0.008451
iteration 13803 : loss : 0.017669, loss_ce: 0.005011
iteration 13804 : loss : 0.029360, loss_ce: 0.008597
iteration 13805 : loss : 0.026109, loss_ce: 0.009909
iteration 13806 : loss : 0.038094, loss_ce: 0.004116
iteration 13807 : loss : 0.029163, loss_ce: 0.005780
iteration 13808 : loss : 0.023417, loss_ce: 0.007682
iteration 13809 : loss : 0.021875, loss_ce: 0.008086
iteration 13810 : loss : 0.020406, loss_ce: 0.007632
iteration 13811 : loss : 0.022045, loss_ce: 0.005484
iteration 13812 : loss : 0.021310, loss_ce: 0.007039
iteration 13813 : loss : 0.020413, loss_ce: 0.007584
iteration 13814 : loss : 0.020375, loss_ce: 0.008039
iteration 13815 : loss : 0.025902, loss_ce: 0.006999
iteration 13816 : loss : 0.027895, loss_ce: 0.010833
iteration 13817 : loss : 0.022100, loss_ce: 0.007486
iteration 13818 : loss : 0.028141, loss_ce: 0.012218
iteration 13819 : loss : 0.024011, loss_ce: 0.008129
iteration 13820 : loss : 0.024155, loss_ce: 0.008107
iteration 13821 : loss : 0.019558, loss_ce: 0.005352
iteration 13822 : loss : 0.023581, loss_ce: 0.010082
iteration 13823 : loss : 0.024706, loss_ce: 0.008783
iteration 13824 : loss : 0.024163, loss_ce: 0.009578
iteration 13825 : loss : 0.020861, loss_ce: 0.008546
iteration 13826 : loss : 0.079320, loss_ce: 0.009751
iteration 13827 : loss : 0.027171, loss_ce: 0.009744
iteration 13828 : loss : 0.024275, loss_ce: 0.008988
iteration 13829 : loss : 0.027134, loss_ce: 0.012828
iteration 13830 : loss : 0.026655, loss_ce: 0.008290
iteration 13831 : loss : 0.022614, loss_ce: 0.011537
iteration 13832 : loss : 0.027185, loss_ce: 0.008035
iteration 13833 : loss : 0.018690, loss_ce: 0.004872
iteration 13834 : loss : 0.025044, loss_ce: 0.010328
iteration 13835 : loss : 0.022455, loss_ce: 0.009954
iteration 13836 : loss : 0.019409, loss_ce: 0.008844
iteration 13837 : loss : 0.026061, loss_ce: 0.006819
iteration 13838 : loss : 0.018627, loss_ce: 0.007240
iteration 13839 : loss : 0.021684, loss_ce: 0.006463
iteration 13840 : loss : 0.018073, loss_ce: 0.005221
iteration 13841 : loss : 0.022797, loss_ce: 0.007622
iteration 13842 : loss : 0.021360, loss_ce: 0.005576
iteration 13843 : loss : 0.027105, loss_ce: 0.009531
iteration 13844 : loss : 0.025602, loss_ce: 0.008259
iteration 13845 : loss : 0.023129, loss_ce: 0.003746
iteration 13846 : loss : 0.025205, loss_ce: 0.007424
iteration 13847 : loss : 0.027295, loss_ce: 0.007604
iteration 13848 : loss : 0.074101, loss_ce: 0.008040
iteration 13849 : loss : 0.020475, loss_ce: 0.006931
iteration 13850 : loss : 0.074753, loss_ce: 0.006370
iteration 13851 : loss : 0.027121, loss_ce: 0.009874
iteration 13852 : loss : 0.022732, loss_ce: 0.008233
iteration 13853 : loss : 0.023033, loss_ce: 0.006788
iteration 13854 : loss : 0.069239, loss_ce: 0.007561
iteration 13855 : loss : 0.022275, loss_ce: 0.006328
iteration 13856 : loss : 0.019802, loss_ce: 0.008159
iteration 13857 : loss : 0.394646, loss_ce: 0.001025
 74%|█████████████████████▌       | 149/200 [2:30:31<46:18, 54.48s/it]iteration 13858 : loss : 0.072600, loss_ce: 0.007811
iteration 13859 : loss : 0.021315, loss_ce: 0.006701
iteration 13860 : loss : 0.030253, loss_ce: 0.010222
iteration 13861 : loss : 0.024619, loss_ce: 0.013008
iteration 13862 : loss : 0.023754, loss_ce: 0.008922
iteration 13863 : loss : 0.022907, loss_ce: 0.009344
iteration 13864 : loss : 0.098502, loss_ce: 0.004205
iteration 13865 : loss : 0.035533, loss_ce: 0.007355
iteration 13866 : loss : 0.021658, loss_ce: 0.006836
iteration 13867 : loss : 0.024509, loss_ce: 0.010688
iteration 13868 : loss : 0.024424, loss_ce: 0.007169
iteration 13869 : loss : 0.080111, loss_ce: 0.007491
iteration 13870 : loss : 0.031885, loss_ce: 0.006456
iteration 13871 : loss : 0.031011, loss_ce: 0.007248
iteration 13872 : loss : 0.027839, loss_ce: 0.006662
iteration 13873 : loss : 0.081665, loss_ce: 0.003493
iteration 13874 : loss : 0.027638, loss_ce: 0.008645
iteration 13875 : loss : 0.024944, loss_ce: 0.010107
iteration 13876 : loss : 0.019112, loss_ce: 0.007332
iteration 13877 : loss : 0.050041, loss_ce: 0.006891
iteration 13878 : loss : 0.029516, loss_ce: 0.008316
iteration 13879 : loss : 0.030145, loss_ce: 0.011539
iteration 13880 : loss : 0.027354, loss_ce: 0.009430
iteration 13881 : loss : 0.027677, loss_ce: 0.010144
iteration 13882 : loss : 0.032325, loss_ce: 0.012784
iteration 13883 : loss : 0.019826, loss_ce: 0.005531
iteration 13884 : loss : 0.027144, loss_ce: 0.011247
iteration 13885 : loss : 0.023765, loss_ce: 0.009151
iteration 13886 : loss : 0.030655, loss_ce: 0.006711
iteration 13887 : loss : 0.023692, loss_ce: 0.009571
iteration 13888 : loss : 0.074534, loss_ce: 0.007197
iteration 13889 : loss : 0.022968, loss_ce: 0.008482
iteration 13890 : loss : 0.023722, loss_ce: 0.007408
iteration 13891 : loss : 0.023487, loss_ce: 0.004929
iteration 13892 : loss : 0.026434, loss_ce: 0.012667
iteration 13893 : loss : 0.126179, loss_ce: 0.004811
iteration 13894 : loss : 0.080482, loss_ce: 0.004473
iteration 13895 : loss : 0.025234, loss_ce: 0.006996
iteration 13896 : loss : 0.029181, loss_ce: 0.013758
iteration 13897 : loss : 0.021782, loss_ce: 0.007914
iteration 13898 : loss : 0.041325, loss_ce: 0.007468
iteration 13899 : loss : 0.025789, loss_ce: 0.012648
iteration 13900 : loss : 0.021431, loss_ce: 0.009145
iteration 13901 : loss : 0.079213, loss_ce: 0.005976
iteration 13902 : loss : 0.020185, loss_ce: 0.007430
iteration 13903 : loss : 0.029973, loss_ce: 0.015089
iteration 13904 : loss : 0.024957, loss_ce: 0.008700
iteration 13905 : loss : 0.021505, loss_ce: 0.008410
iteration 13906 : loss : 0.022953, loss_ce: 0.010102
iteration 13907 : loss : 0.022924, loss_ce: 0.006110
iteration 13908 : loss : 0.073896, loss_ce: 0.006022
iteration 13909 : loss : 0.024890, loss_ce: 0.009940
iteration 13910 : loss : 0.020494, loss_ce: 0.006512
iteration 13911 : loss : 0.018899, loss_ce: 0.005102
iteration 13912 : loss : 0.080708, loss_ce: 0.003535
iteration 13913 : loss : 0.024683, loss_ce: 0.010469
iteration 13914 : loss : 0.024230, loss_ce: 0.009030
iteration 13915 : loss : 0.024571, loss_ce: 0.009594
iteration 13916 : loss : 0.074860, loss_ce: 0.006761
iteration 13917 : loss : 0.027959, loss_ce: 0.008596
iteration 13918 : loss : 0.072766, loss_ce: 0.005301
iteration 13919 : loss : 0.031209, loss_ce: 0.009292
iteration 13920 : loss : 0.034329, loss_ce: 0.010655
iteration 13921 : loss : 0.023965, loss_ce: 0.005701
iteration 13922 : loss : 0.051243, loss_ce: 0.007080
iteration 13923 : loss : 0.021543, loss_ce: 0.009477
iteration 13924 : loss : 0.025030, loss_ce: 0.012181
iteration 13925 : loss : 0.022053, loss_ce: 0.008678
iteration 13926 : loss : 0.022777, loss_ce: 0.007083
iteration 13927 : loss : 0.024235, loss_ce: 0.010245
iteration 13928 : loss : 0.027768, loss_ce: 0.010445
iteration 13929 : loss : 0.020617, loss_ce: 0.008424
iteration 13930 : loss : 0.023212, loss_ce: 0.007866
iteration 13931 : loss : 0.021667, loss_ce: 0.007326
iteration 13932 : loss : 0.022908, loss_ce: 0.006168
iteration 13933 : loss : 0.017600, loss_ce: 0.003564
iteration 13934 : loss : 0.024722, loss_ce: 0.007691
iteration 13935 : loss : 0.024132, loss_ce: 0.007219
iteration 13936 : loss : 0.074677, loss_ce: 0.009296
iteration 13937 : loss : 0.031053, loss_ce: 0.006963
iteration 13938 : loss : 0.031638, loss_ce: 0.012884
iteration 13939 : loss : 0.025416, loss_ce: 0.007943
iteration 13940 : loss : 0.024566, loss_ce: 0.006811
iteration 13941 : loss : 0.023194, loss_ce: 0.006772
iteration 13942 : loss : 0.020594, loss_ce: 0.004740
iteration 13943 : loss : 0.025581, loss_ce: 0.010892
iteration 13944 : loss : 0.024591, loss_ce: 0.008929
iteration 13945 : loss : 0.021299, loss_ce: 0.006943
iteration 13946 : loss : 0.022076, loss_ce: 0.007452
iteration 13947 : loss : 0.022222, loss_ce: 0.007813
iteration 13948 : loss : 0.023008, loss_ce: 0.006608
iteration 13949 : loss : 0.021208, loss_ce: 0.006950
iteration 13950 : loss : 0.338297, loss_ce: 0.002189
save model to ../model/TU_Synapse224/TU_pretrain_R50-ViT-B_16_skip3_epo200_bs24_224/epoch_149.pth
 75%|█████████████████████▊       | 150/200 [2:31:25<45:30, 54.60s/it]iteration 13951 : loss : 0.023825, loss_ce: 0.009030
iteration 13952 : loss : 0.024173, loss_ce: 0.008222
iteration 13953 : loss : 0.023563, loss_ce: 0.005590
iteration 13954 : loss : 0.023896, loss_ce: 0.007329
iteration 13955 : loss : 0.025022, loss_ce: 0.007432
iteration 13956 : loss : 0.022779, loss_ce: 0.010313
iteration 13957 : loss : 0.023840, loss_ce: 0.004665
iteration 13958 : loss : 0.019239, loss_ce: 0.004640
iteration 13959 : loss : 0.018442, loss_ce: 0.008766
iteration 13960 : loss : 0.024642, loss_ce: 0.009818
iteration 13961 : loss : 0.026332, loss_ce: 0.008405
iteration 13962 : loss : 0.022366, loss_ce: 0.006482
iteration 13963 : loss : 0.025238, loss_ce: 0.008219
iteration 13964 : loss : 0.018443, loss_ce: 0.006213
iteration 13965 : loss : 0.019397, loss_ce: 0.007939
iteration 13966 : loss : 0.020973, loss_ce: 0.006779
iteration 13967 : loss : 0.018173, loss_ce: 0.006118
iteration 13968 : loss : 0.021904, loss_ce: 0.005081
iteration 13969 : loss : 0.021975, loss_ce: 0.009778
iteration 13970 : loss : 0.023335, loss_ce: 0.008498
iteration 13971 : loss : 0.023064, loss_ce: 0.006572
iteration 13972 : loss : 0.072308, loss_ce: 0.004395
iteration 13973 : loss : 0.073143, loss_ce: 0.006676
iteration 13974 : loss : 0.023385, loss_ce: 0.009088
iteration 13975 : loss : 0.058494, loss_ce: 0.010137
iteration 13976 : loss : 0.022823, loss_ce: 0.011392
iteration 13977 : loss : 0.021678, loss_ce: 0.007031
iteration 13978 : loss : 0.025420, loss_ce: 0.013494
iteration 13979 : loss : 0.021773, loss_ce: 0.010471
iteration 13980 : loss : 0.028001, loss_ce: 0.009109
iteration 13981 : loss : 0.022287, loss_ce: 0.009524
iteration 13982 : loss : 0.025216, loss_ce: 0.011145
iteration 13983 : loss : 0.024298, loss_ce: 0.006295
iteration 13984 : loss : 0.023692, loss_ce: 0.007840
iteration 13985 : loss : 0.035256, loss_ce: 0.006967
iteration 13986 : loss : 0.025309, loss_ce: 0.008577
iteration 13987 : loss : 0.071235, loss_ce: 0.006098
iteration 13988 : loss : 0.021410, loss_ce: 0.009412
iteration 13989 : loss : 0.023870, loss_ce: 0.007264
iteration 13990 : loss : 0.026131, loss_ce: 0.008715
iteration 13991 : loss : 0.025066, loss_ce: 0.008064
iteration 13992 : loss : 0.020597, loss_ce: 0.009220
iteration 13993 : loss : 0.027571, loss_ce: 0.009248
iteration 13994 : loss : 0.023907, loss_ce: 0.006556
iteration 13995 : loss : 0.025295, loss_ce: 0.008666
iteration 13996 : loss : 0.075703, loss_ce: 0.005438
iteration 13997 : loss : 0.026309, loss_ce: 0.008780
iteration 13998 : loss : 0.073404, loss_ce: 0.005504
iteration 13999 : loss : 0.022323, loss_ce: 0.007933
iteration 14000 : loss : 0.025879, loss_ce: 0.009206
iteration 14001 : loss : 0.019610, loss_ce: 0.005327
iteration 14002 : loss : 0.025790, loss_ce: 0.012487
iteration 14003 : loss : 0.027800, loss_ce: 0.009513
iteration 14004 : loss : 0.021824, loss_ce: 0.010550
iteration 14005 : loss : 0.028663, loss_ce: 0.007730
iteration 14006 : loss : 0.020902, loss_ce: 0.005977
iteration 14007 : loss : 0.021126, loss_ce: 0.009066
iteration 14008 : loss : 0.019293, loss_ce: 0.009680
iteration 14009 : loss : 0.021218, loss_ce: 0.005250
iteration 14010 : loss : 0.024075, loss_ce: 0.011357
iteration 14011 : loss : 0.024722, loss_ce: 0.008736
iteration 14012 : loss : 0.027449, loss_ce: 0.012549
iteration 14013 : loss : 0.023714, loss_ce: 0.008136
iteration 14014 : loss : 0.073041, loss_ce: 0.004211
iteration 14015 : loss : 0.023962, loss_ce: 0.011601
iteration 14016 : loss : 0.028288, loss_ce: 0.006071
iteration 14017 : loss : 0.020371, loss_ce: 0.005579
iteration 14018 : loss : 0.030136, loss_ce: 0.007465
iteration 14019 : loss : 0.021189, loss_ce: 0.005690
iteration 14020 : loss : 0.022965, loss_ce: 0.007503
iteration 14021 : loss : 0.020106, loss_ce: 0.006310
iteration 14022 : loss : 0.054124, loss_ce: 0.007842
iteration 14023 : loss : 0.021060, loss_ce: 0.007642
iteration 14024 : loss : 0.022333, loss_ce: 0.009740
iteration 14025 : loss : 0.021873, loss_ce: 0.006282
iteration 14026 : loss : 0.022728, loss_ce: 0.007881
iteration 14027 : loss : 0.025533, loss_ce: 0.007032
iteration 14028 : loss : 0.022646, loss_ce: 0.009069
iteration 14029 : loss : 0.022475, loss_ce: 0.008179
iteration 14030 : loss : 0.028176, loss_ce: 0.011046
iteration 14031 : loss : 0.023409, loss_ce: 0.009797
iteration 14032 : loss : 0.033431, loss_ce: 0.008357
iteration 14033 : loss : 0.024409, loss_ce: 0.004964
iteration 14034 : loss : 0.023581, loss_ce: 0.007683
iteration 14035 : loss : 0.020431, loss_ce: 0.005932
iteration 14036 : loss : 0.027115, loss_ce: 0.010086
iteration 14037 : loss : 0.029270, loss_ce: 0.008198
iteration 14038 : loss : 0.024015, loss_ce: 0.010401
iteration 14039 : loss : 0.020807, loss_ce: 0.003385
iteration 14040 : loss : 0.023578, loss_ce: 0.006755
iteration 14041 : loss : 0.028364, loss_ce: 0.007648
iteration 14042 : loss : 0.022290, loss_ce: 0.006224
iteration 14043 : loss : 0.338724, loss_ce: 0.008159
 76%|█████████████████████▉       | 151/200 [2:32:20<44:33, 54.57s/it]iteration 14044 : loss : 0.024716, loss_ce: 0.009887
iteration 14045 : loss : 0.027896, loss_ce: 0.010756
iteration 14046 : loss : 0.073960, loss_ce: 0.003341
iteration 14047 : loss : 0.023853, loss_ce: 0.009591
iteration 14048 : loss : 0.021846, loss_ce: 0.010472
iteration 14049 : loss : 0.025432, loss_ce: 0.009154
iteration 14050 : loss : 0.022541, loss_ce: 0.008649
iteration 14051 : loss : 0.023775, loss_ce: 0.008687
iteration 14052 : loss : 0.022181, loss_ce: 0.008378
iteration 14053 : loss : 0.021438, loss_ce: 0.005747
iteration 14054 : loss : 0.021371, loss_ce: 0.011061
iteration 14055 : loss : 0.020955, loss_ce: 0.008278
iteration 14056 : loss : 0.019611, loss_ce: 0.006548
iteration 14057 : loss : 0.074446, loss_ce: 0.008889
iteration 14058 : loss : 0.026328, loss_ce: 0.006555
iteration 14059 : loss : 0.026991, loss_ce: 0.011971
iteration 14060 : loss : 0.021261, loss_ce: 0.004319
iteration 14061 : loss : 0.022413, loss_ce: 0.009396
iteration 14062 : loss : 0.022567, loss_ce: 0.005643
iteration 14063 : loss : 0.022663, loss_ce: 0.006243
iteration 14064 : loss : 0.024102, loss_ce: 0.006423
iteration 14065 : loss : 0.026136, loss_ce: 0.008173
iteration 14066 : loss : 0.024530, loss_ce: 0.006597
iteration 14067 : loss : 0.031552, loss_ce: 0.009840
iteration 14068 : loss : 0.025158, loss_ce: 0.008068
iteration 14069 : loss : 0.022221, loss_ce: 0.006589
iteration 14070 : loss : 0.027429, loss_ce: 0.008026
iteration 14071 : loss : 0.021747, loss_ce: 0.009804
iteration 14072 : loss : 0.021516, loss_ce: 0.006372
iteration 14073 : loss : 0.075154, loss_ce: 0.010170
iteration 14074 : loss : 0.027626, loss_ce: 0.006488
iteration 14075 : loss : 0.024852, loss_ce: 0.005265
iteration 14076 : loss : 0.019275, loss_ce: 0.006929
iteration 14077 : loss : 0.075471, loss_ce: 0.004791
iteration 14078 : loss : 0.033655, loss_ce: 0.011127
iteration 14079 : loss : 0.022147, loss_ce: 0.006193
iteration 14080 : loss : 0.021563, loss_ce: 0.009292
iteration 14081 : loss : 0.025615, loss_ce: 0.012328
iteration 14082 : loss : 0.024050, loss_ce: 0.009481
iteration 14083 : loss : 0.022185, loss_ce: 0.006186
iteration 14084 : loss : 0.022446, loss_ce: 0.008457
iteration 14085 : loss : 0.076520, loss_ce: 0.005192
iteration 14086 : loss : 0.023009, loss_ce: 0.006778
iteration 14087 : loss : 0.019951, loss_ce: 0.009723
iteration 14088 : loss : 0.035894, loss_ce: 0.009285
iteration 14089 : loss : 0.032960, loss_ce: 0.006283
iteration 14090 : loss : 0.023003, loss_ce: 0.006276
iteration 14091 : loss : 0.018605, loss_ce: 0.006764
iteration 14092 : loss : 0.019792, loss_ce: 0.007229
iteration 14093 : loss : 0.029963, loss_ce: 0.009212
iteration 14094 : loss : 0.024028, loss_ce: 0.010425
iteration 14095 : loss : 0.022498, loss_ce: 0.006246
iteration 14096 : loss : 0.032564, loss_ce: 0.007482
iteration 14097 : loss : 0.184075, loss_ce: 0.001734
iteration 14098 : loss : 0.018166, loss_ce: 0.007507
iteration 14099 : loss : 0.074474, loss_ce: 0.005000
iteration 14100 : loss : 0.026240, loss_ce: 0.008218
iteration 14101 : loss : 0.021241, loss_ce: 0.006591
iteration 14102 : loss : 0.026688, loss_ce: 0.006520
iteration 14103 : loss : 0.039912, loss_ce: 0.010540
iteration 14104 : loss : 0.020026, loss_ce: 0.005454
iteration 14105 : loss : 0.029090, loss_ce: 0.009077
iteration 14106 : loss : 0.020172, loss_ce: 0.006481
iteration 14107 : loss : 0.025584, loss_ce: 0.009452
iteration 14108 : loss : 0.026910, loss_ce: 0.008609
iteration 14109 : loss : 0.025324, loss_ce: 0.008930
iteration 14110 : loss : 0.027127, loss_ce: 0.008001
iteration 14111 : loss : 0.024242, loss_ce: 0.009676
iteration 14112 : loss : 0.020159, loss_ce: 0.007523
iteration 14113 : loss : 0.024293, loss_ce: 0.010378
iteration 14114 : loss : 0.021503, loss_ce: 0.006310
iteration 14115 : loss : 0.022614, loss_ce: 0.011413
iteration 14116 : loss : 0.026618, loss_ce: 0.005816
iteration 14117 : loss : 0.074944, loss_ce: 0.006832
iteration 14118 : loss : 0.020605, loss_ce: 0.006901
iteration 14119 : loss : 0.024316, loss_ce: 0.007938
iteration 14120 : loss : 0.023932, loss_ce: 0.006819
iteration 14121 : loss : 0.021884, loss_ce: 0.010698
iteration 14122 : loss : 0.022145, loss_ce: 0.005838
iteration 14123 : loss : 0.024298, loss_ce: 0.009955
iteration 14124 : loss : 0.023062, loss_ce: 0.006182
iteration 14125 : loss : 0.024190, loss_ce: 0.005815
iteration 14126 : loss : 0.025486, loss_ce: 0.010346
iteration 14127 : loss : 0.025764, loss_ce: 0.008586
iteration 14128 : loss : 0.026549, loss_ce: 0.005262
iteration 14129 : loss : 0.024187, loss_ce: 0.009186
iteration 14130 : loss : 0.025339, loss_ce: 0.007228
iteration 14131 : loss : 0.018609, loss_ce: 0.004785
iteration 14132 : loss : 0.019154, loss_ce: 0.007851
iteration 14133 : loss : 0.023890, loss_ce: 0.010063
iteration 14134 : loss : 0.023865, loss_ce: 0.011669
iteration 14135 : loss : 0.022540, loss_ce: 0.009210
iteration 14136 : loss : 0.029573, loss_ce: 0.010239
 76%|██████████████████████       | 152/200 [2:33:14<43:36, 54.50s/it]iteration 14137 : loss : 0.073841, loss_ce: 0.007925
iteration 14138 : loss : 0.022659, loss_ce: 0.005341
iteration 14139 : loss : 0.024857, loss_ce: 0.004660
iteration 14140 : loss : 0.022333, loss_ce: 0.010322
iteration 14141 : loss : 0.026996, loss_ce: 0.009214
iteration 14142 : loss : 0.024809, loss_ce: 0.006390
iteration 14143 : loss : 0.077944, loss_ce: 0.005296
iteration 14144 : loss : 0.022024, loss_ce: 0.007005
iteration 14145 : loss : 0.022189, loss_ce: 0.008861
iteration 14146 : loss : 0.028939, loss_ce: 0.007882
iteration 14147 : loss : 0.025169, loss_ce: 0.008595
iteration 14148 : loss : 0.027026, loss_ce: 0.009684
iteration 14149 : loss : 0.026774, loss_ce: 0.010842
iteration 14150 : loss : 0.025333, loss_ce: 0.013432
iteration 14151 : loss : 0.020452, loss_ce: 0.004706
iteration 14152 : loss : 0.022241, loss_ce: 0.008479
iteration 14153 : loss : 0.023153, loss_ce: 0.008095
iteration 14154 : loss : 0.023846, loss_ce: 0.009954
iteration 14155 : loss : 0.024619, loss_ce: 0.009628
iteration 14156 : loss : 0.020366, loss_ce: 0.006155
iteration 14157 : loss : 0.022355, loss_ce: 0.006997
iteration 14158 : loss : 0.024659, loss_ce: 0.012724
iteration 14159 : loss : 0.072893, loss_ce: 0.005247
iteration 14160 : loss : 0.023897, loss_ce: 0.013124
iteration 14161 : loss : 0.020389, loss_ce: 0.008711
iteration 14162 : loss : 0.025587, loss_ce: 0.005713
iteration 14163 : loss : 0.020735, loss_ce: 0.005546
iteration 14164 : loss : 0.021621, loss_ce: 0.008170
iteration 14165 : loss : 0.022712, loss_ce: 0.011190
iteration 14166 : loss : 0.023984, loss_ce: 0.005835
iteration 14167 : loss : 0.023317, loss_ce: 0.007748
iteration 14168 : loss : 0.023916, loss_ce: 0.005652
iteration 14169 : loss : 0.024570, loss_ce: 0.010523
iteration 14170 : loss : 0.023900, loss_ce: 0.007356
iteration 14171 : loss : 0.024906, loss_ce: 0.011752
iteration 14172 : loss : 0.029478, loss_ce: 0.007756
iteration 14173 : loss : 0.022793, loss_ce: 0.006985
iteration 14174 : loss : 0.072704, loss_ce: 0.004909
iteration 14175 : loss : 0.022524, loss_ce: 0.006914
iteration 14176 : loss : 0.023508, loss_ce: 0.008736
iteration 14177 : loss : 0.022144, loss_ce: 0.008842
iteration 14178 : loss : 0.023415, loss_ce: 0.008856
iteration 14179 : loss : 0.074359, loss_ce: 0.005668
iteration 14180 : loss : 0.019733, loss_ce: 0.007908
iteration 14181 : loss : 0.022069, loss_ce: 0.007881
iteration 14182 : loss : 0.077712, loss_ce: 0.003833
iteration 14183 : loss : 0.022501, loss_ce: 0.006000
iteration 14184 : loss : 0.019234, loss_ce: 0.006165
iteration 14185 : loss : 0.036779, loss_ce: 0.008697
iteration 14186 : loss : 0.020178, loss_ce: 0.008270
iteration 14187 : loss : 0.024451, loss_ce: 0.008822
iteration 14188 : loss : 0.028722, loss_ce: 0.011067
iteration 14189 : loss : 0.032080, loss_ce: 0.004482
iteration 14190 : loss : 0.100109, loss_ce: 0.009031
iteration 14191 : loss : 0.072739, loss_ce: 0.004664
iteration 14192 : loss : 0.024384, loss_ce: 0.011030
iteration 14193 : loss : 0.026143, loss_ce: 0.007843
iteration 14194 : loss : 0.019510, loss_ce: 0.006055
iteration 14195 : loss : 0.018837, loss_ce: 0.006103
iteration 14196 : loss : 0.021242, loss_ce: 0.006528
iteration 14197 : loss : 0.023124, loss_ce: 0.008649
iteration 14198 : loss : 0.023599, loss_ce: 0.005739
iteration 14199 : loss : 0.022151, loss_ce: 0.008838
iteration 14200 : loss : 0.019922, loss_ce: 0.005141
iteration 14201 : loss : 0.023534, loss_ce: 0.006898
iteration 14202 : loss : 0.023042, loss_ce: 0.009021
iteration 14203 : loss : 0.024752, loss_ce: 0.005615
iteration 14204 : loss : 0.022954, loss_ce: 0.007888
iteration 14205 : loss : 0.025217, loss_ce: 0.008022
iteration 14206 : loss : 0.021362, loss_ce: 0.010287
iteration 14207 : loss : 0.024855, loss_ce: 0.012008
iteration 14208 : loss : 0.074820, loss_ce: 0.005188
iteration 14209 : loss : 0.025469, loss_ce: 0.012381
iteration 14210 : loss : 0.023083, loss_ce: 0.009342
iteration 14211 : loss : 0.078251, loss_ce: 0.004115
iteration 14212 : loss : 0.023326, loss_ce: 0.007616
iteration 14213 : loss : 0.023575, loss_ce: 0.007870
iteration 14214 : loss : 0.021757, loss_ce: 0.009268
iteration 14215 : loss : 0.077655, loss_ce: 0.007914
iteration 14216 : loss : 0.021234, loss_ce: 0.008339
iteration 14217 : loss : 0.022101, loss_ce: 0.009355
iteration 14218 : loss : 0.035591, loss_ce: 0.008713
iteration 14219 : loss : 0.028984, loss_ce: 0.005667
iteration 14220 : loss : 0.025576, loss_ce: 0.007339
iteration 14221 : loss : 0.029031, loss_ce: 0.006412
iteration 14222 : loss : 0.022174, loss_ce: 0.006058
iteration 14223 : loss : 0.033598, loss_ce: 0.007732
iteration 14224 : loss : 0.025351, loss_ce: 0.011767
iteration 14225 : loss : 0.027482, loss_ce: 0.009067
iteration 14226 : loss : 0.024247, loss_ce: 0.006469
iteration 14227 : loss : 0.025712, loss_ce: 0.009732
iteration 14228 : loss : 0.019517, loss_ce: 0.004849
iteration 14229 : loss : 0.230408, loss_ce: 0.007196
 76%|██████████████████████▏      | 153/200 [2:34:09<42:40, 54.47s/it]iteration 14230 : loss : 0.026705, loss_ce: 0.005993
iteration 14231 : loss : 0.022168, loss_ce: 0.005985
iteration 14232 : loss : 0.021548, loss_ce: 0.006920
iteration 14233 : loss : 0.022525, loss_ce: 0.009908
iteration 14234 : loss : 0.025793, loss_ce: 0.009224
iteration 14235 : loss : 0.022740, loss_ce: 0.009193
iteration 14236 : loss : 0.022772, loss_ce: 0.005597
iteration 14237 : loss : 0.020474, loss_ce: 0.006757
iteration 14238 : loss : 0.024005, loss_ce: 0.009726
iteration 14239 : loss : 0.022025, loss_ce: 0.007496
iteration 14240 : loss : 0.019588, loss_ce: 0.008677
iteration 14241 : loss : 0.022088, loss_ce: 0.007748
iteration 14242 : loss : 0.022927, loss_ce: 0.006462
iteration 14243 : loss : 0.028336, loss_ce: 0.009730
iteration 14244 : loss : 0.023299, loss_ce: 0.009717
iteration 14245 : loss : 0.024813, loss_ce: 0.009310
iteration 14246 : loss : 0.028033, loss_ce: 0.005482
iteration 14247 : loss : 0.022816, loss_ce: 0.005396
iteration 14248 : loss : 0.018486, loss_ce: 0.005860
iteration 14249 : loss : 0.023761, loss_ce: 0.011414
iteration 14250 : loss : 0.022492, loss_ce: 0.009756
iteration 14251 : loss : 0.029570, loss_ce: 0.007816
iteration 14252 : loss : 0.022824, loss_ce: 0.012994
iteration 14253 : loss : 0.022698, loss_ce: 0.010077
iteration 14254 : loss : 0.030026, loss_ce: 0.006491
iteration 14255 : loss : 0.028400, loss_ce: 0.007943
iteration 14256 : loss : 0.023821, loss_ce: 0.008862
iteration 14257 : loss : 0.019615, loss_ce: 0.009199
iteration 14258 : loss : 0.080353, loss_ce: 0.005321
iteration 14259 : loss : 0.023310, loss_ce: 0.006306
iteration 14260 : loss : 0.019359, loss_ce: 0.006694
iteration 14261 : loss : 0.026709, loss_ce: 0.010212
iteration 14262 : loss : 0.023363, loss_ce: 0.006576
iteration 14263 : loss : 0.021247, loss_ce: 0.008832
iteration 14264 : loss : 0.029164, loss_ce: 0.009169
iteration 14265 : loss : 0.029003, loss_ce: 0.007244
iteration 14266 : loss : 0.026464, loss_ce: 0.007598
iteration 14267 : loss : 0.024529, loss_ce: 0.005108
iteration 14268 : loss : 0.027421, loss_ce: 0.007833
iteration 14269 : loss : 0.026716, loss_ce: 0.006406
iteration 14270 : loss : 0.018610, loss_ce: 0.007365
iteration 14271 : loss : 0.022648, loss_ce: 0.008721
iteration 14272 : loss : 0.025852, loss_ce: 0.004878
iteration 14273 : loss : 0.020255, loss_ce: 0.006863
iteration 14274 : loss : 0.019481, loss_ce: 0.005196
iteration 14275 : loss : 0.022544, loss_ce: 0.009418
iteration 14276 : loss : 0.019933, loss_ce: 0.006458
iteration 14277 : loss : 0.018738, loss_ce: 0.004903
iteration 14278 : loss : 0.025269, loss_ce: 0.004628
iteration 14279 : loss : 0.023206, loss_ce: 0.010316
iteration 14280 : loss : 0.023515, loss_ce: 0.009049
iteration 14281 : loss : 0.025751, loss_ce: 0.007607
iteration 14282 : loss : 0.026583, loss_ce: 0.013552
iteration 14283 : loss : 0.025296, loss_ce: 0.011920
iteration 14284 : loss : 0.025383, loss_ce: 0.005102
iteration 14285 : loss : 0.027912, loss_ce: 0.015221
iteration 14286 : loss : 0.021638, loss_ce: 0.006301
iteration 14287 : loss : 0.023432, loss_ce: 0.008310
iteration 14288 : loss : 0.018529, loss_ce: 0.006474
iteration 14289 : loss : 0.022313, loss_ce: 0.010465
iteration 14290 : loss : 0.019471, loss_ce: 0.007878
iteration 14291 : loss : 0.026108, loss_ce: 0.006733
iteration 14292 : loss : 0.074905, loss_ce: 0.005436
iteration 14293 : loss : 0.021528, loss_ce: 0.007177
iteration 14294 : loss : 0.026793, loss_ce: 0.005878
iteration 14295 : loss : 0.022505, loss_ce: 0.009204
iteration 14296 : loss : 0.071367, loss_ce: 0.003939
iteration 14297 : loss : 0.021412, loss_ce: 0.008999
iteration 14298 : loss : 0.037434, loss_ce: 0.004845
iteration 14299 : loss : 0.023736, loss_ce: 0.007048
iteration 14300 : loss : 0.018871, loss_ce: 0.005596
iteration 14301 : loss : 0.024509, loss_ce: 0.009670
iteration 14302 : loss : 0.021566, loss_ce: 0.007093
iteration 14303 : loss : 0.020494, loss_ce: 0.005311
iteration 14304 : loss : 0.077560, loss_ce: 0.004988
iteration 14305 : loss : 0.026402, loss_ce: 0.005331
iteration 14306 : loss : 0.019542, loss_ce: 0.006366
iteration 14307 : loss : 0.020432, loss_ce: 0.010542
iteration 14308 : loss : 0.022599, loss_ce: 0.010057
iteration 14309 : loss : 0.021354, loss_ce: 0.007128
iteration 14310 : loss : 0.022517, loss_ce: 0.008064
iteration 14311 : loss : 0.022919, loss_ce: 0.007094
iteration 14312 : loss : 0.023106, loss_ce: 0.010670
iteration 14313 : loss : 0.026356, loss_ce: 0.010698
iteration 14314 : loss : 0.024670, loss_ce: 0.009393
iteration 14315 : loss : 0.023950, loss_ce: 0.007550
iteration 14316 : loss : 0.022982, loss_ce: 0.009911
iteration 14317 : loss : 0.019998, loss_ce: 0.009665
iteration 14318 : loss : 0.171196, loss_ce: 0.004734
iteration 14319 : loss : 0.019490, loss_ce: 0.005511
iteration 14320 : loss : 0.021771, loss_ce: 0.006809
iteration 14321 : loss : 0.025751, loss_ce: 0.008426
iteration 14322 : loss : 0.033890, loss_ce: 0.023710
 77%|██████████████████████▎      | 154/200 [2:35:03<41:47, 54.50s/it]iteration 14323 : loss : 0.021199, loss_ce: 0.006610
iteration 14324 : loss : 0.024368, loss_ce: 0.010159
iteration 14325 : loss : 0.075099, loss_ce: 0.007942
iteration 14326 : loss : 0.020422, loss_ce: 0.007088
iteration 14327 : loss : 0.025416, loss_ce: 0.011453
iteration 14328 : loss : 0.079406, loss_ce: 0.007051
iteration 14329 : loss : 0.021169, loss_ce: 0.005095
iteration 14330 : loss : 0.025885, loss_ce: 0.004164
iteration 14331 : loss : 0.022048, loss_ce: 0.007892
iteration 14332 : loss : 0.023561, loss_ce: 0.010266
iteration 14333 : loss : 0.020497, loss_ce: 0.007751
iteration 14334 : loss : 0.018447, loss_ce: 0.008386
iteration 14335 : loss : 0.023738, loss_ce: 0.005706
iteration 14336 : loss : 0.022734, loss_ce: 0.008615
iteration 14337 : loss : 0.020882, loss_ce: 0.007404
iteration 14338 : loss : 0.020996, loss_ce: 0.007969
iteration 14339 : loss : 0.023391, loss_ce: 0.007099
iteration 14340 : loss : 0.027826, loss_ce: 0.012676
iteration 14341 : loss : 0.021995, loss_ce: 0.007764
iteration 14342 : loss : 0.021920, loss_ce: 0.007928
iteration 14343 : loss : 0.021437, loss_ce: 0.004777
iteration 14344 : loss : 0.073413, loss_ce: 0.004977
iteration 14345 : loss : 0.020103, loss_ce: 0.004573
iteration 14346 : loss : 0.075568, loss_ce: 0.007621
iteration 14347 : loss : 0.033396, loss_ce: 0.007961
iteration 14348 : loss : 0.024545, loss_ce: 0.007327
iteration 14349 : loss : 0.024069, loss_ce: 0.008230
iteration 14350 : loss : 0.022258, loss_ce: 0.008289
iteration 14351 : loss : 0.024509, loss_ce: 0.006772
iteration 14352 : loss : 0.020144, loss_ce: 0.005364
iteration 14353 : loss : 0.031635, loss_ce: 0.008127
iteration 14354 : loss : 0.024970, loss_ce: 0.006977
iteration 14355 : loss : 0.024857, loss_ce: 0.007735
iteration 14356 : loss : 0.022644, loss_ce: 0.009448
iteration 14357 : loss : 0.076027, loss_ce: 0.008277
iteration 14358 : loss : 0.027970, loss_ce: 0.009841
iteration 14359 : loss : 0.023104, loss_ce: 0.005456
iteration 14360 : loss : 0.022524, loss_ce: 0.004947
iteration 14361 : loss : 0.023494, loss_ce: 0.011361
iteration 14362 : loss : 0.024925, loss_ce: 0.004709
iteration 14363 : loss : 0.072763, loss_ce: 0.005394
iteration 14364 : loss : 0.016972, loss_ce: 0.004612
iteration 14365 : loss : 0.023849, loss_ce: 0.004342
iteration 14366 : loss : 0.070975, loss_ce: 0.005763
iteration 14367 : loss : 0.023495, loss_ce: 0.008779
iteration 14368 : loss : 0.022207, loss_ce: 0.007573
iteration 14369 : loss : 0.023807, loss_ce: 0.010363
iteration 14370 : loss : 0.017097, loss_ce: 0.006724
iteration 14371 : loss : 0.022533, loss_ce: 0.006228
iteration 14372 : loss : 0.020021, loss_ce: 0.008047
iteration 14373 : loss : 0.018456, loss_ce: 0.005357
iteration 14374 : loss : 0.023772, loss_ce: 0.004983
iteration 14375 : loss : 0.021390, loss_ce: 0.008832
iteration 14376 : loss : 0.022335, loss_ce: 0.008390
iteration 14377 : loss : 0.021721, loss_ce: 0.008997
iteration 14378 : loss : 0.021440, loss_ce: 0.007955
iteration 14379 : loss : 0.075410, loss_ce: 0.009295
iteration 14380 : loss : 0.074315, loss_ce: 0.008237
iteration 14381 : loss : 0.026440, loss_ce: 0.010924
iteration 14382 : loss : 0.024335, loss_ce: 0.011519
iteration 14383 : loss : 0.028893, loss_ce: 0.009990
iteration 14384 : loss : 0.024202, loss_ce: 0.010942
iteration 14385 : loss : 0.029892, loss_ce: 0.009616
iteration 14386 : loss : 0.027270, loss_ce: 0.005611
iteration 14387 : loss : 0.076310, loss_ce: 0.006338
iteration 14388 : loss : 0.022288, loss_ce: 0.012662
iteration 14389 : loss : 0.022294, loss_ce: 0.007883
iteration 14390 : loss : 0.027982, loss_ce: 0.010550
iteration 14391 : loss : 0.057249, loss_ce: 0.003629
iteration 14392 : loss : 0.020311, loss_ce: 0.008306
iteration 14393 : loss : 0.020213, loss_ce: 0.009003
iteration 14394 : loss : 0.021699, loss_ce: 0.006664
iteration 14395 : loss : 0.021838, loss_ce: 0.003696
iteration 14396 : loss : 0.022320, loss_ce: 0.007789
iteration 14397 : loss : 0.032515, loss_ce: 0.014018
iteration 14398 : loss : 0.082974, loss_ce: 0.007412
iteration 14399 : loss : 0.021397, loss_ce: 0.005251
iteration 14400 : loss : 0.024823, loss_ce: 0.010978
iteration 14401 : loss : 0.024440, loss_ce: 0.011780
iteration 14402 : loss : 0.024557, loss_ce: 0.009832
iteration 14403 : loss : 0.080047, loss_ce: 0.005422
iteration 14404 : loss : 0.026697, loss_ce: 0.011395
iteration 14405 : loss : 0.022460, loss_ce: 0.007923
iteration 14406 : loss : 0.023244, loss_ce: 0.009933
iteration 14407 : loss : 0.026551, loss_ce: 0.007901
iteration 14408 : loss : 0.023870, loss_ce: 0.010339
iteration 14409 : loss : 0.025881, loss_ce: 0.009678
iteration 14410 : loss : 0.019903, loss_ce: 0.004126
iteration 14411 : loss : 0.028682, loss_ce: 0.012076
iteration 14412 : loss : 0.022000, loss_ce: 0.007100
iteration 14413 : loss : 0.023309, loss_ce: 0.009539
iteration 14414 : loss : 0.017993, loss_ce: 0.003759
iteration 14415 : loss : 0.338046, loss_ce: 0.003090
 78%|██████████████████████▍      | 155/200 [2:35:58<40:52, 54.51s/it]iteration 14416 : loss : 0.019686, loss_ce: 0.006364
iteration 14417 : loss : 0.027992, loss_ce: 0.005536
iteration 14418 : loss : 0.023619, loss_ce: 0.004969
iteration 14419 : loss : 0.019713, loss_ce: 0.007677
iteration 14420 : loss : 0.024705, loss_ce: 0.008539
iteration 14421 : loss : 0.021373, loss_ce: 0.007004
iteration 14422 : loss : 0.026130, loss_ce: 0.007646
iteration 14423 : loss : 0.026336, loss_ce: 0.006312
iteration 14424 : loss : 0.023314, loss_ce: 0.008425
iteration 14425 : loss : 0.021138, loss_ce: 0.007821
iteration 14426 : loss : 0.027437, loss_ce: 0.008306
iteration 14427 : loss : 0.026140, loss_ce: 0.014361
iteration 14428 : loss : 0.021515, loss_ce: 0.008174
iteration 14429 : loss : 0.023234, loss_ce: 0.007099
iteration 14430 : loss : 0.023646, loss_ce: 0.008427
iteration 14431 : loss : 0.026208, loss_ce: 0.012452
iteration 14432 : loss : 0.027358, loss_ce: 0.005816
iteration 14433 : loss : 0.018762, loss_ce: 0.007060
iteration 14434 : loss : 0.018947, loss_ce: 0.004576
iteration 14435 : loss : 0.023511, loss_ce: 0.007205
iteration 14436 : loss : 0.022383, loss_ce: 0.008787
iteration 14437 : loss : 0.021902, loss_ce: 0.008589
iteration 14438 : loss : 0.022369, loss_ce: 0.004513
iteration 14439 : loss : 0.021938, loss_ce: 0.007013
iteration 14440 : loss : 0.023373, loss_ce: 0.005043
iteration 14441 : loss : 0.023051, loss_ce: 0.009542
iteration 14442 : loss : 0.025497, loss_ce: 0.005541
iteration 14443 : loss : 0.027653, loss_ce: 0.007751
iteration 14444 : loss : 0.023970, loss_ce: 0.013642
iteration 14445 : loss : 0.022711, loss_ce: 0.006785
iteration 14446 : loss : 0.022316, loss_ce: 0.007596
iteration 14447 : loss : 0.021630, loss_ce: 0.004420
iteration 14448 : loss : 0.025262, loss_ce: 0.008945
iteration 14449 : loss : 0.027961, loss_ce: 0.009754
iteration 14450 : loss : 0.025430, loss_ce: 0.005535
iteration 14451 : loss : 0.076196, loss_ce: 0.010397
iteration 14452 : loss : 0.026300, loss_ce: 0.011667
iteration 14453 : loss : 0.073150, loss_ce: 0.005944
iteration 14454 : loss : 0.021470, loss_ce: 0.005791
iteration 14455 : loss : 0.021030, loss_ce: 0.007338
iteration 14456 : loss : 0.025299, loss_ce: 0.010324
iteration 14457 : loss : 0.020200, loss_ce: 0.004316
iteration 14458 : loss : 0.021249, loss_ce: 0.010657
iteration 14459 : loss : 0.023330, loss_ce: 0.009498
iteration 14460 : loss : 0.022147, loss_ce: 0.007237
iteration 14461 : loss : 0.025757, loss_ce: 0.010436
iteration 14462 : loss : 0.024320, loss_ce: 0.007388
iteration 14463 : loss : 0.019988, loss_ce: 0.006747
iteration 14464 : loss : 0.026432, loss_ce: 0.007489
iteration 14465 : loss : 0.023416, loss_ce: 0.007424
iteration 14466 : loss : 0.023061, loss_ce: 0.010841
iteration 14467 : loss : 0.019135, loss_ce: 0.008066
iteration 14468 : loss : 0.019717, loss_ce: 0.005481
iteration 14469 : loss : 0.019691, loss_ce: 0.006796
iteration 14470 : loss : 0.025455, loss_ce: 0.008464
iteration 14471 : loss : 0.025904, loss_ce: 0.010288
iteration 14472 : loss : 0.020410, loss_ce: 0.005157
iteration 14473 : loss : 0.070864, loss_ce: 0.007912
iteration 14474 : loss : 0.027066, loss_ce: 0.014191
iteration 14475 : loss : 0.025084, loss_ce: 0.009963
iteration 14476 : loss : 0.030372, loss_ce: 0.006076
iteration 14477 : loss : 0.024185, loss_ce: 0.004245
iteration 14478 : loss : 0.019972, loss_ce: 0.008874
iteration 14479 : loss : 0.022261, loss_ce: 0.010423
iteration 14480 : loss : 0.019491, loss_ce: 0.004768
iteration 14481 : loss : 0.029077, loss_ce: 0.010035
iteration 14482 : loss : 0.021539, loss_ce: 0.007715
iteration 14483 : loss : 0.022658, loss_ce: 0.006431
iteration 14484 : loss : 0.026077, loss_ce: 0.007397
iteration 14485 : loss : 0.020610, loss_ce: 0.005854
iteration 14486 : loss : 0.022079, loss_ce: 0.006025
iteration 14487 : loss : 0.079343, loss_ce: 0.008115
iteration 14488 : loss : 0.024068, loss_ce: 0.008829
iteration 14489 : loss : 0.019252, loss_ce: 0.007240
iteration 14490 : loss : 0.021548, loss_ce: 0.010661
iteration 14491 : loss : 0.021991, loss_ce: 0.010584
iteration 14492 : loss : 0.022269, loss_ce: 0.008300
iteration 14493 : loss : 0.022939, loss_ce: 0.006224
iteration 14494 : loss : 0.024044, loss_ce: 0.005789
iteration 14495 : loss : 0.024946, loss_ce: 0.009224
iteration 14496 : loss : 0.019279, loss_ce: 0.006351
iteration 14497 : loss : 0.023549, loss_ce: 0.006738
iteration 14498 : loss : 0.021459, loss_ce: 0.006878
iteration 14499 : loss : 0.023442, loss_ce: 0.009968
iteration 14500 : loss : 0.021950, loss_ce: 0.006628
iteration 14501 : loss : 0.020594, loss_ce: 0.008889
iteration 14502 : loss : 0.023926, loss_ce: 0.009380
iteration 14503 : loss : 0.020618, loss_ce: 0.006524
iteration 14504 : loss : 0.022518, loss_ce: 0.006781
iteration 14505 : loss : 0.073512, loss_ce: 0.005903
iteration 14506 : loss : 0.034102, loss_ce: 0.006724
iteration 14507 : loss : 0.019170, loss_ce: 0.006861
iteration 14508 : loss : 0.389156, loss_ce: 0.000769
 78%|██████████████████████▌      | 156/200 [2:36:52<39:58, 54.52s/it]iteration 14509 : loss : 0.045064, loss_ce: 0.007304
iteration 14510 : loss : 0.022902, loss_ce: 0.010876
iteration 14511 : loss : 0.027105, loss_ce: 0.007354
iteration 14512 : loss : 0.079426, loss_ce: 0.007129
iteration 14513 : loss : 0.026305, loss_ce: 0.006373
iteration 14514 : loss : 0.074450, loss_ce: 0.005269
iteration 14515 : loss : 0.024928, loss_ce: 0.007655
iteration 14516 : loss : 0.019056, loss_ce: 0.005542
iteration 14517 : loss : 0.022696, loss_ce: 0.009550
iteration 14518 : loss : 0.021551, loss_ce: 0.009462
iteration 14519 : loss : 0.023999, loss_ce: 0.011416
iteration 14520 : loss : 0.021378, loss_ce: 0.006947
iteration 14521 : loss : 0.027947, loss_ce: 0.007463
iteration 14522 : loss : 0.020741, loss_ce: 0.006669
iteration 14523 : loss : 0.024214, loss_ce: 0.008007
iteration 14524 : loss : 0.017623, loss_ce: 0.007195
iteration 14525 : loss : 0.025007, loss_ce: 0.006192
iteration 14526 : loss : 0.035984, loss_ce: 0.007677
iteration 14527 : loss : 0.018357, loss_ce: 0.007834
iteration 14528 : loss : 0.022864, loss_ce: 0.006127
iteration 14529 : loss : 0.022172, loss_ce: 0.007886
iteration 14530 : loss : 0.019329, loss_ce: 0.005883
iteration 14531 : loss : 0.025479, loss_ce: 0.007060
iteration 14532 : loss : 0.022283, loss_ce: 0.010884
iteration 14533 : loss : 0.022409, loss_ce: 0.006665
iteration 14534 : loss : 0.018802, loss_ce: 0.003276
iteration 14535 : loss : 0.025903, loss_ce: 0.014264
iteration 14536 : loss : 0.019744, loss_ce: 0.006976
iteration 14537 : loss : 0.022263, loss_ce: 0.009773
iteration 14538 : loss : 0.020362, loss_ce: 0.007251
iteration 14539 : loss : 0.022334, loss_ce: 0.005664
iteration 14540 : loss : 0.020687, loss_ce: 0.009036
iteration 14541 : loss : 0.032100, loss_ce: 0.011995
iteration 14542 : loss : 0.016575, loss_ce: 0.003660
iteration 14543 : loss : 0.028384, loss_ce: 0.012977
iteration 14544 : loss : 0.033948, loss_ce: 0.006092
iteration 14545 : loss : 0.021653, loss_ce: 0.005590
iteration 14546 : loss : 0.026877, loss_ce: 0.013778
iteration 14547 : loss : 0.024521, loss_ce: 0.007514
iteration 14548 : loss : 0.024067, loss_ce: 0.007567
iteration 14549 : loss : 0.075872, loss_ce: 0.007621
iteration 14550 : loss : 0.020254, loss_ce: 0.007539
iteration 14551 : loss : 0.021394, loss_ce: 0.004485
iteration 14552 : loss : 0.023224, loss_ce: 0.004731
iteration 14553 : loss : 0.021790, loss_ce: 0.005008
iteration 14554 : loss : 0.025016, loss_ce: 0.005751
iteration 14555 : loss : 0.023655, loss_ce: 0.009453
iteration 14556 : loss : 0.020077, loss_ce: 0.006010
iteration 14557 : loss : 0.022871, loss_ce: 0.010513
iteration 14558 : loss : 0.024651, loss_ce: 0.009165
iteration 14559 : loss : 0.021880, loss_ce: 0.009890
iteration 14560 : loss : 0.029391, loss_ce: 0.003803
iteration 14561 : loss : 0.019330, loss_ce: 0.004916
iteration 14562 : loss : 0.019634, loss_ce: 0.009291
iteration 14563 : loss : 0.025492, loss_ce: 0.004712
iteration 14564 : loss : 0.075666, loss_ce: 0.006817
iteration 14565 : loss : 0.024509, loss_ce: 0.006838
iteration 14566 : loss : 0.019572, loss_ce: 0.008803
iteration 14567 : loss : 0.018479, loss_ce: 0.007208
iteration 14568 : loss : 0.027941, loss_ce: 0.005655
iteration 14569 : loss : 0.025151, loss_ce: 0.010268
iteration 14570 : loss : 0.022608, loss_ce: 0.008837
iteration 14571 : loss : 0.018398, loss_ce: 0.006774
iteration 14572 : loss : 0.022447, loss_ce: 0.010101
iteration 14573 : loss : 0.023967, loss_ce: 0.004558
iteration 14574 : loss : 0.025484, loss_ce: 0.007228
iteration 14575 : loss : 0.027640, loss_ce: 0.009292
iteration 14576 : loss : 0.025184, loss_ce: 0.009129
iteration 14577 : loss : 0.022080, loss_ce: 0.009146
iteration 14578 : loss : 0.023827, loss_ce: 0.009600
iteration 14579 : loss : 0.024939, loss_ce: 0.008595
iteration 14580 : loss : 0.019531, loss_ce: 0.007496
iteration 14581 : loss : 0.023697, loss_ce: 0.007398
iteration 14582 : loss : 0.025324, loss_ce: 0.014456
iteration 14583 : loss : 0.022372, loss_ce: 0.011074
iteration 14584 : loss : 0.020394, loss_ce: 0.006463
iteration 14585 : loss : 0.019304, loss_ce: 0.006696
iteration 14586 : loss : 0.019904, loss_ce: 0.007115
iteration 14587 : loss : 0.025529, loss_ce: 0.009962
iteration 14588 : loss : 0.025976, loss_ce: 0.010624
iteration 14589 : loss : 0.025871, loss_ce: 0.010013
iteration 14590 : loss : 0.020473, loss_ce: 0.005511
iteration 14591 : loss : 0.072425, loss_ce: 0.005609
iteration 14592 : loss : 0.027185, loss_ce: 0.006891
iteration 14593 : loss : 0.020839, loss_ce: 0.008043
iteration 14594 : loss : 0.020811, loss_ce: 0.003952
iteration 14595 : loss : 0.025455, loss_ce: 0.011824
iteration 14596 : loss : 0.077667, loss_ce: 0.012645
iteration 14597 : loss : 0.019242, loss_ce: 0.006789
iteration 14598 : loss : 0.022165, loss_ce: 0.008143
iteration 14599 : loss : 0.017230, loss_ce: 0.003754
iteration 14600 : loss : 0.018272, loss_ce: 0.003979
iteration 14601 : loss : 0.180798, loss_ce: 0.003562
 78%|██████████████████████▊      | 157/200 [2:37:47<39:03, 54.51s/it]iteration 14602 : loss : 0.074251, loss_ce: 0.007605
iteration 14603 : loss : 0.022204, loss_ce: 0.008205
iteration 14604 : loss : 0.026004, loss_ce: 0.007066
iteration 14605 : loss : 0.021539, loss_ce: 0.010777
iteration 14606 : loss : 0.026225, loss_ce: 0.003221
iteration 14607 : loss : 0.020618, loss_ce: 0.007078
iteration 14608 : loss : 0.029855, loss_ce: 0.007569
iteration 14609 : loss : 0.023467, loss_ce: 0.008974
iteration 14610 : loss : 0.025520, loss_ce: 0.010725
iteration 14611 : loss : 0.070104, loss_ce: 0.003820
iteration 14612 : loss : 0.020525, loss_ce: 0.006496
iteration 14613 : loss : 0.025608, loss_ce: 0.008696
iteration 14614 : loss : 0.026810, loss_ce: 0.005249
iteration 14615 : loss : 0.020193, loss_ce: 0.006182
iteration 14616 : loss : 0.021593, loss_ce: 0.008080
iteration 14617 : loss : 0.025950, loss_ce: 0.006286
iteration 14618 : loss : 0.021338, loss_ce: 0.006436
iteration 14619 : loss : 0.019096, loss_ce: 0.006430
iteration 14620 : loss : 0.024030, loss_ce: 0.005797
iteration 14621 : loss : 0.019486, loss_ce: 0.006205
iteration 14622 : loss : 0.018346, loss_ce: 0.007714
iteration 14623 : loss : 0.023752, loss_ce: 0.008885
iteration 14624 : loss : 0.021269, loss_ce: 0.009107
iteration 14625 : loss : 0.023301, loss_ce: 0.005867
iteration 14626 : loss : 0.022252, loss_ce: 0.011339
iteration 14627 : loss : 0.020608, loss_ce: 0.006403
iteration 14628 : loss : 0.022293, loss_ce: 0.007532
iteration 14629 : loss : 0.021940, loss_ce: 0.009849
iteration 14630 : loss : 0.025080, loss_ce: 0.004149
iteration 14631 : loss : 0.019423, loss_ce: 0.006808
iteration 14632 : loss : 0.016878, loss_ce: 0.006006
iteration 14633 : loss : 0.024855, loss_ce: 0.007866
iteration 14634 : loss : 0.021656, loss_ce: 0.007507
iteration 14635 : loss : 0.017139, loss_ce: 0.005362
iteration 14636 : loss : 0.021844, loss_ce: 0.007757
iteration 14637 : loss : 0.020972, loss_ce: 0.007102
iteration 14638 : loss : 0.022724, loss_ce: 0.009435
iteration 14639 : loss : 0.019648, loss_ce: 0.007386
iteration 14640 : loss : 0.028590, loss_ce: 0.008288
iteration 14641 : loss : 0.022956, loss_ce: 0.007575
iteration 14642 : loss : 0.020601, loss_ce: 0.006047
iteration 14643 : loss : 0.018796, loss_ce: 0.006407
iteration 14644 : loss : 0.022867, loss_ce: 0.012115
iteration 14645 : loss : 0.024605, loss_ce: 0.009721
iteration 14646 : loss : 0.022782, loss_ce: 0.007715
iteration 14647 : loss : 0.023230, loss_ce: 0.008777
iteration 14648 : loss : 0.022216, loss_ce: 0.006346
iteration 14649 : loss : 0.022293, loss_ce: 0.010860
iteration 14650 : loss : 0.021764, loss_ce: 0.007197
iteration 14651 : loss : 0.024480, loss_ce: 0.008901
iteration 14652 : loss : 0.024486, loss_ce: 0.006953
iteration 14653 : loss : 0.036600, loss_ce: 0.008443
iteration 14654 : loss : 0.022570, loss_ce: 0.008692
iteration 14655 : loss : 0.024826, loss_ce: 0.007256
iteration 14656 : loss : 0.023644, loss_ce: 0.007157
iteration 14657 : loss : 0.019549, loss_ce: 0.007039
iteration 14658 : loss : 0.021075, loss_ce: 0.007731
iteration 14659 : loss : 0.045817, loss_ce: 0.006551
iteration 14660 : loss : 0.023607, loss_ce: 0.008116
iteration 14661 : loss : 0.021570, loss_ce: 0.007553
iteration 14662 : loss : 0.026095, loss_ce: 0.010722
iteration 14663 : loss : 0.027428, loss_ce: 0.009082
iteration 14664 : loss : 0.071954, loss_ce: 0.005626
iteration 14665 : loss : 0.023429, loss_ce: 0.010077
iteration 14666 : loss : 0.026944, loss_ce: 0.007179
iteration 14667 : loss : 0.022084, loss_ce: 0.006670
iteration 14668 : loss : 0.026957, loss_ce: 0.012627
iteration 14669 : loss : 0.075253, loss_ce: 0.006411
iteration 14670 : loss : 0.025495, loss_ce: 0.010504
iteration 14671 : loss : 0.024024, loss_ce: 0.010815
iteration 14672 : loss : 0.016786, loss_ce: 0.005390
iteration 14673 : loss : 0.024044, loss_ce: 0.008931
iteration 14674 : loss : 0.021486, loss_ce: 0.009433
iteration 14675 : loss : 0.021825, loss_ce: 0.007800
iteration 14676 : loss : 0.023811, loss_ce: 0.011639
iteration 14677 : loss : 0.026033, loss_ce: 0.008603
iteration 14678 : loss : 0.020888, loss_ce: 0.006772
iteration 14679 : loss : 0.024246, loss_ce: 0.008066
iteration 14680 : loss : 0.027110, loss_ce: 0.006363
iteration 14681 : loss : 0.026420, loss_ce: 0.011997
iteration 14682 : loss : 0.024582, loss_ce: 0.007223
iteration 14683 : loss : 0.025677, loss_ce: 0.009839
iteration 14684 : loss : 0.019736, loss_ce: 0.005090
iteration 14685 : loss : 0.025050, loss_ce: 0.011210
iteration 14686 : loss : 0.021893, loss_ce: 0.008341
iteration 14687 : loss : 0.076598, loss_ce: 0.003722
iteration 14688 : loss : 0.030883, loss_ce: 0.007980
iteration 14689 : loss : 0.026349, loss_ce: 0.005575
iteration 14690 : loss : 0.019370, loss_ce: 0.004143
iteration 14691 : loss : 0.073918, loss_ce: 0.005247
iteration 14692 : loss : 0.020704, loss_ce: 0.006398
iteration 14693 : loss : 0.021238, loss_ce: 0.007595
iteration 14694 : loss : 0.033820, loss_ce: 0.017693
 79%|██████████████████████▉      | 158/200 [2:38:41<38:08, 54.49s/it]iteration 14695 : loss : 0.020431, loss_ce: 0.007817
iteration 14696 : loss : 0.021351, loss_ce: 0.008167
iteration 14697 : loss : 0.021991, loss_ce: 0.008660
iteration 14698 : loss : 0.023809, loss_ce: 0.007808
iteration 14699 : loss : 0.026405, loss_ce: 0.010559
iteration 14700 : loss : 0.025003, loss_ce: 0.011353
iteration 14701 : loss : 0.020664, loss_ce: 0.006566
iteration 14702 : loss : 0.018981, loss_ce: 0.007474
iteration 14703 : loss : 0.025937, loss_ce: 0.008429
iteration 14704 : loss : 0.025448, loss_ce: 0.012749
iteration 14705 : loss : 0.023185, loss_ce: 0.005759
iteration 14706 : loss : 0.023330, loss_ce: 0.010096
iteration 14707 : loss : 0.026638, loss_ce: 0.008521
iteration 14708 : loss : 0.075527, loss_ce: 0.006671
iteration 14709 : loss : 0.021412, loss_ce: 0.006541
iteration 14710 : loss : 0.024181, loss_ce: 0.010625
iteration 14711 : loss : 0.023574, loss_ce: 0.003750
iteration 14712 : loss : 0.022466, loss_ce: 0.005295
iteration 14713 : loss : 0.022828, loss_ce: 0.009713
iteration 14714 : loss : 0.022310, loss_ce: 0.007882
iteration 14715 : loss : 0.025516, loss_ce: 0.008794
iteration 14716 : loss : 0.029738, loss_ce: 0.005759
iteration 14717 : loss : 0.022259, loss_ce: 0.011568
iteration 14718 : loss : 0.024756, loss_ce: 0.010145
iteration 14719 : loss : 0.074788, loss_ce: 0.009167
iteration 14720 : loss : 0.075049, loss_ce: 0.006328
iteration 14721 : loss : 0.020984, loss_ce: 0.005225
iteration 14722 : loss : 0.023297, loss_ce: 0.007591
iteration 14723 : loss : 0.026050, loss_ce: 0.005507
iteration 14724 : loss : 0.020682, loss_ce: 0.008382
iteration 14725 : loss : 0.025119, loss_ce: 0.007336
iteration 14726 : loss : 0.020616, loss_ce: 0.005594
iteration 14727 : loss : 0.030425, loss_ce: 0.009743
iteration 14728 : loss : 0.022949, loss_ce: 0.010038
iteration 14729 : loss : 0.020633, loss_ce: 0.007370
iteration 14730 : loss : 0.019553, loss_ce: 0.007419
iteration 14731 : loss : 0.023061, loss_ce: 0.008822
iteration 14732 : loss : 0.020520, loss_ce: 0.009230
iteration 14733 : loss : 0.020778, loss_ce: 0.003946
iteration 14734 : loss : 0.023773, loss_ce: 0.009619
iteration 14735 : loss : 0.020719, loss_ce: 0.006543
iteration 14736 : loss : 0.021721, loss_ce: 0.010383
iteration 14737 : loss : 0.019495, loss_ce: 0.007185
iteration 14738 : loss : 0.033034, loss_ce: 0.004959
iteration 14739 : loss : 0.022792, loss_ce: 0.007437
iteration 14740 : loss : 0.028554, loss_ce: 0.006919
iteration 14741 : loss : 0.032642, loss_ce: 0.007711
iteration 14742 : loss : 0.020717, loss_ce: 0.007649
iteration 14743 : loss : 0.023080, loss_ce: 0.010324
iteration 14744 : loss : 0.021898, loss_ce: 0.008935
iteration 14745 : loss : 0.022932, loss_ce: 0.004511
iteration 14746 : loss : 0.019264, loss_ce: 0.005712
iteration 14747 : loss : 0.019435, loss_ce: 0.005599
iteration 14748 : loss : 0.024957, loss_ce: 0.008469
iteration 14749 : loss : 0.022539, loss_ce: 0.009741
iteration 14750 : loss : 0.026006, loss_ce: 0.006166
iteration 14751 : loss : 0.055149, loss_ce: 0.004548
iteration 14752 : loss : 0.019305, loss_ce: 0.006545
iteration 14753 : loss : 0.028467, loss_ce: 0.004694
iteration 14754 : loss : 0.072970, loss_ce: 0.006434
iteration 14755 : loss : 0.026888, loss_ce: 0.009668
iteration 14756 : loss : 0.026717, loss_ce: 0.009058
iteration 14757 : loss : 0.023266, loss_ce: 0.008363
iteration 14758 : loss : 0.027184, loss_ce: 0.007680
iteration 14759 : loss : 0.022624, loss_ce: 0.007903
iteration 14760 : loss : 0.029863, loss_ce: 0.010391
iteration 14761 : loss : 0.022000, loss_ce: 0.011338
iteration 14762 : loss : 0.022827, loss_ce: 0.008384
iteration 14763 : loss : 0.024870, loss_ce: 0.006182
iteration 14764 : loss : 0.024226, loss_ce: 0.007252
iteration 14765 : loss : 0.018935, loss_ce: 0.004027
iteration 14766 : loss : 0.025366, loss_ce: 0.009305
iteration 14767 : loss : 0.020112, loss_ce: 0.004913
iteration 14768 : loss : 0.025797, loss_ce: 0.007412
iteration 14769 : loss : 0.020737, loss_ce: 0.009406
iteration 14770 : loss : 0.023418, loss_ce: 0.005248
iteration 14771 : loss : 0.021535, loss_ce: 0.007651
iteration 14772 : loss : 0.022927, loss_ce: 0.008110
iteration 14773 : loss : 0.028521, loss_ce: 0.010028
iteration 14774 : loss : 0.025474, loss_ce: 0.012105
iteration 14775 : loss : 0.021135, loss_ce: 0.008005
iteration 14776 : loss : 0.021895, loss_ce: 0.009364
iteration 14777 : loss : 0.021935, loss_ce: 0.007619
iteration 14778 : loss : 0.022729, loss_ce: 0.008492
iteration 14779 : loss : 0.026520, loss_ce: 0.010813
iteration 14780 : loss : 0.024613, loss_ce: 0.006166
iteration 14781 : loss : 0.025180, loss_ce: 0.004171
iteration 14782 : loss : 0.020985, loss_ce: 0.010593
iteration 14783 : loss : 0.073538, loss_ce: 0.002328
iteration 14784 : loss : 0.044349, loss_ce: 0.005539
iteration 14785 : loss : 0.023653, loss_ce: 0.008810
iteration 14786 : loss : 0.021378, loss_ce: 0.005237
iteration 14787 : loss : 0.335846, loss_ce: 0.001588
 80%|███████████████████████      | 159/200 [2:39:36<37:14, 54.50s/it]iteration 14788 : loss : 0.024724, loss_ce: 0.009012
iteration 14789 : loss : 0.022621, loss_ce: 0.005557
iteration 14790 : loss : 0.024499, loss_ce: 0.007541
iteration 14791 : loss : 0.036248, loss_ce: 0.005563
iteration 14792 : loss : 0.020503, loss_ce: 0.007020
iteration 14793 : loss : 0.024402, loss_ce: 0.008174
iteration 14794 : loss : 0.022061, loss_ce: 0.009236
iteration 14795 : loss : 0.018554, loss_ce: 0.006089
iteration 14796 : loss : 0.022400, loss_ce: 0.006633
iteration 14797 : loss : 0.024593, loss_ce: 0.008513
iteration 14798 : loss : 0.080507, loss_ce: 0.006960
iteration 14799 : loss : 0.025263, loss_ce: 0.006473
iteration 14800 : loss : 0.076120, loss_ce: 0.005507
iteration 14801 : loss : 0.020795, loss_ce: 0.006535
iteration 14802 : loss : 0.021470, loss_ce: 0.007491
iteration 14803 : loss : 0.026254, loss_ce: 0.003996
iteration 14804 : loss : 0.024830, loss_ce: 0.008222
iteration 14805 : loss : 0.022634, loss_ce: 0.011037
iteration 14806 : loss : 0.030743, loss_ce: 0.006705
iteration 14807 : loss : 0.024362, loss_ce: 0.008093
iteration 14808 : loss : 0.023377, loss_ce: 0.008680
iteration 14809 : loss : 0.021262, loss_ce: 0.007952
iteration 14810 : loss : 0.022889, loss_ce: 0.006102
iteration 14811 : loss : 0.023142, loss_ce: 0.004960
iteration 14812 : loss : 0.024671, loss_ce: 0.009508
iteration 14813 : loss : 0.020233, loss_ce: 0.008656
iteration 14814 : loss : 0.024143, loss_ce: 0.006527
iteration 14815 : loss : 0.026633, loss_ce: 0.010313
iteration 14816 : loss : 0.027142, loss_ce: 0.010759
iteration 14817 : loss : 0.074398, loss_ce: 0.006404
iteration 14818 : loss : 0.033736, loss_ce: 0.006281
iteration 14819 : loss : 0.020789, loss_ce: 0.006627
iteration 14820 : loss : 0.025510, loss_ce: 0.008387
iteration 14821 : loss : 0.019642, loss_ce: 0.007124
iteration 14822 : loss : 0.019732, loss_ce: 0.007061
iteration 14823 : loss : 0.023509, loss_ce: 0.008264
iteration 14824 : loss : 0.024331, loss_ce: 0.006387
iteration 14825 : loss : 0.022945, loss_ce: 0.007543
iteration 14826 : loss : 0.021146, loss_ce: 0.004753
iteration 14827 : loss : 0.020189, loss_ce: 0.008423
iteration 14828 : loss : 0.023171, loss_ce: 0.008565
iteration 14829 : loss : 0.023501, loss_ce: 0.010952
iteration 14830 : loss : 0.024010, loss_ce: 0.006549
iteration 14831 : loss : 0.020925, loss_ce: 0.008203
iteration 14832 : loss : 0.021079, loss_ce: 0.006056
iteration 14833 : loss : 0.025329, loss_ce: 0.009102
iteration 14834 : loss : 0.024338, loss_ce: 0.006039
iteration 14835 : loss : 0.017636, loss_ce: 0.004893
iteration 14836 : loss : 0.025220, loss_ce: 0.014067
iteration 14837 : loss : 0.074048, loss_ce: 0.007142
iteration 14838 : loss : 0.030998, loss_ce: 0.006424
iteration 14839 : loss : 0.023738, loss_ce: 0.010903
iteration 14840 : loss : 0.026325, loss_ce: 0.009304
iteration 14841 : loss : 0.024458, loss_ce: 0.007467
iteration 14842 : loss : 0.073887, loss_ce: 0.008550
iteration 14843 : loss : 0.024778, loss_ce: 0.012616
iteration 14844 : loss : 0.027421, loss_ce: 0.005704
iteration 14845 : loss : 0.071628, loss_ce: 0.007501
iteration 14846 : loss : 0.019988, loss_ce: 0.006084
iteration 14847 : loss : 0.021812, loss_ce: 0.012005
iteration 14848 : loss : 0.022946, loss_ce: 0.005553
iteration 14849 : loss : 0.022410, loss_ce: 0.008414
iteration 14850 : loss : 0.032937, loss_ce: 0.004672
iteration 14851 : loss : 0.025491, loss_ce: 0.009752
iteration 14852 : loss : 0.022917, loss_ce: 0.008284
iteration 14853 : loss : 0.023895, loss_ce: 0.007962
iteration 14854 : loss : 0.024622, loss_ce: 0.007818
iteration 14855 : loss : 0.027150, loss_ce: 0.011160
iteration 14856 : loss : 0.021638, loss_ce: 0.006327
iteration 14857 : loss : 0.024464, loss_ce: 0.004692
iteration 14858 : loss : 0.021782, loss_ce: 0.007533
iteration 14859 : loss : 0.073910, loss_ce: 0.006359
iteration 14860 : loss : 0.025660, loss_ce: 0.011410
iteration 14861 : loss : 0.023967, loss_ce: 0.012272
iteration 14862 : loss : 0.025670, loss_ce: 0.007045
iteration 14863 : loss : 0.028686, loss_ce: 0.005812
iteration 14864 : loss : 0.075024, loss_ce: 0.005383
iteration 14865 : loss : 0.024075, loss_ce: 0.009911
iteration 14866 : loss : 0.020388, loss_ce: 0.004786
iteration 14867 : loss : 0.025880, loss_ce: 0.011046
iteration 14868 : loss : 0.027891, loss_ce: 0.008956
iteration 14869 : loss : 0.020036, loss_ce: 0.006767
iteration 14870 : loss : 0.024165, loss_ce: 0.009053
iteration 14871 : loss : 0.023068, loss_ce: 0.008503
iteration 14872 : loss : 0.019608, loss_ce: 0.008638
iteration 14873 : loss : 0.021593, loss_ce: 0.009542
iteration 14874 : loss : 0.029240, loss_ce: 0.008427
iteration 14875 : loss : 0.022986, loss_ce: 0.008136
iteration 14876 : loss : 0.021131, loss_ce: 0.009720
iteration 14877 : loss : 0.021795, loss_ce: 0.004844
iteration 14878 : loss : 0.022619, loss_ce: 0.005007
iteration 14879 : loss : 0.024839, loss_ce: 0.008300
iteration 14880 : loss : 0.031863, loss_ce: 0.025749
 80%|███████████████████████▏     | 160/200 [2:40:30<36:21, 54.55s/it]iteration 14881 : loss : 0.021333, loss_ce: 0.008411
iteration 14882 : loss : 0.035316, loss_ce: 0.011923
iteration 14883 : loss : 0.022701, loss_ce: 0.009434
iteration 14884 : loss : 0.029491, loss_ce: 0.005151
iteration 14885 : loss : 0.076279, loss_ce: 0.008778
iteration 14886 : loss : 0.023635, loss_ce: 0.011968
iteration 14887 : loss : 0.020525, loss_ce: 0.005064
iteration 14888 : loss : 0.027587, loss_ce: 0.011963
iteration 14889 : loss : 0.072914, loss_ce: 0.006684
iteration 14890 : loss : 0.017556, loss_ce: 0.004638
iteration 14891 : loss : 0.026066, loss_ce: 0.009129
iteration 14892 : loss : 0.024894, loss_ce: 0.006666
iteration 14893 : loss : 0.020727, loss_ce: 0.007167
iteration 14894 : loss : 0.022447, loss_ce: 0.006708
iteration 14895 : loss : 0.021841, loss_ce: 0.007974
iteration 14896 : loss : 0.017948, loss_ce: 0.005731
iteration 14897 : loss : 0.023865, loss_ce: 0.011613
iteration 14898 : loss : 0.022433, loss_ce: 0.009109
iteration 14899 : loss : 0.023621, loss_ce: 0.006400
iteration 14900 : loss : 0.022843, loss_ce: 0.005703
iteration 14901 : loss : 0.072318, loss_ce: 0.003975
iteration 14902 : loss : 0.020495, loss_ce: 0.006985
iteration 14903 : loss : 0.020362, loss_ce: 0.006739
iteration 14904 : loss : 0.023613, loss_ce: 0.005659
iteration 14905 : loss : 0.023332, loss_ce: 0.010266
iteration 14906 : loss : 0.020623, loss_ce: 0.006188
iteration 14907 : loss : 0.020401, loss_ce: 0.005417
iteration 14908 : loss : 0.029109, loss_ce: 0.007639
iteration 14909 : loss : 0.025859, loss_ce: 0.009201
iteration 14910 : loss : 0.020972, loss_ce: 0.008770
iteration 14911 : loss : 0.018814, loss_ce: 0.006787
iteration 14912 : loss : 0.025312, loss_ce: 0.010964
iteration 14913 : loss : 0.018967, loss_ce: 0.005224
iteration 14914 : loss : 0.023050, loss_ce: 0.007638
iteration 14915 : loss : 0.123283, loss_ce: 0.005315
iteration 14916 : loss : 0.022632, loss_ce: 0.006571
iteration 14917 : loss : 0.022337, loss_ce: 0.007467
iteration 14918 : loss : 0.023266, loss_ce: 0.005744
iteration 14919 : loss : 0.078847, loss_ce: 0.010106
iteration 14920 : loss : 0.023974, loss_ce: 0.008397
iteration 14921 : loss : 0.027688, loss_ce: 0.014351
iteration 14922 : loss : 0.022187, loss_ce: 0.008149
iteration 14923 : loss : 0.019609, loss_ce: 0.006447
iteration 14924 : loss : 0.027820, loss_ce: 0.008274
iteration 14925 : loss : 0.020496, loss_ce: 0.004996
iteration 14926 : loss : 0.022272, loss_ce: 0.006432
iteration 14927 : loss : 0.024901, loss_ce: 0.009150
iteration 14928 : loss : 0.022775, loss_ce: 0.004480
iteration 14929 : loss : 0.023335, loss_ce: 0.007537
iteration 14930 : loss : 0.027182, loss_ce: 0.009595
iteration 14931 : loss : 0.030428, loss_ce: 0.010645
iteration 14932 : loss : 0.019650, loss_ce: 0.006574
iteration 14933 : loss : 0.019397, loss_ce: 0.005022
iteration 14934 : loss : 0.022487, loss_ce: 0.004098
iteration 14935 : loss : 0.020709, loss_ce: 0.006665
iteration 14936 : loss : 0.027752, loss_ce: 0.011250
iteration 14937 : loss : 0.024610, loss_ce: 0.004039
iteration 14938 : loss : 0.024958, loss_ce: 0.004311
iteration 14939 : loss : 0.021463, loss_ce: 0.009714
iteration 14940 : loss : 0.017069, loss_ce: 0.004216
iteration 14941 : loss : 0.018691, loss_ce: 0.003335
iteration 14942 : loss : 0.021393, loss_ce: 0.009424
iteration 14943 : loss : 0.020915, loss_ce: 0.010011
iteration 14944 : loss : 0.021584, loss_ce: 0.006943
iteration 14945 : loss : 0.022818, loss_ce: 0.008710
iteration 14946 : loss : 0.022751, loss_ce: 0.009814
iteration 14947 : loss : 0.027596, loss_ce: 0.008754
iteration 14948 : loss : 0.024178, loss_ce: 0.006816
iteration 14949 : loss : 0.025174, loss_ce: 0.008326
iteration 14950 : loss : 0.026098, loss_ce: 0.008542
iteration 14951 : loss : 0.019039, loss_ce: 0.005531
iteration 14952 : loss : 0.022559, loss_ce: 0.008503
iteration 14953 : loss : 0.023873, loss_ce: 0.008722
iteration 14954 : loss : 0.032684, loss_ce: 0.006176
iteration 14955 : loss : 0.018379, loss_ce: 0.006451
iteration 14956 : loss : 0.020548, loss_ce: 0.006861
iteration 14957 : loss : 0.025288, loss_ce: 0.009595
iteration 14958 : loss : 0.022414, loss_ce: 0.010096
iteration 14959 : loss : 0.020770, loss_ce: 0.010038
iteration 14960 : loss : 0.021708, loss_ce: 0.010229
iteration 14961 : loss : 0.082098, loss_ce: 0.005642
iteration 14962 : loss : 0.072274, loss_ce: 0.005539
iteration 14963 : loss : 0.025093, loss_ce: 0.006407
iteration 14964 : loss : 0.026688, loss_ce: 0.013799
iteration 14965 : loss : 0.024460, loss_ce: 0.006132
iteration 14966 : loss : 0.027785, loss_ce: 0.010877
iteration 14967 : loss : 0.021805, loss_ce: 0.008668
iteration 14968 : loss : 0.020211, loss_ce: 0.010076
iteration 14969 : loss : 0.022384, loss_ce: 0.006514
iteration 14970 : loss : 0.021142, loss_ce: 0.009066
iteration 14971 : loss : 0.021403, loss_ce: 0.008026
iteration 14972 : loss : 0.027480, loss_ce: 0.008837
iteration 14973 : loss : 0.390813, loss_ce: 0.002998
 80%|███████████████████████▎     | 161/200 [2:41:25<35:28, 54.58s/it]iteration 14974 : loss : 0.024318, loss_ce: 0.014910
iteration 14975 : loss : 0.019041, loss_ce: 0.004805
iteration 14976 : loss : 0.018870, loss_ce: 0.006201
iteration 14977 : loss : 0.022615, loss_ce: 0.010627
iteration 14978 : loss : 0.021400, loss_ce: 0.007558
iteration 14979 : loss : 0.022367, loss_ce: 0.008791
iteration 14980 : loss : 0.027689, loss_ce: 0.008670
iteration 14981 : loss : 0.072705, loss_ce: 0.004907
iteration 14982 : loss : 0.022444, loss_ce: 0.005537
iteration 14983 : loss : 0.025269, loss_ce: 0.007944
iteration 14984 : loss : 0.022854, loss_ce: 0.008338
iteration 14985 : loss : 0.019935, loss_ce: 0.008816
iteration 14986 : loss : 0.019129, loss_ce: 0.006019
iteration 14987 : loss : 0.023829, loss_ce: 0.010376
iteration 14988 : loss : 0.020088, loss_ce: 0.007266
iteration 14989 : loss : 0.026618, loss_ce: 0.008830
iteration 14990 : loss : 0.022637, loss_ce: 0.005094
iteration 14991 : loss : 0.025696, loss_ce: 0.008022
iteration 14992 : loss : 0.025141, loss_ce: 0.006489
iteration 14993 : loss : 0.024402, loss_ce: 0.007006
iteration 14994 : loss : 0.017281, loss_ce: 0.006357
iteration 14995 : loss : 0.021939, loss_ce: 0.007164
iteration 14996 : loss : 0.018179, loss_ce: 0.005756
iteration 14997 : loss : 0.025388, loss_ce: 0.008231
iteration 14998 : loss : 0.024936, loss_ce: 0.006664
iteration 14999 : loss : 0.024000, loss_ce: 0.013989
iteration 15000 : loss : 0.026235, loss_ce: 0.007791
iteration 15001 : loss : 0.026968, loss_ce: 0.007346
iteration 15002 : loss : 0.068150, loss_ce: 0.007146
iteration 15003 : loss : 0.019599, loss_ce: 0.006219
iteration 15004 : loss : 0.017886, loss_ce: 0.005295
iteration 15005 : loss : 0.022649, loss_ce: 0.009903
iteration 15006 : loss : 0.023108, loss_ce: 0.009717
iteration 15007 : loss : 0.020975, loss_ce: 0.008083
iteration 15008 : loss : 0.028063, loss_ce: 0.004914
iteration 15009 : loss : 0.075710, loss_ce: 0.008397
iteration 15010 : loss : 0.023607, loss_ce: 0.008306
iteration 15011 : loss : 0.021421, loss_ce: 0.006549
iteration 15012 : loss : 0.025549, loss_ce: 0.007933
iteration 15013 : loss : 0.075768, loss_ce: 0.006389
iteration 15014 : loss : 0.018050, loss_ce: 0.004741
iteration 15015 : loss : 0.023275, loss_ce: 0.006711
iteration 15016 : loss : 0.022977, loss_ce: 0.007150
iteration 15017 : loss : 0.068590, loss_ce: 0.002374
iteration 15018 : loss : 0.021050, loss_ce: 0.008692
iteration 15019 : loss : 0.021365, loss_ce: 0.007735
iteration 15020 : loss : 0.020051, loss_ce: 0.009359
iteration 15021 : loss : 0.023978, loss_ce: 0.008852
iteration 15022 : loss : 0.020958, loss_ce: 0.007537
iteration 15023 : loss : 0.020988, loss_ce: 0.008804
iteration 15024 : loss : 0.017753, loss_ce: 0.007534
iteration 15025 : loss : 0.026545, loss_ce: 0.008870
iteration 15026 : loss : 0.020380, loss_ce: 0.007052
iteration 15027 : loss : 0.027235, loss_ce: 0.007461
iteration 15028 : loss : 0.023070, loss_ce: 0.008253
iteration 15029 : loss : 0.021405, loss_ce: 0.004562
iteration 15030 : loss : 0.029400, loss_ce: 0.006996
iteration 15031 : loss : 0.022534, loss_ce: 0.006919
iteration 15032 : loss : 0.022031, loss_ce: 0.006809
iteration 15033 : loss : 0.019155, loss_ce: 0.006444
iteration 15034 : loss : 0.026410, loss_ce: 0.005300
iteration 15035 : loss : 0.022670, loss_ce: 0.008933
iteration 15036 : loss : 0.021660, loss_ce: 0.007666
iteration 15037 : loss : 0.022159, loss_ce: 0.005576
iteration 15038 : loss : 0.025045, loss_ce: 0.008140
iteration 15039 : loss : 0.022607, loss_ce: 0.008383
iteration 15040 : loss : 0.023717, loss_ce: 0.012130
iteration 15041 : loss : 0.023073, loss_ce: 0.007133
iteration 15042 : loss : 0.023941, loss_ce: 0.007403
iteration 15043 : loss : 0.019015, loss_ce: 0.006888
iteration 15044 : loss : 0.026682, loss_ce: 0.008568
iteration 15045 : loss : 0.022711, loss_ce: 0.006284
iteration 15046 : loss : 0.021966, loss_ce: 0.008533
iteration 15047 : loss : 0.023398, loss_ce: 0.006755
iteration 15048 : loss : 0.023207, loss_ce: 0.009494
iteration 15049 : loss : 0.018703, loss_ce: 0.006035
iteration 15050 : loss : 0.027019, loss_ce: 0.011029
iteration 15051 : loss : 0.023066, loss_ce: 0.009901
iteration 15052 : loss : 0.019914, loss_ce: 0.006709
iteration 15053 : loss : 0.022434, loss_ce: 0.006215
iteration 15054 : loss : 0.024197, loss_ce: 0.011690
iteration 15055 : loss : 0.022121, loss_ce: 0.008208
iteration 15056 : loss : 0.018947, loss_ce: 0.004620
iteration 15057 : loss : 0.022591, loss_ce: 0.010503
iteration 15058 : loss : 0.023705, loss_ce: 0.006153
iteration 15059 : loss : 0.026950, loss_ce: 0.007550
iteration 15060 : loss : 0.024268, loss_ce: 0.010064
iteration 15061 : loss : 0.023551, loss_ce: 0.012552
iteration 15062 : loss : 0.023322, loss_ce: 0.006271
iteration 15063 : loss : 0.018734, loss_ce: 0.006552
iteration 15064 : loss : 0.022448, loss_ce: 0.008977
iteration 15065 : loss : 0.023852, loss_ce: 0.006302
iteration 15066 : loss : 0.081200, loss_ce: 0.010413
 81%|███████████████████████▍     | 162/200 [2:42:20<34:33, 54.57s/it]iteration 15067 : loss : 0.020524, loss_ce: 0.007333
iteration 15068 : loss : 0.022865, loss_ce: 0.004917
iteration 15069 : loss : 0.024262, loss_ce: 0.012208
iteration 15070 : loss : 0.026072, loss_ce: 0.005837
iteration 15071 : loss : 0.021926, loss_ce: 0.007239
iteration 15072 : loss : 0.021831, loss_ce: 0.009576
iteration 15073 : loss : 0.022399, loss_ce: 0.007346
iteration 15074 : loss : 0.022593, loss_ce: 0.005847
iteration 15075 : loss : 0.020545, loss_ce: 0.007308
iteration 15076 : loss : 0.019571, loss_ce: 0.004599
iteration 15077 : loss : 0.019750, loss_ce: 0.006682
iteration 15078 : loss : 0.021787, loss_ce: 0.005152
iteration 15079 : loss : 0.025956, loss_ce: 0.011155
iteration 15080 : loss : 0.054241, loss_ce: 0.010488
iteration 15081 : loss : 0.024183, loss_ce: 0.006619
iteration 15082 : loss : 0.026478, loss_ce: 0.006951
iteration 15083 : loss : 0.024882, loss_ce: 0.011663
iteration 15084 : loss : 0.020416, loss_ce: 0.007325
iteration 15085 : loss : 0.017940, loss_ce: 0.004717
iteration 15086 : loss : 0.019161, loss_ce: 0.004703
iteration 15087 : loss : 0.018583, loss_ce: 0.005813
iteration 15088 : loss : 0.022558, loss_ce: 0.009025
iteration 15089 : loss : 0.026382, loss_ce: 0.007968
iteration 15090 : loss : 0.075303, loss_ce: 0.007588
iteration 15091 : loss : 0.024060, loss_ce: 0.007480
iteration 15092 : loss : 0.022626, loss_ce: 0.006745
iteration 15093 : loss : 0.023588, loss_ce: 0.010992
iteration 15094 : loss : 0.030025, loss_ce: 0.011233
iteration 15095 : loss : 0.021522, loss_ce: 0.008263
iteration 15096 : loss : 0.074163, loss_ce: 0.006104
iteration 15097 : loss : 0.021408, loss_ce: 0.007660
iteration 15098 : loss : 0.024540, loss_ce: 0.007765
iteration 15099 : loss : 0.019232, loss_ce: 0.007866
iteration 15100 : loss : 0.019953, loss_ce: 0.005242
iteration 15101 : loss : 0.033012, loss_ce: 0.006266
iteration 15102 : loss : 0.024404, loss_ce: 0.008357
iteration 15103 : loss : 0.025218, loss_ce: 0.008405
iteration 15104 : loss : 0.024806, loss_ce: 0.007415
iteration 15105 : loss : 0.070960, loss_ce: 0.005479
iteration 15106 : loss : 0.026089, loss_ce: 0.007939
iteration 15107 : loss : 0.025244, loss_ce: 0.011805
iteration 15108 : loss : 0.021941, loss_ce: 0.010155
iteration 15109 : loss : 0.078474, loss_ce: 0.006931
iteration 15110 : loss : 0.022597, loss_ce: 0.008533
iteration 15111 : loss : 0.026270, loss_ce: 0.006248
iteration 15112 : loss : 0.021503, loss_ce: 0.011593
iteration 15113 : loss : 0.019692, loss_ce: 0.006233
iteration 15114 : loss : 0.020532, loss_ce: 0.007865
iteration 15115 : loss : 0.024744, loss_ce: 0.010030
iteration 15116 : loss : 0.022026, loss_ce: 0.008312
iteration 15117 : loss : 0.025462, loss_ce: 0.008947
iteration 15118 : loss : 0.075788, loss_ce: 0.004252
iteration 15119 : loss : 0.021567, loss_ce: 0.008602
iteration 15120 : loss : 0.022141, loss_ce: 0.008422
iteration 15121 : loss : 0.024618, loss_ce: 0.008786
iteration 15122 : loss : 0.017742, loss_ce: 0.004747
iteration 15123 : loss : 0.023241, loss_ce: 0.007321
iteration 15124 : loss : 0.039100, loss_ce: 0.006874
iteration 15125 : loss : 0.024643, loss_ce: 0.007523
iteration 15126 : loss : 0.020992, loss_ce: 0.006769
iteration 15127 : loss : 0.022493, loss_ce: 0.003000
iteration 15128 : loss : 0.023014, loss_ce: 0.006793
iteration 15129 : loss : 0.023508, loss_ce: 0.009801
iteration 15130 : loss : 0.022825, loss_ce: 0.006144
iteration 15131 : loss : 0.022256, loss_ce: 0.006466
iteration 15132 : loss : 0.021175, loss_ce: 0.007797
iteration 15133 : loss : 0.020503, loss_ce: 0.005375
iteration 15134 : loss : 0.027737, loss_ce: 0.012873
iteration 15135 : loss : 0.035328, loss_ce: 0.007588
iteration 15136 : loss : 0.021960, loss_ce: 0.005168
iteration 15137 : loss : 0.023344, loss_ce: 0.008063
iteration 15138 : loss : 0.024054, loss_ce: 0.005818
iteration 15139 : loss : 0.023273, loss_ce: 0.008925
iteration 15140 : loss : 0.026380, loss_ce: 0.010483
iteration 15141 : loss : 0.025043, loss_ce: 0.009864
iteration 15142 : loss : 0.022899, loss_ce: 0.010329
iteration 15143 : loss : 0.024210, loss_ce: 0.004778
iteration 15144 : loss : 0.023676, loss_ce: 0.007892
iteration 15145 : loss : 0.024741, loss_ce: 0.007693
iteration 15146 : loss : 0.027425, loss_ce: 0.009171
iteration 15147 : loss : 0.021073, loss_ce: 0.007554
iteration 15148 : loss : 0.023826, loss_ce: 0.010780
iteration 15149 : loss : 0.024636, loss_ce: 0.011015
iteration 15150 : loss : 0.020868, loss_ce: 0.009489
iteration 15151 : loss : 0.022060, loss_ce: 0.011530
iteration 15152 : loss : 0.019479, loss_ce: 0.009273
iteration 15153 : loss : 0.023144, loss_ce: 0.006961
iteration 15154 : loss : 0.024475, loss_ce: 0.004522
iteration 15155 : loss : 0.026841, loss_ce: 0.007241
iteration 15156 : loss : 0.020390, loss_ce: 0.007300
iteration 15157 : loss : 0.071814, loss_ce: 0.003861
iteration 15158 : loss : 0.020530, loss_ce: 0.004493
iteration 15159 : loss : 0.043310, loss_ce: 0.015058
 82%|███████████████████████▋     | 163/200 [2:43:14<33:38, 54.56s/it]iteration 15160 : loss : 0.021660, loss_ce: 0.009524
iteration 15161 : loss : 0.071308, loss_ce: 0.003791
iteration 15162 : loss : 0.073466, loss_ce: 0.004773
iteration 15163 : loss : 0.021596, loss_ce: 0.009311
iteration 15164 : loss : 0.020238, loss_ce: 0.008319
iteration 15165 : loss : 0.022794, loss_ce: 0.003782
iteration 15166 : loss : 0.022902, loss_ce: 0.005491
iteration 15167 : loss : 0.021268, loss_ce: 0.009157
iteration 15168 : loss : 0.018537, loss_ce: 0.006208
iteration 15169 : loss : 0.030019, loss_ce: 0.005417
iteration 15170 : loss : 0.020634, loss_ce: 0.006669
iteration 15171 : loss : 0.022570, loss_ce: 0.011494
iteration 15172 : loss : 0.024907, loss_ce: 0.008922
iteration 15173 : loss : 0.022379, loss_ce: 0.011264
iteration 15174 : loss : 0.020326, loss_ce: 0.007563
iteration 15175 : loss : 0.021115, loss_ce: 0.004482
iteration 15176 : loss : 0.028715, loss_ce: 0.012148
iteration 15177 : loss : 0.022696, loss_ce: 0.008942
iteration 15178 : loss : 0.022036, loss_ce: 0.009998
iteration 15179 : loss : 0.024120, loss_ce: 0.010376
iteration 15180 : loss : 0.021540, loss_ce: 0.009341
iteration 15181 : loss : 0.030075, loss_ce: 0.005562
iteration 15182 : loss : 0.019633, loss_ce: 0.007440
iteration 15183 : loss : 0.026816, loss_ce: 0.007982
iteration 15184 : loss : 0.028304, loss_ce: 0.012569
iteration 15185 : loss : 0.023383, loss_ce: 0.009796
iteration 15186 : loss : 0.024967, loss_ce: 0.007243
iteration 15187 : loss : 0.024017, loss_ce: 0.005637
iteration 15188 : loss : 0.020569, loss_ce: 0.006854
iteration 15189 : loss : 0.022331, loss_ce: 0.009108
iteration 15190 : loss : 0.020653, loss_ce: 0.009039
iteration 15191 : loss : 0.028394, loss_ce: 0.008777
iteration 15192 : loss : 0.022116, loss_ce: 0.008829
iteration 15193 : loss : 0.021513, loss_ce: 0.006308
iteration 15194 : loss : 0.026476, loss_ce: 0.005605
iteration 15195 : loss : 0.023640, loss_ce: 0.008119
iteration 15196 : loss : 0.075985, loss_ce: 0.009711
iteration 15197 : loss : 0.025073, loss_ce: 0.010622
iteration 15198 : loss : 0.026164, loss_ce: 0.008847
iteration 15199 : loss : 0.019096, loss_ce: 0.005604
iteration 15200 : loss : 0.020544, loss_ce: 0.007561
iteration 15201 : loss : 0.023252, loss_ce: 0.005735
iteration 15202 : loss : 0.025848, loss_ce: 0.007969
iteration 15203 : loss : 0.024570, loss_ce: 0.008676
iteration 15204 : loss : 0.021610, loss_ce: 0.003231
iteration 15205 : loss : 0.024867, loss_ce: 0.009960
iteration 15206 : loss : 0.024043, loss_ce: 0.006165
iteration 15207 : loss : 0.020669, loss_ce: 0.009006
iteration 15208 : loss : 0.021111, loss_ce: 0.009066
iteration 15209 : loss : 0.022122, loss_ce: 0.008590
iteration 15210 : loss : 0.024718, loss_ce: 0.010342
iteration 15211 : loss : 0.023601, loss_ce: 0.005980
iteration 15212 : loss : 0.021595, loss_ce: 0.007184
iteration 15213 : loss : 0.020225, loss_ce: 0.008050
iteration 15214 : loss : 0.026569, loss_ce: 0.010042
iteration 15215 : loss : 0.027044, loss_ce: 0.003374
iteration 15216 : loss : 0.022610, loss_ce: 0.008334
iteration 15217 : loss : 0.020536, loss_ce: 0.007334
iteration 15218 : loss : 0.024166, loss_ce: 0.007126
iteration 15219 : loss : 0.025900, loss_ce: 0.008511
iteration 15220 : loss : 0.073936, loss_ce: 0.005392
iteration 15221 : loss : 0.025733, loss_ce: 0.005501
iteration 15222 : loss : 0.075280, loss_ce: 0.004854
iteration 15223 : loss : 0.022507, loss_ce: 0.009491
iteration 15224 : loss : 0.020185, loss_ce: 0.008051
iteration 15225 : loss : 0.030294, loss_ce: 0.006748
iteration 15226 : loss : 0.028284, loss_ce: 0.009914
iteration 15227 : loss : 0.020271, loss_ce: 0.007486
iteration 15228 : loss : 0.020038, loss_ce: 0.007577
iteration 15229 : loss : 0.017074, loss_ce: 0.004447
iteration 15230 : loss : 0.025217, loss_ce: 0.008818
iteration 15231 : loss : 0.022601, loss_ce: 0.008210
iteration 15232 : loss : 0.078068, loss_ce: 0.006641
iteration 15233 : loss : 0.070518, loss_ce: 0.003327
iteration 15234 : loss : 0.026303, loss_ce: 0.011567
iteration 15235 : loss : 0.016298, loss_ce: 0.003470
iteration 15236 : loss : 0.024455, loss_ce: 0.008350
iteration 15237 : loss : 0.028959, loss_ce: 0.010499
iteration 15238 : loss : 0.019562, loss_ce: 0.004343
iteration 15239 : loss : 0.020790, loss_ce: 0.004693
iteration 15240 : loss : 0.021620, loss_ce: 0.011779
iteration 15241 : loss : 0.076388, loss_ce: 0.008474
iteration 15242 : loss : 0.020998, loss_ce: 0.008222
iteration 15243 : loss : 0.022686, loss_ce: 0.007965
iteration 15244 : loss : 0.020337, loss_ce: 0.006288
iteration 15245 : loss : 0.019169, loss_ce: 0.005676
iteration 15246 : loss : 0.023179, loss_ce: 0.009537
iteration 15247 : loss : 0.024048, loss_ce: 0.006654
iteration 15248 : loss : 0.024543, loss_ce: 0.008779
iteration 15249 : loss : 0.036955, loss_ce: 0.008015
iteration 15250 : loss : 0.023510, loss_ce: 0.005535
iteration 15251 : loss : 0.019124, loss_ce: 0.008451
iteration 15252 : loss : 0.080980, loss_ce: 0.009731
 82%|███████████████████████▊     | 164/200 [2:44:09<32:43, 54.55s/it]iteration 15253 : loss : 0.023860, loss_ce: 0.006954
iteration 15254 : loss : 0.022229, loss_ce: 0.007654
iteration 15255 : loss : 0.016727, loss_ce: 0.003957
iteration 15256 : loss : 0.019675, loss_ce: 0.009738
iteration 15257 : loss : 0.023820, loss_ce: 0.010038
iteration 15258 : loss : 0.020301, loss_ce: 0.005020
iteration 15259 : loss : 0.074634, loss_ce: 0.008486
iteration 15260 : loss : 0.019319, loss_ce: 0.004968
iteration 15261 : loss : 0.022081, loss_ce: 0.007398
iteration 15262 : loss : 0.019943, loss_ce: 0.006656
iteration 15263 : loss : 0.022503, loss_ce: 0.005596
iteration 15264 : loss : 0.075539, loss_ce: 0.009165
iteration 15265 : loss : 0.024112, loss_ce: 0.007386
iteration 15266 : loss : 0.028741, loss_ce: 0.012752
iteration 15267 : loss : 0.024654, loss_ce: 0.008613
iteration 15268 : loss : 0.021161, loss_ce: 0.006364
iteration 15269 : loss : 0.020508, loss_ce: 0.009088
iteration 15270 : loss : 0.025170, loss_ce: 0.009488
iteration 15271 : loss : 0.035498, loss_ce: 0.008576
iteration 15272 : loss : 0.023731, loss_ce: 0.010183
iteration 15273 : loss : 0.021221, loss_ce: 0.003530
iteration 15274 : loss : 0.071995, loss_ce: 0.004622
iteration 15275 : loss : 0.018833, loss_ce: 0.008902
iteration 15276 : loss : 0.021023, loss_ce: 0.008528
iteration 15277 : loss : 0.070997, loss_ce: 0.005295
iteration 15278 : loss : 0.023788, loss_ce: 0.007751
iteration 15279 : loss : 0.037175, loss_ce: 0.005667
iteration 15280 : loss : 0.027093, loss_ce: 0.005518
iteration 15281 : loss : 0.022455, loss_ce: 0.008010
iteration 15282 : loss : 0.021851, loss_ce: 0.007876
iteration 15283 : loss : 0.021726, loss_ce: 0.005891
iteration 15284 : loss : 0.022034, loss_ce: 0.005291
iteration 15285 : loss : 0.021130, loss_ce: 0.002974
iteration 15286 : loss : 0.022968, loss_ce: 0.006473
iteration 15287 : loss : 0.027938, loss_ce: 0.008206
iteration 15288 : loss : 0.025427, loss_ce: 0.010934
iteration 15289 : loss : 0.027186, loss_ce: 0.007266
iteration 15290 : loss : 0.023016, loss_ce: 0.005256
iteration 15291 : loss : 0.020719, loss_ce: 0.005515
iteration 15292 : loss : 0.021294, loss_ce: 0.007887
iteration 15293 : loss : 0.073579, loss_ce: 0.006571
iteration 15294 : loss : 0.027028, loss_ce: 0.007811
iteration 15295 : loss : 0.020637, loss_ce: 0.008558
iteration 15296 : loss : 0.020657, loss_ce: 0.008907
iteration 15297 : loss : 0.025878, loss_ce: 0.007464
iteration 15298 : loss : 0.022742, loss_ce: 0.010527
iteration 15299 : loss : 0.018945, loss_ce: 0.008142
iteration 15300 : loss : 0.018107, loss_ce: 0.005592
iteration 15301 : loss : 0.025143, loss_ce: 0.006972
iteration 15302 : loss : 0.073253, loss_ce: 0.006244
iteration 15303 : loss : 0.029651, loss_ce: 0.011104
iteration 15304 : loss : 0.025454, loss_ce: 0.008923
iteration 15305 : loss : 0.021083, loss_ce: 0.008255
iteration 15306 : loss : 0.023511, loss_ce: 0.010317
iteration 15307 : loss : 0.036103, loss_ce: 0.004977
iteration 15308 : loss : 0.073084, loss_ce: 0.006631
iteration 15309 : loss : 0.020924, loss_ce: 0.005349
iteration 15310 : loss : 0.021687, loss_ce: 0.008090
iteration 15311 : loss : 0.023582, loss_ce: 0.010240
iteration 15312 : loss : 0.021137, loss_ce: 0.006605
iteration 15313 : loss : 0.021754, loss_ce: 0.008277
iteration 15314 : loss : 0.030807, loss_ce: 0.008824
iteration 15315 : loss : 0.022819, loss_ce: 0.006366
iteration 15316 : loss : 0.017919, loss_ce: 0.005909
iteration 15317 : loss : 0.022928, loss_ce: 0.004617
iteration 15318 : loss : 0.023307, loss_ce: 0.008832
iteration 15319 : loss : 0.024647, loss_ce: 0.010429
iteration 15320 : loss : 0.024690, loss_ce: 0.008744
iteration 15321 : loss : 0.025224, loss_ce: 0.006896
iteration 15322 : loss : 0.025644, loss_ce: 0.007068
iteration 15323 : loss : 0.025759, loss_ce: 0.004524
iteration 15324 : loss : 0.021914, loss_ce: 0.008373
iteration 15325 : loss : 0.025306, loss_ce: 0.010254
iteration 15326 : loss : 0.017473, loss_ce: 0.006441
iteration 15327 : loss : 0.025656, loss_ce: 0.009705
iteration 15328 : loss : 0.022132, loss_ce: 0.004562
iteration 15329 : loss : 0.025475, loss_ce: 0.008419
iteration 15330 : loss : 0.021465, loss_ce: 0.009698
iteration 15331 : loss : 0.023733, loss_ce: 0.012539
iteration 15332 : loss : 0.025543, loss_ce: 0.007343
iteration 15333 : loss : 0.030335, loss_ce: 0.010880
iteration 15334 : loss : 0.026322, loss_ce: 0.009201
iteration 15335 : loss : 0.052455, loss_ce: 0.007564
iteration 15336 : loss : 0.022464, loss_ce: 0.010151
iteration 15337 : loss : 0.021538, loss_ce: 0.008561
iteration 15338 : loss : 0.022015, loss_ce: 0.010187
iteration 15339 : loss : 0.022513, loss_ce: 0.010243
iteration 15340 : loss : 0.019395, loss_ce: 0.007421
iteration 15341 : loss : 0.019703, loss_ce: 0.009669
iteration 15342 : loss : 0.022450, loss_ce: 0.007352
iteration 15343 : loss : 0.022020, loss_ce: 0.006833
iteration 15344 : loss : 0.018883, loss_ce: 0.005717
iteration 15345 : loss : 0.283998, loss_ce: 0.004589
 82%|███████████████████████▉     | 165/200 [2:45:03<31:49, 54.57s/it]iteration 15346 : loss : 0.075684, loss_ce: 0.009919
iteration 15347 : loss : 0.072744, loss_ce: 0.006834
iteration 15348 : loss : 0.021537, loss_ce: 0.007917
iteration 15349 : loss : 0.022792, loss_ce: 0.009000
iteration 15350 : loss : 0.025318, loss_ce: 0.008350
iteration 15351 : loss : 0.024016, loss_ce: 0.009676
iteration 15352 : loss : 0.024566, loss_ce: 0.008907
iteration 15353 : loss : 0.018399, loss_ce: 0.005587
iteration 15354 : loss : 0.020169, loss_ce: 0.008186
iteration 15355 : loss : 0.023358, loss_ce: 0.009162
iteration 15356 : loss : 0.024001, loss_ce: 0.009197
iteration 15357 : loss : 0.072109, loss_ce: 0.003492
iteration 15358 : loss : 0.023422, loss_ce: 0.009135
iteration 15359 : loss : 0.021341, loss_ce: 0.007540
iteration 15360 : loss : 0.018881, loss_ce: 0.005797
iteration 15361 : loss : 0.021476, loss_ce: 0.007006
iteration 15362 : loss : 0.020147, loss_ce: 0.007995
iteration 15363 : loss : 0.020549, loss_ce: 0.006762
iteration 15364 : loss : 0.018592, loss_ce: 0.005591
iteration 15365 : loss : 0.022201, loss_ce: 0.007539
iteration 15366 : loss : 0.020041, loss_ce: 0.004127
iteration 15367 : loss : 0.024165, loss_ce: 0.007756
iteration 15368 : loss : 0.018617, loss_ce: 0.004992
iteration 15369 : loss : 0.023071, loss_ce: 0.008814
iteration 15370 : loss : 0.020302, loss_ce: 0.003084
iteration 15371 : loss : 0.021964, loss_ce: 0.010517
iteration 15372 : loss : 0.022797, loss_ce: 0.010192
iteration 15373 : loss : 0.019698, loss_ce: 0.006644
iteration 15374 : loss : 0.022911, loss_ce: 0.011596
iteration 15375 : loss : 0.074541, loss_ce: 0.005575
iteration 15376 : loss : 0.028214, loss_ce: 0.009242
iteration 15377 : loss : 0.023702, loss_ce: 0.008524
iteration 15378 : loss : 0.073418, loss_ce: 0.007398
iteration 15379 : loss : 0.023496, loss_ce: 0.004364
iteration 15380 : loss : 0.024264, loss_ce: 0.007287
iteration 15381 : loss : 0.021493, loss_ce: 0.008284
iteration 15382 : loss : 0.025756, loss_ce: 0.008217
iteration 15383 : loss : 0.023235, loss_ce: 0.008944
iteration 15384 : loss : 0.025113, loss_ce: 0.010002
iteration 15385 : loss : 0.022871, loss_ce: 0.011837
iteration 15386 : loss : 0.075707, loss_ce: 0.007258
iteration 15387 : loss : 0.024744, loss_ce: 0.004971
iteration 15388 : loss : 0.020259, loss_ce: 0.006324
iteration 15389 : loss : 0.020012, loss_ce: 0.008982
iteration 15390 : loss : 0.019349, loss_ce: 0.005660
iteration 15391 : loss : 0.018428, loss_ce: 0.005735
iteration 15392 : loss : 0.025207, loss_ce: 0.009288
iteration 15393 : loss : 0.018349, loss_ce: 0.006591
iteration 15394 : loss : 0.024237, loss_ce: 0.010881
iteration 15395 : loss : 0.019438, loss_ce: 0.005281
iteration 15396 : loss : 0.022740, loss_ce: 0.009275
iteration 15397 : loss : 0.023036, loss_ce: 0.008932
iteration 15398 : loss : 0.022286, loss_ce: 0.007297
iteration 15399 : loss : 0.018587, loss_ce: 0.007902
iteration 15400 : loss : 0.018044, loss_ce: 0.005328
iteration 15401 : loss : 0.027312, loss_ce: 0.011825
iteration 15402 : loss : 0.022179, loss_ce: 0.009876
iteration 15403 : loss : 0.023402, loss_ce: 0.008002
iteration 15404 : loss : 0.026615, loss_ce: 0.010218
iteration 15405 : loss : 0.022040, loss_ce: 0.004998
iteration 15406 : loss : 0.022655, loss_ce: 0.008959
iteration 15407 : loss : 0.024230, loss_ce: 0.015045
iteration 15408 : loss : 0.025047, loss_ce: 0.007148
iteration 15409 : loss : 0.073532, loss_ce: 0.005285
iteration 15410 : loss : 0.019278, loss_ce: 0.006619
iteration 15411 : loss : 0.021613, loss_ce: 0.006632
iteration 15412 : loss : 0.025395, loss_ce: 0.004699
iteration 15413 : loss : 0.022282, loss_ce: 0.007526
iteration 15414 : loss : 0.026758, loss_ce: 0.004159
iteration 15415 : loss : 0.024590, loss_ce: 0.010490
iteration 15416 : loss : 0.024428, loss_ce: 0.009058
iteration 15417 : loss : 0.024829, loss_ce: 0.004798
iteration 15418 : loss : 0.024808, loss_ce: 0.008071
iteration 15419 : loss : 0.023642, loss_ce: 0.009992
iteration 15420 : loss : 0.019082, loss_ce: 0.006055
iteration 15421 : loss : 0.075583, loss_ce: 0.008365
iteration 15422 : loss : 0.076784, loss_ce: 0.008277
iteration 15423 : loss : 0.030618, loss_ce: 0.009053
iteration 15424 : loss : 0.018964, loss_ce: 0.008351
iteration 15425 : loss : 0.025103, loss_ce: 0.011093
iteration 15426 : loss : 0.073322, loss_ce: 0.006781
iteration 15427 : loss : 0.025872, loss_ce: 0.006309
iteration 15428 : loss : 0.021049, loss_ce: 0.007919
iteration 15429 : loss : 0.075309, loss_ce: 0.007551
iteration 15430 : loss : 0.021019, loss_ce: 0.008585
iteration 15431 : loss : 0.074304, loss_ce: 0.007115
iteration 15432 : loss : 0.021847, loss_ce: 0.009116
iteration 15433 : loss : 0.023189, loss_ce: 0.008475
iteration 15434 : loss : 0.043753, loss_ce: 0.002985
iteration 15435 : loss : 0.030743, loss_ce: 0.004988
iteration 15436 : loss : 0.077054, loss_ce: 0.003723
iteration 15437 : loss : 0.021250, loss_ce: 0.006001
iteration 15438 : loss : 0.130441, loss_ce: 0.006899
 83%|████████████████████████     | 166/200 [2:45:58<30:55, 54.56s/it]iteration 15439 : loss : 0.021462, loss_ce: 0.008037
iteration 15440 : loss : 0.021878, loss_ce: 0.008216
iteration 15441 : loss : 0.022654, loss_ce: 0.007205
iteration 15442 : loss : 0.022239, loss_ce: 0.009644
iteration 15443 : loss : 0.026007, loss_ce: 0.009897
iteration 15444 : loss : 0.023408, loss_ce: 0.009245
iteration 15445 : loss : 0.023387, loss_ce: 0.009134
iteration 15446 : loss : 0.021795, loss_ce: 0.010260
iteration 15447 : loss : 0.023588, loss_ce: 0.007260
iteration 15448 : loss : 0.027723, loss_ce: 0.011430
iteration 15449 : loss : 0.021206, loss_ce: 0.008217
iteration 15450 : loss : 0.095682, loss_ce: 0.003993
iteration 15451 : loss : 0.021539, loss_ce: 0.008964
iteration 15452 : loss : 0.029464, loss_ce: 0.008295
iteration 15453 : loss : 0.021948, loss_ce: 0.008599
iteration 15454 : loss : 0.022862, loss_ce: 0.007572
iteration 15455 : loss : 0.022304, loss_ce: 0.006133
iteration 15456 : loss : 0.025110, loss_ce: 0.009244
iteration 15457 : loss : 0.075567, loss_ce: 0.003801
iteration 15458 : loss : 0.018710, loss_ce: 0.005445
iteration 15459 : loss : 0.021392, loss_ce: 0.004506
iteration 15460 : loss : 0.028008, loss_ce: 0.005844
iteration 15461 : loss : 0.026138, loss_ce: 0.010777
iteration 15462 : loss : 0.029625, loss_ce: 0.008427
iteration 15463 : loss : 0.026205, loss_ce: 0.009508
iteration 15464 : loss : 0.029571, loss_ce: 0.009835
iteration 15465 : loss : 0.080168, loss_ce: 0.007615
iteration 15466 : loss : 0.076938, loss_ce: 0.007642
iteration 15467 : loss : 0.029842, loss_ce: 0.015424
iteration 15468 : loss : 0.030549, loss_ce: 0.009399
iteration 15469 : loss : 0.041404, loss_ce: 0.007291
iteration 15470 : loss : 0.031117, loss_ce: 0.006182
iteration 15471 : loss : 0.023716, loss_ce: 0.007701
iteration 15472 : loss : 0.024390, loss_ce: 0.007900
iteration 15473 : loss : 0.022705, loss_ce: 0.008820
iteration 15474 : loss : 0.024639, loss_ce: 0.008822
iteration 15475 : loss : 0.021948, loss_ce: 0.004701
iteration 15476 : loss : 0.025738, loss_ce: 0.009462
iteration 15477 : loss : 0.027022, loss_ce: 0.010557
iteration 15478 : loss : 0.025202, loss_ce: 0.006185
iteration 15479 : loss : 0.035791, loss_ce: 0.007624
iteration 15480 : loss : 0.023350, loss_ce: 0.007485
iteration 15481 : loss : 0.034394, loss_ce: 0.010533
iteration 15482 : loss : 0.025603, loss_ce: 0.007923
iteration 15483 : loss : 0.022445, loss_ce: 0.005417
iteration 15484 : loss : 0.026195, loss_ce: 0.006272
iteration 15485 : loss : 0.024158, loss_ce: 0.010314
iteration 15486 : loss : 0.035776, loss_ce: 0.006280
iteration 15487 : loss : 0.022444, loss_ce: 0.006993
iteration 15488 : loss : 0.072156, loss_ce: 0.004315
iteration 15489 : loss : 0.023297, loss_ce: 0.007411
iteration 15490 : loss : 0.024801, loss_ce: 0.008916
iteration 15491 : loss : 0.026348, loss_ce: 0.007603
iteration 15492 : loss : 0.023177, loss_ce: 0.008328
iteration 15493 : loss : 0.021845, loss_ce: 0.010159
iteration 15494 : loss : 0.021358, loss_ce: 0.007223
iteration 15495 : loss : 0.024366, loss_ce: 0.006252
iteration 15496 : loss : 0.021964, loss_ce: 0.007882
iteration 15497 : loss : 0.022653, loss_ce: 0.009552
iteration 15498 : loss : 0.025579, loss_ce: 0.007413
iteration 15499 : loss : 0.040165, loss_ce: 0.007967
iteration 15500 : loss : 0.029290, loss_ce: 0.007242
iteration 15501 : loss : 0.025274, loss_ce: 0.010903
iteration 15502 : loss : 0.025097, loss_ce: 0.008687
iteration 15503 : loss : 0.021650, loss_ce: 0.005658
iteration 15504 : loss : 0.024380, loss_ce: 0.010483
iteration 15505 : loss : 0.021714, loss_ce: 0.008594
iteration 15506 : loss : 0.023228, loss_ce: 0.008924
iteration 15507 : loss : 0.024065, loss_ce: 0.008086
iteration 15508 : loss : 0.024039, loss_ce: 0.008689
iteration 15509 : loss : 0.020476, loss_ce: 0.007593
iteration 15510 : loss : 0.021379, loss_ce: 0.008203
iteration 15511 : loss : 0.026914, loss_ce: 0.010223
iteration 15512 : loss : 0.024720, loss_ce: 0.005814
iteration 15513 : loss : 0.039704, loss_ce: 0.006702
iteration 15514 : loss : 0.022029, loss_ce: 0.006945
iteration 15515 : loss : 0.021846, loss_ce: 0.011000
iteration 15516 : loss : 0.025883, loss_ce: 0.006834
iteration 15517 : loss : 0.034787, loss_ce: 0.007719
iteration 15518 : loss : 0.021770, loss_ce: 0.006787
iteration 15519 : loss : 0.026418, loss_ce: 0.014097
iteration 15520 : loss : 0.018294, loss_ce: 0.004755
iteration 15521 : loss : 0.031095, loss_ce: 0.010116
iteration 15522 : loss : 0.023742, loss_ce: 0.011471
iteration 15523 : loss : 0.022745, loss_ce: 0.004910
iteration 15524 : loss : 0.020849, loss_ce: 0.005000
iteration 15525 : loss : 0.021221, loss_ce: 0.006180
iteration 15526 : loss : 0.060825, loss_ce: 0.007933
iteration 15527 : loss : 0.025874, loss_ce: 0.008575
iteration 15528 : loss : 0.027427, loss_ce: 0.008108
iteration 15529 : loss : 0.025306, loss_ce: 0.008026
iteration 15530 : loss : 0.025179, loss_ce: 0.006614
iteration 15531 : loss : 0.187184, loss_ce: 0.006632
 84%|████████████████████████▏    | 167/200 [2:46:52<30:00, 54.56s/it]iteration 15532 : loss : 0.024441, loss_ce: 0.010454
iteration 15533 : loss : 0.027805, loss_ce: 0.005123
iteration 15534 : loss : 0.025495, loss_ce: 0.006115
iteration 15535 : loss : 0.023044, loss_ce: 0.007831
iteration 15536 : loss : 0.022154, loss_ce: 0.007099
iteration 15537 : loss : 0.024597, loss_ce: 0.011930
iteration 15538 : loss : 0.024646, loss_ce: 0.009137
iteration 15539 : loss : 0.023664, loss_ce: 0.005721
iteration 15540 : loss : 0.022404, loss_ce: 0.008678
iteration 15541 : loss : 0.021536, loss_ce: 0.007071
iteration 15542 : loss : 0.025225, loss_ce: 0.009596
iteration 15543 : loss : 0.025143, loss_ce: 0.006457
iteration 15544 : loss : 0.020881, loss_ce: 0.008766
iteration 15545 : loss : 0.021927, loss_ce: 0.006100
iteration 15546 : loss : 0.022589, loss_ce: 0.005921
iteration 15547 : loss : 0.023043, loss_ce: 0.007997
iteration 15548 : loss : 0.029063, loss_ce: 0.010297
iteration 15549 : loss : 0.049029, loss_ce: 0.003890
iteration 15550 : loss : 0.024218, loss_ce: 0.006173
iteration 15551 : loss : 0.027254, loss_ce: 0.010453
iteration 15552 : loss : 0.015091, loss_ce: 0.006068
iteration 15553 : loss : 0.033349, loss_ce: 0.007796
iteration 15554 : loss : 0.124539, loss_ce: 0.005064
iteration 15555 : loss : 0.074676, loss_ce: 0.006991
iteration 15556 : loss : 0.023023, loss_ce: 0.008084
iteration 15557 : loss : 0.020873, loss_ce: 0.007214
iteration 15558 : loss : 0.022821, loss_ce: 0.007422
iteration 15559 : loss : 0.027657, loss_ce: 0.010980
iteration 15560 : loss : 0.022459, loss_ce: 0.008933
iteration 15561 : loss : 0.018977, loss_ce: 0.004904
iteration 15562 : loss : 0.021385, loss_ce: 0.010242
iteration 15563 : loss : 0.022267, loss_ce: 0.009361
iteration 15564 : loss : 0.022893, loss_ce: 0.006563
iteration 15565 : loss : 0.112870, loss_ce: 0.005317
iteration 15566 : loss : 0.076912, loss_ce: 0.006436
iteration 15567 : loss : 0.021479, loss_ce: 0.010039
iteration 15568 : loss : 0.020845, loss_ce: 0.006456
iteration 15569 : loss : 0.022231, loss_ce: 0.006281
iteration 15570 : loss : 0.082090, loss_ce: 0.008738
iteration 15571 : loss : 0.025610, loss_ce: 0.006536
iteration 15572 : loss : 0.023688, loss_ce: 0.006777
iteration 15573 : loss : 0.021656, loss_ce: 0.007013
iteration 15574 : loss : 0.019997, loss_ce: 0.007125
iteration 15575 : loss : 0.024716, loss_ce: 0.008643
iteration 15576 : loss : 0.017751, loss_ce: 0.003830
iteration 15577 : loss : 0.019548, loss_ce: 0.005979
iteration 15578 : loss : 0.023537, loss_ce: 0.012902
iteration 15579 : loss : 0.018771, loss_ce: 0.007766
iteration 15580 : loss : 0.022381, loss_ce: 0.008106
iteration 15581 : loss : 0.029076, loss_ce: 0.006595
iteration 15582 : loss : 0.024292, loss_ce: 0.006172
iteration 15583 : loss : 0.022424, loss_ce: 0.007929
iteration 15584 : loss : 0.023299, loss_ce: 0.009333
iteration 15585 : loss : 0.023064, loss_ce: 0.008998
iteration 15586 : loss : 0.020055, loss_ce: 0.008521
iteration 15587 : loss : 0.027931, loss_ce: 0.011221
iteration 15588 : loss : 0.021106, loss_ce: 0.007060
iteration 15589 : loss : 0.021909, loss_ce: 0.008862
iteration 15590 : loss : 0.027009, loss_ce: 0.010888
iteration 15591 : loss : 0.025829, loss_ce: 0.008054
iteration 15592 : loss : 0.021270, loss_ce: 0.006812
iteration 15593 : loss : 0.024071, loss_ce: 0.009390
iteration 15594 : loss : 0.025652, loss_ce: 0.009003
iteration 15595 : loss : 0.023379, loss_ce: 0.006925
iteration 15596 : loss : 0.025190, loss_ce: 0.010265
iteration 15597 : loss : 0.023246, loss_ce: 0.005688
iteration 15598 : loss : 0.027804, loss_ce: 0.005208
iteration 15599 : loss : 0.023638, loss_ce: 0.006034
iteration 15600 : loss : 0.020843, loss_ce: 0.005218
iteration 15601 : loss : 0.024856, loss_ce: 0.007792
iteration 15602 : loss : 0.033373, loss_ce: 0.008491
iteration 15603 : loss : 0.023811, loss_ce: 0.011929
iteration 15604 : loss : 0.025950, loss_ce: 0.010809
iteration 15605 : loss : 0.021556, loss_ce: 0.009152
iteration 15606 : loss : 0.021895, loss_ce: 0.006479
iteration 15607 : loss : 0.020315, loss_ce: 0.009221
iteration 15608 : loss : 0.025788, loss_ce: 0.009395
iteration 15609 : loss : 0.023578, loss_ce: 0.007422
iteration 15610 : loss : 0.024373, loss_ce: 0.008231
iteration 15611 : loss : 0.021750, loss_ce: 0.011633
iteration 15612 : loss : 0.024164, loss_ce: 0.005058
iteration 15613 : loss : 0.029819, loss_ce: 0.007415
iteration 15614 : loss : 0.019652, loss_ce: 0.005293
iteration 15615 : loss : 0.073370, loss_ce: 0.006761
iteration 15616 : loss : 0.025096, loss_ce: 0.012086
iteration 15617 : loss : 0.025002, loss_ce: 0.004620
iteration 15618 : loss : 0.021726, loss_ce: 0.007456
iteration 15619 : loss : 0.021233, loss_ce: 0.008792
iteration 15620 : loss : 0.021231, loss_ce: 0.007962
iteration 15621 : loss : 0.024207, loss_ce: 0.006030
iteration 15622 : loss : 0.072213, loss_ce: 0.005830
iteration 15623 : loss : 0.025351, loss_ce: 0.008601
iteration 15624 : loss : 0.235703, loss_ce: 0.003748
 84%|████████████████████████▎    | 168/200 [2:47:47<29:05, 54.55s/it]iteration 15625 : loss : 0.023979, loss_ce: 0.006520
iteration 15626 : loss : 0.021676, loss_ce: 0.006440
iteration 15627 : loss : 0.024542, loss_ce: 0.011324
iteration 15628 : loss : 0.026491, loss_ce: 0.009037
iteration 15629 : loss : 0.071893, loss_ce: 0.005186
iteration 15630 : loss : 0.019270, loss_ce: 0.006931
iteration 15631 : loss : 0.028568, loss_ce: 0.011812
iteration 15632 : loss : 0.026974, loss_ce: 0.007464
iteration 15633 : loss : 0.028202, loss_ce: 0.007006
iteration 15634 : loss : 0.021637, loss_ce: 0.006793
iteration 15635 : loss : 0.026522, loss_ce: 0.007203
iteration 15636 : loss : 0.021469, loss_ce: 0.006075
iteration 15637 : loss : 0.022125, loss_ce: 0.006563
iteration 15638 : loss : 0.020409, loss_ce: 0.007941
iteration 15639 : loss : 0.021980, loss_ce: 0.009984
iteration 15640 : loss : 0.023140, loss_ce: 0.011356
iteration 15641 : loss : 0.019546, loss_ce: 0.007384
iteration 15642 : loss : 0.021753, loss_ce: 0.006796
iteration 15643 : loss : 0.020902, loss_ce: 0.007934
iteration 15644 : loss : 0.018767, loss_ce: 0.004737
iteration 15645 : loss : 0.021450, loss_ce: 0.007770
iteration 15646 : loss : 0.030570, loss_ce: 0.010287
iteration 15647 : loss : 0.029318, loss_ce: 0.006710
iteration 15648 : loss : 0.020204, loss_ce: 0.009113
iteration 15649 : loss : 0.024477, loss_ce: 0.007929
iteration 15650 : loss : 0.019840, loss_ce: 0.007393
iteration 15651 : loss : 0.022706, loss_ce: 0.011801
iteration 15652 : loss : 0.029875, loss_ce: 0.007128
iteration 15653 : loss : 0.021008, loss_ce: 0.007454
iteration 15654 : loss : 0.024875, loss_ce: 0.009139
iteration 15655 : loss : 0.023384, loss_ce: 0.005305
iteration 15656 : loss : 0.023945, loss_ce: 0.004422
iteration 15657 : loss : 0.027424, loss_ce: 0.013475
iteration 15658 : loss : 0.024004, loss_ce: 0.005128
iteration 15659 : loss : 0.020659, loss_ce: 0.007585
iteration 15660 : loss : 0.025058, loss_ce: 0.009454
iteration 15661 : loss : 0.020446, loss_ce: 0.004533
iteration 15662 : loss : 0.023151, loss_ce: 0.010451
iteration 15663 : loss : 0.025831, loss_ce: 0.011611
iteration 15664 : loss : 0.025690, loss_ce: 0.008121
iteration 15665 : loss : 0.022368, loss_ce: 0.009133
iteration 15666 : loss : 0.018633, loss_ce: 0.004541
iteration 15667 : loss : 0.024210, loss_ce: 0.011451
iteration 15668 : loss : 0.023669, loss_ce: 0.010576
iteration 15669 : loss : 0.024237, loss_ce: 0.008269
iteration 15670 : loss : 0.020219, loss_ce: 0.007898
iteration 15671 : loss : 0.020892, loss_ce: 0.009466
iteration 15672 : loss : 0.024560, loss_ce: 0.008422
iteration 15673 : loss : 0.022613, loss_ce: 0.008353
iteration 15674 : loss : 0.026417, loss_ce: 0.010106
iteration 15675 : loss : 0.019867, loss_ce: 0.005272
iteration 15676 : loss : 0.074507, loss_ce: 0.002955
iteration 15677 : loss : 0.021863, loss_ce: 0.010987
iteration 15678 : loss : 0.018483, loss_ce: 0.005396
iteration 15679 : loss : 0.016452, loss_ce: 0.006109
iteration 15680 : loss : 0.021113, loss_ce: 0.005690
iteration 15681 : loss : 0.019049, loss_ce: 0.003546
iteration 15682 : loss : 0.021553, loss_ce: 0.007631
iteration 15683 : loss : 0.027302, loss_ce: 0.008406
iteration 15684 : loss : 0.024016, loss_ce: 0.008824
iteration 15685 : loss : 0.023244, loss_ce: 0.007140
iteration 15686 : loss : 0.022364, loss_ce: 0.007879
iteration 15687 : loss : 0.019870, loss_ce: 0.005119
iteration 15688 : loss : 0.041507, loss_ce: 0.007003
iteration 15689 : loss : 0.021689, loss_ce: 0.008581
iteration 15690 : loss : 0.026929, loss_ce: 0.006473
iteration 15691 : loss : 0.074843, loss_ce: 0.005158
iteration 15692 : loss : 0.021955, loss_ce: 0.007480
iteration 15693 : loss : 0.023303, loss_ce: 0.011142
iteration 15694 : loss : 0.072995, loss_ce: 0.007119
iteration 15695 : loss : 0.038083, loss_ce: 0.006441
iteration 15696 : loss : 0.021890, loss_ce: 0.008687
iteration 15697 : loss : 0.021953, loss_ce: 0.006970
iteration 15698 : loss : 0.021021, loss_ce: 0.009432
iteration 15699 : loss : 0.021812, loss_ce: 0.004811
iteration 15700 : loss : 0.021260, loss_ce: 0.010807
iteration 15701 : loss : 0.025546, loss_ce: 0.013297
iteration 15702 : loss : 0.074898, loss_ce: 0.004996
iteration 15703 : loss : 0.025736, loss_ce: 0.008982
iteration 15704 : loss : 0.023162, loss_ce: 0.008777
iteration 15705 : loss : 0.027773, loss_ce: 0.008567
iteration 15706 : loss : 0.024047, loss_ce: 0.008743
iteration 15707 : loss : 0.021883, loss_ce: 0.006328
iteration 15708 : loss : 0.026130, loss_ce: 0.008779
iteration 15709 : loss : 0.017783, loss_ce: 0.006848
iteration 15710 : loss : 0.026198, loss_ce: 0.006517
iteration 15711 : loss : 0.020694, loss_ce: 0.005976
iteration 15712 : loss : 0.019746, loss_ce: 0.006223
iteration 15713 : loss : 0.022283, loss_ce: 0.008138
iteration 15714 : loss : 0.022519, loss_ce: 0.005657
iteration 15715 : loss : 0.029106, loss_ce: 0.005714
iteration 15716 : loss : 0.021583, loss_ce: 0.005367
iteration 15717 : loss : 0.280326, loss_ce: 0.004634
 84%|████████████████████████▌    | 169/200 [2:48:41<28:11, 54.56s/it]iteration 15718 : loss : 0.022807, loss_ce: 0.006131
iteration 15719 : loss : 0.020910, loss_ce: 0.005526
iteration 15720 : loss : 0.024939, loss_ce: 0.010242
iteration 15721 : loss : 0.023601, loss_ce: 0.009081
iteration 15722 : loss : 0.019364, loss_ce: 0.004653
iteration 15723 : loss : 0.028302, loss_ce: 0.006963
iteration 15724 : loss : 0.029006, loss_ce: 0.010041
iteration 15725 : loss : 0.019676, loss_ce: 0.006674
iteration 15726 : loss : 0.021640, loss_ce: 0.007864
iteration 15727 : loss : 0.019002, loss_ce: 0.006334
iteration 15728 : loss : 0.021833, loss_ce: 0.008648
iteration 15729 : loss : 0.023951, loss_ce: 0.010313
iteration 15730 : loss : 0.019351, loss_ce: 0.006870
iteration 15731 : loss : 0.071924, loss_ce: 0.006644
iteration 15732 : loss : 0.023899, loss_ce: 0.009586
iteration 15733 : loss : 0.020822, loss_ce: 0.005071
iteration 15734 : loss : 0.021834, loss_ce: 0.007526
iteration 15735 : loss : 0.023100, loss_ce: 0.007403
iteration 15736 : loss : 0.024009, loss_ce: 0.010263
iteration 15737 : loss : 0.026591, loss_ce: 0.010058
iteration 15738 : loss : 0.020542, loss_ce: 0.008297
iteration 15739 : loss : 0.023403, loss_ce: 0.008278
iteration 15740 : loss : 0.020417, loss_ce: 0.007918
iteration 15741 : loss : 0.019675, loss_ce: 0.006879
iteration 15742 : loss : 0.018080, loss_ce: 0.004943
iteration 15743 : loss : 0.019392, loss_ce: 0.007679
iteration 15744 : loss : 0.019769, loss_ce: 0.005607
iteration 15745 : loss : 0.024803, loss_ce: 0.010895
iteration 15746 : loss : 0.020645, loss_ce: 0.005599
iteration 15747 : loss : 0.021469, loss_ce: 0.006154
iteration 15748 : loss : 0.074519, loss_ce: 0.006373
iteration 15749 : loss : 0.022587, loss_ce: 0.008991
iteration 15750 : loss : 0.019387, loss_ce: 0.007917
iteration 15751 : loss : 0.024902, loss_ce: 0.010097
iteration 15752 : loss : 0.028149, loss_ce: 0.008009
iteration 15753 : loss : 0.019922, loss_ce: 0.005984
iteration 15754 : loss : 0.019208, loss_ce: 0.008222
iteration 15755 : loss : 0.023378, loss_ce: 0.007566
iteration 15756 : loss : 0.029763, loss_ce: 0.009196
iteration 15757 : loss : 0.027553, loss_ce: 0.007294
iteration 15758 : loss : 0.020559, loss_ce: 0.008959
iteration 15759 : loss : 0.178189, loss_ce: 0.006005
iteration 15760 : loss : 0.023539, loss_ce: 0.009313
iteration 15761 : loss : 0.021674, loss_ce: 0.006118
iteration 15762 : loss : 0.022322, loss_ce: 0.007409
iteration 15763 : loss : 0.024419, loss_ce: 0.007940
iteration 15764 : loss : 0.022655, loss_ce: 0.009356
iteration 15765 : loss : 0.021362, loss_ce: 0.006297
iteration 15766 : loss : 0.029362, loss_ce: 0.004747
iteration 15767 : loss : 0.021277, loss_ce: 0.008026
iteration 15768 : loss : 0.025091, loss_ce: 0.006406
iteration 15769 : loss : 0.020960, loss_ce: 0.006827
iteration 15770 : loss : 0.024194, loss_ce: 0.006493
iteration 15771 : loss : 0.018504, loss_ce: 0.004608
iteration 15772 : loss : 0.022405, loss_ce: 0.009154
iteration 15773 : loss : 0.020831, loss_ce: 0.007181
iteration 15774 : loss : 0.025407, loss_ce: 0.007534
iteration 15775 : loss : 0.020423, loss_ce: 0.006010
iteration 15776 : loss : 0.024658, loss_ce: 0.009093
iteration 15777 : loss : 0.025014, loss_ce: 0.010018
iteration 15778 : loss : 0.020266, loss_ce: 0.006653
iteration 15779 : loss : 0.022160, loss_ce: 0.007950
iteration 15780 : loss : 0.022396, loss_ce: 0.007735
iteration 15781 : loss : 0.020723, loss_ce: 0.008153
iteration 15782 : loss : 0.020404, loss_ce: 0.009095
iteration 15783 : loss : 0.029951, loss_ce: 0.008903
iteration 15784 : loss : 0.020865, loss_ce: 0.007498
iteration 15785 : loss : 0.028022, loss_ce: 0.007044
iteration 15786 : loss : 0.029430, loss_ce: 0.010422
iteration 15787 : loss : 0.018969, loss_ce: 0.006586
iteration 15788 : loss : 0.023305, loss_ce: 0.009327
iteration 15789 : loss : 0.123131, loss_ce: 0.004438
iteration 15790 : loss : 0.021213, loss_ce: 0.008121
iteration 15791 : loss : 0.021294, loss_ce: 0.008529
iteration 15792 : loss : 0.020505, loss_ce: 0.006452
iteration 15793 : loss : 0.022728, loss_ce: 0.009171
iteration 15794 : loss : 0.019498, loss_ce: 0.010440
iteration 15795 : loss : 0.023560, loss_ce: 0.004385
iteration 15796 : loss : 0.025449, loss_ce: 0.005562
iteration 15797 : loss : 0.024763, loss_ce: 0.009992
iteration 15798 : loss : 0.072818, loss_ce: 0.005205
iteration 15799 : loss : 0.029056, loss_ce: 0.010488
iteration 15800 : loss : 0.023135, loss_ce: 0.007816
iteration 15801 : loss : 0.022060, loss_ce: 0.007141
iteration 15802 : loss : 0.022000, loss_ce: 0.011771
iteration 15803 : loss : 0.021332, loss_ce: 0.004091
iteration 15804 : loss : 0.022325, loss_ce: 0.004712
iteration 15805 : loss : 0.019532, loss_ce: 0.008727
iteration 15806 : loss : 0.074053, loss_ce: 0.006390
iteration 15807 : loss : 0.021265, loss_ce: 0.010052
iteration 15808 : loss : 0.028471, loss_ce: 0.008641
iteration 15809 : loss : 0.019393, loss_ce: 0.005224
iteration 15810 : loss : 0.187830, loss_ce: 0.016661
 85%|████████████████████████▋    | 170/200 [2:49:36<27:16, 54.56s/it]iteration 15811 : loss : 0.027955, loss_ce: 0.005986
iteration 15812 : loss : 0.023012, loss_ce: 0.010882
iteration 15813 : loss : 0.023906, loss_ce: 0.009814
iteration 15814 : loss : 0.023892, loss_ce: 0.010419
iteration 15815 : loss : 0.022971, loss_ce: 0.007148
iteration 15816 : loss : 0.074446, loss_ce: 0.007498
iteration 15817 : loss : 0.023264, loss_ce: 0.009135
iteration 15818 : loss : 0.026664, loss_ce: 0.010398
iteration 15819 : loss : 0.081550, loss_ce: 0.005908
iteration 15820 : loss : 0.025785, loss_ce: 0.010228
iteration 15821 : loss : 0.022227, loss_ce: 0.009773
iteration 15822 : loss : 0.019146, loss_ce: 0.006324
iteration 15823 : loss : 0.018490, loss_ce: 0.005624
iteration 15824 : loss : 0.019669, loss_ce: 0.007789
iteration 15825 : loss : 0.022293, loss_ce: 0.008392
iteration 15826 : loss : 0.021566, loss_ce: 0.007682
iteration 15827 : loss : 0.073674, loss_ce: 0.008035
iteration 15828 : loss : 0.023811, loss_ce: 0.007173
iteration 15829 : loss : 0.028940, loss_ce: 0.007976
iteration 15830 : loss : 0.023407, loss_ce: 0.007433
iteration 15831 : loss : 0.019719, loss_ce: 0.008595
iteration 15832 : loss : 0.023669, loss_ce: 0.010471
iteration 15833 : loss : 0.025869, loss_ce: 0.009898
iteration 15834 : loss : 0.026159, loss_ce: 0.007941
iteration 15835 : loss : 0.022983, loss_ce: 0.009234
iteration 15836 : loss : 0.020557, loss_ce: 0.006369
iteration 15837 : loss : 0.021853, loss_ce: 0.008174
iteration 15838 : loss : 0.022252, loss_ce: 0.006566
iteration 15839 : loss : 0.026895, loss_ce: 0.011639
iteration 15840 : loss : 0.022489, loss_ce: 0.006441
iteration 15841 : loss : 0.021966, loss_ce: 0.007933
iteration 15842 : loss : 0.023845, loss_ce: 0.005214
iteration 15843 : loss : 0.021910, loss_ce: 0.008102
iteration 15844 : loss : 0.020164, loss_ce: 0.006334
iteration 15845 : loss : 0.019514, loss_ce: 0.008100
iteration 15846 : loss : 0.026294, loss_ce: 0.009182
iteration 15847 : loss : 0.019598, loss_ce: 0.007267
iteration 15848 : loss : 0.020308, loss_ce: 0.006777
iteration 15849 : loss : 0.024338, loss_ce: 0.011640
iteration 15850 : loss : 0.018375, loss_ce: 0.005410
iteration 15851 : loss : 0.019609, loss_ce: 0.006759
iteration 15852 : loss : 0.021521, loss_ce: 0.007492
iteration 15853 : loss : 0.026213, loss_ce: 0.007330
iteration 15854 : loss : 0.024200, loss_ce: 0.009379
iteration 15855 : loss : 0.020863, loss_ce: 0.007188
iteration 15856 : loss : 0.023910, loss_ce: 0.007651
iteration 15857 : loss : 0.022635, loss_ce: 0.007379
iteration 15858 : loss : 0.019456, loss_ce: 0.006650
iteration 15859 : loss : 0.076130, loss_ce: 0.006162
iteration 15860 : loss : 0.020317, loss_ce: 0.005635
iteration 15861 : loss : 0.023051, loss_ce: 0.007901
iteration 15862 : loss : 0.020715, loss_ce: 0.007570
iteration 15863 : loss : 0.026182, loss_ce: 0.006451
iteration 15864 : loss : 0.020738, loss_ce: 0.004893
iteration 15865 : loss : 0.073918, loss_ce: 0.004277
iteration 15866 : loss : 0.071470, loss_ce: 0.005241
iteration 15867 : loss : 0.022769, loss_ce: 0.006075
iteration 15868 : loss : 0.073160, loss_ce: 0.007352
iteration 15869 : loss : 0.026532, loss_ce: 0.014086
iteration 15870 : loss : 0.091567, loss_ce: 0.003368
iteration 15871 : loss : 0.022723, loss_ce: 0.008715
iteration 15872 : loss : 0.019196, loss_ce: 0.007005
iteration 15873 : loss : 0.019971, loss_ce: 0.007224
iteration 15874 : loss : 0.020011, loss_ce: 0.004687
iteration 15875 : loss : 0.027020, loss_ce: 0.010155
iteration 15876 : loss : 0.020326, loss_ce: 0.007886
iteration 15877 : loss : 0.028746, loss_ce: 0.008241
iteration 15878 : loss : 0.020963, loss_ce: 0.006501
iteration 15879 : loss : 0.021455, loss_ce: 0.006921
iteration 15880 : loss : 0.027399, loss_ce: 0.012223
iteration 15881 : loss : 0.023744, loss_ce: 0.011143
iteration 15882 : loss : 0.071142, loss_ce: 0.006445
iteration 15883 : loss : 0.020083, loss_ce: 0.004712
iteration 15884 : loss : 0.018191, loss_ce: 0.007045
iteration 15885 : loss : 0.023444, loss_ce: 0.008147
iteration 15886 : loss : 0.020809, loss_ce: 0.003405
iteration 15887 : loss : 0.021878, loss_ce: 0.005989
iteration 15888 : loss : 0.019602, loss_ce: 0.006097
iteration 15889 : loss : 0.020392, loss_ce: 0.006690
iteration 15890 : loss : 0.023262, loss_ce: 0.008903
iteration 15891 : loss : 0.019458, loss_ce: 0.008621
iteration 15892 : loss : 0.021889, loss_ce: 0.006303
iteration 15893 : loss : 0.020262, loss_ce: 0.007815
iteration 15894 : loss : 0.022038, loss_ce: 0.009916
iteration 15895 : loss : 0.021902, loss_ce: 0.007426
iteration 15896 : loss : 0.070344, loss_ce: 0.004906
iteration 15897 : loss : 0.025036, loss_ce: 0.009850
iteration 15898 : loss : 0.027662, loss_ce: 0.009824
iteration 15899 : loss : 0.074376, loss_ce: 0.004975
iteration 15900 : loss : 0.023654, loss_ce: 0.009865
iteration 15901 : loss : 0.075103, loss_ce: 0.004650
iteration 15902 : loss : 0.073577, loss_ce: 0.007870
iteration 15903 : loss : 0.240017, loss_ce: 0.004738
 86%|████████████████████████▊    | 171/200 [2:50:31<26:22, 54.58s/it]iteration 15904 : loss : 0.022943, loss_ce: 0.006461
iteration 15905 : loss : 0.022802, loss_ce: 0.007510
iteration 15906 : loss : 0.024192, loss_ce: 0.009924
iteration 15907 : loss : 0.020293, loss_ce: 0.006826
iteration 15908 : loss : 0.019765, loss_ce: 0.005119
iteration 15909 : loss : 0.022715, loss_ce: 0.008358
iteration 15910 : loss : 0.023894, loss_ce: 0.007309
iteration 15911 : loss : 0.021146, loss_ce: 0.005609
iteration 15912 : loss : 0.022871, loss_ce: 0.003610
iteration 15913 : loss : 0.028401, loss_ce: 0.005523
iteration 15914 : loss : 0.026160, loss_ce: 0.009676
iteration 15915 : loss : 0.024612, loss_ce: 0.008289
iteration 15916 : loss : 0.019252, loss_ce: 0.007321
iteration 15917 : loss : 0.023733, loss_ce: 0.008022
iteration 15918 : loss : 0.021675, loss_ce: 0.007414
iteration 15919 : loss : 0.022292, loss_ce: 0.006636
iteration 15920 : loss : 0.023114, loss_ce: 0.013047
iteration 15921 : loss : 0.025256, loss_ce: 0.010613
iteration 15922 : loss : 0.022786, loss_ce: 0.006982
iteration 15923 : loss : 0.026108, loss_ce: 0.009716
iteration 15924 : loss : 0.022331, loss_ce: 0.009103
iteration 15925 : loss : 0.026563, loss_ce: 0.011910
iteration 15926 : loss : 0.021530, loss_ce: 0.005997
iteration 15927 : loss : 0.026475, loss_ce: 0.012541
iteration 15928 : loss : 0.021517, loss_ce: 0.010832
iteration 15929 : loss : 0.021202, loss_ce: 0.007155
iteration 15930 : loss : 0.019723, loss_ce: 0.008321
iteration 15931 : loss : 0.073166, loss_ce: 0.006145
iteration 15932 : loss : 0.078590, loss_ce: 0.005244
iteration 15933 : loss : 0.021539, loss_ce: 0.005827
iteration 15934 : loss : 0.020894, loss_ce: 0.009439
iteration 15935 : loss : 0.021393, loss_ce: 0.005128
iteration 15936 : loss : 0.023031, loss_ce: 0.007549
iteration 15937 : loss : 0.025033, loss_ce: 0.008955
iteration 15938 : loss : 0.030938, loss_ce: 0.009117
iteration 15939 : loss : 0.020421, loss_ce: 0.005111
iteration 15940 : loss : 0.023070, loss_ce: 0.008186
iteration 15941 : loss : 0.021065, loss_ce: 0.005732
iteration 15942 : loss : 0.021867, loss_ce: 0.008411
iteration 15943 : loss : 0.023296, loss_ce: 0.005980
iteration 15944 : loss : 0.025305, loss_ce: 0.011789
iteration 15945 : loss : 0.021737, loss_ce: 0.008609
iteration 15946 : loss : 0.023200, loss_ce: 0.007044
iteration 15947 : loss : 0.021513, loss_ce: 0.006428
iteration 15948 : loss : 0.020448, loss_ce: 0.007706
iteration 15949 : loss : 0.026236, loss_ce: 0.005458
iteration 15950 : loss : 0.025686, loss_ce: 0.008416
iteration 15951 : loss : 0.019196, loss_ce: 0.007736
iteration 15952 : loss : 0.026324, loss_ce: 0.012395
iteration 15953 : loss : 0.020608, loss_ce: 0.005961
iteration 15954 : loss : 0.025676, loss_ce: 0.008348
iteration 15955 : loss : 0.020539, loss_ce: 0.006404
iteration 15956 : loss : 0.020445, loss_ce: 0.007573
iteration 15957 : loss : 0.023299, loss_ce: 0.005260
iteration 15958 : loss : 0.019922, loss_ce: 0.006513
iteration 15959 : loss : 0.021010, loss_ce: 0.006741
iteration 15960 : loss : 0.020744, loss_ce: 0.006314
iteration 15961 : loss : 0.021108, loss_ce: 0.006990
iteration 15962 : loss : 0.021157, loss_ce: 0.008347
iteration 15963 : loss : 0.020953, loss_ce: 0.010485
iteration 15964 : loss : 0.029461, loss_ce: 0.009104
iteration 15965 : loss : 0.049455, loss_ce: 0.004968
iteration 15966 : loss : 0.023791, loss_ce: 0.009770
iteration 15967 : loss : 0.021678, loss_ce: 0.006841
iteration 15968 : loss : 0.023311, loss_ce: 0.004316
iteration 15969 : loss : 0.020123, loss_ce: 0.008222
iteration 15970 : loss : 0.022473, loss_ce: 0.009304
iteration 15971 : loss : 0.022485, loss_ce: 0.005702
iteration 15972 : loss : 0.021702, loss_ce: 0.010195
iteration 15973 : loss : 0.022651, loss_ce: 0.012700
iteration 15974 : loss : 0.022612, loss_ce: 0.008871
iteration 15975 : loss : 0.023565, loss_ce: 0.009323
iteration 15976 : loss : 0.023240, loss_ce: 0.006273
iteration 15977 : loss : 0.022471, loss_ce: 0.009014
iteration 15978 : loss : 0.027120, loss_ce: 0.007466
iteration 15979 : loss : 0.100301, loss_ce: 0.001909
iteration 15980 : loss : 0.021082, loss_ce: 0.007093
iteration 15981 : loss : 0.025286, loss_ce: 0.005073
iteration 15982 : loss : 0.025400, loss_ce: 0.006337
iteration 15983 : loss : 0.023294, loss_ce: 0.004733
iteration 15984 : loss : 0.021510, loss_ce: 0.006889
iteration 15985 : loss : 0.023828, loss_ce: 0.010863
iteration 15986 : loss : 0.020778, loss_ce: 0.007572
iteration 15987 : loss : 0.026764, loss_ce: 0.009510
iteration 15988 : loss : 0.026829, loss_ce: 0.013127
iteration 15989 : loss : 0.021691, loss_ce: 0.007746
iteration 15990 : loss : 0.022071, loss_ce: 0.007371
iteration 15991 : loss : 0.020727, loss_ce: 0.006248
iteration 15992 : loss : 0.026054, loss_ce: 0.005668
iteration 15993 : loss : 0.020731, loss_ce: 0.007499
iteration 15994 : loss : 0.021114, loss_ce: 0.007044
iteration 15995 : loss : 0.023605, loss_ce: 0.006771
iteration 15996 : loss : 0.243711, loss_ce: 0.023779
 86%|████████████████████████▉    | 172/200 [2:51:25<25:28, 54.58s/it]iteration 15997 : loss : 0.020554, loss_ce: 0.006860
iteration 15998 : loss : 0.023598, loss_ce: 0.008572
iteration 15999 : loss : 0.022718, loss_ce: 0.006439
iteration 16000 : loss : 0.024596, loss_ce: 0.010668
iteration 16001 : loss : 0.021361, loss_ce: 0.007016
iteration 16002 : loss : 0.070124, loss_ce: 0.002825
iteration 16003 : loss : 0.025141, loss_ce: 0.007617
iteration 16004 : loss : 0.021187, loss_ce: 0.008135
iteration 16005 : loss : 0.023780, loss_ce: 0.010343
iteration 16006 : loss : 0.027880, loss_ce: 0.006343
iteration 16007 : loss : 0.027393, loss_ce: 0.006198
iteration 16008 : loss : 0.024408, loss_ce: 0.009045
iteration 16009 : loss : 0.020522, loss_ce: 0.007970
iteration 16010 : loss : 0.022829, loss_ce: 0.006847
iteration 16011 : loss : 0.022380, loss_ce: 0.008921
iteration 16012 : loss : 0.020097, loss_ce: 0.004898
iteration 16013 : loss : 0.021012, loss_ce: 0.004560
iteration 16014 : loss : 0.022563, loss_ce: 0.007120
iteration 16015 : loss : 0.022674, loss_ce: 0.008444
iteration 16016 : loss : 0.019018, loss_ce: 0.009545
iteration 16017 : loss : 0.030277, loss_ce: 0.006978
iteration 16018 : loss : 0.023246, loss_ce: 0.007836
iteration 16019 : loss : 0.020985, loss_ce: 0.008167
iteration 16020 : loss : 0.021085, loss_ce: 0.006083
iteration 16021 : loss : 0.024433, loss_ce: 0.008472
iteration 16022 : loss : 0.019698, loss_ce: 0.004747
iteration 16023 : loss : 0.073631, loss_ce: 0.005401
iteration 16024 : loss : 0.020842, loss_ce: 0.004760
iteration 16025 : loss : 0.021433, loss_ce: 0.011421
iteration 16026 : loss : 0.026955, loss_ce: 0.006255
iteration 16027 : loss : 0.020227, loss_ce: 0.008507
iteration 16028 : loss : 0.022694, loss_ce: 0.007620
iteration 16029 : loss : 0.019869, loss_ce: 0.008214
iteration 16030 : loss : 0.018327, loss_ce: 0.005995
iteration 16031 : loss : 0.021098, loss_ce: 0.006855
iteration 16032 : loss : 0.022626, loss_ce: 0.006723
iteration 16033 : loss : 0.022364, loss_ce: 0.007846
iteration 16034 : loss : 0.024037, loss_ce: 0.008720
iteration 16035 : loss : 0.022846, loss_ce: 0.006735
iteration 16036 : loss : 0.031307, loss_ce: 0.009895
iteration 16037 : loss : 0.022204, loss_ce: 0.007191
iteration 16038 : loss : 0.021106, loss_ce: 0.005744
iteration 16039 : loss : 0.026259, loss_ce: 0.007135
iteration 16040 : loss : 0.023679, loss_ce: 0.008042
iteration 16041 : loss : 0.020569, loss_ce: 0.008225
iteration 16042 : loss : 0.024028, loss_ce: 0.007448
iteration 16043 : loss : 0.024966, loss_ce: 0.010560
iteration 16044 : loss : 0.024124, loss_ce: 0.007183
iteration 16045 : loss : 0.023149, loss_ce: 0.008156
iteration 16046 : loss : 0.032640, loss_ce: 0.006310
iteration 16047 : loss : 0.026880, loss_ce: 0.015427
iteration 16048 : loss : 0.020950, loss_ce: 0.009837
iteration 16049 : loss : 0.027046, loss_ce: 0.003459
iteration 16050 : loss : 0.027817, loss_ce: 0.008920
iteration 16051 : loss : 0.020892, loss_ce: 0.006434
iteration 16052 : loss : 0.073559, loss_ce: 0.006967
iteration 16053 : loss : 0.019810, loss_ce: 0.006750
iteration 16054 : loss : 0.017847, loss_ce: 0.002676
iteration 16055 : loss : 0.024345, loss_ce: 0.006503
iteration 16056 : loss : 0.024186, loss_ce: 0.008310
iteration 16057 : loss : 0.020516, loss_ce: 0.006207
iteration 16058 : loss : 0.021072, loss_ce: 0.008418
iteration 16059 : loss : 0.026058, loss_ce: 0.007121
iteration 16060 : loss : 0.019788, loss_ce: 0.008218
iteration 16061 : loss : 0.026667, loss_ce: 0.009841
iteration 16062 : loss : 0.024241, loss_ce: 0.007714
iteration 16063 : loss : 0.019212, loss_ce: 0.007165
iteration 16064 : loss : 0.022978, loss_ce: 0.009776
iteration 16065 : loss : 0.020941, loss_ce: 0.005808
iteration 16066 : loss : 0.024287, loss_ce: 0.005861
iteration 16067 : loss : 0.018590, loss_ce: 0.005104
iteration 16068 : loss : 0.020238, loss_ce: 0.008540
iteration 16069 : loss : 0.023957, loss_ce: 0.009597
iteration 16070 : loss : 0.020143, loss_ce: 0.007622
iteration 16071 : loss : 0.026871, loss_ce: 0.010130
iteration 16072 : loss : 0.019930, loss_ce: 0.006685
iteration 16073 : loss : 0.023937, loss_ce: 0.008279
iteration 16074 : loss : 0.022282, loss_ce: 0.011866
iteration 16075 : loss : 0.025790, loss_ce: 0.011883
iteration 16076 : loss : 0.072176, loss_ce: 0.005760
iteration 16077 : loss : 0.021449, loss_ce: 0.007388
iteration 16078 : loss : 0.028495, loss_ce: 0.006906
iteration 16079 : loss : 0.018899, loss_ce: 0.004913
iteration 16080 : loss : 0.024861, loss_ce: 0.006493
iteration 16081 : loss : 0.026951, loss_ce: 0.013413
iteration 16082 : loss : 0.073748, loss_ce: 0.007332
iteration 16083 : loss : 0.026798, loss_ce: 0.004838
iteration 16084 : loss : 0.018692, loss_ce: 0.008876
iteration 16085 : loss : 0.019183, loss_ce: 0.007907
iteration 16086 : loss : 0.027828, loss_ce: 0.007414
iteration 16087 : loss : 0.023404, loss_ce: 0.012014
iteration 16088 : loss : 0.017386, loss_ce: 0.004828
iteration 16089 : loss : 0.070097, loss_ce: 0.020283
 86%|█████████████████████████    | 173/200 [2:52:20<24:32, 54.55s/it]iteration 16090 : loss : 0.020728, loss_ce: 0.006628
iteration 16091 : loss : 0.023324, loss_ce: 0.009102
iteration 16092 : loss : 0.021726, loss_ce: 0.004929
iteration 16093 : loss : 0.022604, loss_ce: 0.007412
iteration 16094 : loss : 0.023364, loss_ce: 0.010493
iteration 16095 : loss : 0.021888, loss_ce: 0.007666
iteration 16096 : loss : 0.019425, loss_ce: 0.006077
iteration 16097 : loss : 0.020384, loss_ce: 0.008263
iteration 16098 : loss : 0.023717, loss_ce: 0.005562
iteration 16099 : loss : 0.020544, loss_ce: 0.005915
iteration 16100 : loss : 0.022028, loss_ce: 0.011861
iteration 16101 : loss : 0.018552, loss_ce: 0.005557
iteration 16102 : loss : 0.029813, loss_ce: 0.006550
iteration 16103 : loss : 0.016210, loss_ce: 0.005127
iteration 16104 : loss : 0.023371, loss_ce: 0.007418
iteration 16105 : loss : 0.017394, loss_ce: 0.005480
iteration 16106 : loss : 0.019680, loss_ce: 0.008316
iteration 16107 : loss : 0.024258, loss_ce: 0.011843
iteration 16108 : loss : 0.016440, loss_ce: 0.008462
iteration 16109 : loss : 0.017246, loss_ce: 0.005305
iteration 16110 : loss : 0.021421, loss_ce: 0.005784
iteration 16111 : loss : 0.019904, loss_ce: 0.007937
iteration 16112 : loss : 0.024931, loss_ce: 0.010739
iteration 16113 : loss : 0.024418, loss_ce: 0.010100
iteration 16114 : loss : 0.023747, loss_ce: 0.011438
iteration 16115 : loss : 0.024761, loss_ce: 0.008375
iteration 16116 : loss : 0.023077, loss_ce: 0.009216
iteration 16117 : loss : 0.020535, loss_ce: 0.006219
iteration 16118 : loss : 0.073440, loss_ce: 0.004190
iteration 16119 : loss : 0.024688, loss_ce: 0.009764
iteration 16120 : loss : 0.020726, loss_ce: 0.007272
iteration 16121 : loss : 0.071020, loss_ce: 0.005132
iteration 16122 : loss : 0.020461, loss_ce: 0.007704
iteration 16123 : loss : 0.020712, loss_ce: 0.008489
iteration 16124 : loss : 0.043483, loss_ce: 0.006284
iteration 16125 : loss : 0.030678, loss_ce: 0.006913
iteration 16126 : loss : 0.029268, loss_ce: 0.005468
iteration 16127 : loss : 0.028050, loss_ce: 0.012357
iteration 16128 : loss : 0.026311, loss_ce: 0.008733
iteration 16129 : loss : 0.022978, loss_ce: 0.007590
iteration 16130 : loss : 0.021241, loss_ce: 0.009565
iteration 16131 : loss : 0.028292, loss_ce: 0.008447
iteration 16132 : loss : 0.023889, loss_ce: 0.010776
iteration 16133 : loss : 0.020230, loss_ce: 0.005098
iteration 16134 : loss : 0.021600, loss_ce: 0.006956
iteration 16135 : loss : 0.075034, loss_ce: 0.008597
iteration 16136 : loss : 0.024092, loss_ce: 0.006323
iteration 16137 : loss : 0.018945, loss_ce: 0.007036
iteration 16138 : loss : 0.021064, loss_ce: 0.006134
iteration 16139 : loss : 0.038316, loss_ce: 0.008076
iteration 16140 : loss : 0.021650, loss_ce: 0.008873
iteration 16141 : loss : 0.020553, loss_ce: 0.006471
iteration 16142 : loss : 0.020824, loss_ce: 0.006523
iteration 16143 : loss : 0.022294, loss_ce: 0.009129
iteration 16144 : loss : 0.025989, loss_ce: 0.009565
iteration 16145 : loss : 0.022240, loss_ce: 0.005842
iteration 16146 : loss : 0.022464, loss_ce: 0.006972
iteration 16147 : loss : 0.019677, loss_ce: 0.008374
iteration 16148 : loss : 0.040315, loss_ce: 0.007755
iteration 16149 : loss : 0.021083, loss_ce: 0.008168
iteration 16150 : loss : 0.023901, loss_ce: 0.007923
iteration 16151 : loss : 0.020348, loss_ce: 0.003835
iteration 16152 : loss : 0.022093, loss_ce: 0.010226
iteration 16153 : loss : 0.021306, loss_ce: 0.005767
iteration 16154 : loss : 0.023621, loss_ce: 0.009870
iteration 16155 : loss : 0.022198, loss_ce: 0.007311
iteration 16156 : loss : 0.022057, loss_ce: 0.004215
iteration 16157 : loss : 0.018858, loss_ce: 0.004506
iteration 16158 : loss : 0.023178, loss_ce: 0.009510
iteration 16159 : loss : 0.022897, loss_ce: 0.006860
iteration 16160 : loss : 0.020325, loss_ce: 0.010233
iteration 16161 : loss : 0.021985, loss_ce: 0.007868
iteration 16162 : loss : 0.022026, loss_ce: 0.007455
iteration 16163 : loss : 0.025742, loss_ce: 0.007908
iteration 16164 : loss : 0.078438, loss_ce: 0.002881
iteration 16165 : loss : 0.020323, loss_ce: 0.007892
iteration 16166 : loss : 0.021793, loss_ce: 0.006514
iteration 16167 : loss : 0.022857, loss_ce: 0.008811
iteration 16168 : loss : 0.021943, loss_ce: 0.007167
iteration 16169 : loss : 0.025842, loss_ce: 0.011498
iteration 16170 : loss : 0.024566, loss_ce: 0.007292
iteration 16171 : loss : 0.020613, loss_ce: 0.008410
iteration 16172 : loss : 0.018975, loss_ce: 0.008062
iteration 16173 : loss : 0.072793, loss_ce: 0.003419
iteration 16174 : loss : 0.028116, loss_ce: 0.013562
iteration 16175 : loss : 0.021400, loss_ce: 0.009241
iteration 16176 : loss : 0.020472, loss_ce: 0.004121
iteration 16177 : loss : 0.024146, loss_ce: 0.009107
iteration 16178 : loss : 0.074174, loss_ce: 0.008510
iteration 16179 : loss : 0.024065, loss_ce: 0.011243
iteration 16180 : loss : 0.023833, loss_ce: 0.008064
iteration 16181 : loss : 0.019652, loss_ce: 0.004636
iteration 16182 : loss : 0.079476, loss_ce: 0.010859
 87%|█████████████████████████▏   | 174/200 [2:53:14<23:38, 54.57s/it]iteration 16183 : loss : 0.023002, loss_ce: 0.009685
iteration 16184 : loss : 0.021898, loss_ce: 0.007561
iteration 16185 : loss : 0.072821, loss_ce: 0.005117
iteration 16186 : loss : 0.025485, loss_ce: 0.007585
iteration 16187 : loss : 0.074981, loss_ce: 0.009712
iteration 16188 : loss : 0.021045, loss_ce: 0.007019
iteration 16189 : loss : 0.021753, loss_ce: 0.005104
iteration 16190 : loss : 0.018882, loss_ce: 0.008497
iteration 16191 : loss : 0.023656, loss_ce: 0.006800
iteration 16192 : loss : 0.022685, loss_ce: 0.008135
iteration 16193 : loss : 0.024074, loss_ce: 0.008342
iteration 16194 : loss : 0.069480, loss_ce: 0.006768
iteration 16195 : loss : 0.019110, loss_ce: 0.005573
iteration 16196 : loss : 0.022696, loss_ce: 0.008837
iteration 16197 : loss : 0.020769, loss_ce: 0.006842
iteration 16198 : loss : 0.019907, loss_ce: 0.007345
iteration 16199 : loss : 0.021015, loss_ce: 0.007007
iteration 16200 : loss : 0.024990, loss_ce: 0.007873
iteration 16201 : loss : 0.021398, loss_ce: 0.007406
iteration 16202 : loss : 0.019797, loss_ce: 0.003245
iteration 16203 : loss : 0.024034, loss_ce: 0.010664
iteration 16204 : loss : 0.017754, loss_ce: 0.009374
iteration 16205 : loss : 0.071225, loss_ce: 0.004803
iteration 16206 : loss : 0.024574, loss_ce: 0.007095
iteration 16207 : loss : 0.022586, loss_ce: 0.009032
iteration 16208 : loss : 0.022357, loss_ce: 0.009109
iteration 16209 : loss : 0.020916, loss_ce: 0.006510
iteration 16210 : loss : 0.022793, loss_ce: 0.010456
iteration 16211 : loss : 0.021636, loss_ce: 0.007403
iteration 16212 : loss : 0.027340, loss_ce: 0.006553
iteration 16213 : loss : 0.021626, loss_ce: 0.007693
iteration 16214 : loss : 0.025722, loss_ce: 0.008437
iteration 16215 : loss : 0.019772, loss_ce: 0.008085
iteration 16216 : loss : 0.017514, loss_ce: 0.006522
iteration 16217 : loss : 0.023643, loss_ce: 0.007957
iteration 16218 : loss : 0.027585, loss_ce: 0.011800
iteration 16219 : loss : 0.019859, loss_ce: 0.006331
iteration 16220 : loss : 0.019582, loss_ce: 0.005895
iteration 16221 : loss : 0.021838, loss_ce: 0.005877
iteration 16222 : loss : 0.032725, loss_ce: 0.010431
iteration 16223 : loss : 0.019793, loss_ce: 0.009115
iteration 16224 : loss : 0.021087, loss_ce: 0.005742
iteration 16225 : loss : 0.020284, loss_ce: 0.006863
iteration 16226 : loss : 0.027739, loss_ce: 0.006512
iteration 16227 : loss : 0.021539, loss_ce: 0.010949
iteration 16228 : loss : 0.019302, loss_ce: 0.004388
iteration 16229 : loss : 0.020554, loss_ce: 0.008404
iteration 16230 : loss : 0.017598, loss_ce: 0.007923
iteration 16231 : loss : 0.021052, loss_ce: 0.005942
iteration 16232 : loss : 0.020391, loss_ce: 0.009545
iteration 16233 : loss : 0.027759, loss_ce: 0.013626
iteration 16234 : loss : 0.025716, loss_ce: 0.005635
iteration 16235 : loss : 0.017638, loss_ce: 0.005952
iteration 16236 : loss : 0.023155, loss_ce: 0.003485
iteration 16237 : loss : 0.023177, loss_ce: 0.011682
iteration 16238 : loss : 0.070620, loss_ce: 0.005425
iteration 16239 : loss : 0.022366, loss_ce: 0.009145
iteration 16240 : loss : 0.021588, loss_ce: 0.005587
iteration 16241 : loss : 0.034913, loss_ce: 0.006460
iteration 16242 : loss : 0.016705, loss_ce: 0.006244
iteration 16243 : loss : 0.021292, loss_ce: 0.008872
iteration 16244 : loss : 0.026161, loss_ce: 0.006346
iteration 16245 : loss : 0.020018, loss_ce: 0.004856
iteration 16246 : loss : 0.020040, loss_ce: 0.004132
iteration 16247 : loss : 0.021595, loss_ce: 0.005779
iteration 16248 : loss : 0.075084, loss_ce: 0.006720
iteration 16249 : loss : 0.020680, loss_ce: 0.004892
iteration 16250 : loss : 0.028314, loss_ce: 0.007814
iteration 16251 : loss : 0.072874, loss_ce: 0.003012
iteration 16252 : loss : 0.076361, loss_ce: 0.006430
iteration 16253 : loss : 0.023061, loss_ce: 0.005053
iteration 16254 : loss : 0.020489, loss_ce: 0.008142
iteration 16255 : loss : 0.021328, loss_ce: 0.008102
iteration 16256 : loss : 0.020342, loss_ce: 0.007294
iteration 16257 : loss : 0.025569, loss_ce: 0.008489
iteration 16258 : loss : 0.019908, loss_ce: 0.006379
iteration 16259 : loss : 0.020455, loss_ce: 0.008998
iteration 16260 : loss : 0.020145, loss_ce: 0.008330
iteration 16261 : loss : 0.021848, loss_ce: 0.009728
iteration 16262 : loss : 0.023120, loss_ce: 0.012079
iteration 16263 : loss : 0.070571, loss_ce: 0.006139
iteration 16264 : loss : 0.020673, loss_ce: 0.008400
iteration 16265 : loss : 0.030130, loss_ce: 0.006577
iteration 16266 : loss : 0.022819, loss_ce: 0.008707
iteration 16267 : loss : 0.023397, loss_ce: 0.010155
iteration 16268 : loss : 0.024685, loss_ce: 0.005517
iteration 16269 : loss : 0.020040, loss_ce: 0.007307
iteration 16270 : loss : 0.021378, loss_ce: 0.009443
iteration 16271 : loss : 0.022181, loss_ce: 0.007022
iteration 16272 : loss : 0.021675, loss_ce: 0.005812
iteration 16273 : loss : 0.026011, loss_ce: 0.011777
iteration 16274 : loss : 0.022606, loss_ce: 0.009319
iteration 16275 : loss : 0.236833, loss_ce: 0.016831
 88%|█████████████████████████▍   | 175/200 [2:54:09<22:42, 54.52s/it]iteration 16276 : loss : 0.025770, loss_ce: 0.010670
iteration 16277 : loss : 0.024354, loss_ce: 0.009923
iteration 16278 : loss : 0.024753, loss_ce: 0.013645
iteration 16279 : loss : 0.021992, loss_ce: 0.010314
iteration 16280 : loss : 0.024685, loss_ce: 0.008153
iteration 16281 : loss : 0.023961, loss_ce: 0.007609
iteration 16282 : loss : 0.023747, loss_ce: 0.006458
iteration 16283 : loss : 0.020401, loss_ce: 0.005036
iteration 16284 : loss : 0.024449, loss_ce: 0.008208
iteration 16285 : loss : 0.020882, loss_ce: 0.008280
iteration 16286 : loss : 0.019177, loss_ce: 0.007399
iteration 16287 : loss : 0.018125, loss_ce: 0.004053
iteration 16288 : loss : 0.022819, loss_ce: 0.010276
iteration 16289 : loss : 0.023370, loss_ce: 0.012251
iteration 16290 : loss : 0.020387, loss_ce: 0.008214
iteration 16291 : loss : 0.023282, loss_ce: 0.006398
iteration 16292 : loss : 0.019096, loss_ce: 0.005828
iteration 16293 : loss : 0.020739, loss_ce: 0.007767
iteration 16294 : loss : 0.072808, loss_ce: 0.006018
iteration 16295 : loss : 0.018962, loss_ce: 0.008958
iteration 16296 : loss : 0.022095, loss_ce: 0.006342
iteration 16297 : loss : 0.021413, loss_ce: 0.008893
iteration 16298 : loss : 0.023097, loss_ce: 0.009495
iteration 16299 : loss : 0.022555, loss_ce: 0.010789
iteration 16300 : loss : 0.020741, loss_ce: 0.004916
iteration 16301 : loss : 0.024190, loss_ce: 0.004797
iteration 16302 : loss : 0.024822, loss_ce: 0.008663
iteration 16303 : loss : 0.020803, loss_ce: 0.004498
iteration 16304 : loss : 0.021419, loss_ce: 0.009323
iteration 16305 : loss : 0.019280, loss_ce: 0.008066
iteration 16306 : loss : 0.021136, loss_ce: 0.005745
iteration 16307 : loss : 0.020197, loss_ce: 0.008408
iteration 16308 : loss : 0.023280, loss_ce: 0.010478
iteration 16309 : loss : 0.020684, loss_ce: 0.007192
iteration 16310 : loss : 0.024545, loss_ce: 0.008651
iteration 16311 : loss : 0.069894, loss_ce: 0.002590
iteration 16312 : loss : 0.022738, loss_ce: 0.005196
iteration 16313 : loss : 0.024595, loss_ce: 0.008244
iteration 16314 : loss : 0.025024, loss_ce: 0.005254
iteration 16315 : loss : 0.024206, loss_ce: 0.006495
iteration 16316 : loss : 0.019779, loss_ce: 0.007127
iteration 16317 : loss : 0.026100, loss_ce: 0.010918
iteration 16318 : loss : 0.021263, loss_ce: 0.005900
iteration 16319 : loss : 0.018164, loss_ce: 0.006048
iteration 16320 : loss : 0.023534, loss_ce: 0.008421
iteration 16321 : loss : 0.020488, loss_ce: 0.007263
iteration 16322 : loss : 0.021076, loss_ce: 0.009423
iteration 16323 : loss : 0.022431, loss_ce: 0.006552
iteration 16324 : loss : 0.023540, loss_ce: 0.008089
iteration 16325 : loss : 0.030500, loss_ce: 0.010775
iteration 16326 : loss : 0.017354, loss_ce: 0.006241
iteration 16327 : loss : 0.020571, loss_ce: 0.007720
iteration 16328 : loss : 0.023454, loss_ce: 0.007911
iteration 16329 : loss : 0.024311, loss_ce: 0.006672
iteration 16330 : loss : 0.022038, loss_ce: 0.006174
iteration 16331 : loss : 0.027431, loss_ce: 0.005454
iteration 16332 : loss : 0.024519, loss_ce: 0.012617
iteration 16333 : loss : 0.019446, loss_ce: 0.006894
iteration 16334 : loss : 0.021852, loss_ce: 0.007365
iteration 16335 : loss : 0.019636, loss_ce: 0.006060
iteration 16336 : loss : 0.021229, loss_ce: 0.006890
iteration 16337 : loss : 0.021200, loss_ce: 0.005426
iteration 16338 : loss : 0.052933, loss_ce: 0.006923
iteration 16339 : loss : 0.021151, loss_ce: 0.008367
iteration 16340 : loss : 0.018345, loss_ce: 0.004550
iteration 16341 : loss : 0.024015, loss_ce: 0.007880
iteration 16342 : loss : 0.021093, loss_ce: 0.005222
iteration 16343 : loss : 0.077276, loss_ce: 0.007375
iteration 16344 : loss : 0.019610, loss_ce: 0.007691
iteration 16345 : loss : 0.026165, loss_ce: 0.013140
iteration 16346 : loss : 0.023047, loss_ce: 0.006645
iteration 16347 : loss : 0.017557, loss_ce: 0.005877
iteration 16348 : loss : 0.030654, loss_ce: 0.006052
iteration 16349 : loss : 0.020956, loss_ce: 0.006381
iteration 16350 : loss : 0.023829, loss_ce: 0.009864
iteration 16351 : loss : 0.072243, loss_ce: 0.004378
iteration 16352 : loss : 0.023852, loss_ce: 0.007311
iteration 16353 : loss : 0.022575, loss_ce: 0.012052
iteration 16354 : loss : 0.020213, loss_ce: 0.006459
iteration 16355 : loss : 0.073840, loss_ce: 0.005080
iteration 16356 : loss : 0.019581, loss_ce: 0.006434
iteration 16357 : loss : 0.020581, loss_ce: 0.009413
iteration 16358 : loss : 0.022023, loss_ce: 0.009945
iteration 16359 : loss : 0.026243, loss_ce: 0.008763
iteration 16360 : loss : 0.023486, loss_ce: 0.008487
iteration 16361 : loss : 0.023380, loss_ce: 0.009613
iteration 16362 : loss : 0.024192, loss_ce: 0.002969
iteration 16363 : loss : 0.027903, loss_ce: 0.007353
iteration 16364 : loss : 0.025285, loss_ce: 0.009777
iteration 16365 : loss : 0.020716, loss_ce: 0.005418
iteration 16366 : loss : 0.020144, loss_ce: 0.007284
iteration 16367 : loss : 0.019839, loss_ce: 0.007656
iteration 16368 : loss : 0.099641, loss_ce: 0.009748
 88%|█████████████████████████▌   | 176/200 [2:55:03<21:48, 54.50s/it]iteration 16369 : loss : 0.018903, loss_ce: 0.005157
iteration 16370 : loss : 0.032048, loss_ce: 0.007535
iteration 16371 : loss : 0.027403, loss_ce: 0.006861
iteration 16372 : loss : 0.024268, loss_ce: 0.009905
iteration 16373 : loss : 0.029537, loss_ce: 0.005542
iteration 16374 : loss : 0.024160, loss_ce: 0.004759
iteration 16375 : loss : 0.021382, loss_ce: 0.007875
iteration 16376 : loss : 0.072660, loss_ce: 0.008079
iteration 16377 : loss : 0.018913, loss_ce: 0.006080
iteration 16378 : loss : 0.022361, loss_ce: 0.010403
iteration 16379 : loss : 0.022264, loss_ce: 0.006987
iteration 16380 : loss : 0.021114, loss_ce: 0.006397
iteration 16381 : loss : 0.124099, loss_ce: 0.003132
iteration 16382 : loss : 0.025599, loss_ce: 0.007719
iteration 16383 : loss : 0.026540, loss_ce: 0.009074
iteration 16384 : loss : 0.020902, loss_ce: 0.007229
iteration 16385 : loss : 0.018837, loss_ce: 0.006688
iteration 16386 : loss : 0.032277, loss_ce: 0.006935
iteration 16387 : loss : 0.019068, loss_ce: 0.007771
iteration 16388 : loss : 0.021269, loss_ce: 0.008138
iteration 16389 : loss : 0.024218, loss_ce: 0.008897
iteration 16390 : loss : 0.021478, loss_ce: 0.005162
iteration 16391 : loss : 0.019728, loss_ce: 0.007204
iteration 16392 : loss : 0.021510, loss_ce: 0.009064
iteration 16393 : loss : 0.020075, loss_ce: 0.008684
iteration 16394 : loss : 0.017825, loss_ce: 0.003405
iteration 16395 : loss : 0.074445, loss_ce: 0.004598
iteration 16396 : loss : 0.025464, loss_ce: 0.008702
iteration 16397 : loss : 0.021888, loss_ce: 0.007529
iteration 16398 : loss : 0.023748, loss_ce: 0.004681
iteration 16399 : loss : 0.020809, loss_ce: 0.007570
iteration 16400 : loss : 0.022641, loss_ce: 0.006304
iteration 16401 : loss : 0.019018, loss_ce: 0.004260
iteration 16402 : loss : 0.021648, loss_ce: 0.006355
iteration 16403 : loss : 0.022737, loss_ce: 0.005642
iteration 16404 : loss : 0.022887, loss_ce: 0.008650
iteration 16405 : loss : 0.023549, loss_ce: 0.005866
iteration 16406 : loss : 0.025954, loss_ce: 0.012520
iteration 16407 : loss : 0.027893, loss_ce: 0.010147
iteration 16408 : loss : 0.019918, loss_ce: 0.010169
iteration 16409 : loss : 0.018447, loss_ce: 0.006123
iteration 16410 : loss : 0.023678, loss_ce: 0.005555
iteration 16411 : loss : 0.023305, loss_ce: 0.009495
iteration 16412 : loss : 0.021213, loss_ce: 0.007560
iteration 16413 : loss : 0.023947, loss_ce: 0.009695
iteration 16414 : loss : 0.021411, loss_ce: 0.006756
iteration 16415 : loss : 0.020667, loss_ce: 0.007092
iteration 16416 : loss : 0.021183, loss_ce: 0.009004
iteration 16417 : loss : 0.028182, loss_ce: 0.007317
iteration 16418 : loss : 0.075131, loss_ce: 0.005937
iteration 16419 : loss : 0.022849, loss_ce: 0.009781
iteration 16420 : loss : 0.025712, loss_ce: 0.007757
iteration 16421 : loss : 0.023522, loss_ce: 0.004598
iteration 16422 : loss : 0.022914, loss_ce: 0.008006
iteration 16423 : loss : 0.017062, loss_ce: 0.005130
iteration 16424 : loss : 0.018610, loss_ce: 0.006322
iteration 16425 : loss : 0.020826, loss_ce: 0.007809
iteration 16426 : loss : 0.023549, loss_ce: 0.004858
iteration 16427 : loss : 0.021782, loss_ce: 0.007978
iteration 16428 : loss : 0.021596, loss_ce: 0.009956
iteration 16429 : loss : 0.022180, loss_ce: 0.008242
iteration 16430 : loss : 0.019337, loss_ce: 0.005054
iteration 16431 : loss : 0.023644, loss_ce: 0.008453
iteration 16432 : loss : 0.020041, loss_ce: 0.010439
iteration 16433 : loss : 0.022936, loss_ce: 0.008486
iteration 16434 : loss : 0.022566, loss_ce: 0.008112
iteration 16435 : loss : 0.020878, loss_ce: 0.007049
iteration 16436 : loss : 0.020736, loss_ce: 0.006738
iteration 16437 : loss : 0.024485, loss_ce: 0.012916
iteration 16438 : loss : 0.026144, loss_ce: 0.005748
iteration 16439 : loss : 0.021161, loss_ce: 0.007382
iteration 16440 : loss : 0.020879, loss_ce: 0.010589
iteration 16441 : loss : 0.022649, loss_ce: 0.007709
iteration 16442 : loss : 0.022548, loss_ce: 0.009341
iteration 16443 : loss : 0.074808, loss_ce: 0.004189
iteration 16444 : loss : 0.019356, loss_ce: 0.007014
iteration 16445 : loss : 0.022117, loss_ce: 0.005232
iteration 16446 : loss : 0.023345, loss_ce: 0.010753
iteration 16447 : loss : 0.022257, loss_ce: 0.010810
iteration 16448 : loss : 0.019806, loss_ce: 0.006919
iteration 16449 : loss : 0.021520, loss_ce: 0.007143
iteration 16450 : loss : 0.024971, loss_ce: 0.009183
iteration 16451 : loss : 0.020525, loss_ce: 0.005911
iteration 16452 : loss : 0.024681, loss_ce: 0.011597
iteration 16453 : loss : 0.073939, loss_ce: 0.007394
iteration 16454 : loss : 0.023916, loss_ce: 0.009282
iteration 16455 : loss : 0.021660, loss_ce: 0.008959
iteration 16456 : loss : 0.018609, loss_ce: 0.007704
iteration 16457 : loss : 0.023267, loss_ce: 0.008622
iteration 16458 : loss : 0.020609, loss_ce: 0.007093
iteration 16459 : loss : 0.021032, loss_ce: 0.007521
iteration 16460 : loss : 0.019884, loss_ce: 0.008200
iteration 16461 : loss : 0.177448, loss_ce: 0.005945
 88%|█████████████████████████▋   | 177/200 [2:55:58<20:53, 54.52s/it]iteration 16462 : loss : 0.025668, loss_ce: 0.008774
iteration 16463 : loss : 0.023383, loss_ce: 0.009019
iteration 16464 : loss : 0.019814, loss_ce: 0.009901
iteration 16465 : loss : 0.021981, loss_ce: 0.009175
iteration 16466 : loss : 0.024612, loss_ce: 0.008312
iteration 16467 : loss : 0.019838, loss_ce: 0.005094
iteration 16468 : loss : 0.026481, loss_ce: 0.006663
iteration 16469 : loss : 0.017757, loss_ce: 0.007724
iteration 16470 : loss : 0.020944, loss_ce: 0.006273
iteration 16471 : loss : 0.022211, loss_ce: 0.009346
iteration 16472 : loss : 0.020076, loss_ce: 0.005564
iteration 16473 : loss : 0.020994, loss_ce: 0.009276
iteration 16474 : loss : 0.023626, loss_ce: 0.005945
iteration 16475 : loss : 0.021627, loss_ce: 0.008128
iteration 16476 : loss : 0.020299, loss_ce: 0.006499
iteration 16477 : loss : 0.024022, loss_ce: 0.007056
iteration 16478 : loss : 0.020286, loss_ce: 0.005425
iteration 16479 : loss : 0.022469, loss_ce: 0.008341
iteration 16480 : loss : 0.023030, loss_ce: 0.004469
iteration 16481 : loss : 0.020395, loss_ce: 0.006620
iteration 16482 : loss : 0.085834, loss_ce: 0.002567
iteration 16483 : loss : 0.022226, loss_ce: 0.007871
iteration 16484 : loss : 0.091746, loss_ce: 0.004056
iteration 16485 : loss : 0.023430, loss_ce: 0.007898
iteration 16486 : loss : 0.024584, loss_ce: 0.008588
iteration 16487 : loss : 0.022090, loss_ce: 0.006628
iteration 16488 : loss : 0.022386, loss_ce: 0.006422
iteration 16489 : loss : 0.025755, loss_ce: 0.011176
iteration 16490 : loss : 0.023446, loss_ce: 0.006491
iteration 16491 : loss : 0.021013, loss_ce: 0.010640
iteration 16492 : loss : 0.023596, loss_ce: 0.011831
iteration 16493 : loss : 0.110966, loss_ce: 0.005571
iteration 16494 : loss : 0.022343, loss_ce: 0.009271
iteration 16495 : loss : 0.026997, loss_ce: 0.009451
iteration 16496 : loss : 0.022110, loss_ce: 0.004858
iteration 16497 : loss : 0.026446, loss_ce: 0.009469
iteration 16498 : loss : 0.019580, loss_ce: 0.008976
iteration 16499 : loss : 0.075342, loss_ce: 0.005995
iteration 16500 : loss : 0.024446, loss_ce: 0.006873
iteration 16501 : loss : 0.017695, loss_ce: 0.004655
iteration 16502 : loss : 0.021962, loss_ce: 0.006987
iteration 16503 : loss : 0.022487, loss_ce: 0.006987
iteration 16504 : loss : 0.023653, loss_ce: 0.010179
iteration 16505 : loss : 0.068648, loss_ce: 0.002652
iteration 16506 : loss : 0.023155, loss_ce: 0.009484
iteration 16507 : loss : 0.025543, loss_ce: 0.004752
iteration 16508 : loss : 0.049541, loss_ce: 0.005392
iteration 16509 : loss : 0.026494, loss_ce: 0.006964
iteration 16510 : loss : 0.024773, loss_ce: 0.005217
iteration 16511 : loss : 0.025159, loss_ce: 0.008353
iteration 16512 : loss : 0.019959, loss_ce: 0.004551
iteration 16513 : loss : 0.021824, loss_ce: 0.010197
iteration 16514 : loss : 0.077155, loss_ce: 0.005938
iteration 16515 : loss : 0.020931, loss_ce: 0.009736
iteration 16516 : loss : 0.023346, loss_ce: 0.013022
iteration 16517 : loss : 0.023189, loss_ce: 0.008944
iteration 16518 : loss : 0.022929, loss_ce: 0.008570
iteration 16519 : loss : 0.020513, loss_ce: 0.009617
iteration 16520 : loss : 0.027195, loss_ce: 0.009069
iteration 16521 : loss : 0.018718, loss_ce: 0.006237
iteration 16522 : loss : 0.025740, loss_ce: 0.008986
iteration 16523 : loss : 0.019696, loss_ce: 0.006754
iteration 16524 : loss : 0.071607, loss_ce: 0.004832
iteration 16525 : loss : 0.023001, loss_ce: 0.009473
iteration 16526 : loss : 0.023287, loss_ce: 0.008500
iteration 16527 : loss : 0.020874, loss_ce: 0.006807
iteration 16528 : loss : 0.021699, loss_ce: 0.009289
iteration 16529 : loss : 0.076603, loss_ce: 0.006575
iteration 16530 : loss : 0.019566, loss_ce: 0.005855
iteration 16531 : loss : 0.020949, loss_ce: 0.005520
iteration 16532 : loss : 0.026353, loss_ce: 0.009095
iteration 16533 : loss : 0.024167, loss_ce: 0.011082
iteration 16534 : loss : 0.023110, loss_ce: 0.005893
iteration 16535 : loss : 0.024201, loss_ce: 0.012442
iteration 16536 : loss : 0.022504, loss_ce: 0.007825
iteration 16537 : loss : 0.023130, loss_ce: 0.006688
iteration 16538 : loss : 0.018338, loss_ce: 0.007180
iteration 16539 : loss : 0.018961, loss_ce: 0.005795
iteration 16540 : loss : 0.022645, loss_ce: 0.007232
iteration 16541 : loss : 0.021469, loss_ce: 0.005834
iteration 16542 : loss : 0.022878, loss_ce: 0.007962
iteration 16543 : loss : 0.024915, loss_ce: 0.008163
iteration 16544 : loss : 0.021936, loss_ce: 0.009301
iteration 16545 : loss : 0.027888, loss_ce: 0.006951
iteration 16546 : loss : 0.026328, loss_ce: 0.008111
iteration 16547 : loss : 0.074413, loss_ce: 0.006266
iteration 16548 : loss : 0.023665, loss_ce: 0.010046
iteration 16549 : loss : 0.026248, loss_ce: 0.010428
iteration 16550 : loss : 0.017267, loss_ce: 0.006211
iteration 16551 : loss : 0.022139, loss_ce: 0.007882
iteration 16552 : loss : 0.017127, loss_ce: 0.007083
iteration 16553 : loss : 0.020342, loss_ce: 0.008618
iteration 16554 : loss : 0.029912, loss_ce: 0.016446
 89%|█████████████████████████▊   | 178/200 [2:56:52<19:59, 54.53s/it]iteration 16555 : loss : 0.020873, loss_ce: 0.004650
iteration 16556 : loss : 0.023710, loss_ce: 0.009001
iteration 16557 : loss : 0.019210, loss_ce: 0.006449
iteration 16558 : loss : 0.021746, loss_ce: 0.010133
iteration 16559 : loss : 0.072708, loss_ce: 0.002760
iteration 16560 : loss : 0.021818, loss_ce: 0.008355
iteration 16561 : loss : 0.020093, loss_ce: 0.007261
iteration 16562 : loss : 0.022504, loss_ce: 0.010666
iteration 16563 : loss : 0.072034, loss_ce: 0.005046
iteration 16564 : loss : 0.022663, loss_ce: 0.010316
iteration 16565 : loss : 0.024151, loss_ce: 0.009664
iteration 16566 : loss : 0.022035, loss_ce: 0.010535
iteration 16567 : loss : 0.019841, loss_ce: 0.006347
iteration 16568 : loss : 0.017294, loss_ce: 0.005971
iteration 16569 : loss : 0.073100, loss_ce: 0.006477
iteration 16570 : loss : 0.028354, loss_ce: 0.011597
iteration 16571 : loss : 0.024032, loss_ce: 0.007926
iteration 16572 : loss : 0.025565, loss_ce: 0.008453
iteration 16573 : loss : 0.074495, loss_ce: 0.008036
iteration 16574 : loss : 0.018962, loss_ce: 0.004926
iteration 16575 : loss : 0.024429, loss_ce: 0.008186
iteration 16576 : loss : 0.021194, loss_ce: 0.008029
iteration 16577 : loss : 0.020035, loss_ce: 0.006784
iteration 16578 : loss : 0.025296, loss_ce: 0.008783
iteration 16579 : loss : 0.022605, loss_ce: 0.003997
iteration 16580 : loss : 0.022008, loss_ce: 0.009245
iteration 16581 : loss : 0.018894, loss_ce: 0.006134
iteration 16582 : loss : 0.022952, loss_ce: 0.009507
iteration 16583 : loss : 0.072399, loss_ce: 0.004485
iteration 16584 : loss : 0.073506, loss_ce: 0.006784
iteration 16585 : loss : 0.023025, loss_ce: 0.005252
iteration 16586 : loss : 0.021578, loss_ce: 0.006427
iteration 16587 : loss : 0.021602, loss_ce: 0.008492
iteration 16588 : loss : 0.021077, loss_ce: 0.009413
iteration 16589 : loss : 0.021172, loss_ce: 0.006089
iteration 16590 : loss : 0.023379, loss_ce: 0.011749
iteration 16591 : loss : 0.022581, loss_ce: 0.009353
iteration 16592 : loss : 0.076786, loss_ce: 0.010208
iteration 16593 : loss : 0.023140, loss_ce: 0.009146
iteration 16594 : loss : 0.019692, loss_ce: 0.008354
iteration 16595 : loss : 0.029398, loss_ce: 0.009252
iteration 16596 : loss : 0.021441, loss_ce: 0.008317
iteration 16597 : loss : 0.018843, loss_ce: 0.006414
iteration 16598 : loss : 0.021351, loss_ce: 0.009361
iteration 16599 : loss : 0.020045, loss_ce: 0.004514
iteration 16600 : loss : 0.020406, loss_ce: 0.004751
iteration 16601 : loss : 0.024474, loss_ce: 0.004904
iteration 16602 : loss : 0.022453, loss_ce: 0.006209
iteration 16603 : loss : 0.020968, loss_ce: 0.008896
iteration 16604 : loss : 0.022097, loss_ce: 0.009498
iteration 16605 : loss : 0.022705, loss_ce: 0.010470
iteration 16606 : loss : 0.023670, loss_ce: 0.005280
iteration 16607 : loss : 0.021069, loss_ce: 0.006915
iteration 16608 : loss : 0.016329, loss_ce: 0.004133
iteration 16609 : loss : 0.021149, loss_ce: 0.008546
iteration 16610 : loss : 0.023311, loss_ce: 0.008014
iteration 16611 : loss : 0.019339, loss_ce: 0.006253
iteration 16612 : loss : 0.021317, loss_ce: 0.004840
iteration 16613 : loss : 0.022021, loss_ce: 0.003974
iteration 16614 : loss : 0.024836, loss_ce: 0.009240
iteration 16615 : loss : 0.021362, loss_ce: 0.007428
iteration 16616 : loss : 0.023188, loss_ce: 0.005230
iteration 16617 : loss : 0.021099, loss_ce: 0.011963
iteration 16618 : loss : 0.021849, loss_ce: 0.007448
iteration 16619 : loss : 0.019966, loss_ce: 0.010023
iteration 16620 : loss : 0.022047, loss_ce: 0.007629
iteration 16621 : loss : 0.020318, loss_ce: 0.009659
iteration 16622 : loss : 0.021503, loss_ce: 0.006798
iteration 16623 : loss : 0.029999, loss_ce: 0.005104
iteration 16624 : loss : 0.022430, loss_ce: 0.009685
iteration 16625 : loss : 0.118907, loss_ce: 0.001182
iteration 16626 : loss : 0.018791, loss_ce: 0.004637
iteration 16627 : loss : 0.024694, loss_ce: 0.007297
iteration 16628 : loss : 0.023379, loss_ce: 0.006540
iteration 16629 : loss : 0.019323, loss_ce: 0.006742
iteration 16630 : loss : 0.022501, loss_ce: 0.008537
iteration 16631 : loss : 0.023845, loss_ce: 0.011645
iteration 16632 : loss : 0.022157, loss_ce: 0.005954
iteration 16633 : loss : 0.022090, loss_ce: 0.007222
iteration 16634 : loss : 0.026199, loss_ce: 0.005736
iteration 16635 : loss : 0.025922, loss_ce: 0.013088
iteration 16636 : loss : 0.020160, loss_ce: 0.006357
iteration 16637 : loss : 0.023201, loss_ce: 0.010192
iteration 16638 : loss : 0.023424, loss_ce: 0.008195
iteration 16639 : loss : 0.026442, loss_ce: 0.004502
iteration 16640 : loss : 0.020992, loss_ce: 0.007105
iteration 16641 : loss : 0.023618, loss_ce: 0.007270
iteration 16642 : loss : 0.018454, loss_ce: 0.006842
iteration 16643 : loss : 0.021050, loss_ce: 0.009786
iteration 16644 : loss : 0.019898, loss_ce: 0.006901
iteration 16645 : loss : 0.020413, loss_ce: 0.005120
iteration 16646 : loss : 0.018182, loss_ce: 0.006563
iteration 16647 : loss : 0.382755, loss_ce: 0.002604
 90%|█████████████████████████▉   | 179/200 [2:57:47<19:04, 54.51s/it]iteration 16648 : loss : 0.021702, loss_ce: 0.008058
iteration 16649 : loss : 0.024431, loss_ce: 0.006263
iteration 16650 : loss : 0.077163, loss_ce: 0.008411
iteration 16651 : loss : 0.017098, loss_ce: 0.004081
iteration 16652 : loss : 0.018997, loss_ce: 0.008358
iteration 16653 : loss : 0.022741, loss_ce: 0.005227
iteration 16654 : loss : 0.075940, loss_ce: 0.006022
iteration 16655 : loss : 0.020226, loss_ce: 0.006700
iteration 16656 : loss : 0.022086, loss_ce: 0.004054
iteration 16657 : loss : 0.019212, loss_ce: 0.006515
iteration 16658 : loss : 0.021447, loss_ce: 0.005372
iteration 16659 : loss : 0.020435, loss_ce: 0.007657
iteration 16660 : loss : 0.021549, loss_ce: 0.008836
iteration 16661 : loss : 0.022049, loss_ce: 0.009223
iteration 16662 : loss : 0.023702, loss_ce: 0.009419
iteration 16663 : loss : 0.025556, loss_ce: 0.006741
iteration 16664 : loss : 0.020339, loss_ce: 0.004994
iteration 16665 : loss : 0.075020, loss_ce: 0.008189
iteration 16666 : loss : 0.019410, loss_ce: 0.007042
iteration 16667 : loss : 0.019037, loss_ce: 0.007429
iteration 16668 : loss : 0.021208, loss_ce: 0.005404
iteration 16669 : loss : 0.022513, loss_ce: 0.008958
iteration 16670 : loss : 0.071988, loss_ce: 0.005942
iteration 16671 : loss : 0.021518, loss_ce: 0.008048
iteration 16672 : loss : 0.020382, loss_ce: 0.007713
iteration 16673 : loss : 0.019901, loss_ce: 0.007548
iteration 16674 : loss : 0.019899, loss_ce: 0.007889
iteration 16675 : loss : 0.022850, loss_ce: 0.007410
iteration 16676 : loss : 0.019861, loss_ce: 0.004821
iteration 16677 : loss : 0.027365, loss_ce: 0.009531
iteration 16678 : loss : 0.027623, loss_ce: 0.011197
iteration 16679 : loss : 0.025608, loss_ce: 0.007146
iteration 16680 : loss : 0.022038, loss_ce: 0.005637
iteration 16681 : loss : 0.070631, loss_ce: 0.006764
iteration 16682 : loss : 0.022864, loss_ce: 0.012218
iteration 16683 : loss : 0.021556, loss_ce: 0.009983
iteration 16684 : loss : 0.020473, loss_ce: 0.006338
iteration 16685 : loss : 0.023106, loss_ce: 0.010716
iteration 16686 : loss : 0.021863, loss_ce: 0.007400
iteration 16687 : loss : 0.024326, loss_ce: 0.008960
iteration 16688 : loss : 0.020501, loss_ce: 0.006614
iteration 16689 : loss : 0.017647, loss_ce: 0.005249
iteration 16690 : loss : 0.024956, loss_ce: 0.007959
iteration 16691 : loss : 0.020991, loss_ce: 0.008055
iteration 16692 : loss : 0.024850, loss_ce: 0.003043
iteration 16693 : loss : 0.021822, loss_ce: 0.006191
iteration 16694 : loss : 0.019973, loss_ce: 0.009129
iteration 16695 : loss : 0.017017, loss_ce: 0.005789
iteration 16696 : loss : 0.020600, loss_ce: 0.009213
iteration 16697 : loss : 0.021608, loss_ce: 0.007018
iteration 16698 : loss : 0.026608, loss_ce: 0.008926
iteration 16699 : loss : 0.072299, loss_ce: 0.005811
iteration 16700 : loss : 0.021061, loss_ce: 0.006039
iteration 16701 : loss : 0.019420, loss_ce: 0.009463
iteration 16702 : loss : 0.025483, loss_ce: 0.005430
iteration 16703 : loss : 0.025174, loss_ce: 0.006193
iteration 16704 : loss : 0.025519, loss_ce: 0.008881
iteration 16705 : loss : 0.020143, loss_ce: 0.007078
iteration 16706 : loss : 0.026927, loss_ce: 0.007465
iteration 16707 : loss : 0.021167, loss_ce: 0.008636
iteration 16708 : loss : 0.033014, loss_ce: 0.005698
iteration 16709 : loss : 0.024217, loss_ce: 0.007900
iteration 16710 : loss : 0.026652, loss_ce: 0.008285
iteration 16711 : loss : 0.021930, loss_ce: 0.008299
iteration 16712 : loss : 0.021577, loss_ce: 0.008305
iteration 16713 : loss : 0.022106, loss_ce: 0.008802
iteration 16714 : loss : 0.022460, loss_ce: 0.006821
iteration 16715 : loss : 0.026121, loss_ce: 0.012437
iteration 16716 : loss : 0.022686, loss_ce: 0.008236
iteration 16717 : loss : 0.025428, loss_ce: 0.007358
iteration 16718 : loss : 0.025825, loss_ce: 0.007156
iteration 16719 : loss : 0.019231, loss_ce: 0.007077
iteration 16720 : loss : 0.022395, loss_ce: 0.007046
iteration 16721 : loss : 0.019502, loss_ce: 0.007012
iteration 16722 : loss : 0.028945, loss_ce: 0.008969
iteration 16723 : loss : 0.022014, loss_ce: 0.008205
iteration 16724 : loss : 0.023901, loss_ce: 0.013104
iteration 16725 : loss : 0.075361, loss_ce: 0.005942
iteration 16726 : loss : 0.020801, loss_ce: 0.007566
iteration 16727 : loss : 0.036557, loss_ce: 0.007593
iteration 16728 : loss : 0.026444, loss_ce: 0.010138
iteration 16729 : loss : 0.025776, loss_ce: 0.008990
iteration 16730 : loss : 0.024799, loss_ce: 0.012164
iteration 16731 : loss : 0.020984, loss_ce: 0.006806
iteration 16732 : loss : 0.073744, loss_ce: 0.003868
iteration 16733 : loss : 0.023827, loss_ce: 0.008450
iteration 16734 : loss : 0.021463, loss_ce: 0.007941
iteration 16735 : loss : 0.025955, loss_ce: 0.010348
iteration 16736 : loss : 0.020157, loss_ce: 0.007336
iteration 16737 : loss : 0.023367, loss_ce: 0.010379
iteration 16738 : loss : 0.022570, loss_ce: 0.007385
iteration 16739 : loss : 0.018854, loss_ce: 0.006200
iteration 16740 : loss : 0.280167, loss_ce: 0.002291
 90%|██████████████████████████   | 180/200 [2:58:41<18:10, 54.53s/it]iteration 16741 : loss : 0.022693, loss_ce: 0.007425
iteration 16742 : loss : 0.073099, loss_ce: 0.004800
iteration 16743 : loss : 0.023365, loss_ce: 0.007777
iteration 16744 : loss : 0.020409, loss_ce: 0.009516
iteration 16745 : loss : 0.030371, loss_ce: 0.011562
iteration 16746 : loss : 0.022399, loss_ce: 0.007873
iteration 16747 : loss : 0.026157, loss_ce: 0.007073
iteration 16748 : loss : 0.022684, loss_ce: 0.008956
iteration 16749 : loss : 0.072188, loss_ce: 0.004392
iteration 16750 : loss : 0.023733, loss_ce: 0.010132
iteration 16751 : loss : 0.035949, loss_ce: 0.008462
iteration 16752 : loss : 0.025669, loss_ce: 0.008013
iteration 16753 : loss : 0.022403, loss_ce: 0.007142
iteration 16754 : loss : 0.031461, loss_ce: 0.008915
iteration 16755 : loss : 0.022097, loss_ce: 0.008077
iteration 16756 : loss : 0.024792, loss_ce: 0.007332
iteration 16757 : loss : 0.021998, loss_ce: 0.006003
iteration 16758 : loss : 0.022658, loss_ce: 0.005280
iteration 16759 : loss : 0.019045, loss_ce: 0.005579
iteration 16760 : loss : 0.021056, loss_ce: 0.008045
iteration 16761 : loss : 0.020476, loss_ce: 0.005230
iteration 16762 : loss : 0.019063, loss_ce: 0.005240
iteration 16763 : loss : 0.021246, loss_ce: 0.007295
iteration 16764 : loss : 0.020128, loss_ce: 0.005174
iteration 16765 : loss : 0.023520, loss_ce: 0.009649
iteration 16766 : loss : 0.023273, loss_ce: 0.008634
iteration 16767 : loss : 0.020983, loss_ce: 0.006956
iteration 16768 : loss : 0.023968, loss_ce: 0.010562
iteration 16769 : loss : 0.074355, loss_ce: 0.003468
iteration 16770 : loss : 0.021158, loss_ce: 0.008159
iteration 16771 : loss : 0.021173, loss_ce: 0.008385
iteration 16772 : loss : 0.020469, loss_ce: 0.007591
iteration 16773 : loss : 0.024048, loss_ce: 0.010861
iteration 16774 : loss : 0.020910, loss_ce: 0.006088
iteration 16775 : loss : 0.022435, loss_ce: 0.009716
iteration 16776 : loss : 0.021067, loss_ce: 0.005056
iteration 16777 : loss : 0.027248, loss_ce: 0.007368
iteration 16778 : loss : 0.021365, loss_ce: 0.007803
iteration 16779 : loss : 0.076683, loss_ce: 0.006590
iteration 16780 : loss : 0.021050, loss_ce: 0.009571
iteration 16781 : loss : 0.020453, loss_ce: 0.006914
iteration 16782 : loss : 0.020543, loss_ce: 0.005783
iteration 16783 : loss : 0.021574, loss_ce: 0.008063
iteration 16784 : loss : 0.022300, loss_ce: 0.008870
iteration 16785 : loss : 0.025139, loss_ce: 0.006243
iteration 16786 : loss : 0.075125, loss_ce: 0.006906
iteration 16787 : loss : 0.024051, loss_ce: 0.005088
iteration 16788 : loss : 0.073170, loss_ce: 0.007233
iteration 16789 : loss : 0.022545, loss_ce: 0.007868
iteration 16790 : loss : 0.016209, loss_ce: 0.005133
iteration 16791 : loss : 0.021785, loss_ce: 0.011836
iteration 16792 : loss : 0.021628, loss_ce: 0.011731
iteration 16793 : loss : 0.017909, loss_ce: 0.003597
iteration 16794 : loss : 0.021971, loss_ce: 0.007234
iteration 16795 : loss : 0.018847, loss_ce: 0.006896
iteration 16796 : loss : 0.021902, loss_ce: 0.005715
iteration 16797 : loss : 0.020041, loss_ce: 0.007138
iteration 16798 : loss : 0.022403, loss_ce: 0.006772
iteration 16799 : loss : 0.020009, loss_ce: 0.010145
iteration 16800 : loss : 0.022756, loss_ce: 0.008195
iteration 16801 : loss : 0.020920, loss_ce: 0.009009
iteration 16802 : loss : 0.031516, loss_ce: 0.006338
iteration 16803 : loss : 0.027376, loss_ce: 0.009593
iteration 16804 : loss : 0.019144, loss_ce: 0.011376
iteration 16805 : loss : 0.023296, loss_ce: 0.008704
iteration 16806 : loss : 0.021018, loss_ce: 0.009316
iteration 16807 : loss : 0.021223, loss_ce: 0.009291
iteration 16808 : loss : 0.025292, loss_ce: 0.012999
iteration 16809 : loss : 0.019875, loss_ce: 0.004856
iteration 16810 : loss : 0.023822, loss_ce: 0.006321
iteration 16811 : loss : 0.026513, loss_ce: 0.009350
iteration 16812 : loss : 0.023307, loss_ce: 0.011086
iteration 16813 : loss : 0.035442, loss_ce: 0.006270
iteration 16814 : loss : 0.021018, loss_ce: 0.006999
iteration 16815 : loss : 0.022273, loss_ce: 0.007411
iteration 16816 : loss : 0.022442, loss_ce: 0.007809
iteration 16817 : loss : 0.022482, loss_ce: 0.006740
iteration 16818 : loss : 0.021832, loss_ce: 0.006655
iteration 16819 : loss : 0.019533, loss_ce: 0.007232
iteration 16820 : loss : 0.019027, loss_ce: 0.005170
iteration 16821 : loss : 0.019784, loss_ce: 0.006432
iteration 16822 : loss : 0.022851, loss_ce: 0.007688
iteration 16823 : loss : 0.018423, loss_ce: 0.005515
iteration 16824 : loss : 0.017946, loss_ce: 0.007312
iteration 16825 : loss : 0.019640, loss_ce: 0.009052
iteration 16826 : loss : 0.023582, loss_ce: 0.011415
iteration 16827 : loss : 0.020690, loss_ce: 0.009449
iteration 16828 : loss : 0.027246, loss_ce: 0.007986
iteration 16829 : loss : 0.022256, loss_ce: 0.006650
iteration 16830 : loss : 0.071192, loss_ce: 0.003276
iteration 16831 : loss : 0.018603, loss_ce: 0.004214
iteration 16832 : loss : 0.021654, loss_ce: 0.008690
iteration 16833 : loss : 0.389314, loss_ce: 0.001158
 90%|██████████████████████████▏  | 181/200 [2:59:36<17:15, 54.53s/it]iteration 16834 : loss : 0.024412, loss_ce: 0.008466
iteration 16835 : loss : 0.028273, loss_ce: 0.009980
iteration 16836 : loss : 0.019826, loss_ce: 0.007761
iteration 16837 : loss : 0.021837, loss_ce: 0.008199
iteration 16838 : loss : 0.024369, loss_ce: 0.005975
iteration 16839 : loss : 0.022272, loss_ce: 0.005240
iteration 16840 : loss : 0.024479, loss_ce: 0.011021
iteration 16841 : loss : 0.029011, loss_ce: 0.005433
iteration 16842 : loss : 0.019720, loss_ce: 0.008226
iteration 16843 : loss : 0.022189, loss_ce: 0.006907
iteration 16844 : loss : 0.073392, loss_ce: 0.006182
iteration 16845 : loss : 0.021437, loss_ce: 0.008054
iteration 16846 : loss : 0.023281, loss_ce: 0.005526
iteration 16847 : loss : 0.018061, loss_ce: 0.005749
iteration 16848 : loss : 0.023595, loss_ce: 0.007842
iteration 16849 : loss : 0.020472, loss_ce: 0.008049
iteration 16850 : loss : 0.021346, loss_ce: 0.006627
iteration 16851 : loss : 0.019687, loss_ce: 0.006783
iteration 16852 : loss : 0.020973, loss_ce: 0.005262
iteration 16853 : loss : 0.021776, loss_ce: 0.007498
iteration 16854 : loss : 0.023766, loss_ce: 0.007226
iteration 16855 : loss : 0.024779, loss_ce: 0.009576
iteration 16856 : loss : 0.021362, loss_ce: 0.006511
iteration 16857 : loss : 0.022684, loss_ce: 0.009858
iteration 16858 : loss : 0.024436, loss_ce: 0.011215
iteration 16859 : loss : 0.022959, loss_ce: 0.007287
iteration 16860 : loss : 0.020462, loss_ce: 0.007833
iteration 16861 : loss : 0.019747, loss_ce: 0.006711
iteration 16862 : loss : 0.017979, loss_ce: 0.005507
iteration 16863 : loss : 0.021306, loss_ce: 0.009868
iteration 16864 : loss : 0.022447, loss_ce: 0.008361
iteration 16865 : loss : 0.022706, loss_ce: 0.005000
iteration 16866 : loss : 0.018155, loss_ce: 0.004464
iteration 16867 : loss : 0.021417, loss_ce: 0.007510
iteration 16868 : loss : 0.021973, loss_ce: 0.010618
iteration 16869 : loss : 0.038655, loss_ce: 0.003722
iteration 16870 : loss : 0.021209, loss_ce: 0.009317
iteration 16871 : loss : 0.020680, loss_ce: 0.010420
iteration 16872 : loss : 0.020877, loss_ce: 0.008134
iteration 16873 : loss : 0.029994, loss_ce: 0.009086
iteration 16874 : loss : 0.027122, loss_ce: 0.005264
iteration 16875 : loss : 0.123978, loss_ce: 0.004692
iteration 16876 : loss : 0.024628, loss_ce: 0.005537
iteration 16877 : loss : 0.023044, loss_ce: 0.009347
iteration 16878 : loss : 0.021962, loss_ce: 0.012791
iteration 16879 : loss : 0.018807, loss_ce: 0.008451
iteration 16880 : loss : 0.020620, loss_ce: 0.005915
iteration 16881 : loss : 0.022686, loss_ce: 0.008218
iteration 16882 : loss : 0.019145, loss_ce: 0.006150
iteration 16883 : loss : 0.074000, loss_ce: 0.007168
iteration 16884 : loss : 0.022283, loss_ce: 0.008016
iteration 16885 : loss : 0.022037, loss_ce: 0.005431
iteration 16886 : loss : 0.021204, loss_ce: 0.008080
iteration 16887 : loss : 0.022965, loss_ce: 0.010547
iteration 16888 : loss : 0.023978, loss_ce: 0.009387
iteration 16889 : loss : 0.021277, loss_ce: 0.006189
iteration 16890 : loss : 0.019403, loss_ce: 0.005249
iteration 16891 : loss : 0.020216, loss_ce: 0.007460
iteration 16892 : loss : 0.017218, loss_ce: 0.006982
iteration 16893 : loss : 0.074930, loss_ce: 0.006848
iteration 16894 : loss : 0.022165, loss_ce: 0.008365
iteration 16895 : loss : 0.021015, loss_ce: 0.007661
iteration 16896 : loss : 0.027591, loss_ce: 0.006814
iteration 16897 : loss : 0.020040, loss_ce: 0.005404
iteration 16898 : loss : 0.022150, loss_ce: 0.005974
iteration 16899 : loss : 0.019517, loss_ce: 0.005893
iteration 16900 : loss : 0.024792, loss_ce: 0.008611
iteration 16901 : loss : 0.025447, loss_ce: 0.008069
iteration 16902 : loss : 0.020300, loss_ce: 0.005889
iteration 16903 : loss : 0.020736, loss_ce: 0.010686
iteration 16904 : loss : 0.019640, loss_ce: 0.007542
iteration 16905 : loss : 0.020251, loss_ce: 0.008352
iteration 16906 : loss : 0.027405, loss_ce: 0.005294
iteration 16907 : loss : 0.024595, loss_ce: 0.013294
iteration 16908 : loss : 0.026073, loss_ce: 0.007883
iteration 16909 : loss : 0.021372, loss_ce: 0.006369
iteration 16910 : loss : 0.019794, loss_ce: 0.012103
iteration 16911 : loss : 0.027477, loss_ce: 0.007616
iteration 16912 : loss : 0.022679, loss_ce: 0.007473
iteration 16913 : loss : 0.022809, loss_ce: 0.007315
iteration 16914 : loss : 0.020746, loss_ce: 0.005852
iteration 16915 : loss : 0.022466, loss_ce: 0.007792
iteration 16916 : loss : 0.025524, loss_ce: 0.008903
iteration 16917 : loss : 0.019070, loss_ce: 0.005644
iteration 16918 : loss : 0.081279, loss_ce: 0.003889
iteration 16919 : loss : 0.018664, loss_ce: 0.007063
iteration 16920 : loss : 0.024261, loss_ce: 0.011735
iteration 16921 : loss : 0.021676, loss_ce: 0.006612
iteration 16922 : loss : 0.020016, loss_ce: 0.005661
iteration 16923 : loss : 0.074970, loss_ce: 0.008048
iteration 16924 : loss : 0.124502, loss_ce: 0.003934
iteration 16925 : loss : 0.024330, loss_ce: 0.009111
iteration 16926 : loss : 0.227049, loss_ce: 0.002911
 91%|██████████████████████████▍  | 182/200 [3:00:30<16:21, 54.53s/it]iteration 16927 : loss : 0.022566, loss_ce: 0.008079
iteration 16928 : loss : 0.021648, loss_ce: 0.009940
iteration 16929 : loss : 0.024022, loss_ce: 0.009622
iteration 16930 : loss : 0.021152, loss_ce: 0.009514
iteration 16931 : loss : 0.022317, loss_ce: 0.004681
iteration 16932 : loss : 0.021497, loss_ce: 0.004239
iteration 16933 : loss : 0.028431, loss_ce: 0.008732
iteration 16934 : loss : 0.020234, loss_ce: 0.007330
iteration 16935 : loss : 0.019975, loss_ce: 0.006515
iteration 16936 : loss : 0.025296, loss_ce: 0.004844
iteration 16937 : loss : 0.018240, loss_ce: 0.006538
iteration 16938 : loss : 0.018711, loss_ce: 0.005348
iteration 16939 : loss : 0.021527, loss_ce: 0.007694
iteration 16940 : loss : 0.020865, loss_ce: 0.009409
iteration 16941 : loss : 0.018139, loss_ce: 0.005863
iteration 16942 : loss : 0.042721, loss_ce: 0.005814
iteration 16943 : loss : 0.020217, loss_ce: 0.006460
iteration 16944 : loss : 0.019795, loss_ce: 0.005739
iteration 16945 : loss : 0.020657, loss_ce: 0.005481
iteration 16946 : loss : 0.020952, loss_ce: 0.007703
iteration 16947 : loss : 0.017889, loss_ce: 0.006472
iteration 16948 : loss : 0.074280, loss_ce: 0.005757
iteration 16949 : loss : 0.020255, loss_ce: 0.007985
iteration 16950 : loss : 0.020788, loss_ce: 0.004365
iteration 16951 : loss : 0.020082, loss_ce: 0.007651
iteration 16952 : loss : 0.023160, loss_ce: 0.008989
iteration 16953 : loss : 0.023813, loss_ce: 0.010450
iteration 16954 : loss : 0.020680, loss_ce: 0.007789
iteration 16955 : loss : 0.024471, loss_ce: 0.009718
iteration 16956 : loss : 0.030776, loss_ce: 0.006742
iteration 16957 : loss : 0.020352, loss_ce: 0.007585
iteration 16958 : loss : 0.024425, loss_ce: 0.006940
iteration 16959 : loss : 0.019796, loss_ce: 0.005000
iteration 16960 : loss : 0.017132, loss_ce: 0.003386
iteration 16961 : loss : 0.023229, loss_ce: 0.013445
iteration 16962 : loss : 0.027483, loss_ce: 0.007305
iteration 16963 : loss : 0.020323, loss_ce: 0.007072
iteration 16964 : loss : 0.023734, loss_ce: 0.012003
iteration 16965 : loss : 0.026574, loss_ce: 0.010085
iteration 16966 : loss : 0.019753, loss_ce: 0.007463
iteration 16967 : loss : 0.023674, loss_ce: 0.008625
iteration 16968 : loss : 0.021689, loss_ce: 0.007212
iteration 16969 : loss : 0.020901, loss_ce: 0.006370
iteration 16970 : loss : 0.021964, loss_ce: 0.004051
iteration 16971 : loss : 0.025386, loss_ce: 0.008585
iteration 16972 : loss : 0.022576, loss_ce: 0.009354
iteration 16973 : loss : 0.016889, loss_ce: 0.006880
iteration 16974 : loss : 0.023106, loss_ce: 0.007911
iteration 16975 : loss : 0.019861, loss_ce: 0.006067
iteration 16976 : loss : 0.020950, loss_ce: 0.005725
iteration 16977 : loss : 0.023905, loss_ce: 0.005630
iteration 16978 : loss : 0.020479, loss_ce: 0.006599
iteration 16979 : loss : 0.027036, loss_ce: 0.008848
iteration 16980 : loss : 0.071691, loss_ce: 0.006226
iteration 16981 : loss : 0.018553, loss_ce: 0.004417
iteration 16982 : loss : 0.022021, loss_ce: 0.006982
iteration 16983 : loss : 0.019742, loss_ce: 0.009568
iteration 16984 : loss : 0.023088, loss_ce: 0.008950
iteration 16985 : loss : 0.023711, loss_ce: 0.007195
iteration 16986 : loss : 0.017766, loss_ce: 0.005511
iteration 16987 : loss : 0.021840, loss_ce: 0.007033
iteration 16988 : loss : 0.025037, loss_ce: 0.005503
iteration 16989 : loss : 0.027467, loss_ce: 0.006899
iteration 16990 : loss : 0.020766, loss_ce: 0.005544
iteration 16991 : loss : 0.021979, loss_ce: 0.007364
iteration 16992 : loss : 0.021382, loss_ce: 0.006593
iteration 16993 : loss : 0.019272, loss_ce: 0.006257
iteration 16994 : loss : 0.021779, loss_ce: 0.009240
iteration 16995 : loss : 0.019554, loss_ce: 0.009080
iteration 16996 : loss : 0.024982, loss_ce: 0.007879
iteration 16997 : loss : 0.020182, loss_ce: 0.008779
iteration 16998 : loss : 0.021878, loss_ce: 0.006938
iteration 16999 : loss : 0.020011, loss_ce: 0.006808
iteration 17000 : loss : 0.018222, loss_ce: 0.008021
iteration 17001 : loss : 0.020935, loss_ce: 0.008313
iteration 17002 : loss : 0.022709, loss_ce: 0.010167
iteration 17003 : loss : 0.019411, loss_ce: 0.007298
iteration 17004 : loss : 0.019346, loss_ce: 0.005359
iteration 17005 : loss : 0.019439, loss_ce: 0.007355
iteration 17006 : loss : 0.029877, loss_ce: 0.005007
iteration 17007 : loss : 0.024976, loss_ce: 0.008109
iteration 17008 : loss : 0.022580, loss_ce: 0.006717
iteration 17009 : loss : 0.023331, loss_ce: 0.007948
iteration 17010 : loss : 0.025915, loss_ce: 0.010828
iteration 17011 : loss : 0.023431, loss_ce: 0.008515
iteration 17012 : loss : 0.023940, loss_ce: 0.011091
iteration 17013 : loss : 0.026201, loss_ce: 0.005105
iteration 17014 : loss : 0.020620, loss_ce: 0.009359
iteration 17015 : loss : 0.025058, loss_ce: 0.006758
iteration 17016 : loss : 0.020661, loss_ce: 0.008751
iteration 17017 : loss : 0.024153, loss_ce: 0.008497
iteration 17018 : loss : 0.021576, loss_ce: 0.009540
iteration 17019 : loss : 0.088589, loss_ce: 0.011639
 92%|██████████████████████████▌  | 183/200 [3:01:25<15:27, 54.54s/it]iteration 17020 : loss : 0.079854, loss_ce: 0.007445
iteration 17021 : loss : 0.021727, loss_ce: 0.008331
iteration 17022 : loss : 0.020567, loss_ce: 0.011315
iteration 17023 : loss : 0.022219, loss_ce: 0.008738
iteration 17024 : loss : 0.027497, loss_ce: 0.009316
iteration 17025 : loss : 0.023700, loss_ce: 0.010029
iteration 17026 : loss : 0.022855, loss_ce: 0.008769
iteration 17027 : loss : 0.018775, loss_ce: 0.005710
iteration 17028 : loss : 0.020215, loss_ce: 0.007639
iteration 17029 : loss : 0.019401, loss_ce: 0.007871
iteration 17030 : loss : 0.023488, loss_ce: 0.007853
iteration 17031 : loss : 0.029382, loss_ce: 0.007645
iteration 17032 : loss : 0.026094, loss_ce: 0.011056
iteration 17033 : loss : 0.020325, loss_ce: 0.006507
iteration 17034 : loss : 0.023605, loss_ce: 0.004784
iteration 17035 : loss : 0.023735, loss_ce: 0.010272
iteration 17036 : loss : 0.019559, loss_ce: 0.007691
iteration 17037 : loss : 0.021854, loss_ce: 0.008670
iteration 17038 : loss : 0.021889, loss_ce: 0.009154
iteration 17039 : loss : 0.022157, loss_ce: 0.006659
iteration 17040 : loss : 0.035720, loss_ce: 0.005666
iteration 17041 : loss : 0.021082, loss_ce: 0.010154
iteration 17042 : loss : 0.022115, loss_ce: 0.006049
iteration 17043 : loss : 0.023534, loss_ce: 0.010218
iteration 17044 : loss : 0.023015, loss_ce: 0.010398
iteration 17045 : loss : 0.022481, loss_ce: 0.007435
iteration 17046 : loss : 0.021127, loss_ce: 0.005663
iteration 17047 : loss : 0.021034, loss_ce: 0.007433
iteration 17048 : loss : 0.021801, loss_ce: 0.007568
iteration 17049 : loss : 0.022986, loss_ce: 0.005525
iteration 17050 : loss : 0.036904, loss_ce: 0.006101
iteration 17051 : loss : 0.022008, loss_ce: 0.007577
iteration 17052 : loss : 0.077653, loss_ce: 0.009792
iteration 17053 : loss : 0.024325, loss_ce: 0.006809
iteration 17054 : loss : 0.022543, loss_ce: 0.007589
iteration 17055 : loss : 0.023002, loss_ce: 0.006214
iteration 17056 : loss : 0.074537, loss_ce: 0.007576
iteration 17057 : loss : 0.021985, loss_ce: 0.008319
iteration 17058 : loss : 0.020096, loss_ce: 0.007044
iteration 17059 : loss : 0.022517, loss_ce: 0.010522
iteration 17060 : loss : 0.020984, loss_ce: 0.005465
iteration 17061 : loss : 0.024143, loss_ce: 0.009170
iteration 17062 : loss : 0.020179, loss_ce: 0.003550
iteration 17063 : loss : 0.024343, loss_ce: 0.008310
iteration 17064 : loss : 0.022409, loss_ce: 0.008559
iteration 17065 : loss : 0.023373, loss_ce: 0.006704
iteration 17066 : loss : 0.019514, loss_ce: 0.006640
iteration 17067 : loss : 0.019352, loss_ce: 0.008710
iteration 17068 : loss : 0.024609, loss_ce: 0.004813
iteration 17069 : loss : 0.023386, loss_ce: 0.005405
iteration 17070 : loss : 0.022365, loss_ce: 0.007259
iteration 17071 : loss : 0.023348, loss_ce: 0.009207
iteration 17072 : loss : 0.071003, loss_ce: 0.004226
iteration 17073 : loss : 0.022877, loss_ce: 0.007474
iteration 17074 : loss : 0.019169, loss_ce: 0.008287
iteration 17075 : loss : 0.022651, loss_ce: 0.008776
iteration 17076 : loss : 0.026497, loss_ce: 0.005639
iteration 17077 : loss : 0.021508, loss_ce: 0.007050
iteration 17078 : loss : 0.021497, loss_ce: 0.007838
iteration 17079 : loss : 0.018005, loss_ce: 0.005688
iteration 17080 : loss : 0.077479, loss_ce: 0.010461
iteration 17081 : loss : 0.019526, loss_ce: 0.006040
iteration 17082 : loss : 0.022725, loss_ce: 0.009243
iteration 17083 : loss : 0.023748, loss_ce: 0.009751
iteration 17084 : loss : 0.021394, loss_ce: 0.007516
iteration 17085 : loss : 0.021046, loss_ce: 0.006183
iteration 17086 : loss : 0.026579, loss_ce: 0.007971
iteration 17087 : loss : 0.070916, loss_ce: 0.005135
iteration 17088 : loss : 0.016105, loss_ce: 0.006428
iteration 17089 : loss : 0.074713, loss_ce: 0.003683
iteration 17090 : loss : 0.020929, loss_ce: 0.006413
iteration 17091 : loss : 0.023097, loss_ce: 0.004997
iteration 17092 : loss : 0.019493, loss_ce: 0.007070
iteration 17093 : loss : 0.021544, loss_ce: 0.010657
iteration 17094 : loss : 0.024723, loss_ce: 0.008655
iteration 17095 : loss : 0.023234, loss_ce: 0.011037
iteration 17096 : loss : 0.020552, loss_ce: 0.005453
iteration 17097 : loss : 0.020184, loss_ce: 0.009055
iteration 17098 : loss : 0.023039, loss_ce: 0.008814
iteration 17099 : loss : 0.026512, loss_ce: 0.007153
iteration 17100 : loss : 0.022450, loss_ce: 0.005539
iteration 17101 : loss : 0.026108, loss_ce: 0.008491
iteration 17102 : loss : 0.023605, loss_ce: 0.008524
iteration 17103 : loss : 0.018802, loss_ce: 0.005457
iteration 17104 : loss : 0.069608, loss_ce: 0.005404
iteration 17105 : loss : 0.025047, loss_ce: 0.008652
iteration 17106 : loss : 0.021660, loss_ce: 0.005735
iteration 17107 : loss : 0.021845, loss_ce: 0.009958
iteration 17108 : loss : 0.022087, loss_ce: 0.007115
iteration 17109 : loss : 0.019692, loss_ce: 0.006559
iteration 17110 : loss : 0.025286, loss_ce: 0.007616
iteration 17111 : loss : 0.019767, loss_ce: 0.006714
iteration 17112 : loss : 0.029834, loss_ce: 0.011439
 92%|██████████████████████████▋  | 184/200 [3:02:20<14:32, 54.55s/it]iteration 17113 : loss : 0.021632, loss_ce: 0.007678
iteration 17114 : loss : 0.022845, loss_ce: 0.007082
iteration 17115 : loss : 0.022334, loss_ce: 0.011585
iteration 17116 : loss : 0.020529, loss_ce: 0.005168
iteration 17117 : loss : 0.028310, loss_ce: 0.007550
iteration 17118 : loss : 0.024777, loss_ce: 0.007876
iteration 17119 : loss : 0.070041, loss_ce: 0.007007
iteration 17120 : loss : 0.021014, loss_ce: 0.007149
iteration 17121 : loss : 0.021501, loss_ce: 0.008344
iteration 17122 : loss : 0.022394, loss_ce: 0.006776
iteration 17123 : loss : 0.020799, loss_ce: 0.008664
iteration 17124 : loss : 0.070439, loss_ce: 0.003728
iteration 17125 : loss : 0.021830, loss_ce: 0.008427
iteration 17126 : loss : 0.071981, loss_ce: 0.003956
iteration 17127 : loss : 0.020963, loss_ce: 0.008698
iteration 17128 : loss : 0.021230, loss_ce: 0.006289
iteration 17129 : loss : 0.022285, loss_ce: 0.006225
iteration 17130 : loss : 0.020343, loss_ce: 0.007722
iteration 17131 : loss : 0.021429, loss_ce: 0.008541
iteration 17132 : loss : 0.025052, loss_ce: 0.009974
iteration 17133 : loss : 0.018684, loss_ce: 0.005903
iteration 17134 : loss : 0.020177, loss_ce: 0.006817
iteration 17135 : loss : 0.019621, loss_ce: 0.006867
iteration 17136 : loss : 0.019278, loss_ce: 0.007756
iteration 17137 : loss : 0.025500, loss_ce: 0.004745
iteration 17138 : loss : 0.036310, loss_ce: 0.005835
iteration 17139 : loss : 0.023884, loss_ce: 0.008925
iteration 17140 : loss : 0.023068, loss_ce: 0.004748
iteration 17141 : loss : 0.021532, loss_ce: 0.006788
iteration 17142 : loss : 0.018245, loss_ce: 0.005174
iteration 17143 : loss : 0.033949, loss_ce: 0.003537
iteration 17144 : loss : 0.020814, loss_ce: 0.005587
iteration 17145 : loss : 0.021851, loss_ce: 0.011658
iteration 17146 : loss : 0.021251, loss_ce: 0.005340
iteration 17147 : loss : 0.026079, loss_ce: 0.009774
iteration 17148 : loss : 0.021847, loss_ce: 0.007803
iteration 17149 : loss : 0.020496, loss_ce: 0.008295
iteration 17150 : loss : 0.017370, loss_ce: 0.003918
iteration 17151 : loss : 0.021548, loss_ce: 0.011828
iteration 17152 : loss : 0.023430, loss_ce: 0.007629
iteration 17153 : loss : 0.022139, loss_ce: 0.010030
iteration 17154 : loss : 0.021694, loss_ce: 0.009187
iteration 17155 : loss : 0.021849, loss_ce: 0.008699
iteration 17156 : loss : 0.018990, loss_ce: 0.007600
iteration 17157 : loss : 0.023212, loss_ce: 0.006845
iteration 17158 : loss : 0.021777, loss_ce: 0.008148
iteration 17159 : loss : 0.024720, loss_ce: 0.008336
iteration 17160 : loss : 0.021640, loss_ce: 0.010259
iteration 17161 : loss : 0.024106, loss_ce: 0.010004
iteration 17162 : loss : 0.027584, loss_ce: 0.007390
iteration 17163 : loss : 0.023756, loss_ce: 0.009153
iteration 17164 : loss : 0.023642, loss_ce: 0.011994
iteration 17165 : loss : 0.020606, loss_ce: 0.007200
iteration 17166 : loss : 0.020399, loss_ce: 0.006203
iteration 17167 : loss : 0.021642, loss_ce: 0.009454
iteration 17168 : loss : 0.017307, loss_ce: 0.004848
iteration 17169 : loss : 0.021522, loss_ce: 0.006645
iteration 17170 : loss : 0.020442, loss_ce: 0.006297
iteration 17171 : loss : 0.023313, loss_ce: 0.006733
iteration 17172 : loss : 0.020327, loss_ce: 0.008436
iteration 17173 : loss : 0.018524, loss_ce: 0.007973
iteration 17174 : loss : 0.022318, loss_ce: 0.005614
iteration 17175 : loss : 0.023421, loss_ce: 0.004338
iteration 17176 : loss : 0.037830, loss_ce: 0.005332
iteration 17177 : loss : 0.023327, loss_ce: 0.005093
iteration 17178 : loss : 0.026495, loss_ce: 0.010052
iteration 17179 : loss : 0.023271, loss_ce: 0.003503
iteration 17180 : loss : 0.019884, loss_ce: 0.005894
iteration 17181 : loss : 0.020858, loss_ce: 0.008488
iteration 17182 : loss : 0.021638, loss_ce: 0.005548
iteration 17183 : loss : 0.075916, loss_ce: 0.006360
iteration 17184 : loss : 0.025785, loss_ce: 0.009896
iteration 17185 : loss : 0.074993, loss_ce: 0.006502
iteration 17186 : loss : 0.022303, loss_ce: 0.009259
iteration 17187 : loss : 0.023674, loss_ce: 0.009670
iteration 17188 : loss : 0.020437, loss_ce: 0.009562
iteration 17189 : loss : 0.021191, loss_ce: 0.008734
iteration 17190 : loss : 0.024801, loss_ce: 0.008330
iteration 17191 : loss : 0.023282, loss_ce: 0.011395
iteration 17192 : loss : 0.024829, loss_ce: 0.013331
iteration 17193 : loss : 0.020553, loss_ce: 0.005281
iteration 17194 : loss : 0.021120, loss_ce: 0.006930
iteration 17195 : loss : 0.025493, loss_ce: 0.011310
iteration 17196 : loss : 0.019115, loss_ce: 0.005433
iteration 17197 : loss : 0.021574, loss_ce: 0.007716
iteration 17198 : loss : 0.019133, loss_ce: 0.005765
iteration 17199 : loss : 0.024002, loss_ce: 0.007325
iteration 17200 : loss : 0.021026, loss_ce: 0.005297
iteration 17201 : loss : 0.023277, loss_ce: 0.009044
iteration 17202 : loss : 0.022634, loss_ce: 0.009307
iteration 17203 : loss : 0.025341, loss_ce: 0.007237
iteration 17204 : loss : 0.024792, loss_ce: 0.006250
iteration 17205 : loss : 0.281838, loss_ce: 0.005208
 92%|██████████████████████████▊  | 185/200 [3:03:14<13:38, 54.57s/it]iteration 17206 : loss : 0.023090, loss_ce: 0.005341
iteration 17207 : loss : 0.030281, loss_ce: 0.006135
iteration 17208 : loss : 0.021099, loss_ce: 0.004236
iteration 17209 : loss : 0.021473, loss_ce: 0.010273
iteration 17210 : loss : 0.025087, loss_ce: 0.009190
iteration 17211 : loss : 0.021169, loss_ce: 0.009171
iteration 17212 : loss : 0.020047, loss_ce: 0.007129
iteration 17213 : loss : 0.022435, loss_ce: 0.009419
iteration 17214 : loss : 0.022386, loss_ce: 0.009810
iteration 17215 : loss : 0.023045, loss_ce: 0.009933
iteration 17216 : loss : 0.020137, loss_ce: 0.009270
iteration 17217 : loss : 0.075642, loss_ce: 0.004113
iteration 17218 : loss : 0.025488, loss_ce: 0.007050
iteration 17219 : loss : 0.127169, loss_ce: 0.004895
iteration 17220 : loss : 0.018955, loss_ce: 0.007362
iteration 17221 : loss : 0.025189, loss_ce: 0.007920
iteration 17222 : loss : 0.022077, loss_ce: 0.010804
iteration 17223 : loss : 0.022282, loss_ce: 0.012191
iteration 17224 : loss : 0.021629, loss_ce: 0.009625
iteration 17225 : loss : 0.018977, loss_ce: 0.005995
iteration 17226 : loss : 0.017143, loss_ce: 0.005160
iteration 17227 : loss : 0.022247, loss_ce: 0.009999
iteration 17228 : loss : 0.024801, loss_ce: 0.006466
iteration 17229 : loss : 0.023016, loss_ce: 0.005746
iteration 17230 : loss : 0.019019, loss_ce: 0.005748
iteration 17231 : loss : 0.021354, loss_ce: 0.009611
iteration 17232 : loss : 0.020324, loss_ce: 0.005002
iteration 17233 : loss : 0.022865, loss_ce: 0.009187
iteration 17234 : loss : 0.017890, loss_ce: 0.005348
iteration 17235 : loss : 0.022939, loss_ce: 0.003845
iteration 17236 : loss : 0.023277, loss_ce: 0.006053
iteration 17237 : loss : 0.022887, loss_ce: 0.008878
iteration 17238 : loss : 0.022467, loss_ce: 0.010882
iteration 17239 : loss : 0.023978, loss_ce: 0.009889
iteration 17240 : loss : 0.021743, loss_ce: 0.009629
iteration 17241 : loss : 0.021685, loss_ce: 0.008753
iteration 17242 : loss : 0.021526, loss_ce: 0.009805
iteration 17243 : loss : 0.020778, loss_ce: 0.006800
iteration 17244 : loss : 0.021993, loss_ce: 0.009882
iteration 17245 : loss : 0.019814, loss_ce: 0.006437
iteration 17246 : loss : 0.028963, loss_ce: 0.005120
iteration 17247 : loss : 0.020917, loss_ce: 0.010180
iteration 17248 : loss : 0.021310, loss_ce: 0.006706
iteration 17249 : loss : 0.023320, loss_ce: 0.008320
iteration 17250 : loss : 0.022512, loss_ce: 0.010527
iteration 17251 : loss : 0.019407, loss_ce: 0.005401
iteration 17252 : loss : 0.024150, loss_ce: 0.010081
iteration 17253 : loss : 0.026440, loss_ce: 0.006694
iteration 17254 : loss : 0.021274, loss_ce: 0.006885
iteration 17255 : loss : 0.025645, loss_ce: 0.007451
iteration 17256 : loss : 0.018606, loss_ce: 0.005982
iteration 17257 : loss : 0.019137, loss_ce: 0.008758
iteration 17258 : loss : 0.022713, loss_ce: 0.006203
iteration 17259 : loss : 0.021936, loss_ce: 0.008835
iteration 17260 : loss : 0.023806, loss_ce: 0.010247
iteration 17261 : loss : 0.022573, loss_ce: 0.006754
iteration 17262 : loss : 0.019368, loss_ce: 0.007446
iteration 17263 : loss : 0.018327, loss_ce: 0.002986
iteration 17264 : loss : 0.020281, loss_ce: 0.009552
iteration 17265 : loss : 0.074005, loss_ce: 0.008659
iteration 17266 : loss : 0.020861, loss_ce: 0.009158
iteration 17267 : loss : 0.023978, loss_ce: 0.007905
iteration 17268 : loss : 0.023479, loss_ce: 0.007213
iteration 17269 : loss : 0.021119, loss_ce: 0.007808
iteration 17270 : loss : 0.027102, loss_ce: 0.006816
iteration 17271 : loss : 0.073822, loss_ce: 0.008840
iteration 17272 : loss : 0.022188, loss_ce: 0.006221
iteration 17273 : loss : 0.024199, loss_ce: 0.010692
iteration 17274 : loss : 0.072994, loss_ce: 0.005662
iteration 17275 : loss : 0.021744, loss_ce: 0.005530
iteration 17276 : loss : 0.022153, loss_ce: 0.004608
iteration 17277 : loss : 0.022810, loss_ce: 0.008601
iteration 17278 : loss : 0.022723, loss_ce: 0.005434
iteration 17279 : loss : 0.020919, loss_ce: 0.006022
iteration 17280 : loss : 0.020871, loss_ce: 0.007968
iteration 17281 : loss : 0.015138, loss_ce: 0.002914
iteration 17282 : loss : 0.020703, loss_ce: 0.006235
iteration 17283 : loss : 0.020993, loss_ce: 0.007453
iteration 17284 : loss : 0.022440, loss_ce: 0.008555
iteration 17285 : loss : 0.021128, loss_ce: 0.006649
iteration 17286 : loss : 0.026758, loss_ce: 0.007640
iteration 17287 : loss : 0.024997, loss_ce: 0.008310
iteration 17288 : loss : 0.024901, loss_ce: 0.007998
iteration 17289 : loss : 0.025552, loss_ce: 0.006110
iteration 17290 : loss : 0.022117, loss_ce: 0.006376
iteration 17291 : loss : 0.020234, loss_ce: 0.007785
iteration 17292 : loss : 0.025164, loss_ce: 0.010514
iteration 17293 : loss : 0.017220, loss_ce: 0.004764
iteration 17294 : loss : 0.073195, loss_ce: 0.005909
iteration 17295 : loss : 0.024156, loss_ce: 0.006451
iteration 17296 : loss : 0.022652, loss_ce: 0.004049
iteration 17297 : loss : 0.022182, loss_ce: 0.005411
iteration 17298 : loss : 0.285118, loss_ce: 0.002521
 93%|██████████████████████████▉  | 186/200 [3:04:09<12:43, 54.57s/it]iteration 17299 : loss : 0.021622, loss_ce: 0.009391
iteration 17300 : loss : 0.022471, loss_ce: 0.009269
iteration 17301 : loss : 0.023895, loss_ce: 0.007959
iteration 17302 : loss : 0.019141, loss_ce: 0.005622
iteration 17303 : loss : 0.024747, loss_ce: 0.007916
iteration 17304 : loss : 0.020727, loss_ce: 0.007651
iteration 17305 : loss : 0.025430, loss_ce: 0.003598
iteration 17306 : loss : 0.020205, loss_ce: 0.008392
iteration 17307 : loss : 0.022828, loss_ce: 0.008370
iteration 17308 : loss : 0.023271, loss_ce: 0.007439
iteration 17309 : loss : 0.020290, loss_ce: 0.009880
iteration 17310 : loss : 0.070258, loss_ce: 0.003135
iteration 17311 : loss : 0.022058, loss_ce: 0.005694
iteration 17312 : loss : 0.023697, loss_ce: 0.009471
iteration 17313 : loss : 0.016471, loss_ce: 0.005576
iteration 17314 : loss : 0.019912, loss_ce: 0.008007
iteration 17315 : loss : 0.016596, loss_ce: 0.005208
iteration 17316 : loss : 0.019713, loss_ce: 0.007964
iteration 17317 : loss : 0.021791, loss_ce: 0.006038
iteration 17318 : loss : 0.021433, loss_ce: 0.008938
iteration 17319 : loss : 0.023555, loss_ce: 0.010551
iteration 17320 : loss : 0.018506, loss_ce: 0.007005
iteration 17321 : loss : 0.023701, loss_ce: 0.005516
iteration 17322 : loss : 0.024805, loss_ce: 0.008448
iteration 17323 : loss : 0.021001, loss_ce: 0.007441
iteration 17324 : loss : 0.022097, loss_ce: 0.008361
iteration 17325 : loss : 0.018767, loss_ce: 0.006060
iteration 17326 : loss : 0.019813, loss_ce: 0.005693
iteration 17327 : loss : 0.020255, loss_ce: 0.005969
iteration 17328 : loss : 0.018737, loss_ce: 0.007099
iteration 17329 : loss : 0.019266, loss_ce: 0.006573
iteration 17330 : loss : 0.016706, loss_ce: 0.006857
iteration 17331 : loss : 0.024033, loss_ce: 0.011279
iteration 17332 : loss : 0.037744, loss_ce: 0.003376
iteration 17333 : loss : 0.024389, loss_ce: 0.006402
iteration 17334 : loss : 0.035519, loss_ce: 0.006434
iteration 17335 : loss : 0.073053, loss_ce: 0.006305
iteration 17336 : loss : 0.024827, loss_ce: 0.007771
iteration 17337 : loss : 0.022494, loss_ce: 0.007956
iteration 17338 : loss : 0.020302, loss_ce: 0.009392
iteration 17339 : loss : 0.022704, loss_ce: 0.011270
iteration 17340 : loss : 0.025612, loss_ce: 0.010056
iteration 17341 : loss : 0.019691, loss_ce: 0.007228
iteration 17342 : loss : 0.072248, loss_ce: 0.006278
iteration 17343 : loss : 0.019244, loss_ce: 0.009267
iteration 17344 : loss : 0.024757, loss_ce: 0.009762
iteration 17345 : loss : 0.019715, loss_ce: 0.004821
iteration 17346 : loss : 0.021681, loss_ce: 0.005103
iteration 17347 : loss : 0.021268, loss_ce: 0.007825
iteration 17348 : loss : 0.022608, loss_ce: 0.010475
iteration 17349 : loss : 0.076952, loss_ce: 0.003180
iteration 17350 : loss : 0.022318, loss_ce: 0.007834
iteration 17351 : loss : 0.022458, loss_ce: 0.007339
iteration 17352 : loss : 0.019843, loss_ce: 0.006440
iteration 17353 : loss : 0.020093, loss_ce: 0.007491
iteration 17354 : loss : 0.023796, loss_ce: 0.010590
iteration 17355 : loss : 0.020497, loss_ce: 0.004451
iteration 17356 : loss : 0.022958, loss_ce: 0.009696
iteration 17357 : loss : 0.024506, loss_ce: 0.012199
iteration 17358 : loss : 0.018379, loss_ce: 0.005054
iteration 17359 : loss : 0.071556, loss_ce: 0.005406
iteration 17360 : loss : 0.021802, loss_ce: 0.004723
iteration 17361 : loss : 0.022882, loss_ce: 0.004910
iteration 17362 : loss : 0.070147, loss_ce: 0.005706
iteration 17363 : loss : 0.021658, loss_ce: 0.009946
iteration 17364 : loss : 0.021590, loss_ce: 0.007916
iteration 17365 : loss : 0.023782, loss_ce: 0.005448
iteration 17366 : loss : 0.020569, loss_ce: 0.006553
iteration 17367 : loss : 0.020205, loss_ce: 0.007319
iteration 17368 : loss : 0.022101, loss_ce: 0.009024
iteration 17369 : loss : 0.024505, loss_ce: 0.009474
iteration 17370 : loss : 0.023413, loss_ce: 0.005052
iteration 17371 : loss : 0.019411, loss_ce: 0.007647
iteration 17372 : loss : 0.019592, loss_ce: 0.006346
iteration 17373 : loss : 0.023224, loss_ce: 0.008539
iteration 17374 : loss : 0.023767, loss_ce: 0.009828
iteration 17375 : loss : 0.021937, loss_ce: 0.013212
iteration 17376 : loss : 0.021919, loss_ce: 0.007098
iteration 17377 : loss : 0.022657, loss_ce: 0.004102
iteration 17378 : loss : 0.022528, loss_ce: 0.009269
iteration 17379 : loss : 0.020127, loss_ce: 0.007977
iteration 17380 : loss : 0.019922, loss_ce: 0.006961
iteration 17381 : loss : 0.024354, loss_ce: 0.011032
iteration 17382 : loss : 0.027505, loss_ce: 0.007038
iteration 17383 : loss : 0.025032, loss_ce: 0.009423
iteration 17384 : loss : 0.073784, loss_ce: 0.007757
iteration 17385 : loss : 0.071742, loss_ce: 0.005823
iteration 17386 : loss : 0.020759, loss_ce: 0.008322
iteration 17387 : loss : 0.021428, loss_ce: 0.008224
iteration 17388 : loss : 0.029147, loss_ce: 0.004616
iteration 17389 : loss : 0.021874, loss_ce: 0.007672
iteration 17390 : loss : 0.020662, loss_ce: 0.007866
iteration 17391 : loss : 0.086457, loss_ce: 0.018169
 94%|███████████████████████████  | 187/200 [3:05:03<11:49, 54.58s/it]iteration 17392 : loss : 0.024038, loss_ce: 0.008298
iteration 17393 : loss : 0.023202, loss_ce: 0.010016
iteration 17394 : loss : 0.021832, loss_ce: 0.008463
iteration 17395 : loss : 0.024995, loss_ce: 0.009920
iteration 17396 : loss : 0.021342, loss_ce: 0.008134
iteration 17397 : loss : 0.071665, loss_ce: 0.005028
iteration 17398 : loss : 0.019436, loss_ce: 0.006705
iteration 17399 : loss : 0.020968, loss_ce: 0.008909
iteration 17400 : loss : 0.021203, loss_ce: 0.009860
iteration 17401 : loss : 0.021767, loss_ce: 0.009100
iteration 17402 : loss : 0.019855, loss_ce: 0.006244
iteration 17403 : loss : 0.021626, loss_ce: 0.009693
iteration 17404 : loss : 0.023216, loss_ce: 0.006668
iteration 17405 : loss : 0.017683, loss_ce: 0.008048
iteration 17406 : loss : 0.020367, loss_ce: 0.007487
iteration 17407 : loss : 0.022386, loss_ce: 0.008427
iteration 17408 : loss : 0.019428, loss_ce: 0.008649
iteration 17409 : loss : 0.021244, loss_ce: 0.009111
iteration 17410 : loss : 0.023335, loss_ce: 0.011460
iteration 17411 : loss : 0.018737, loss_ce: 0.005203
iteration 17412 : loss : 0.018463, loss_ce: 0.006054
iteration 17413 : loss : 0.018264, loss_ce: 0.007819
iteration 17414 : loss : 0.020905, loss_ce: 0.010600
iteration 17415 : loss : 0.025142, loss_ce: 0.007917
iteration 17416 : loss : 0.019099, loss_ce: 0.007751
iteration 17417 : loss : 0.021243, loss_ce: 0.003312
iteration 17418 : loss : 0.023455, loss_ce: 0.007114
iteration 17419 : loss : 0.021436, loss_ce: 0.005521
iteration 17420 : loss : 0.020181, loss_ce: 0.007825
iteration 17421 : loss : 0.020162, loss_ce: 0.005296
iteration 17422 : loss : 0.020295, loss_ce: 0.004787
iteration 17423 : loss : 0.025869, loss_ce: 0.006472
iteration 17424 : loss : 0.023594, loss_ce: 0.006878
iteration 17425 : loss : 0.020892, loss_ce: 0.009125
iteration 17426 : loss : 0.024130, loss_ce: 0.010673
iteration 17427 : loss : 0.020689, loss_ce: 0.007069
iteration 17428 : loss : 0.072424, loss_ce: 0.005537
iteration 17429 : loss : 0.019281, loss_ce: 0.008352
iteration 17430 : loss : 0.021596, loss_ce: 0.009654
iteration 17431 : loss : 0.022140, loss_ce: 0.011212
iteration 17432 : loss : 0.069212, loss_ce: 0.003102
iteration 17433 : loss : 0.022754, loss_ce: 0.008467
iteration 17434 : loss : 0.018363, loss_ce: 0.004464
iteration 17435 : loss : 0.020900, loss_ce: 0.006279
iteration 17436 : loss : 0.022800, loss_ce: 0.008358
iteration 17437 : loss : 0.025771, loss_ce: 0.009923
iteration 17438 : loss : 0.027471, loss_ce: 0.012322
iteration 17439 : loss : 0.022500, loss_ce: 0.008945
iteration 17440 : loss : 0.024535, loss_ce: 0.006784
iteration 17441 : loss : 0.028033, loss_ce: 0.004199
iteration 17442 : loss : 0.022346, loss_ce: 0.007797
iteration 17443 : loss : 0.019104, loss_ce: 0.005281
iteration 17444 : loss : 0.022992, loss_ce: 0.009724
iteration 17445 : loss : 0.018297, loss_ce: 0.004822
iteration 17446 : loss : 0.020166, loss_ce: 0.005273
iteration 17447 : loss : 0.019238, loss_ce: 0.006290
iteration 17448 : loss : 0.070589, loss_ce: 0.005741
iteration 17449 : loss : 0.071414, loss_ce: 0.004084
iteration 17450 : loss : 0.024912, loss_ce: 0.009205
iteration 17451 : loss : 0.022910, loss_ce: 0.007794
iteration 17452 : loss : 0.024664, loss_ce: 0.007336
iteration 17453 : loss : 0.023404, loss_ce: 0.004089
iteration 17454 : loss : 0.020831, loss_ce: 0.006541
iteration 17455 : loss : 0.018404, loss_ce: 0.007553
iteration 17456 : loss : 0.025295, loss_ce: 0.006699
iteration 17457 : loss : 0.022698, loss_ce: 0.007667
iteration 17458 : loss : 0.024864, loss_ce: 0.010019
iteration 17459 : loss : 0.019527, loss_ce: 0.007703
iteration 17460 : loss : 0.019624, loss_ce: 0.007014
iteration 17461 : loss : 0.019049, loss_ce: 0.007422
iteration 17462 : loss : 0.018833, loss_ce: 0.007820
iteration 17463 : loss : 0.022356, loss_ce: 0.006671
iteration 17464 : loss : 0.019019, loss_ce: 0.006051
iteration 17465 : loss : 0.023087, loss_ce: 0.010484
iteration 17466 : loss : 0.021337, loss_ce: 0.008378
iteration 17467 : loss : 0.074904, loss_ce: 0.007035
iteration 17468 : loss : 0.021701, loss_ce: 0.003772
iteration 17469 : loss : 0.020689, loss_ce: 0.006846
iteration 17470 : loss : 0.021450, loss_ce: 0.008808
iteration 17471 : loss : 0.023224, loss_ce: 0.007664
iteration 17472 : loss : 0.020402, loss_ce: 0.007053
iteration 17473 : loss : 0.021611, loss_ce: 0.005382
iteration 17474 : loss : 0.019006, loss_ce: 0.005746
iteration 17475 : loss : 0.019021, loss_ce: 0.006530
iteration 17476 : loss : 0.027453, loss_ce: 0.008920
iteration 17477 : loss : 0.023695, loss_ce: 0.011921
iteration 17478 : loss : 0.022467, loss_ce: 0.009031
iteration 17479 : loss : 0.020828, loss_ce: 0.004514
iteration 17480 : loss : 0.022332, loss_ce: 0.009504
iteration 17481 : loss : 0.023990, loss_ce: 0.004958
iteration 17482 : loss : 0.018546, loss_ce: 0.006715
iteration 17483 : loss : 0.027549, loss_ce: 0.005908
iteration 17484 : loss : 0.129861, loss_ce: 0.007582
 94%|███████████████████████████▎ | 188/200 [3:05:58<10:55, 54.59s/it]iteration 17485 : loss : 0.071718, loss_ce: 0.007012
iteration 17486 : loss : 0.025365, loss_ce: 0.007377
iteration 17487 : loss : 0.073029, loss_ce: 0.005876
iteration 17488 : loss : 0.020508, loss_ce: 0.005524
iteration 17489 : loss : 0.027049, loss_ce: 0.006150
iteration 17490 : loss : 0.016245, loss_ce: 0.002719
iteration 17491 : loss : 0.023465, loss_ce: 0.007355
iteration 17492 : loss : 0.022360, loss_ce: 0.008960
iteration 17493 : loss : 0.020096, loss_ce: 0.006717
iteration 17494 : loss : 0.020633, loss_ce: 0.008719
iteration 17495 : loss : 0.024142, loss_ce: 0.008592
iteration 17496 : loss : 0.023627, loss_ce: 0.007937
iteration 17497 : loss : 0.019952, loss_ce: 0.007730
iteration 17498 : loss : 0.021564, loss_ce: 0.007534
iteration 17499 : loss : 0.020179, loss_ce: 0.006689
iteration 17500 : loss : 0.021589, loss_ce: 0.005676
iteration 17501 : loss : 0.025849, loss_ce: 0.011985
iteration 17502 : loss : 0.019732, loss_ce: 0.007966
iteration 17503 : loss : 0.021096, loss_ce: 0.005387
iteration 17504 : loss : 0.023713, loss_ce: 0.009881
iteration 17505 : loss : 0.019851, loss_ce: 0.005037
iteration 17506 : loss : 0.021353, loss_ce: 0.006068
iteration 17507 : loss : 0.019664, loss_ce: 0.009343
iteration 17508 : loss : 0.018753, loss_ce: 0.007492
iteration 17509 : loss : 0.018712, loss_ce: 0.006677
iteration 17510 : loss : 0.026023, loss_ce: 0.009777
iteration 17511 : loss : 0.023868, loss_ce: 0.007480
iteration 17512 : loss : 0.020336, loss_ce: 0.006562
iteration 17513 : loss : 0.018977, loss_ce: 0.005833
iteration 17514 : loss : 0.022025, loss_ce: 0.008428
iteration 17515 : loss : 0.019208, loss_ce: 0.005002
iteration 17516 : loss : 0.021356, loss_ce: 0.006094
iteration 17517 : loss : 0.023812, loss_ce: 0.005449
iteration 17518 : loss : 0.023555, loss_ce: 0.011325
iteration 17519 : loss : 0.026137, loss_ce: 0.006346
iteration 17520 : loss : 0.021686, loss_ce: 0.009093
iteration 17521 : loss : 0.017157, loss_ce: 0.006851
iteration 17522 : loss : 0.026477, loss_ce: 0.009267
iteration 17523 : loss : 0.021408, loss_ce: 0.006316
iteration 17524 : loss : 0.021480, loss_ce: 0.006078
iteration 17525 : loss : 0.074882, loss_ce: 0.006195
iteration 17526 : loss : 0.022003, loss_ce: 0.009494
iteration 17527 : loss : 0.021665, loss_ce: 0.008181
iteration 17528 : loss : 0.023984, loss_ce: 0.009680
iteration 17529 : loss : 0.021170, loss_ce: 0.008973
iteration 17530 : loss : 0.025176, loss_ce: 0.008952
iteration 17531 : loss : 0.021605, loss_ce: 0.006645
iteration 17532 : loss : 0.022887, loss_ce: 0.011905
iteration 17533 : loss : 0.020875, loss_ce: 0.008039
iteration 17534 : loss : 0.022329, loss_ce: 0.011908
iteration 17535 : loss : 0.024652, loss_ce: 0.009995
iteration 17536 : loss : 0.018664, loss_ce: 0.005558
iteration 17537 : loss : 0.023326, loss_ce: 0.007086
iteration 17538 : loss : 0.019541, loss_ce: 0.007129
iteration 17539 : loss : 0.022761, loss_ce: 0.007594
iteration 17540 : loss : 0.025452, loss_ce: 0.012730
iteration 17541 : loss : 0.027506, loss_ce: 0.008393
iteration 17542 : loss : 0.019611, loss_ce: 0.007681
iteration 17543 : loss : 0.026991, loss_ce: 0.008268
iteration 17544 : loss : 0.022155, loss_ce: 0.010474
iteration 17545 : loss : 0.024112, loss_ce: 0.006702
iteration 17546 : loss : 0.019527, loss_ce: 0.005099
iteration 17547 : loss : 0.020985, loss_ce: 0.006001
iteration 17548 : loss : 0.020265, loss_ce: 0.007701
iteration 17549 : loss : 0.017284, loss_ce: 0.003851
iteration 17550 : loss : 0.021909, loss_ce: 0.005757
iteration 17551 : loss : 0.038763, loss_ce: 0.007369
iteration 17552 : loss : 0.023998, loss_ce: 0.008169
iteration 17553 : loss : 0.023927, loss_ce: 0.005367
iteration 17554 : loss : 0.023942, loss_ce: 0.005806
iteration 17555 : loss : 0.017998, loss_ce: 0.005373
iteration 17556 : loss : 0.071284, loss_ce: 0.006094
iteration 17557 : loss : 0.020144, loss_ce: 0.005782
iteration 17558 : loss : 0.019283, loss_ce: 0.006695
iteration 17559 : loss : 0.025125, loss_ce: 0.009652
iteration 17560 : loss : 0.017991, loss_ce: 0.006005
iteration 17561 : loss : 0.015675, loss_ce: 0.005103
iteration 17562 : loss : 0.018788, loss_ce: 0.006979
iteration 17563 : loss : 0.022079, loss_ce: 0.007780
iteration 17564 : loss : 0.019592, loss_ce: 0.008108
iteration 17565 : loss : 0.020749, loss_ce: 0.007991
iteration 17566 : loss : 0.019829, loss_ce: 0.007499
iteration 17567 : loss : 0.018779, loss_ce: 0.006486
iteration 17568 : loss : 0.019817, loss_ce: 0.007830
iteration 17569 : loss : 0.020258, loss_ce: 0.008069
iteration 17570 : loss : 0.024194, loss_ce: 0.008116
iteration 17571 : loss : 0.021364, loss_ce: 0.005847
iteration 17572 : loss : 0.020089, loss_ce: 0.006336
iteration 17573 : loss : 0.017868, loss_ce: 0.006392
iteration 17574 : loss : 0.027224, loss_ce: 0.006500
iteration 17575 : loss : 0.021067, loss_ce: 0.006936
iteration 17576 : loss : 0.019501, loss_ce: 0.007913
iteration 17577 : loss : 0.437781, loss_ce: 0.000302
 94%|███████████████████████████▍ | 189/200 [3:06:52<10:00, 54.57s/it]iteration 17578 : loss : 0.023982, loss_ce: 0.007659
iteration 17579 : loss : 0.026131, loss_ce: 0.013056
iteration 17580 : loss : 0.073004, loss_ce: 0.005569
iteration 17581 : loss : 0.025014, loss_ce: 0.011481
iteration 17582 : loss : 0.018566, loss_ce: 0.006133
iteration 17583 : loss : 0.018616, loss_ce: 0.006302
iteration 17584 : loss : 0.020327, loss_ce: 0.006968
iteration 17585 : loss : 0.020676, loss_ce: 0.007511
iteration 17586 : loss : 0.023980, loss_ce: 0.009211
iteration 17587 : loss : 0.023937, loss_ce: 0.009390
iteration 17588 : loss : 0.022229, loss_ce: 0.006048
iteration 17589 : loss : 0.021747, loss_ce: 0.007503
iteration 17590 : loss : 0.074835, loss_ce: 0.008618
iteration 17591 : loss : 0.020477, loss_ce: 0.007070
iteration 17592 : loss : 0.022080, loss_ce: 0.006068
iteration 17593 : loss : 0.022656, loss_ce: 0.010462
iteration 17594 : loss : 0.020445, loss_ce: 0.010433
iteration 17595 : loss : 0.024026, loss_ce: 0.009210
iteration 17596 : loss : 0.018473, loss_ce: 0.007449
iteration 17597 : loss : 0.029132, loss_ce: 0.010158
iteration 17598 : loss : 0.022498, loss_ce: 0.005545
iteration 17599 : loss : 0.024662, loss_ce: 0.007359
iteration 17600 : loss : 0.024666, loss_ce: 0.007924
iteration 17601 : loss : 0.022806, loss_ce: 0.007726
iteration 17602 : loss : 0.023448, loss_ce: 0.003188
iteration 17603 : loss : 0.022130, loss_ce: 0.006660
iteration 17604 : loss : 0.073709, loss_ce: 0.004576
iteration 17605 : loss : 0.020497, loss_ce: 0.006899
iteration 17606 : loss : 0.072264, loss_ce: 0.007114
iteration 17607 : loss : 0.021056, loss_ce: 0.008817
iteration 17608 : loss : 0.024904, loss_ce: 0.011169
iteration 17609 : loss : 0.018166, loss_ce: 0.006699
iteration 17610 : loss : 0.020506, loss_ce: 0.008467
iteration 17611 : loss : 0.019432, loss_ce: 0.004840
iteration 17612 : loss : 0.023406, loss_ce: 0.007971
iteration 17613 : loss : 0.019415, loss_ce: 0.005252
iteration 17614 : loss : 0.020180, loss_ce: 0.008984
iteration 17615 : loss : 0.023536, loss_ce: 0.007069
iteration 17616 : loss : 0.020206, loss_ce: 0.007367
iteration 17617 : loss : 0.022599, loss_ce: 0.005863
iteration 17618 : loss : 0.020825, loss_ce: 0.006932
iteration 17619 : loss : 0.023006, loss_ce: 0.007157
iteration 17620 : loss : 0.024257, loss_ce: 0.011557
iteration 17621 : loss : 0.020409, loss_ce: 0.005449
iteration 17622 : loss : 0.039042, loss_ce: 0.002687
iteration 17623 : loss : 0.072835, loss_ce: 0.004059
iteration 17624 : loss : 0.022847, loss_ce: 0.005202
iteration 17625 : loss : 0.022147, loss_ce: 0.007031
iteration 17626 : loss : 0.019356, loss_ce: 0.006060
iteration 17627 : loss : 0.024058, loss_ce: 0.003933
iteration 17628 : loss : 0.027889, loss_ce: 0.006437
iteration 17629 : loss : 0.018846, loss_ce: 0.007555
iteration 17630 : loss : 0.023835, loss_ce: 0.009679
iteration 17631 : loss : 0.020338, loss_ce: 0.006778
iteration 17632 : loss : 0.020482, loss_ce: 0.004914
iteration 17633 : loss : 0.021487, loss_ce: 0.008461
iteration 17634 : loss : 0.020146, loss_ce: 0.008124
iteration 17635 : loss : 0.018809, loss_ce: 0.004814
iteration 17636 : loss : 0.019313, loss_ce: 0.006173
iteration 17637 : loss : 0.022509, loss_ce: 0.004433
iteration 17638 : loss : 0.022573, loss_ce: 0.006042
iteration 17639 : loss : 0.023429, loss_ce: 0.007722
iteration 17640 : loss : 0.023570, loss_ce: 0.011374
iteration 17641 : loss : 0.023942, loss_ce: 0.008331
iteration 17642 : loss : 0.073549, loss_ce: 0.008097
iteration 17643 : loss : 0.020904, loss_ce: 0.008858
iteration 17644 : loss : 0.020473, loss_ce: 0.010270
iteration 17645 : loss : 0.021807, loss_ce: 0.007915
iteration 17646 : loss : 0.019238, loss_ce: 0.008153
iteration 17647 : loss : 0.023340, loss_ce: 0.009776
iteration 17648 : loss : 0.019848, loss_ce: 0.007833
iteration 17649 : loss : 0.023638, loss_ce: 0.006728
iteration 17650 : loss : 0.022368, loss_ce: 0.007899
iteration 17651 : loss : 0.019053, loss_ce: 0.006805
iteration 17652 : loss : 0.021727, loss_ce: 0.010088
iteration 17653 : loss : 0.023405, loss_ce: 0.011874
iteration 17654 : loss : 0.018712, loss_ce: 0.004546
iteration 17655 : loss : 0.022215, loss_ce: 0.008916
iteration 17656 : loss : 0.023506, loss_ce: 0.010584
iteration 17657 : loss : 0.024450, loss_ce: 0.008842
iteration 17658 : loss : 0.025688, loss_ce: 0.008675
iteration 17659 : loss : 0.024861, loss_ce: 0.007666
iteration 17660 : loss : 0.018846, loss_ce: 0.007825
iteration 17661 : loss : 0.020303, loss_ce: 0.005141
iteration 17662 : loss : 0.021533, loss_ce: 0.005159
iteration 17663 : loss : 0.018573, loss_ce: 0.008435
iteration 17664 : loss : 0.023532, loss_ce: 0.010100
iteration 17665 : loss : 0.020800, loss_ce: 0.005871
iteration 17666 : loss : 0.020161, loss_ce: 0.005450
iteration 17667 : loss : 0.024309, loss_ce: 0.010481
iteration 17668 : loss : 0.022665, loss_ce: 0.005835
iteration 17669 : loss : 0.017507, loss_ce: 0.003321
iteration 17670 : loss : 0.132986, loss_ce: 0.006183
 95%|███████████████████████████▌ | 190/200 [3:07:47<09:05, 54.54s/it]iteration 17671 : loss : 0.072334, loss_ce: 0.004613
iteration 17672 : loss : 0.028179, loss_ce: 0.007369
iteration 17673 : loss : 0.021538, loss_ce: 0.005668
iteration 17674 : loss : 0.022506, loss_ce: 0.006958
iteration 17675 : loss : 0.022387, loss_ce: 0.008845
iteration 17676 : loss : 0.021291, loss_ce: 0.005685
iteration 17677 : loss : 0.019979, loss_ce: 0.004736
iteration 17678 : loss : 0.023334, loss_ce: 0.008644
iteration 17679 : loss : 0.026262, loss_ce: 0.008876
iteration 17680 : loss : 0.021202, loss_ce: 0.007991
iteration 17681 : loss : 0.020898, loss_ce: 0.006737
iteration 17682 : loss : 0.020445, loss_ce: 0.006287
iteration 17683 : loss : 0.022879, loss_ce: 0.008223
iteration 17684 : loss : 0.019683, loss_ce: 0.006667
iteration 17685 : loss : 0.073775, loss_ce: 0.006396
iteration 17686 : loss : 0.017921, loss_ce: 0.005937
iteration 17687 : loss : 0.021715, loss_ce: 0.009258
iteration 17688 : loss : 0.027490, loss_ce: 0.013364
iteration 17689 : loss : 0.074623, loss_ce: 0.004598
iteration 17690 : loss : 0.024851, loss_ce: 0.009622
iteration 17691 : loss : 0.024553, loss_ce: 0.009615
iteration 17692 : loss : 0.020318, loss_ce: 0.007310
iteration 17693 : loss : 0.021591, loss_ce: 0.010242
iteration 17694 : loss : 0.021530, loss_ce: 0.008673
iteration 17695 : loss : 0.074169, loss_ce: 0.006045
iteration 17696 : loss : 0.072108, loss_ce: 0.003898
iteration 17697 : loss : 0.019161, loss_ce: 0.007487
iteration 17698 : loss : 0.029066, loss_ce: 0.010991
iteration 17699 : loss : 0.020766, loss_ce: 0.004932
iteration 17700 : loss : 0.023392, loss_ce: 0.009020
iteration 17701 : loss : 0.069906, loss_ce: 0.004501
iteration 17702 : loss : 0.019609, loss_ce: 0.005706
iteration 17703 : loss : 0.074824, loss_ce: 0.005304
iteration 17704 : loss : 0.019280, loss_ce: 0.009302
iteration 17705 : loss : 0.027544, loss_ce: 0.011772
iteration 17706 : loss : 0.020473, loss_ce: 0.005576
iteration 17707 : loss : 0.020581, loss_ce: 0.007437
iteration 17708 : loss : 0.023698, loss_ce: 0.011029
iteration 17709 : loss : 0.070806, loss_ce: 0.006319
iteration 17710 : loss : 0.022322, loss_ce: 0.008567
iteration 17711 : loss : 0.020833, loss_ce: 0.008786
iteration 17712 : loss : 0.017625, loss_ce: 0.005030
iteration 17713 : loss : 0.073611, loss_ce: 0.005250
iteration 17714 : loss : 0.020010, loss_ce: 0.005814
iteration 17715 : loss : 0.019034, loss_ce: 0.007542
iteration 17716 : loss : 0.022755, loss_ce: 0.008045
iteration 17717 : loss : 0.021626, loss_ce: 0.004719
iteration 17718 : loss : 0.017906, loss_ce: 0.004616
iteration 17719 : loss : 0.022413, loss_ce: 0.007754
iteration 17720 : loss : 0.025869, loss_ce: 0.009562
iteration 17721 : loss : 0.027126, loss_ce: 0.012364
iteration 17722 : loss : 0.022538, loss_ce: 0.009695
iteration 17723 : loss : 0.020260, loss_ce: 0.007689
iteration 17724 : loss : 0.020732, loss_ce: 0.008697
iteration 17725 : loss : 0.021359, loss_ce: 0.008990
iteration 17726 : loss : 0.021857, loss_ce: 0.007372
iteration 17727 : loss : 0.018809, loss_ce: 0.008006
iteration 17728 : loss : 0.023326, loss_ce: 0.009674
iteration 17729 : loss : 0.073892, loss_ce: 0.006290
iteration 17730 : loss : 0.020182, loss_ce: 0.008446
iteration 17731 : loss : 0.020455, loss_ce: 0.007062
iteration 17732 : loss : 0.023728, loss_ce: 0.008234
iteration 17733 : loss : 0.075672, loss_ce: 0.006242
iteration 17734 : loss : 0.020960, loss_ce: 0.007084
iteration 17735 : loss : 0.072421, loss_ce: 0.003472
iteration 17736 : loss : 0.021470, loss_ce: 0.009446
iteration 17737 : loss : 0.019890, loss_ce: 0.006084
iteration 17738 : loss : 0.022589, loss_ce: 0.009397
iteration 17739 : loss : 0.020983, loss_ce: 0.010281
iteration 17740 : loss : 0.074989, loss_ce: 0.004822
iteration 17741 : loss : 0.023419, loss_ce: 0.006692
iteration 17742 : loss : 0.020368, loss_ce: 0.007410
iteration 17743 : loss : 0.024679, loss_ce: 0.011027
iteration 17744 : loss : 0.015896, loss_ce: 0.006329
iteration 17745 : loss : 0.019202, loss_ce: 0.007189
iteration 17746 : loss : 0.019201, loss_ce: 0.004838
iteration 17747 : loss : 0.021495, loss_ce: 0.008188
iteration 17748 : loss : 0.037882, loss_ce: 0.003000
iteration 17749 : loss : 0.022109, loss_ce: 0.010008
iteration 17750 : loss : 0.019913, loss_ce: 0.009932
iteration 17751 : loss : 0.019363, loss_ce: 0.005350
iteration 17752 : loss : 0.029278, loss_ce: 0.008245
iteration 17753 : loss : 0.019369, loss_ce: 0.004863
iteration 17754 : loss : 0.023101, loss_ce: 0.007125
iteration 17755 : loss : 0.024130, loss_ce: 0.011429
iteration 17756 : loss : 0.016970, loss_ce: 0.004057
iteration 17757 : loss : 0.020422, loss_ce: 0.006824
iteration 17758 : loss : 0.022117, loss_ce: 0.011012
iteration 17759 : loss : 0.020484, loss_ce: 0.006516
iteration 17760 : loss : 0.036225, loss_ce: 0.006873
iteration 17761 : loss : 0.029113, loss_ce: 0.006948
iteration 17762 : loss : 0.021047, loss_ce: 0.003209
iteration 17763 : loss : 0.125755, loss_ce: 0.005491
 96%|███████████████████████████▋ | 191/200 [3:08:42<08:11, 54.56s/it]iteration 17764 : loss : 0.016683, loss_ce: 0.007175
iteration 17765 : loss : 0.024880, loss_ce: 0.006356
iteration 17766 : loss : 0.020730, loss_ce: 0.008358
iteration 17767 : loss : 0.022855, loss_ce: 0.010029
iteration 17768 : loss : 0.024736, loss_ce: 0.011008
iteration 17769 : loss : 0.022472, loss_ce: 0.005764
iteration 17770 : loss : 0.022875, loss_ce: 0.008731
iteration 17771 : loss : 0.022079, loss_ce: 0.008314
iteration 17772 : loss : 0.025702, loss_ce: 0.007952
iteration 17773 : loss : 0.019773, loss_ce: 0.009335
iteration 17774 : loss : 0.021177, loss_ce: 0.006792
iteration 17775 : loss : 0.024249, loss_ce: 0.005782
iteration 17776 : loss : 0.021570, loss_ce: 0.007342
iteration 17777 : loss : 0.022324, loss_ce: 0.009065
iteration 17778 : loss : 0.019589, loss_ce: 0.008183
iteration 17779 : loss : 0.022303, loss_ce: 0.008195
iteration 17780 : loss : 0.018763, loss_ce: 0.005568
iteration 17781 : loss : 0.020224, loss_ce: 0.009149
iteration 17782 : loss : 0.026065, loss_ce: 0.008125
iteration 17783 : loss : 0.021347, loss_ce: 0.004995
iteration 17784 : loss : 0.026484, loss_ce: 0.005861
iteration 17785 : loss : 0.019193, loss_ce: 0.007665
iteration 17786 : loss : 0.027969, loss_ce: 0.010485
iteration 17787 : loss : 0.016962, loss_ce: 0.003733
iteration 17788 : loss : 0.019128, loss_ce: 0.007118
iteration 17789 : loss : 0.021660, loss_ce: 0.009314
iteration 17790 : loss : 0.025624, loss_ce: 0.010371
iteration 17791 : loss : 0.018684, loss_ce: 0.007569
iteration 17792 : loss : 0.020168, loss_ce: 0.007480
iteration 17793 : loss : 0.021800, loss_ce: 0.009177
iteration 17794 : loss : 0.021185, loss_ce: 0.006891
iteration 17795 : loss : 0.018594, loss_ce: 0.007728
iteration 17796 : loss : 0.016782, loss_ce: 0.004512
iteration 17797 : loss : 0.017491, loss_ce: 0.007910
iteration 17798 : loss : 0.077413, loss_ce: 0.005694
iteration 17799 : loss : 0.019812, loss_ce: 0.003503
iteration 17800 : loss : 0.022430, loss_ce: 0.006716
iteration 17801 : loss : 0.074120, loss_ce: 0.004151
iteration 17802 : loss : 0.072087, loss_ce: 0.004968
iteration 17803 : loss : 0.019375, loss_ce: 0.005884
iteration 17804 : loss : 0.021812, loss_ce: 0.009179
iteration 17805 : loss : 0.019445, loss_ce: 0.006192
iteration 17806 : loss : 0.022084, loss_ce: 0.009183
iteration 17807 : loss : 0.023342, loss_ce: 0.008709
iteration 17808 : loss : 0.123488, loss_ce: 0.004513
iteration 17809 : loss : 0.022186, loss_ce: 0.007021
iteration 17810 : loss : 0.024031, loss_ce: 0.006927
iteration 17811 : loss : 0.021212, loss_ce: 0.009820
iteration 17812 : loss : 0.019082, loss_ce: 0.007692
iteration 17813 : loss : 0.027763, loss_ce: 0.006603
iteration 17814 : loss : 0.025490, loss_ce: 0.009192
iteration 17815 : loss : 0.021439, loss_ce: 0.007487
iteration 17816 : loss : 0.020422, loss_ce: 0.008751
iteration 17817 : loss : 0.027848, loss_ce: 0.005456
iteration 17818 : loss : 0.023562, loss_ce: 0.009216
iteration 17819 : loss : 0.021982, loss_ce: 0.007759
iteration 17820 : loss : 0.022254, loss_ce: 0.005891
iteration 17821 : loss : 0.021992, loss_ce: 0.008503
iteration 17822 : loss : 0.022852, loss_ce: 0.009592
iteration 17823 : loss : 0.019037, loss_ce: 0.005802
iteration 17824 : loss : 0.021679, loss_ce: 0.009924
iteration 17825 : loss : 0.023633, loss_ce: 0.005710
iteration 17826 : loss : 0.024834, loss_ce: 0.009919
iteration 17827 : loss : 0.021087, loss_ce: 0.007194
iteration 17828 : loss : 0.022299, loss_ce: 0.010618
iteration 17829 : loss : 0.022617, loss_ce: 0.004326
iteration 17830 : loss : 0.020154, loss_ce: 0.005365
iteration 17831 : loss : 0.021282, loss_ce: 0.008301
iteration 17832 : loss : 0.024936, loss_ce: 0.005395
iteration 17833 : loss : 0.030952, loss_ce: 0.008641
iteration 17834 : loss : 0.020135, loss_ce: 0.006667
iteration 17835 : loss : 0.019617, loss_ce: 0.004959
iteration 17836 : loss : 0.024885, loss_ce: 0.010134
iteration 17837 : loss : 0.021214, loss_ce: 0.008713
iteration 17838 : loss : 0.017584, loss_ce: 0.003862
iteration 17839 : loss : 0.024585, loss_ce: 0.009522
iteration 17840 : loss : 0.020401, loss_ce: 0.009557
iteration 17841 : loss : 0.073161, loss_ce: 0.006012
iteration 17842 : loss : 0.020584, loss_ce: 0.008059
iteration 17843 : loss : 0.021238, loss_ce: 0.006812
iteration 17844 : loss : 0.017904, loss_ce: 0.005957
iteration 17845 : loss : 0.072881, loss_ce: 0.003136
iteration 17846 : loss : 0.021963, loss_ce: 0.007539
iteration 17847 : loss : 0.022270, loss_ce: 0.007094
iteration 17848 : loss : 0.022964, loss_ce: 0.006580
iteration 17849 : loss : 0.024020, loss_ce: 0.007397
iteration 17850 : loss : 0.023202, loss_ce: 0.007624
iteration 17851 : loss : 0.022659, loss_ce: 0.006375
iteration 17852 : loss : 0.021471, loss_ce: 0.009688
iteration 17853 : loss : 0.023487, loss_ce: 0.009661
iteration 17854 : loss : 0.029643, loss_ce: 0.006746
iteration 17855 : loss : 0.020033, loss_ce: 0.009313
iteration 17856 : loss : 0.037217, loss_ce: 0.023463
 96%|███████████████████████████▊ | 192/200 [3:09:36<07:16, 54.55s/it]iteration 17857 : loss : 0.024196, loss_ce: 0.011080
iteration 17858 : loss : 0.021268, loss_ce: 0.008900
iteration 17859 : loss : 0.044266, loss_ce: 0.008818
iteration 17860 : loss : 0.021811, loss_ce: 0.009255
iteration 17861 : loss : 0.020207, loss_ce: 0.008297
iteration 17862 : loss : 0.021477, loss_ce: 0.007704
iteration 17863 : loss : 0.020330, loss_ce: 0.005269
iteration 17864 : loss : 0.024952, loss_ce: 0.009237
iteration 17865 : loss : 0.022819, loss_ce: 0.005509
iteration 17866 : loss : 0.020952, loss_ce: 0.006332
iteration 17867 : loss : 0.020021, loss_ce: 0.007596
iteration 17868 : loss : 0.020856, loss_ce: 0.006888
iteration 17869 : loss : 0.020933, loss_ce: 0.005944
iteration 17870 : loss : 0.024047, loss_ce: 0.006874
iteration 17871 : loss : 0.019995, loss_ce: 0.008961
iteration 17872 : loss : 0.033119, loss_ce: 0.005679
iteration 17873 : loss : 0.020051, loss_ce: 0.007660
iteration 17874 : loss : 0.020136, loss_ce: 0.007149
iteration 17875 : loss : 0.020341, loss_ce: 0.005890
iteration 17876 : loss : 0.018475, loss_ce: 0.005249
iteration 17877 : loss : 0.022172, loss_ce: 0.007576
iteration 17878 : loss : 0.023421, loss_ce: 0.005357
iteration 17879 : loss : 0.025390, loss_ce: 0.009024
iteration 17880 : loss : 0.021421, loss_ce: 0.009509
iteration 17881 : loss : 0.023446, loss_ce: 0.009003
iteration 17882 : loss : 0.017244, loss_ce: 0.005653
iteration 17883 : loss : 0.019898, loss_ce: 0.007548
iteration 17884 : loss : 0.021405, loss_ce: 0.007019
iteration 17885 : loss : 0.022390, loss_ce: 0.007506
iteration 17886 : loss : 0.020319, loss_ce: 0.006284
iteration 17887 : loss : 0.023337, loss_ce: 0.009322
iteration 17888 : loss : 0.020184, loss_ce: 0.007632
iteration 17889 : loss : 0.019765, loss_ce: 0.006947
iteration 17890 : loss : 0.018512, loss_ce: 0.007207
iteration 17891 : loss : 0.023694, loss_ce: 0.007645
iteration 17892 : loss : 0.022211, loss_ce: 0.008110
iteration 17893 : loss : 0.021516, loss_ce: 0.008361
iteration 17894 : loss : 0.024879, loss_ce: 0.010428
iteration 17895 : loss : 0.026033, loss_ce: 0.007028
iteration 17896 : loss : 0.018475, loss_ce: 0.007649
iteration 17897 : loss : 0.018233, loss_ce: 0.005192
iteration 17898 : loss : 0.020704, loss_ce: 0.005645
iteration 17899 : loss : 0.075921, loss_ce: 0.005014
iteration 17900 : loss : 0.023793, loss_ce: 0.009842
iteration 17901 : loss : 0.021176, loss_ce: 0.009228
iteration 17902 : loss : 0.025104, loss_ce: 0.008215
iteration 17903 : loss : 0.026426, loss_ce: 0.008619
iteration 17904 : loss : 0.019088, loss_ce: 0.007861
iteration 17905 : loss : 0.020688, loss_ce: 0.007664
iteration 17906 : loss : 0.023193, loss_ce: 0.005465
iteration 17907 : loss : 0.019110, loss_ce: 0.005038
iteration 17908 : loss : 0.021279, loss_ce: 0.009722
iteration 17909 : loss : 0.021138, loss_ce: 0.010593
iteration 17910 : loss : 0.022572, loss_ce: 0.009561
iteration 17911 : loss : 0.026853, loss_ce: 0.007701
iteration 17912 : loss : 0.017569, loss_ce: 0.006010
iteration 17913 : loss : 0.017810, loss_ce: 0.005604
iteration 17914 : loss : 0.018580, loss_ce: 0.007330
iteration 17915 : loss : 0.022235, loss_ce: 0.008280
iteration 17916 : loss : 0.075753, loss_ce: 0.003568
iteration 17917 : loss : 0.031856, loss_ce: 0.010226
iteration 17918 : loss : 0.022533, loss_ce: 0.008896
iteration 17919 : loss : 0.021005, loss_ce: 0.010290
iteration 17920 : loss : 0.026993, loss_ce: 0.004476
iteration 17921 : loss : 0.022698, loss_ce: 0.008990
iteration 17922 : loss : 0.029871, loss_ce: 0.007457
iteration 17923 : loss : 0.020527, loss_ce: 0.007880
iteration 17924 : loss : 0.020871, loss_ce: 0.007083
iteration 17925 : loss : 0.021382, loss_ce: 0.008159
iteration 17926 : loss : 0.024410, loss_ce: 0.010799
iteration 17927 : loss : 0.020528, loss_ce: 0.007708
iteration 17928 : loss : 0.023908, loss_ce: 0.006012
iteration 17929 : loss : 0.020586, loss_ce: 0.006800
iteration 17930 : loss : 0.018106, loss_ce: 0.008118
iteration 17931 : loss : 0.028537, loss_ce: 0.004406
iteration 17932 : loss : 0.021165, loss_ce: 0.007078
iteration 17933 : loss : 0.023628, loss_ce: 0.008801
iteration 17934 : loss : 0.021114, loss_ce: 0.008220
iteration 17935 : loss : 0.020857, loss_ce: 0.007575
iteration 17936 : loss : 0.076799, loss_ce: 0.002402
iteration 17937 : loss : 0.022683, loss_ce: 0.008384
iteration 17938 : loss : 0.020106, loss_ce: 0.006804
iteration 17939 : loss : 0.072757, loss_ce: 0.004807
iteration 17940 : loss : 0.021264, loss_ce: 0.008155
iteration 17941 : loss : 0.020573, loss_ce: 0.007382
iteration 17942 : loss : 0.025015, loss_ce: 0.011289
iteration 17943 : loss : 0.023835, loss_ce: 0.006653
iteration 17944 : loss : 0.071408, loss_ce: 0.005122
iteration 17945 : loss : 0.022559, loss_ce: 0.010454
iteration 17946 : loss : 0.074911, loss_ce: 0.007896
iteration 17947 : loss : 0.020710, loss_ce: 0.006926
iteration 17948 : loss : 0.071071, loss_ce: 0.004094
iteration 17949 : loss : 0.340159, loss_ce: 0.001191
 96%|███████████████████████████▉ | 193/200 [3:10:31<06:21, 54.57s/it]iteration 17950 : loss : 0.018336, loss_ce: 0.007538
iteration 17951 : loss : 0.024905, loss_ce: 0.014195
iteration 17952 : loss : 0.024703, loss_ce: 0.005499
iteration 17953 : loss : 0.021547, loss_ce: 0.005907
iteration 17954 : loss : 0.073009, loss_ce: 0.005699
iteration 17955 : loss : 0.023901, loss_ce: 0.007300
iteration 17956 : loss : 0.029982, loss_ce: 0.007580
iteration 17957 : loss : 0.025273, loss_ce: 0.010500
iteration 17958 : loss : 0.031793, loss_ce: 0.004123
iteration 17959 : loss : 0.021318, loss_ce: 0.008378
iteration 17960 : loss : 0.023826, loss_ce: 0.007104
iteration 17961 : loss : 0.020099, loss_ce: 0.004832
iteration 17962 : loss : 0.020860, loss_ce: 0.007330
iteration 17963 : loss : 0.022726, loss_ce: 0.010058
iteration 17964 : loss : 0.021644, loss_ce: 0.009065
iteration 17965 : loss : 0.021060, loss_ce: 0.005096
iteration 17966 : loss : 0.017674, loss_ce: 0.005485
iteration 17967 : loss : 0.020526, loss_ce: 0.007514
iteration 17968 : loss : 0.017200, loss_ce: 0.003633
iteration 17969 : loss : 0.017471, loss_ce: 0.005530
iteration 17970 : loss : 0.021534, loss_ce: 0.008232
iteration 17971 : loss : 0.026640, loss_ce: 0.009583
iteration 17972 : loss : 0.024458, loss_ce: 0.006526
iteration 17973 : loss : 0.020753, loss_ce: 0.008148
iteration 17974 : loss : 0.074351, loss_ce: 0.007998
iteration 17975 : loss : 0.024182, loss_ce: 0.008652
iteration 17976 : loss : 0.022354, loss_ce: 0.007722
iteration 17977 : loss : 0.021659, loss_ce: 0.006980
iteration 17978 : loss : 0.021952, loss_ce: 0.006684
iteration 17979 : loss : 0.020590, loss_ce: 0.008248
iteration 17980 : loss : 0.021777, loss_ce: 0.009609
iteration 17981 : loss : 0.020551, loss_ce: 0.008880
iteration 17982 : loss : 0.021618, loss_ce: 0.004754
iteration 17983 : loss : 0.023685, loss_ce: 0.010504
iteration 17984 : loss : 0.021039, loss_ce: 0.005997
iteration 17985 : loss : 0.020959, loss_ce: 0.005969
iteration 17986 : loss : 0.023997, loss_ce: 0.008519
iteration 17987 : loss : 0.023031, loss_ce: 0.006869
iteration 17988 : loss : 0.022453, loss_ce: 0.008566
iteration 17989 : loss : 0.021069, loss_ce: 0.004312
iteration 17990 : loss : 0.025900, loss_ce: 0.008499
iteration 17991 : loss : 0.024454, loss_ce: 0.009443
iteration 17992 : loss : 0.025359, loss_ce: 0.007958
iteration 17993 : loss : 0.024559, loss_ce: 0.008492
iteration 17994 : loss : 0.018454, loss_ce: 0.006442
iteration 17995 : loss : 0.022264, loss_ce: 0.008170
iteration 17996 : loss : 0.021636, loss_ce: 0.007878
iteration 17997 : loss : 0.019316, loss_ce: 0.008398
iteration 17998 : loss : 0.023488, loss_ce: 0.008514
iteration 17999 : loss : 0.023802, loss_ce: 0.007959
iteration 18000 : loss : 0.020205, loss_ce: 0.008487
iteration 18001 : loss : 0.019621, loss_ce: 0.010539
iteration 18002 : loss : 0.022632, loss_ce: 0.005963
iteration 18003 : loss : 0.021190, loss_ce: 0.007078
iteration 18004 : loss : 0.018649, loss_ce: 0.004222
iteration 18005 : loss : 0.074336, loss_ce: 0.007858
iteration 18006 : loss : 0.022252, loss_ce: 0.009080
iteration 18007 : loss : 0.021984, loss_ce: 0.008472
iteration 18008 : loss : 0.024787, loss_ce: 0.004522
iteration 18009 : loss : 0.046189, loss_ce: 0.002839
iteration 18010 : loss : 0.022166, loss_ce: 0.008296
iteration 18011 : loss : 0.076649, loss_ce: 0.006974
iteration 18012 : loss : 0.073329, loss_ce: 0.006139
iteration 18013 : loss : 0.020977, loss_ce: 0.006902
iteration 18014 : loss : 0.022519, loss_ce: 0.007000
iteration 18015 : loss : 0.020911, loss_ce: 0.009743
iteration 18016 : loss : 0.070643, loss_ce: 0.003674
iteration 18017 : loss : 0.026836, loss_ce: 0.004808
iteration 18018 : loss : 0.022522, loss_ce: 0.007580
iteration 18019 : loss : 0.019641, loss_ce: 0.008280
iteration 18020 : loss : 0.019796, loss_ce: 0.009029
iteration 18021 : loss : 0.021551, loss_ce: 0.010451
iteration 18022 : loss : 0.072657, loss_ce: 0.004538
iteration 18023 : loss : 0.019895, loss_ce: 0.006335
iteration 18024 : loss : 0.027243, loss_ce: 0.008359
iteration 18025 : loss : 0.021367, loss_ce: 0.008854
iteration 18026 : loss : 0.020301, loss_ce: 0.009542
iteration 18027 : loss : 0.020404, loss_ce: 0.006826
iteration 18028 : loss : 0.022758, loss_ce: 0.004237
iteration 18029 : loss : 0.074711, loss_ce: 0.009576
iteration 18030 : loss : 0.022641, loss_ce: 0.004753
iteration 18031 : loss : 0.020477, loss_ce: 0.007142
iteration 18032 : loss : 0.020562, loss_ce: 0.007663
iteration 18033 : loss : 0.019282, loss_ce: 0.006133
iteration 18034 : loss : 0.021125, loss_ce: 0.006079
iteration 18035 : loss : 0.025191, loss_ce: 0.009479
iteration 18036 : loss : 0.021491, loss_ce: 0.007847
iteration 18037 : loss : 0.022735, loss_ce: 0.010192
iteration 18038 : loss : 0.019680, loss_ce: 0.004235
iteration 18039 : loss : 0.021826, loss_ce: 0.010116
iteration 18040 : loss : 0.074325, loss_ce: 0.007385
iteration 18041 : loss : 0.020248, loss_ce: 0.009016
iteration 18042 : loss : 0.280325, loss_ce: 0.004093
 97%|████████████████████████████▏| 194/200 [3:11:25<05:27, 54.58s/it]iteration 18043 : loss : 0.016964, loss_ce: 0.004615
iteration 18044 : loss : 0.018657, loss_ce: 0.006209
iteration 18045 : loss : 0.024776, loss_ce: 0.007140
iteration 18046 : loss : 0.022494, loss_ce: 0.007430
iteration 18047 : loss : 0.020694, loss_ce: 0.007482
iteration 18048 : loss : 0.021131, loss_ce: 0.007975
iteration 18049 : loss : 0.024586, loss_ce: 0.007289
iteration 18050 : loss : 0.026404, loss_ce: 0.011237
iteration 18051 : loss : 0.022263, loss_ce: 0.008562
iteration 18052 : loss : 0.024450, loss_ce: 0.010901
iteration 18053 : loss : 0.022348, loss_ce: 0.007450
iteration 18054 : loss : 0.018921, loss_ce: 0.007981
iteration 18055 : loss : 0.027635, loss_ce: 0.010162
iteration 18056 : loss : 0.021172, loss_ce: 0.006601
iteration 18057 : loss : 0.021411, loss_ce: 0.007773
iteration 18058 : loss : 0.032534, loss_ce: 0.005628
iteration 18059 : loss : 0.020649, loss_ce: 0.006782
iteration 18060 : loss : 0.070536, loss_ce: 0.002570
iteration 18061 : loss : 0.021021, loss_ce: 0.006355
iteration 18062 : loss : 0.021049, loss_ce: 0.005131
iteration 18063 : loss : 0.019872, loss_ce: 0.005655
iteration 18064 : loss : 0.018938, loss_ce: 0.006648
iteration 18065 : loss : 0.023161, loss_ce: 0.010568
iteration 18066 : loss : 0.085399, loss_ce: 0.005612
iteration 18067 : loss : 0.020356, loss_ce: 0.008778
iteration 18068 : loss : 0.018456, loss_ce: 0.005479
iteration 18069 : loss : 0.018181, loss_ce: 0.005606
iteration 18070 : loss : 0.020881, loss_ce: 0.006538
iteration 18071 : loss : 0.023108, loss_ce: 0.008492
iteration 18072 : loss : 0.021799, loss_ce: 0.006371
iteration 18073 : loss : 0.021859, loss_ce: 0.007763
iteration 18074 : loss : 0.022158, loss_ce: 0.008502
iteration 18075 : loss : 0.018791, loss_ce: 0.008451
iteration 18076 : loss : 0.030176, loss_ce: 0.009055
iteration 18077 : loss : 0.073746, loss_ce: 0.006100
iteration 18078 : loss : 0.025161, loss_ce: 0.007798
iteration 18079 : loss : 0.024716, loss_ce: 0.007823
iteration 18080 : loss : 0.031393, loss_ce: 0.006288
iteration 18081 : loss : 0.022533, loss_ce: 0.007104
iteration 18082 : loss : 0.021602, loss_ce: 0.010536
iteration 18083 : loss : 0.019722, loss_ce: 0.004600
iteration 18084 : loss : 0.024178, loss_ce: 0.005574
iteration 18085 : loss : 0.023707, loss_ce: 0.008255
iteration 18086 : loss : 0.022603, loss_ce: 0.011127
iteration 18087 : loss : 0.021530, loss_ce: 0.007550
iteration 18088 : loss : 0.018950, loss_ce: 0.006715
iteration 18089 : loss : 0.021917, loss_ce: 0.010641
iteration 18090 : loss : 0.017460, loss_ce: 0.005844
iteration 18091 : loss : 0.022450, loss_ce: 0.008671
iteration 18092 : loss : 0.075768, loss_ce: 0.005851
iteration 18093 : loss : 0.020019, loss_ce: 0.005192
iteration 18094 : loss : 0.023629, loss_ce: 0.009540
iteration 18095 : loss : 0.019924, loss_ce: 0.003891
iteration 18096 : loss : 0.018659, loss_ce: 0.004217
iteration 18097 : loss : 0.021945, loss_ce: 0.007849
iteration 18098 : loss : 0.074639, loss_ce: 0.006944
iteration 18099 : loss : 0.020586, loss_ce: 0.007374
iteration 18100 : loss : 0.021783, loss_ce: 0.007406
iteration 18101 : loss : 0.019720, loss_ce: 0.007471
iteration 18102 : loss : 0.020766, loss_ce: 0.008001
iteration 18103 : loss : 0.022020, loss_ce: 0.011687
iteration 18104 : loss : 0.076434, loss_ce: 0.004729
iteration 18105 : loss : 0.021838, loss_ce: 0.008173
iteration 18106 : loss : 0.018482, loss_ce: 0.007158
iteration 18107 : loss : 0.026442, loss_ce: 0.007415
iteration 18108 : loss : 0.020735, loss_ce: 0.005576
iteration 18109 : loss : 0.023897, loss_ce: 0.008310
iteration 18110 : loss : 0.023187, loss_ce: 0.006318
iteration 18111 : loss : 0.030074, loss_ce: 0.007598
iteration 18112 : loss : 0.021889, loss_ce: 0.004825
iteration 18113 : loss : 0.022901, loss_ce: 0.006002
iteration 18114 : loss : 0.021645, loss_ce: 0.010852
iteration 18115 : loss : 0.018848, loss_ce: 0.007738
iteration 18116 : loss : 0.019589, loss_ce: 0.004703
iteration 18117 : loss : 0.023135, loss_ce: 0.010170
iteration 18118 : loss : 0.022506, loss_ce: 0.009809
iteration 18119 : loss : 0.020097, loss_ce: 0.007513
iteration 18120 : loss : 0.018639, loss_ce: 0.006922
iteration 18121 : loss : 0.075778, loss_ce: 0.006109
iteration 18122 : loss : 0.021711, loss_ce: 0.010402
iteration 18123 : loss : 0.019115, loss_ce: 0.006104
iteration 18124 : loss : 0.020171, loss_ce: 0.010984
iteration 18125 : loss : 0.020285, loss_ce: 0.006769
iteration 18126 : loss : 0.023740, loss_ce: 0.007812
iteration 18127 : loss : 0.029463, loss_ce: 0.008961
iteration 18128 : loss : 0.020669, loss_ce: 0.006056
iteration 18129 : loss : 0.025214, loss_ce: 0.007525
iteration 18130 : loss : 0.020596, loss_ce: 0.005633
iteration 18131 : loss : 0.023784, loss_ce: 0.009269
iteration 18132 : loss : 0.021755, loss_ce: 0.005856
iteration 18133 : loss : 0.022739, loss_ce: 0.008837
iteration 18134 : loss : 0.020674, loss_ce: 0.006287
iteration 18135 : loss : 0.037807, loss_ce: 0.031386
 98%|████████████████████████████▎| 195/200 [3:12:20<04:32, 54.59s/it]iteration 18136 : loss : 0.020587, loss_ce: 0.007383
iteration 18137 : loss : 0.025014, loss_ce: 0.008711
iteration 18138 : loss : 0.023399, loss_ce: 0.005063
iteration 18139 : loss : 0.022232, loss_ce: 0.006307
iteration 18140 : loss : 0.020474, loss_ce: 0.007832
iteration 18141 : loss : 0.018570, loss_ce: 0.005422
iteration 18142 : loss : 0.022619, loss_ce: 0.009267
iteration 18143 : loss : 0.020281, loss_ce: 0.005348
iteration 18144 : loss : 0.021729, loss_ce: 0.007577
iteration 18145 : loss : 0.021946, loss_ce: 0.009254
iteration 18146 : loss : 0.017799, loss_ce: 0.006258
iteration 18147 : loss : 0.019721, loss_ce: 0.007793
iteration 18148 : loss : 0.024023, loss_ce: 0.014220
iteration 18149 : loss : 0.024801, loss_ce: 0.007602
iteration 18150 : loss : 0.021738, loss_ce: 0.008399
iteration 18151 : loss : 0.022581, loss_ce: 0.010480
iteration 18152 : loss : 0.022999, loss_ce: 0.009607
iteration 18153 : loss : 0.019752, loss_ce: 0.004522
iteration 18154 : loss : 0.025614, loss_ce: 0.008277
iteration 18155 : loss : 0.023496, loss_ce: 0.004426
iteration 18156 : loss : 0.020409, loss_ce: 0.009259
iteration 18157 : loss : 0.018873, loss_ce: 0.006863
iteration 18158 : loss : 0.073177, loss_ce: 0.008103
iteration 18159 : loss : 0.020532, loss_ce: 0.004898
iteration 18160 : loss : 0.070655, loss_ce: 0.002828
iteration 18161 : loss : 0.019779, loss_ce: 0.007003
iteration 18162 : loss : 0.022850, loss_ce: 0.012751
iteration 18163 : loss : 0.020764, loss_ce: 0.010839
iteration 18164 : loss : 0.021440, loss_ce: 0.004814
iteration 18165 : loss : 0.022739, loss_ce: 0.009224
iteration 18166 : loss : 0.015466, loss_ce: 0.004714
iteration 18167 : loss : 0.017816, loss_ce: 0.005125
iteration 18168 : loss : 0.017249, loss_ce: 0.005313
iteration 18169 : loss : 0.023832, loss_ce: 0.010134
iteration 18170 : loss : 0.030608, loss_ce: 0.006315
iteration 18171 : loss : 0.023014, loss_ce: 0.008410
iteration 18172 : loss : 0.020434, loss_ce: 0.005963
iteration 18173 : loss : 0.027230, loss_ce: 0.008362
iteration 18174 : loss : 0.022792, loss_ce: 0.007489
iteration 18175 : loss : 0.021561, loss_ce: 0.007122
iteration 18176 : loss : 0.021365, loss_ce: 0.010144
iteration 18177 : loss : 0.022555, loss_ce: 0.008012
iteration 18178 : loss : 0.023378, loss_ce: 0.006565
iteration 18179 : loss : 0.020006, loss_ce: 0.006402
iteration 18180 : loss : 0.021882, loss_ce: 0.009610
iteration 18181 : loss : 0.023413, loss_ce: 0.007407
iteration 18182 : loss : 0.022411, loss_ce: 0.006388
iteration 18183 : loss : 0.019570, loss_ce: 0.003545
iteration 18184 : loss : 0.025072, loss_ce: 0.007337
iteration 18185 : loss : 0.025532, loss_ce: 0.009313
iteration 18186 : loss : 0.023639, loss_ce: 0.009289
iteration 18187 : loss : 0.019748, loss_ce: 0.006977
iteration 18188 : loss : 0.022144, loss_ce: 0.004680
iteration 18189 : loss : 0.020784, loss_ce: 0.010074
iteration 18190 : loss : 0.022478, loss_ce: 0.008662
iteration 18191 : loss : 0.021727, loss_ce: 0.005798
iteration 18192 : loss : 0.019497, loss_ce: 0.008867
iteration 18193 : loss : 0.018475, loss_ce: 0.006290
iteration 18194 : loss : 0.077349, loss_ce: 0.005888
iteration 18195 : loss : 0.020532, loss_ce: 0.007507
iteration 18196 : loss : 0.020710, loss_ce: 0.008784
iteration 18197 : loss : 0.020962, loss_ce: 0.007749
iteration 18198 : loss : 0.021274, loss_ce: 0.008092
iteration 18199 : loss : 0.019355, loss_ce: 0.004798
iteration 18200 : loss : 0.020763, loss_ce: 0.007307
iteration 18201 : loss : 0.017513, loss_ce: 0.003819
iteration 18202 : loss : 0.023000, loss_ce: 0.009298
iteration 18203 : loss : 0.024998, loss_ce: 0.004922
iteration 18204 : loss : 0.023587, loss_ce: 0.006660
iteration 18205 : loss : 0.018476, loss_ce: 0.005982
iteration 18206 : loss : 0.023422, loss_ce: 0.008736
iteration 18207 : loss : 0.071602, loss_ce: 0.004980
iteration 18208 : loss : 0.022269, loss_ce: 0.009940
iteration 18209 : loss : 0.023782, loss_ce: 0.008885
iteration 18210 : loss : 0.042696, loss_ce: 0.004258
iteration 18211 : loss : 0.028808, loss_ce: 0.009387
iteration 18212 : loss : 0.020237, loss_ce: 0.008385
iteration 18213 : loss : 0.022787, loss_ce: 0.006052
iteration 18214 : loss : 0.020974, loss_ce: 0.010802
iteration 18215 : loss : 0.021269, loss_ce: 0.007770
iteration 18216 : loss : 0.019228, loss_ce: 0.007790
iteration 18217 : loss : 0.036346, loss_ce: 0.003931
iteration 18218 : loss : 0.019761, loss_ce: 0.008692
iteration 18219 : loss : 0.021717, loss_ce: 0.006923
iteration 18220 : loss : 0.022737, loss_ce: 0.006078
iteration 18221 : loss : 0.021157, loss_ce: 0.007982
iteration 18222 : loss : 0.018181, loss_ce: 0.005224
iteration 18223 : loss : 0.023446, loss_ce: 0.004523
iteration 18224 : loss : 0.023779, loss_ce: 0.011304
iteration 18225 : loss : 0.023424, loss_ce: 0.005576
iteration 18226 : loss : 0.021444, loss_ce: 0.009162
iteration 18227 : loss : 0.020182, loss_ce: 0.009497
iteration 18228 : loss : 0.296073, loss_ce: 0.006859
 98%|████████████████████████████▍| 196/200 [3:13:14<03:38, 54.58s/it]iteration 18229 : loss : 0.017317, loss_ce: 0.004314
iteration 18230 : loss : 0.019587, loss_ce: 0.005493
iteration 18231 : loss : 0.072803, loss_ce: 0.005564
iteration 18232 : loss : 0.024718, loss_ce: 0.007534
iteration 18233 : loss : 0.022149, loss_ce: 0.006572
iteration 18234 : loss : 0.019978, loss_ce: 0.005281
iteration 18235 : loss : 0.024739, loss_ce: 0.007837
iteration 18236 : loss : 0.024226, loss_ce: 0.009593
iteration 18237 : loss : 0.024169, loss_ce: 0.013582
iteration 18238 : loss : 0.023506, loss_ce: 0.005560
iteration 18239 : loss : 0.022072, loss_ce: 0.008942
iteration 18240 : loss : 0.023074, loss_ce: 0.009403
iteration 18241 : loss : 0.024881, loss_ce: 0.009143
iteration 18242 : loss : 0.021587, loss_ce: 0.006241
iteration 18243 : loss : 0.017887, loss_ce: 0.005511
iteration 18244 : loss : 0.020988, loss_ce: 0.007616
iteration 18245 : loss : 0.028814, loss_ce: 0.005902
iteration 18246 : loss : 0.026183, loss_ce: 0.009962
iteration 18247 : loss : 0.021131, loss_ce: 0.008371
iteration 18248 : loss : 0.021234, loss_ce: 0.005237
iteration 18249 : loss : 0.022549, loss_ce: 0.009726
iteration 18250 : loss : 0.027818, loss_ce: 0.004156
iteration 18251 : loss : 0.019899, loss_ce: 0.007626
iteration 18252 : loss : 0.025681, loss_ce: 0.012150
iteration 18253 : loss : 0.025546, loss_ce: 0.006976
iteration 18254 : loss : 0.022810, loss_ce: 0.008621
iteration 18255 : loss : 0.023654, loss_ce: 0.008318
iteration 18256 : loss : 0.020212, loss_ce: 0.003839
iteration 18257 : loss : 0.019309, loss_ce: 0.005943
iteration 18258 : loss : 0.023915, loss_ce: 0.011943
iteration 18259 : loss : 0.018860, loss_ce: 0.006945
iteration 18260 : loss : 0.018630, loss_ce: 0.007110
iteration 18261 : loss : 0.022041, loss_ce: 0.005097
iteration 18262 : loss : 0.020691, loss_ce: 0.006569
iteration 18263 : loss : 0.019294, loss_ce: 0.006262
iteration 18264 : loss : 0.021599, loss_ce: 0.007294
iteration 18265 : loss : 0.019805, loss_ce: 0.006305
iteration 18266 : loss : 0.020484, loss_ce: 0.007436
iteration 18267 : loss : 0.021953, loss_ce: 0.007369
iteration 18268 : loss : 0.071567, loss_ce: 0.003596
iteration 18269 : loss : 0.019108, loss_ce: 0.007139
iteration 18270 : loss : 0.022402, loss_ce: 0.007217
iteration 18271 : loss : 0.024077, loss_ce: 0.009097
iteration 18272 : loss : 0.075862, loss_ce: 0.010485
iteration 18273 : loss : 0.023838, loss_ce: 0.005478
iteration 18274 : loss : 0.020883, loss_ce: 0.006771
iteration 18275 : loss : 0.019932, loss_ce: 0.007290
iteration 18276 : loss : 0.021840, loss_ce: 0.005950
iteration 18277 : loss : 0.020822, loss_ce: 0.006286
iteration 18278 : loss : 0.020978, loss_ce: 0.007721
iteration 18279 : loss : 0.024241, loss_ce: 0.011514
iteration 18280 : loss : 0.019807, loss_ce: 0.009311
iteration 18281 : loss : 0.020711, loss_ce: 0.008809
iteration 18282 : loss : 0.017624, loss_ce: 0.004637
iteration 18283 : loss : 0.017385, loss_ce: 0.006708
iteration 18284 : loss : 0.023470, loss_ce: 0.006854
iteration 18285 : loss : 0.070567, loss_ce: 0.005263
iteration 18286 : loss : 0.020687, loss_ce: 0.008297
iteration 18287 : loss : 0.021632, loss_ce: 0.008851
iteration 18288 : loss : 0.021612, loss_ce: 0.007424
iteration 18289 : loss : 0.024926, loss_ce: 0.012775
iteration 18290 : loss : 0.020312, loss_ce: 0.009722
iteration 18291 : loss : 0.027806, loss_ce: 0.012492
iteration 18292 : loss : 0.017438, loss_ce: 0.004055
iteration 18293 : loss : 0.020790, loss_ce: 0.006476
iteration 18294 : loss : 0.021772, loss_ce: 0.008008
iteration 18295 : loss : 0.020969, loss_ce: 0.007160
iteration 18296 : loss : 0.020626, loss_ce: 0.006713
iteration 18297 : loss : 0.021473, loss_ce: 0.006161
iteration 18298 : loss : 0.027175, loss_ce: 0.008925
iteration 18299 : loss : 0.019973, loss_ce: 0.007609
iteration 18300 : loss : 0.022760, loss_ce: 0.006136
iteration 18301 : loss : 0.025194, loss_ce: 0.010625
iteration 18302 : loss : 0.076117, loss_ce: 0.006374
iteration 18303 : loss : 0.020407, loss_ce: 0.008005
iteration 18304 : loss : 0.016752, loss_ce: 0.005840
iteration 18305 : loss : 0.021430, loss_ce: 0.006944
iteration 18306 : loss : 0.070839, loss_ce: 0.005732
iteration 18307 : loss : 0.018065, loss_ce: 0.008039
iteration 18308 : loss : 0.018816, loss_ce: 0.006331
iteration 18309 : loss : 0.024921, loss_ce: 0.010780
iteration 18310 : loss : 0.021754, loss_ce: 0.009480
iteration 18311 : loss : 0.019497, loss_ce: 0.006595
iteration 18312 : loss : 0.024100, loss_ce: 0.007999
iteration 18313 : loss : 0.021678, loss_ce: 0.005991
iteration 18314 : loss : 0.021229, loss_ce: 0.007405
iteration 18315 : loss : 0.020285, loss_ce: 0.005717
iteration 18316 : loss : 0.026113, loss_ce: 0.010603
iteration 18317 : loss : 0.017063, loss_ce: 0.004922
iteration 18318 : loss : 0.076508, loss_ce: 0.006210
iteration 18319 : loss : 0.020702, loss_ce: 0.005348
iteration 18320 : loss : 0.018177, loss_ce: 0.004887
iteration 18321 : loss : 0.227553, loss_ce: 0.003753
 98%|████████████████████████████▌| 197/200 [3:14:09<02:43, 54.57s/it]iteration 18322 : loss : 0.022706, loss_ce: 0.008389
iteration 18323 : loss : 0.018914, loss_ce: 0.009612
iteration 18324 : loss : 0.071815, loss_ce: 0.005905
iteration 18325 : loss : 0.019268, loss_ce: 0.008155
iteration 18326 : loss : 0.020855, loss_ce: 0.004720
iteration 18327 : loss : 0.027486, loss_ce: 0.003850
iteration 18328 : loss : 0.017915, loss_ce: 0.004771
iteration 18329 : loss : 0.019117, loss_ce: 0.005492
iteration 18330 : loss : 0.022853, loss_ce: 0.007158
iteration 18331 : loss : 0.021334, loss_ce: 0.006708
iteration 18332 : loss : 0.020207, loss_ce: 0.009109
iteration 18333 : loss : 0.024311, loss_ce: 0.008357
iteration 18334 : loss : 0.026311, loss_ce: 0.007276
iteration 18335 : loss : 0.024467, loss_ce: 0.006079
iteration 18336 : loss : 0.021575, loss_ce: 0.008995
iteration 18337 : loss : 0.017762, loss_ce: 0.006002
iteration 18338 : loss : 0.020576, loss_ce: 0.008335
iteration 18339 : loss : 0.021846, loss_ce: 0.009253
iteration 18340 : loss : 0.020204, loss_ce: 0.006376
iteration 18341 : loss : 0.015846, loss_ce: 0.002863
iteration 18342 : loss : 0.020331, loss_ce: 0.006521
iteration 18343 : loss : 0.021058, loss_ce: 0.005722
iteration 18344 : loss : 0.022836, loss_ce: 0.008206
iteration 18345 : loss : 0.022626, loss_ce: 0.008344
iteration 18346 : loss : 0.022424, loss_ce: 0.011259
iteration 18347 : loss : 0.075254, loss_ce: 0.003778
iteration 18348 : loss : 0.022798, loss_ce: 0.005984
iteration 18349 : loss : 0.025518, loss_ce: 0.009245
iteration 18350 : loss : 0.018465, loss_ce: 0.003679
iteration 18351 : loss : 0.021509, loss_ce: 0.008242
iteration 18352 : loss : 0.022116, loss_ce: 0.008100
iteration 18353 : loss : 0.074644, loss_ce: 0.005800
iteration 18354 : loss : 0.019177, loss_ce: 0.005517
iteration 18355 : loss : 0.020970, loss_ce: 0.008946
iteration 18356 : loss : 0.023066, loss_ce: 0.008746
iteration 18357 : loss : 0.020993, loss_ce: 0.003308
iteration 18358 : loss : 0.073154, loss_ce: 0.006872
iteration 18359 : loss : 0.017493, loss_ce: 0.006383
iteration 18360 : loss : 0.022040, loss_ce: 0.010320
iteration 18361 : loss : 0.021907, loss_ce: 0.009965
iteration 18362 : loss : 0.020192, loss_ce: 0.007630
iteration 18363 : loss : 0.021944, loss_ce: 0.008342
iteration 18364 : loss : 0.020006, loss_ce: 0.005814
iteration 18365 : loss : 0.024158, loss_ce: 0.008285
iteration 18366 : loss : 0.020884, loss_ce: 0.007276
iteration 18367 : loss : 0.021042, loss_ce: 0.008175
iteration 18368 : loss : 0.026310, loss_ce: 0.006967
iteration 18369 : loss : 0.018964, loss_ce: 0.005101
iteration 18370 : loss : 0.019978, loss_ce: 0.009029
iteration 18371 : loss : 0.027054, loss_ce: 0.009204
iteration 18372 : loss : 0.016305, loss_ce: 0.003343
iteration 18373 : loss : 0.019431, loss_ce: 0.006473
iteration 18374 : loss : 0.028656, loss_ce: 0.008477
iteration 18375 : loss : 0.020587, loss_ce: 0.005499
iteration 18376 : loss : 0.021708, loss_ce: 0.007268
iteration 18377 : loss : 0.025180, loss_ce: 0.006460
iteration 18378 : loss : 0.075792, loss_ce: 0.007282
iteration 18379 : loss : 0.021490, loss_ce: 0.008771
iteration 18380 : loss : 0.020983, loss_ce: 0.010006
iteration 18381 : loss : 0.023014, loss_ce: 0.008817
iteration 18382 : loss : 0.022848, loss_ce: 0.007813
iteration 18383 : loss : 0.020090, loss_ce: 0.007075
iteration 18384 : loss : 0.021656, loss_ce: 0.009438
iteration 18385 : loss : 0.020941, loss_ce: 0.007170
iteration 18386 : loss : 0.023148, loss_ce: 0.007850
iteration 18387 : loss : 0.019307, loss_ce: 0.005618
iteration 18388 : loss : 0.025055, loss_ce: 0.011438
iteration 18389 : loss : 0.027722, loss_ce: 0.005981
iteration 18390 : loss : 0.023514, loss_ce: 0.011685
iteration 18391 : loss : 0.019491, loss_ce: 0.007930
iteration 18392 : loss : 0.025215, loss_ce: 0.008096
iteration 18393 : loss : 0.018727, loss_ce: 0.007830
iteration 18394 : loss : 0.023127, loss_ce: 0.009920
iteration 18395 : loss : 0.022115, loss_ce: 0.007646
iteration 18396 : loss : 0.022489, loss_ce: 0.006627
iteration 18397 : loss : 0.070474, loss_ce: 0.005862
iteration 18398 : loss : 0.021550, loss_ce: 0.008186
iteration 18399 : loss : 0.017846, loss_ce: 0.007045
iteration 18400 : loss : 0.124442, loss_ce: 0.003483
iteration 18401 : loss : 0.021379, loss_ce: 0.009069
iteration 18402 : loss : 0.070755, loss_ce: 0.005728
iteration 18403 : loss : 0.023559, loss_ce: 0.005746
iteration 18404 : loss : 0.024600, loss_ce: 0.008420
iteration 18405 : loss : 0.020108, loss_ce: 0.005089
iteration 18406 : loss : 0.021877, loss_ce: 0.006728
iteration 18407 : loss : 0.024098, loss_ce: 0.009065
iteration 18408 : loss : 0.024139, loss_ce: 0.012378
iteration 18409 : loss : 0.018414, loss_ce: 0.007455
iteration 18410 : loss : 0.021904, loss_ce: 0.008722
iteration 18411 : loss : 0.020120, loss_ce: 0.008353
iteration 18412 : loss : 0.023087, loss_ce: 0.010133
iteration 18413 : loss : 0.020865, loss_ce: 0.008352
iteration 18414 : loss : 0.093441, loss_ce: 0.006996
 99%|████████████████████████████▋| 198/200 [3:15:03<01:49, 54.53s/it]iteration 18415 : loss : 0.023556, loss_ce: 0.008646
iteration 18416 : loss : 0.026003, loss_ce: 0.007736
iteration 18417 : loss : 0.074100, loss_ce: 0.006411
iteration 18418 : loss : 0.021789, loss_ce: 0.005211
iteration 18419 : loss : 0.021475, loss_ce: 0.008681
iteration 18420 : loss : 0.018192, loss_ce: 0.003803
iteration 18421 : loss : 0.017150, loss_ce: 0.005046
iteration 18422 : loss : 0.022113, loss_ce: 0.008413
iteration 18423 : loss : 0.019789, loss_ce: 0.009715
iteration 18424 : loss : 0.022020, loss_ce: 0.007896
iteration 18425 : loss : 0.030713, loss_ce: 0.008015
iteration 18426 : loss : 0.021772, loss_ce: 0.008240
iteration 18427 : loss : 0.022341, loss_ce: 0.010585
iteration 18428 : loss : 0.020783, loss_ce: 0.006460
iteration 18429 : loss : 0.020931, loss_ce: 0.008995
iteration 18430 : loss : 0.072513, loss_ce: 0.003083
iteration 18431 : loss : 0.025877, loss_ce: 0.007689
iteration 18432 : loss : 0.021546, loss_ce: 0.007828
iteration 18433 : loss : 0.021588, loss_ce: 0.008083
iteration 18434 : loss : 0.022328, loss_ce: 0.007773
iteration 18435 : loss : 0.019367, loss_ce: 0.007513
iteration 18436 : loss : 0.023497, loss_ce: 0.010892
iteration 18437 : loss : 0.020913, loss_ce: 0.006596
iteration 18438 : loss : 0.020416, loss_ce: 0.008068
iteration 18439 : loss : 0.024397, loss_ce: 0.007403
iteration 18440 : loss : 0.021058, loss_ce: 0.005225
iteration 18441 : loss : 0.034706, loss_ce: 0.006148
iteration 18442 : loss : 0.024397, loss_ce: 0.011833
iteration 18443 : loss : 0.017790, loss_ce: 0.005076
iteration 18444 : loss : 0.019674, loss_ce: 0.005502
iteration 18445 : loss : 0.022079, loss_ce: 0.007547
iteration 18446 : loss : 0.019671, loss_ce: 0.006104
iteration 18447 : loss : 0.019961, loss_ce: 0.008693
iteration 18448 : loss : 0.028066, loss_ce: 0.003803
iteration 18449 : loss : 0.019994, loss_ce: 0.005473
iteration 18450 : loss : 0.071882, loss_ce: 0.005815
iteration 18451 : loss : 0.019557, loss_ce: 0.007578
iteration 18452 : loss : 0.016545, loss_ce: 0.004666
iteration 18453 : loss : 0.022523, loss_ce: 0.008250
iteration 18454 : loss : 0.018901, loss_ce: 0.006413
iteration 18455 : loss : 0.023852, loss_ce: 0.011977
iteration 18456 : loss : 0.020285, loss_ce: 0.007220
iteration 18457 : loss : 0.023801, loss_ce: 0.005035
iteration 18458 : loss : 0.019436, loss_ce: 0.006290
iteration 18459 : loss : 0.025969, loss_ce: 0.008659
iteration 18460 : loss : 0.024882, loss_ce: 0.007361
iteration 18461 : loss : 0.021842, loss_ce: 0.011058
iteration 18462 : loss : 0.020949, loss_ce: 0.007705
iteration 18463 : loss : 0.024217, loss_ce: 0.009573
iteration 18464 : loss : 0.022442, loss_ce: 0.007177
iteration 18465 : loss : 0.018946, loss_ce: 0.006364
iteration 18466 : loss : 0.023735, loss_ce: 0.011883
iteration 18467 : loss : 0.022325, loss_ce: 0.009021
iteration 18468 : loss : 0.021980, loss_ce: 0.005283
iteration 18469 : loss : 0.017026, loss_ce: 0.006080
iteration 18470 : loss : 0.018755, loss_ce: 0.005542
iteration 18471 : loss : 0.021062, loss_ce: 0.006552
iteration 18472 : loss : 0.022201, loss_ce: 0.010117
iteration 18473 : loss : 0.030361, loss_ce: 0.007954
iteration 18474 : loss : 0.018887, loss_ce: 0.005569
iteration 18475 : loss : 0.019111, loss_ce: 0.008671
iteration 18476 : loss : 0.024182, loss_ce: 0.005696
iteration 18477 : loss : 0.020178, loss_ce: 0.005017
iteration 18478 : loss : 0.024764, loss_ce: 0.006437
iteration 18479 : loss : 0.019259, loss_ce: 0.005847
iteration 18480 : loss : 0.026298, loss_ce: 0.005820
iteration 18481 : loss : 0.018234, loss_ce: 0.004735
iteration 18482 : loss : 0.025285, loss_ce: 0.009700
iteration 18483 : loss : 0.024056, loss_ce: 0.008988
iteration 18484 : loss : 0.019216, loss_ce: 0.004721
iteration 18485 : loss : 0.018800, loss_ce: 0.005886
iteration 18486 : loss : 0.021657, loss_ce: 0.008687
iteration 18487 : loss : 0.020790, loss_ce: 0.005691
iteration 18488 : loss : 0.018350, loss_ce: 0.007630
iteration 18489 : loss : 0.019814, loss_ce: 0.006843
iteration 18490 : loss : 0.020625, loss_ce: 0.010399
iteration 18491 : loss : 0.017429, loss_ce: 0.007028
iteration 18492 : loss : 0.023157, loss_ce: 0.009577
iteration 18493 : loss : 0.071877, loss_ce: 0.006857
iteration 18494 : loss : 0.020228, loss_ce: 0.007127
iteration 18495 : loss : 0.031715, loss_ce: 0.011420
iteration 18496 : loss : 0.023176, loss_ce: 0.004412
iteration 18497 : loss : 0.021795, loss_ce: 0.007888
iteration 18498 : loss : 0.073150, loss_ce: 0.002946
iteration 18499 : loss : 0.025895, loss_ce: 0.011930
iteration 18500 : loss : 0.018683, loss_ce: 0.005391
iteration 18501 : loss : 0.020335, loss_ce: 0.009703
iteration 18502 : loss : 0.025320, loss_ce: 0.008398
iteration 18503 : loss : 0.021248, loss_ce: 0.007157
iteration 18504 : loss : 0.020421, loss_ce: 0.009770
iteration 18505 : loss : 0.023176, loss_ce: 0.007892
iteration 18506 : loss : 0.019069, loss_ce: 0.005531
iteration 18507 : loss : 0.029094, loss_ce: 0.025965
100%|████████████████████████████▊| 199/200 [3:15:58<00:54, 54.55s/it]iteration 18508 : loss : 0.019078, loss_ce: 0.006855
iteration 18509 : loss : 0.031103, loss_ce: 0.004961
iteration 18510 : loss : 0.069276, loss_ce: 0.004389
iteration 18511 : loss : 0.022869, loss_ce: 0.009169
iteration 18512 : loss : 0.018601, loss_ce: 0.008095
iteration 18513 : loss : 0.020942, loss_ce: 0.007179
iteration 18514 : loss : 0.073895, loss_ce: 0.007502
iteration 18515 : loss : 0.017443, loss_ce: 0.006128
iteration 18516 : loss : 0.031668, loss_ce: 0.006553
iteration 18517 : loss : 0.018489, loss_ce: 0.003053
iteration 18518 : loss : 0.041651, loss_ce: 0.004742
iteration 18519 : loss : 0.021664, loss_ce: 0.006368
iteration 18520 : loss : 0.020826, loss_ce: 0.008134
iteration 18521 : loss : 0.022345, loss_ce: 0.007992
iteration 18522 : loss : 0.022374, loss_ce: 0.006874
iteration 18523 : loss : 0.027114, loss_ce: 0.003749
iteration 18524 : loss : 0.021767, loss_ce: 0.006948
iteration 18525 : loss : 0.026808, loss_ce: 0.009337
iteration 18526 : loss : 0.019791, loss_ce: 0.008736
iteration 18527 : loss : 0.021480, loss_ce: 0.009448
iteration 18528 : loss : 0.018242, loss_ce: 0.006215
iteration 18529 : loss : 0.022737, loss_ce: 0.007832
iteration 18530 : loss : 0.020651, loss_ce: 0.009870
iteration 18531 : loss : 0.020424, loss_ce: 0.006628
iteration 18532 : loss : 0.021456, loss_ce: 0.006718
iteration 18533 : loss : 0.021104, loss_ce: 0.005473
iteration 18534 : loss : 0.019509, loss_ce: 0.007083
iteration 18535 : loss : 0.025155, loss_ce: 0.010490
iteration 18536 : loss : 0.080591, loss_ce: 0.008004
iteration 18537 : loss : 0.022331, loss_ce: 0.009952
iteration 18538 : loss : 0.021994, loss_ce: 0.008235
iteration 18539 : loss : 0.022105, loss_ce: 0.007232
iteration 18540 : loss : 0.020693, loss_ce: 0.009305
iteration 18541 : loss : 0.073163, loss_ce: 0.006066
iteration 18542 : loss : 0.034430, loss_ce: 0.008286
iteration 18543 : loss : 0.021232, loss_ce: 0.005124
iteration 18544 : loss : 0.030780, loss_ce: 0.008306
iteration 18545 : loss : 0.024563, loss_ce: 0.009404
iteration 18546 : loss : 0.019298, loss_ce: 0.006386
iteration 18547 : loss : 0.021448, loss_ce: 0.007624
iteration 18548 : loss : 0.039221, loss_ce: 0.003786
iteration 18549 : loss : 0.023157, loss_ce: 0.005386
iteration 18550 : loss : 0.024312, loss_ce: 0.011082
iteration 18551 : loss : 0.021722, loss_ce: 0.006242
iteration 18552 : loss : 0.018404, loss_ce: 0.004959
iteration 18553 : loss : 0.025715, loss_ce: 0.007908
iteration 18554 : loss : 0.019101, loss_ce: 0.005288
iteration 18555 : loss : 0.021204, loss_ce: 0.009220
iteration 18556 : loss : 0.019027, loss_ce: 0.006623
iteration 18557 : loss : 0.027563, loss_ce: 0.007746
iteration 18558 : loss : 0.019013, loss_ce: 0.008989
iteration 18559 : loss : 0.022374, loss_ce: 0.004927
iteration 18560 : loss : 0.024364, loss_ce: 0.008025
iteration 18561 : loss : 0.023870, loss_ce: 0.005916
iteration 18562 : loss : 0.020844, loss_ce: 0.007993
iteration 18563 : loss : 0.022685, loss_ce: 0.009635
iteration 18564 : loss : 0.022268, loss_ce: 0.008703
iteration 18565 : loss : 0.020029, loss_ce: 0.005706
iteration 18566 : loss : 0.025567, loss_ce: 0.008056
iteration 18567 : loss : 0.020077, loss_ce: 0.008172
iteration 18568 : loss : 0.072980, loss_ce: 0.005392
iteration 18569 : loss : 0.022328, loss_ce: 0.004476
iteration 18570 : loss : 0.018038, loss_ce: 0.006727
iteration 18571 : loss : 0.023416, loss_ce: 0.007757
iteration 18572 : loss : 0.020422, loss_ce: 0.007359
iteration 18573 : loss : 0.022896, loss_ce: 0.007023
iteration 18574 : loss : 0.022645, loss_ce: 0.009327
iteration 18575 : loss : 0.021450, loss_ce: 0.008035
iteration 18576 : loss : 0.020644, loss_ce: 0.007875
iteration 18577 : loss : 0.023911, loss_ce: 0.008282
iteration 18578 : loss : 0.017131, loss_ce: 0.005338
iteration 18579 : loss : 0.020655, loss_ce: 0.007944
iteration 18580 : loss : 0.021101, loss_ce: 0.006583
iteration 18581 : loss : 0.021812, loss_ce: 0.008903
iteration 18582 : loss : 0.019350, loss_ce: 0.008055
iteration 18583 : loss : 0.019975, loss_ce: 0.010733
iteration 18584 : loss : 0.022448, loss_ce: 0.009560
iteration 18585 : loss : 0.018295, loss_ce: 0.004496
iteration 18586 : loss : 0.020127, loss_ce: 0.010007
iteration 18587 : loss : 0.024805, loss_ce: 0.008668
iteration 18588 : loss : 0.021045, loss_ce: 0.005914
iteration 18589 : loss : 0.025411, loss_ce: 0.008883
iteration 18590 : loss : 0.020714, loss_ce: 0.008454
iteration 18591 : loss : 0.023915, loss_ce: 0.008137
iteration 18592 : loss : 0.018804, loss_ce: 0.005233
iteration 18593 : loss : 0.037268, loss_ce: 0.006594
iteration 18594 : loss : 0.022374, loss_ce: 0.006872
iteration 18595 : loss : 0.025022, loss_ce: 0.012127
iteration 18596 : loss : 0.021522, loss_ce: 0.007686
iteration 18597 : loss : 0.019531, loss_ce: 0.007707
iteration 18598 : loss : 0.015304, loss_ce: 0.004195
iteration 18599 : loss : 0.024781, loss_ce: 0.010521
iteration 18600 : loss : 0.131351, loss_ce: 0.006728
save model to ../model/TU_Synapse224/TU_pretrain_R50-ViT-B_16_skip3_epo200_bs24_224/epoch_199.pth
save model to ../model/TU_Synapse224/TU_pretrain_R50-ViT-B_16_skip3_epo200_bs24_224/epoch_199.pth
100%|████████████████████████████▊| 199/200 [3:16:54<00:59, 59.37s/it]
Traceback (most recent call last):
  File "train.py", line 10, in <module>
    from trainer import trainer_synapse
  File "/home/koutsoubn8/Transunet_project/TransUNet/trainer.py", line 83
    wandb.log({"lr" : lr_,iter_num})
                                  ^
SyntaxError: invalid syntax
wandb: Currently logged in as: niko_k98. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.15.8
wandb: Run data is saved locally in /home/koutsoubn8/Transunet_project/TransUNet/wandb/run-20230820_181148-73ibihjx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-glade-108
wandb: ⭐️ View project at https://wandb.ai/niko_k98/TransUnet
wandb: 🚀 View run at https://wandb.ai/niko_k98/TransUnet/runs/73ibihjx
Namespace(base_lr=0.01, batch_size=24, dataset='Synapse', deterministic=1, exp='TU_Synapse224', img_size=224, is_pretrain=True, list_dir='./lists/lists_Synapse', max_epochs=200, max_iterations=30000, n_gpu=1, n_skip=3, num_classes=9, root_path='../data/Synapse/train_npz', seed=1234, vit_name='R50-ViT-B_16', vit_patches_size=16)
The length of train set is: 2211
93 iterations per epoch. 18600 max iterations 
  0%|                                         | 0/200 [00:00<?, ?it/s]iteration 1 : loss : 1.464503, loss_ce: 1.995603
iteration 2 : loss : 1.420081, loss_ce: 1.912340
iteration 3 : loss : 1.335443, loss_ce: 1.751881
iteration 4 : loss : 1.227609, loss_ce: 1.551252
iteration 5 : loss : 1.110209, loss_ce: 1.328396
iteration 6 : loss : 0.981786, loss_ce: 1.082304
iteration 7 : loss : 0.879936, loss_ce: 0.901778
iteration 8 : loss : 0.792271, loss_ce: 0.735532
iteration 9 : loss : 0.711950, loss_ce: 0.578232
iteration 10 : loss : 0.639531, loss_ce: 0.442466
iteration 11 : loss : 0.608909, loss_ce: 0.381065
iteration 12 : loss : 0.546038, loss_ce: 0.240422
iteration 13 : loss : 0.570661, loss_ce: 0.302343
iteration 14 : loss : 0.537121, loss_ce: 0.236787
iteration 15 : loss : 0.528261, loss_ce: 0.224680
iteration 16 : loss : 0.499396, loss_ce: 0.156368
iteration 17 : loss : 0.506101, loss_ce: 0.180354
iteration 18 : loss : 0.505432, loss_ce: 0.191607
iteration 19 : loss : 0.500319, loss_ce: 0.173400
iteration 20 : loss : 0.479055, loss_ce: 0.143072
iteration 21 : loss : 0.510182, loss_ce: 0.206651
iteration 22 : loss : 0.491050, loss_ce: 0.179814
iteration 23 : loss : 0.493258, loss_ce: 0.185799
iteration 24 : loss : 0.482466, loss_ce: 0.148726
iteration 25 : loss : 0.513115, loss_ce: 0.216662
iteration 26 : loss : 0.508664, loss_ce: 0.215897
iteration 27 : loss : 0.480760, loss_ce: 0.175058
iteration 28 : loss : 0.466785, loss_ce: 0.156681
iteration 29 : loss : 0.507425, loss_ce: 0.212569
iteration 30 : loss : 0.513358, loss_ce: 0.227570
iteration 31 : loss : 0.508690, loss_ce: 0.214434
pred_sum 0
gtsum tensor(175, device='cuda:0')
iteration 32 : loss : 0.528346, loss_ce: 0.267269
iteration 33 : loss : 0.494809, loss_ce: 0.203067
iteration 34 : loss : 0.474648, loss_ce: 0.169404
iteration 35 : loss : 0.469659, loss_ce: 0.155984
iteration 36 : loss : 0.480983, loss_ce: 0.161979
iteration 37 : loss : 0.503722, loss_ce: 0.204274
iteration 38 : loss : 0.497780, loss_ce: 0.192201
iteration 39 : loss : 0.454178, loss_ce: 0.130229
iteration 40 : loss : 0.512274, loss_ce: 0.224211
iteration 41 : loss : 0.452935, loss_ce: 0.138351
iteration 42 : loss : 0.462776, loss_ce: 0.133001
iteration 43 : loss : 0.457662, loss_ce: 0.129386
iteration 44 : loss : 0.451922, loss_ce: 0.113044
iteration 45 : loss : 0.493053, loss_ce: 0.181583
iteration 46 : loss : 0.485567, loss_ce: 0.177097
iteration 47 : loss : 0.495648, loss_ce: 0.198118
iteration 48 : loss : 0.462020, loss_ce: 0.144779
iteration 49 : loss : 0.509170, loss_ce: 0.223399
iteration 50 : loss : 0.467477, loss_ce: 0.167367
iteration 51 : loss : 0.450612, loss_ce: 0.134082
iteration 52 : loss : 0.467192, loss_ce: 0.149755
iteration 53 : loss : 0.462827, loss_ce: 0.153240
iteration 54 : loss : 0.448249, loss_ce: 0.128688
iteration 55 : loss : 0.461826, loss_ce: 0.140874
iteration 56 : loss : 0.474542, loss_ce: 0.148520
iteration 57 : loss : 0.445421, loss_ce: 0.114726
iteration 58 : loss : 0.447164, loss_ce: 0.112949
iteration 59 : loss : 0.467297, loss_ce: 0.130657
iteration 60 : loss : 0.454604, loss_ce: 0.131053
iteration 61 : loss : 0.503303, loss_ce: 0.218515
iteration 62 : loss : 0.443824, loss_ce: 0.111724
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 63 : loss : 0.459287, loss_ce: 0.139812
iteration 64 : loss : 0.495573, loss_ce: 0.193847
iteration 65 : loss : 0.444199, loss_ce: 0.114069
iteration 66 : loss : 0.450293, loss_ce: 0.131030
iteration 67 : loss : 0.459387, loss_ce: 0.145603
iteration 68 : loss : 0.456972, loss_ce: 0.140484
iteration 69 : loss : 0.472660, loss_ce: 0.163178
iteration 70 : loss : 0.463463, loss_ce: 0.137422
iteration 71 : loss : 0.520619, loss_ce: 0.243469
iteration 72 : loss : 0.445193, loss_ce: 0.117357
iteration 73 : loss : 0.464837, loss_ce: 0.147488
iteration 74 : loss : 0.459278, loss_ce: 0.143225
iteration 75 : loss : 0.471354, loss_ce: 0.169636
iteration 76 : loss : 0.460182, loss_ce: 0.155456
iteration 77 : loss : 0.445160, loss_ce: 0.113348
iteration 78 : loss : 0.461169, loss_ce: 0.147752
iteration 79 : loss : 0.463356, loss_ce: 0.149486
iteration 80 : loss : 0.460660, loss_ce: 0.138743
iteration 81 : loss : 0.431737, loss_ce: 0.081813
iteration 82 : loss : 0.465870, loss_ce: 0.143597
iteration 83 : loss : 0.471547, loss_ce: 0.151208
iteration 84 : loss : 0.500323, loss_ce: 0.206367
iteration 85 : loss : 0.465763, loss_ce: 0.146771
iteration 86 : loss : 0.468084, loss_ce: 0.163896
iteration 87 : loss : 0.435350, loss_ce: 0.100421
iteration 88 : loss : 0.451397, loss_ce: 0.140074
iteration 89 : loss : 0.439443, loss_ce: 0.123267
iteration 90 : loss : 0.440058, loss_ce: 0.123134
iteration 91 : loss : 0.476667, loss_ce: 0.177772
iteration 92 : loss : 0.476418, loss_ce: 0.177022
iteration 93 : loss : 0.474032, loss_ce: 0.074877
  0%|▏                              | 1/200 [00:52<2:53:07, 52.20s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 94 : loss : 0.463071, loss_ce: 0.155902
iteration 95 : loss : 0.469159, loss_ce: 0.168621
iteration 96 : loss : 0.440379, loss_ce: 0.119430
iteration 97 : loss : 0.442534, loss_ce: 0.122269
iteration 98 : loss : 0.461137, loss_ce: 0.153355
iteration 99 : loss : 0.451541, loss_ce: 0.153044
iteration 100 : loss : 0.420022, loss_ce: 0.099077
iteration 101 : loss : 0.425210, loss_ce: 0.103480
iteration 102 : loss : 0.412725, loss_ce: 0.093709
iteration 103 : loss : 0.419301, loss_ce: 0.097138
iteration 104 : loss : 0.428494, loss_ce: 0.108591
iteration 105 : loss : 0.399182, loss_ce: 0.082892
iteration 106 : loss : 0.420972, loss_ce: 0.115067
iteration 107 : loss : 0.412174, loss_ce: 0.103702
iteration 108 : loss : 0.425810, loss_ce: 0.134527
iteration 109 : loss : 0.402238, loss_ce: 0.102636
iteration 110 : loss : 0.419312, loss_ce: 0.110537
iteration 111 : loss : 0.417500, loss_ce: 0.125687
iteration 112 : loss : 0.410083, loss_ce: 0.111829
iteration 113 : loss : 0.422051, loss_ce: 0.133123
iteration 114 : loss : 0.390370, loss_ce: 0.096057
iteration 115 : loss : 0.395550, loss_ce: 0.081079
iteration 116 : loss : 0.418880, loss_ce: 0.101982
iteration 117 : loss : 0.408719, loss_ce: 0.105380
iteration 118 : loss : 0.398593, loss_ce: 0.088076
iteration 119 : loss : 0.438239, loss_ce: 0.155776
iteration 120 : loss : 0.418075, loss_ce: 0.118233
iteration 121 : loss : 0.407453, loss_ce: 0.111004
iteration 122 : loss : 0.435089, loss_ce: 0.161926
iteration 123 : loss : 0.400158, loss_ce: 0.107734
iteration 124 : loss : 0.405475, loss_ce: 0.116094
pred_sum 0
gtsum tensor(16824, device='cuda:0')
iteration 125 : loss : 0.420458, loss_ce: 0.097493
iteration 126 : loss : 0.390385, loss_ce: 0.085324
iteration 127 : loss : 0.385891, loss_ce: 0.064547
iteration 128 : loss : 0.402255, loss_ce: 0.098302
iteration 129 : loss : 0.431277, loss_ce: 0.142265
iteration 130 : loss : 0.407193, loss_ce: 0.119427
iteration 131 : loss : 0.417859, loss_ce: 0.130364
iteration 132 : loss : 0.405129, loss_ce: 0.116560
iteration 133 : loss : 0.381329, loss_ce: 0.077474
iteration 134 : loss : 0.412959, loss_ce: 0.118540
iteration 135 : loss : 0.429520, loss_ce: 0.143505
iteration 136 : loss : 0.405301, loss_ce: 0.105853
iteration 137 : loss : 0.390811, loss_ce: 0.094309
iteration 138 : loss : 0.410360, loss_ce: 0.100867
iteration 139 : loss : 0.400572, loss_ce: 0.093272
iteration 140 : loss : 0.386296, loss_ce: 0.081211
iteration 141 : loss : 0.408604, loss_ce: 0.111873
iteration 142 : loss : 0.406386, loss_ce: 0.097910
iteration 143 : loss : 0.404010, loss_ce: 0.099653
iteration 144 : loss : 0.389406, loss_ce: 0.077283
iteration 145 : loss : 0.423314, loss_ce: 0.132567
iteration 146 : loss : 0.387449, loss_ce: 0.086710
iteration 147 : loss : 0.406668, loss_ce: 0.117924
iteration 148 : loss : 0.390258, loss_ce: 0.096487
iteration 149 : loss : 0.421162, loss_ce: 0.147843
iteration 150 : loss : 0.408772, loss_ce: 0.124368
iteration 151 : loss : 0.418440, loss_ce: 0.146526
iteration 152 : loss : 0.384392, loss_ce: 0.097997
iteration 153 : loss : 0.396260, loss_ce: 0.099004
iteration 154 : loss : 0.387433, loss_ce: 0.086072
iteration 155 : loss : 0.409622, loss_ce: 0.112753
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 156 : loss : 0.401124, loss_ce: 0.090545
iteration 157 : loss : 0.389917, loss_ce: 0.087512
iteration 158 : loss : 0.389167, loss_ce: 0.084516
iteration 159 : loss : 0.393056, loss_ce: 0.095382
iteration 160 : loss : 0.411526, loss_ce: 0.116406
iteration 161 : loss : 0.397145, loss_ce: 0.103933
iteration 162 : loss : 0.401734, loss_ce: 0.109450
iteration 163 : loss : 0.390324, loss_ce: 0.093337
iteration 164 : loss : 0.386330, loss_ce: 0.086979
iteration 165 : loss : 0.399089, loss_ce: 0.115366
iteration 166 : loss : 0.407932, loss_ce: 0.125545
iteration 167 : loss : 0.395391, loss_ce: 0.104612
iteration 168 : loss : 0.399484, loss_ce: 0.115262
iteration 169 : loss : 0.388727, loss_ce: 0.086578
iteration 170 : loss : 0.403399, loss_ce: 0.124328
iteration 171 : loss : 0.385395, loss_ce: 0.091583
iteration 172 : loss : 0.395283, loss_ce: 0.104847
iteration 173 : loss : 0.398249, loss_ce: 0.109547
iteration 174 : loss : 0.403669, loss_ce: 0.110621
iteration 175 : loss : 0.382493, loss_ce: 0.084626
iteration 176 : loss : 0.398665, loss_ce: 0.105052
iteration 177 : loss : 0.394950, loss_ce: 0.097757
iteration 178 : loss : 0.398576, loss_ce: 0.115450
iteration 179 : loss : 0.373391, loss_ce: 0.084716
iteration 180 : loss : 0.397131, loss_ce: 0.105047
iteration 181 : loss : 0.405376, loss_ce: 0.129319
iteration 182 : loss : 0.391991, loss_ce: 0.106993
iteration 183 : loss : 0.383554, loss_ce: 0.071678
iteration 184 : loss : 0.389876, loss_ce: 0.097786
iteration 185 : loss : 0.397166, loss_ce: 0.081345
iteration 186 : loss : 0.484047, loss_ce: 0.163644
  1%|▎                              | 2/200 [01:45<2:53:26, 52.56s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 187 : loss : 0.376532, loss_ce: 0.065751
iteration 188 : loss : 0.383284, loss_ce: 0.076503
iteration 189 : loss : 0.389926, loss_ce: 0.093005
iteration 190 : loss : 0.407406, loss_ce: 0.110592
iteration 191 : loss : 0.389948, loss_ce: 0.099730
iteration 192 : loss : 0.387312, loss_ce: 0.095963
iteration 193 : loss : 0.385055, loss_ce: 0.085617
iteration 194 : loss : 0.388863, loss_ce: 0.101228
iteration 195 : loss : 0.363339, loss_ce: 0.065913
iteration 196 : loss : 0.375663, loss_ce: 0.094828
iteration 197 : loss : 0.372543, loss_ce: 0.087316
iteration 198 : loss : 0.362827, loss_ce: 0.074736
iteration 199 : loss : 0.371534, loss_ce: 0.091144
iteration 200 : loss : 0.380982, loss_ce: 0.094048
iteration 201 : loss : 0.395197, loss_ce: 0.123889
iteration 202 : loss : 0.363591, loss_ce: 0.064072
iteration 203 : loss : 0.383180, loss_ce: 0.089525
iteration 204 : loss : 0.407597, loss_ce: 0.127374
iteration 205 : loss : 0.366604, loss_ce: 0.089583
iteration 206 : loss : 0.384986, loss_ce: 0.102510
iteration 207 : loss : 0.386033, loss_ce: 0.109182
iteration 208 : loss : 0.400228, loss_ce: 0.126635
iteration 209 : loss : 0.384901, loss_ce: 0.110730
iteration 210 : loss : 0.384522, loss_ce: 0.113367
iteration 211 : loss : 0.392701, loss_ce: 0.119018
iteration 212 : loss : 0.377838, loss_ce: 0.103198
iteration 213 : loss : 0.370473, loss_ce: 0.095319
iteration 214 : loss : 0.384239, loss_ce: 0.101686
iteration 215 : loss : 0.381195, loss_ce: 0.096990
iteration 216 : loss : 0.366409, loss_ce: 0.071024
iteration 217 : loss : 0.389917, loss_ce: 0.103225
pred_sum 6596
gtsum tensor(11417, device='cuda:0')
iteration 218 : loss : 0.393226, loss_ce: 0.107535
iteration 219 : loss : 0.361016, loss_ce: 0.050921
iteration 220 : loss : 0.392524, loss_ce: 0.099163
iteration 221 : loss : 0.385129, loss_ce: 0.104920
iteration 222 : loss : 0.370721, loss_ce: 0.079225
iteration 223 : loss : 0.375841, loss_ce: 0.091722
iteration 224 : loss : 0.377255, loss_ce: 0.103874
iteration 225 : loss : 0.378607, loss_ce: 0.096228
iteration 226 : loss : 0.381225, loss_ce: 0.090687
iteration 227 : loss : 0.385014, loss_ce: 0.082972
iteration 228 : loss : 0.371534, loss_ce: 0.085150
iteration 229 : loss : 0.380061, loss_ce: 0.097143
iteration 230 : loss : 0.380938, loss_ce: 0.100641
iteration 231 : loss : 0.395409, loss_ce: 0.120916
iteration 232 : loss : 0.385186, loss_ce: 0.108434
iteration 233 : loss : 0.383402, loss_ce: 0.108140
iteration 234 : loss : 0.371653, loss_ce: 0.092488
iteration 235 : loss : 0.372920, loss_ce: 0.091353
iteration 236 : loss : 0.373124, loss_ce: 0.090624
iteration 237 : loss : 0.366331, loss_ce: 0.065354
iteration 238 : loss : 0.359989, loss_ce: 0.064077
iteration 239 : loss : 0.390015, loss_ce: 0.098499
iteration 240 : loss : 0.365514, loss_ce: 0.073102
iteration 241 : loss : 0.384540, loss_ce: 0.093982
iteration 242 : loss : 0.389885, loss_ce: 0.131544
iteration 243 : loss : 0.379860, loss_ce: 0.112672
iteration 244 : loss : 0.383079, loss_ce: 0.113098
iteration 245 : loss : 0.389469, loss_ce: 0.118078
iteration 246 : loss : 0.356980, loss_ce: 0.084467
iteration 247 : loss : 0.377377, loss_ce: 0.104585
iteration 248 : loss : 0.367643, loss_ce: 0.094180
pred_sum 34853
gtsum tensor(52997, device='cuda:0')
iteration 249 : loss : 0.365061, loss_ce: 0.098972
iteration 250 : loss : 0.376476, loss_ce: 0.085854
iteration 251 : loss : 0.374396, loss_ce: 0.102605
iteration 252 : loss : 0.359563, loss_ce: 0.083523
iteration 253 : loss : 0.381627, loss_ce: 0.103611
iteration 254 : loss : 0.381621, loss_ce: 0.111862
iteration 255 : loss : 0.353255, loss_ce: 0.062269
iteration 256 : loss : 0.382595, loss_ce: 0.122895
iteration 257 : loss : 0.354948, loss_ce: 0.078797
iteration 258 : loss : 0.348241, loss_ce: 0.064013
iteration 259 : loss : 0.375445, loss_ce: 0.107651
iteration 260 : loss : 0.358743, loss_ce: 0.067544
iteration 261 : loss : 0.364139, loss_ce: 0.088520
iteration 262 : loss : 0.396359, loss_ce: 0.107989
iteration 263 : loss : 0.364446, loss_ce: 0.098589
iteration 264 : loss : 0.357313, loss_ce: 0.081166
iteration 265 : loss : 0.349862, loss_ce: 0.081783
iteration 266 : loss : 0.364864, loss_ce: 0.097268
iteration 267 : loss : 0.375488, loss_ce: 0.110190
iteration 268 : loss : 0.356738, loss_ce: 0.083678
iteration 269 : loss : 0.350773, loss_ce: 0.071098
iteration 270 : loss : 0.362388, loss_ce: 0.067514
iteration 271 : loss : 0.361093, loss_ce: 0.079879
iteration 272 : loss : 0.361774, loss_ce: 0.086076
iteration 273 : loss : 0.367092, loss_ce: 0.076635
iteration 274 : loss : 0.372270, loss_ce: 0.096281
iteration 275 : loss : 0.364782, loss_ce: 0.090724
iteration 276 : loss : 0.366966, loss_ce: 0.107306
iteration 277 : loss : 0.357414, loss_ce: 0.091658
iteration 278 : loss : 0.343683, loss_ce: 0.070412
iteration 279 : loss : 0.437967, loss_ce: 0.116119
  2%|▍                              | 3/200 [02:38<2:53:38, 52.89s/it]pred_sum 12372
gtsum tensor(7648, device='cuda:0')
iteration 280 : loss : 0.363034, loss_ce: 0.098567
iteration 281 : loss : 0.357819, loss_ce: 0.088746
iteration 282 : loss : 0.355268, loss_ce: 0.082766
iteration 283 : loss : 0.354515, loss_ce: 0.073390
iteration 284 : loss : 0.348185, loss_ce: 0.064452
iteration 285 : loss : 0.370050, loss_ce: 0.097981
iteration 286 : loss : 0.363889, loss_ce: 0.091388
iteration 287 : loss : 0.363159, loss_ce: 0.085350
iteration 288 : loss : 0.365599, loss_ce: 0.089596
iteration 289 : loss : 0.365482, loss_ce: 0.102460
iteration 290 : loss : 0.342313, loss_ce: 0.075200
iteration 291 : loss : 0.357978, loss_ce: 0.078871
iteration 292 : loss : 0.363763, loss_ce: 0.097933
iteration 293 : loss : 0.385914, loss_ce: 0.136366
iteration 294 : loss : 0.344151, loss_ce: 0.056665
iteration 295 : loss : 0.360677, loss_ce: 0.084278
iteration 296 : loss : 0.351489, loss_ce: 0.071281
iteration 297 : loss : 0.339926, loss_ce: 0.061475
iteration 298 : loss : 0.383082, loss_ce: 0.117444
iteration 299 : loss : 0.364161, loss_ce: 0.099861
iteration 300 : loss : 0.353102, loss_ce: 0.082425
iteration 301 : loss : 0.359507, loss_ce: 0.076935
iteration 302 : loss : 0.361736, loss_ce: 0.084843
iteration 303 : loss : 0.349126, loss_ce: 0.079235
iteration 304 : loss : 0.353407, loss_ce: 0.062789
iteration 305 : loss : 0.352644, loss_ce: 0.066973
iteration 306 : loss : 0.334703, loss_ce: 0.054304
iteration 307 : loss : 0.374252, loss_ce: 0.086851
iteration 308 : loss : 0.359672, loss_ce: 0.076321
iteration 309 : loss : 0.352661, loss_ce: 0.069057
iteration 310 : loss : 0.372004, loss_ce: 0.109966
pred_sum 24075
gtsum tensor(46247, device='cuda:0')
iteration 311 : loss : 0.358150, loss_ce: 0.086449
iteration 312 : loss : 0.348562, loss_ce: 0.082249
iteration 313 : loss : 0.355707, loss_ce: 0.079485
iteration 314 : loss : 0.365861, loss_ce: 0.101322
iteration 315 : loss : 0.371397, loss_ce: 0.126818
iteration 316 : loss : 0.352787, loss_ce: 0.081735
iteration 317 : loss : 0.373191, loss_ce: 0.080869
iteration 318 : loss : 0.355803, loss_ce: 0.084900
iteration 319 : loss : 0.357951, loss_ce: 0.090592
iteration 320 : loss : 0.345566, loss_ce: 0.068767
iteration 321 : loss : 0.357061, loss_ce: 0.080133
iteration 322 : loss : 0.356506, loss_ce: 0.081479
iteration 323 : loss : 0.356222, loss_ce: 0.085996
iteration 324 : loss : 0.348957, loss_ce: 0.077048
iteration 325 : loss : 0.362309, loss_ce: 0.089047
iteration 326 : loss : 0.333827, loss_ce: 0.067120
iteration 327 : loss : 0.360299, loss_ce: 0.090825
iteration 328 : loss : 0.352235, loss_ce: 0.082332
iteration 329 : loss : 0.330240, loss_ce: 0.060772
iteration 330 : loss : 0.338359, loss_ce: 0.059917
iteration 331 : loss : 0.337036, loss_ce: 0.071002
iteration 332 : loss : 0.367054, loss_ce: 0.105849
iteration 333 : loss : 0.337008, loss_ce: 0.071580
iteration 334 : loss : 0.339115, loss_ce: 0.066365
iteration 335 : loss : 0.374942, loss_ce: 0.124385
iteration 336 : loss : 0.343655, loss_ce: 0.082177
iteration 337 : loss : 0.341374, loss_ce: 0.061265
iteration 338 : loss : 0.355655, loss_ce: 0.086369
iteration 339 : loss : 0.337428, loss_ce: 0.067812
iteration 340 : loss : 0.344673, loss_ce: 0.083657
iteration 341 : loss : 0.356194, loss_ce: 0.100661
pred_sum 476
gtsum tensor(382, device='cuda:0')
iteration 342 : loss : 0.345001, loss_ce: 0.066186
iteration 343 : loss : 0.340471, loss_ce: 0.080023
iteration 344 : loss : 0.384909, loss_ce: 0.144592
iteration 345 : loss : 0.346383, loss_ce: 0.072161
iteration 346 : loss : 0.316858, loss_ce: 0.056834
iteration 347 : loss : 0.348601, loss_ce: 0.082514
iteration 348 : loss : 0.324441, loss_ce: 0.052967
iteration 349 : loss : 0.323742, loss_ce: 0.060852
iteration 350 : loss : 0.342709, loss_ce: 0.065151
iteration 351 : loss : 0.352144, loss_ce: 0.091200
iteration 352 : loss : 0.345859, loss_ce: 0.083937
iteration 353 : loss : 0.349415, loss_ce: 0.100122
iteration 354 : loss : 0.355186, loss_ce: 0.097396
iteration 355 : loss : 0.334115, loss_ce: 0.074596
iteration 356 : loss : 0.327748, loss_ce: 0.063950
iteration 357 : loss : 0.357124, loss_ce: 0.105412
iteration 358 : loss : 0.327146, loss_ce: 0.069653
iteration 359 : loss : 0.345587, loss_ce: 0.079143
iteration 360 : loss : 0.345102, loss_ce: 0.090106
iteration 361 : loss : 0.340434, loss_ce: 0.083914
iteration 362 : loss : 0.343598, loss_ce: 0.090743
iteration 363 : loss : 0.362038, loss_ce: 0.118255
iteration 364 : loss : 0.334920, loss_ce: 0.074486
iteration 365 : loss : 0.325455, loss_ce: 0.067774
iteration 366 : loss : 0.341186, loss_ce: 0.076332
iteration 367 : loss : 0.328744, loss_ce: 0.073430
iteration 368 : loss : 0.341245, loss_ce: 0.084551
iteration 369 : loss : 0.360644, loss_ce: 0.111658
iteration 370 : loss : 0.343715, loss_ce: 0.094800
iteration 371 : loss : 0.337290, loss_ce: 0.074299
iteration 372 : loss : 0.402457, loss_ce: 0.068274
  2%|▌                              | 4/200 [03:32<2:53:51, 53.22s/it]pred_sum 453
gtsum tensor(140, device='cuda:0')
iteration 373 : loss : 0.317782, loss_ce: 0.071235
iteration 374 : loss : 0.324890, loss_ce: 0.057293
iteration 375 : loss : 0.341558, loss_ce: 0.082903
iteration 376 : loss : 0.304185, loss_ce: 0.045020
iteration 377 : loss : 0.329480, loss_ce: 0.075439
iteration 378 : loss : 0.323895, loss_ce: 0.067865
iteration 379 : loss : 0.323783, loss_ce: 0.062110
iteration 380 : loss : 0.323909, loss_ce: 0.076351
iteration 381 : loss : 0.307618, loss_ce: 0.057069
iteration 382 : loss : 0.320218, loss_ce: 0.079071
iteration 383 : loss : 0.326284, loss_ce: 0.078558
iteration 384 : loss : 0.324535, loss_ce: 0.080195
iteration 385 : loss : 0.333364, loss_ce: 0.100272
iteration 386 : loss : 0.313891, loss_ce: 0.067827
iteration 387 : loss : 0.321600, loss_ce: 0.054325
iteration 388 : loss : 0.317605, loss_ce: 0.076426
iteration 389 : loss : 0.312853, loss_ce: 0.062804
iteration 390 : loss : 0.328858, loss_ce: 0.094658
iteration 391 : loss : 0.316141, loss_ce: 0.086846
iteration 392 : loss : 0.307763, loss_ce: 0.077046
iteration 393 : loss : 0.312084, loss_ce: 0.075852
iteration 394 : loss : 0.301509, loss_ce: 0.078844
iteration 395 : loss : 0.310704, loss_ce: 0.031285
iteration 396 : loss : 0.306081, loss_ce: 0.086410
iteration 397 : loss : 0.293267, loss_ce: 0.067951
iteration 398 : loss : 0.308114, loss_ce: 0.079874
iteration 399 : loss : 0.278922, loss_ce: 0.045864
iteration 400 : loss : 0.307177, loss_ce: 0.057403
iteration 401 : loss : 0.261587, loss_ce: 0.045858
iteration 402 : loss : 0.278095, loss_ce: 0.059538
iteration 403 : loss : 0.292302, loss_ce: 0.067591
pred_sum 18388
gtsum tensor(28553, device='cuda:0')
iteration 404 : loss : 0.308352, loss_ce: 0.059850
iteration 405 : loss : 0.274852, loss_ce: 0.043690
iteration 406 : loss : 0.281106, loss_ce: 0.058910
iteration 407 : loss : 0.280290, loss_ce: 0.068867
iteration 408 : loss : 0.304744, loss_ce: 0.051396
iteration 409 : loss : 0.261690, loss_ce: 0.052640
iteration 410 : loss : 0.292876, loss_ce: 0.067234
iteration 411 : loss : 0.293623, loss_ce: 0.069540
iteration 412 : loss : 0.290816, loss_ce: 0.072612
iteration 413 : loss : 0.298808, loss_ce: 0.079120
iteration 414 : loss : 0.284621, loss_ce: 0.030468
iteration 415 : loss : 0.293714, loss_ce: 0.081757
iteration 416 : loss : 0.319018, loss_ce: 0.053869
iteration 417 : loss : 0.314164, loss_ce: 0.074653
iteration 418 : loss : 0.312255, loss_ce: 0.084151
iteration 419 : loss : 0.308080, loss_ce: 0.084739
iteration 420 : loss : 0.310672, loss_ce: 0.098601
iteration 421 : loss : 0.265325, loss_ce: 0.059355
iteration 422 : loss : 0.276379, loss_ce: 0.062583
iteration 423 : loss : 0.289301, loss_ce: 0.080440
iteration 424 : loss : 0.307931, loss_ce: 0.079643
iteration 425 : loss : 0.283136, loss_ce: 0.072477
iteration 426 : loss : 0.275880, loss_ce: 0.063340
iteration 427 : loss : 0.284728, loss_ce: 0.061271
iteration 428 : loss : 0.276406, loss_ce: 0.065840
iteration 429 : loss : 0.302699, loss_ce: 0.093420
iteration 430 : loss : 0.279843, loss_ce: 0.063034
iteration 431 : loss : 0.318033, loss_ce: 0.107709
iteration 432 : loss : 0.291782, loss_ce: 0.062854
iteration 433 : loss : 0.281107, loss_ce: 0.046956
iteration 434 : loss : 0.336400, loss_ce: 0.132447
pred_sum 0
gtsum tensor(1521, device='cuda:0')
iteration 435 : loss : 0.321338, loss_ce: 0.089073
iteration 436 : loss : 0.287231, loss_ce: 0.070381
iteration 437 : loss : 0.295578, loss_ce: 0.075253
iteration 438 : loss : 0.299367, loss_ce: 0.086219
iteration 439 : loss : 0.302856, loss_ce: 0.070134
iteration 440 : loss : 0.285435, loss_ce: 0.074998
iteration 441 : loss : 0.287736, loss_ce: 0.077277
iteration 442 : loss : 0.275813, loss_ce: 0.071600
iteration 443 : loss : 0.288464, loss_ce: 0.093413
iteration 444 : loss : 0.295530, loss_ce: 0.077691
iteration 445 : loss : 0.287067, loss_ce: 0.093498
iteration 446 : loss : 0.266528, loss_ce: 0.048940
iteration 447 : loss : 0.258462, loss_ce: 0.043247
iteration 448 : loss : 0.262759, loss_ce: 0.065756
iteration 449 : loss : 0.259291, loss_ce: 0.041473
iteration 450 : loss : 0.260868, loss_ce: 0.034193
iteration 451 : loss : 0.282717, loss_ce: 0.056467
iteration 452 : loss : 0.274227, loss_ce: 0.066713
iteration 453 : loss : 0.282812, loss_ce: 0.079969
iteration 454 : loss : 0.275599, loss_ce: 0.059912
iteration 455 : loss : 0.280732, loss_ce: 0.068924
iteration 456 : loss : 0.263985, loss_ce: 0.080135
iteration 457 : loss : 0.265326, loss_ce: 0.061817
iteration 458 : loss : 0.291895, loss_ce: 0.055691
iteration 459 : loss : 0.290745, loss_ce: 0.099805
iteration 460 : loss : 0.280134, loss_ce: 0.079393
iteration 461 : loss : 0.270196, loss_ce: 0.066423
iteration 462 : loss : 0.294524, loss_ce: 0.068083
iteration 463 : loss : 0.288616, loss_ce: 0.079759
iteration 464 : loss : 0.256935, loss_ce: 0.064266
iteration 465 : loss : 0.384035, loss_ce: 0.036301
  2%|▊                              | 5/200 [04:25<2:53:47, 53.47s/it]pred_sum 1919
gtsum tensor(0, device='cuda:0')
iteration 466 : loss : 0.272350, loss_ce: 0.068958
iteration 467 : loss : 0.272888, loss_ce: 0.056758
iteration 468 : loss : 0.257010, loss_ce: 0.054538
iteration 469 : loss : 0.262062, loss_ce: 0.052417
iteration 470 : loss : 0.260706, loss_ce: 0.065823
iteration 471 : loss : 0.261595, loss_ce: 0.038710
iteration 472 : loss : 0.266396, loss_ce: 0.063789
iteration 473 : loss : 0.251973, loss_ce: 0.038689
iteration 474 : loss : 0.271184, loss_ce: 0.053051
iteration 475 : loss : 0.268242, loss_ce: 0.069484
iteration 476 : loss : 0.273673, loss_ce: 0.076893
iteration 477 : loss : 0.264708, loss_ce: 0.059055
iteration 478 : loss : 0.266903, loss_ce: 0.062550
iteration 479 : loss : 0.253306, loss_ce: 0.051301
iteration 480 : loss : 0.274007, loss_ce: 0.061836
iteration 481 : loss : 0.232495, loss_ce: 0.039694
iteration 482 : loss : 0.252504, loss_ce: 0.049431
iteration 483 : loss : 0.274920, loss_ce: 0.064700
iteration 484 : loss : 0.250127, loss_ce: 0.045005
iteration 485 : loss : 0.279469, loss_ce: 0.075177
iteration 486 : loss : 0.266132, loss_ce: 0.062385
iteration 487 : loss : 0.256444, loss_ce: 0.070495
iteration 488 : loss : 0.268303, loss_ce: 0.066545
iteration 489 : loss : 0.257278, loss_ce: 0.059333
iteration 490 : loss : 0.281428, loss_ce: 0.037608
iteration 491 : loss : 0.243174, loss_ce: 0.041611
iteration 492 : loss : 0.282286, loss_ce: 0.078486
iteration 493 : loss : 0.245922, loss_ce: 0.041262
iteration 494 : loss : 0.261191, loss_ce: 0.052066
iteration 495 : loss : 0.281736, loss_ce: 0.081359
iteration 496 : loss : 0.275108, loss_ce: 0.054861
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 497 : loss : 0.238678, loss_ce: 0.042884
iteration 498 : loss : 0.250374, loss_ce: 0.047953
iteration 499 : loss : 0.273321, loss_ce: 0.083263
iteration 500 : loss : 0.286327, loss_ce: 0.057420
iteration 501 : loss : 0.277694, loss_ce: 0.058679
iteration 502 : loss : 0.264255, loss_ce: 0.060115
iteration 503 : loss : 0.260936, loss_ce: 0.048455
iteration 504 : loss : 0.242972, loss_ce: 0.043857
iteration 505 : loss : 0.261138, loss_ce: 0.062000
iteration 506 : loss : 0.249188, loss_ce: 0.058071
iteration 507 : loss : 0.256165, loss_ce: 0.053648
iteration 508 : loss : 0.253838, loss_ce: 0.068213
iteration 509 : loss : 0.240322, loss_ce: 0.044824
iteration 510 : loss : 0.244900, loss_ce: 0.053618
iteration 511 : loss : 0.253804, loss_ce: 0.062099
iteration 512 : loss : 0.248827, loss_ce: 0.062689
iteration 513 : loss : 0.248255, loss_ce: 0.069943
iteration 514 : loss : 0.242300, loss_ce: 0.050282
iteration 515 : loss : 0.236992, loss_ce: 0.043762
iteration 516 : loss : 0.274872, loss_ce: 0.068035
iteration 517 : loss : 0.246128, loss_ce: 0.051344
iteration 518 : loss : 0.246009, loss_ce: 0.063097
iteration 519 : loss : 0.253145, loss_ce: 0.071821
iteration 520 : loss : 0.241102, loss_ce: 0.072119
iteration 521 : loss : 0.242231, loss_ce: 0.066250
iteration 522 : loss : 0.247483, loss_ce: 0.075728
iteration 523 : loss : 0.252146, loss_ce: 0.075507
iteration 524 : loss : 0.260625, loss_ce: 0.084055
iteration 525 : loss : 0.224011, loss_ce: 0.051110
iteration 526 : loss : 0.243876, loss_ce: 0.055123
iteration 527 : loss : 0.249816, loss_ce: 0.055874
pred_sum 7
gtsum tensor(0, device='cuda:0')
iteration 528 : loss : 0.250257, loss_ce: 0.062488
iteration 529 : loss : 0.237716, loss_ce: 0.047314
iteration 530 : loss : 0.251834, loss_ce: 0.053941
iteration 531 : loss : 0.255690, loss_ce: 0.045413
iteration 532 : loss : 0.215423, loss_ce: 0.034075
iteration 533 : loss : 0.254025, loss_ce: 0.064046
iteration 534 : loss : 0.248581, loss_ce: 0.055387
iteration 535 : loss : 0.244743, loss_ce: 0.042708
iteration 536 : loss : 0.229243, loss_ce: 0.049345
iteration 537 : loss : 0.231721, loss_ce: 0.057951
iteration 538 : loss : 0.253208, loss_ce: 0.056080
iteration 539 : loss : 0.238049, loss_ce: 0.057382
iteration 540 : loss : 0.234213, loss_ce: 0.043057
iteration 541 : loss : 0.236793, loss_ce: 0.057452
iteration 542 : loss : 0.244077, loss_ce: 0.058423
iteration 543 : loss : 0.231429, loss_ce: 0.053544
iteration 544 : loss : 0.237279, loss_ce: 0.046250
iteration 545 : loss : 0.237670, loss_ce: 0.044868
iteration 546 : loss : 0.236947, loss_ce: 0.050969
iteration 547 : loss : 0.234201, loss_ce: 0.057024
iteration 548 : loss : 0.239212, loss_ce: 0.055895
iteration 549 : loss : 0.229854, loss_ce: 0.039908
iteration 550 : loss : 0.257903, loss_ce: 0.045012
iteration 551 : loss : 0.230127, loss_ce: 0.056708
iteration 552 : loss : 0.253529, loss_ce: 0.044802
iteration 553 : loss : 0.240958, loss_ce: 0.057161
iteration 554 : loss : 0.246863, loss_ce: 0.044284
iteration 555 : loss : 0.243223, loss_ce: 0.068138
iteration 556 : loss : 0.239379, loss_ce: 0.050190
iteration 557 : loss : 0.237081, loss_ce: 0.046054
iteration 558 : loss : 0.325289, loss_ce: 0.047396
  3%|▉                              | 6/200 [05:20<2:53:38, 53.71s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 559 : loss : 0.228420, loss_ce: 0.045523
iteration 560 : loss : 0.245964, loss_ce: 0.051974
iteration 561 : loss : 0.246492, loss_ce: 0.066057
iteration 562 : loss : 0.235371, loss_ce: 0.051296
iteration 563 : loss : 0.259364, loss_ce: 0.065764
iteration 564 : loss : 0.232322, loss_ce: 0.058803
iteration 565 : loss : 0.227816, loss_ce: 0.054027
iteration 566 : loss : 0.238066, loss_ce: 0.066963
iteration 567 : loss : 0.234915, loss_ce: 0.054141
iteration 568 : loss : 0.237857, loss_ce: 0.042697
iteration 569 : loss : 0.242706, loss_ce: 0.062607
iteration 570 : loss : 0.250055, loss_ce: 0.040913
iteration 571 : loss : 0.238197, loss_ce: 0.052956
iteration 572 : loss : 0.222597, loss_ce: 0.050058
iteration 573 : loss : 0.233920, loss_ce: 0.044994
iteration 574 : loss : 0.225533, loss_ce: 0.047530
iteration 575 : loss : 0.217810, loss_ce: 0.052287
iteration 576 : loss : 0.233383, loss_ce: 0.049869
iteration 577 : loss : 0.226327, loss_ce: 0.053166
iteration 578 : loss : 0.221185, loss_ce: 0.060841
iteration 579 : loss : 0.202916, loss_ce: 0.039734
iteration 580 : loss : 0.234360, loss_ce: 0.047219
iteration 581 : loss : 0.245905, loss_ce: 0.051722
iteration 582 : loss : 0.233510, loss_ce: 0.043640
iteration 583 : loss : 0.258278, loss_ce: 0.056752
iteration 584 : loss : 0.222626, loss_ce: 0.039131
iteration 585 : loss : 0.220450, loss_ce: 0.054853
iteration 586 : loss : 0.248603, loss_ce: 0.048287
iteration 587 : loss : 0.246211, loss_ce: 0.056593
iteration 588 : loss : 0.235188, loss_ce: 0.062577
iteration 589 : loss : 0.251787, loss_ce: 0.060968
pred_sum 5846
gtsum tensor(8542, device='cuda:0')
iteration 590 : loss : 0.234809, loss_ce: 0.048006
iteration 591 : loss : 0.237038, loss_ce: 0.043145
iteration 592 : loss : 0.243403, loss_ce: 0.061018
iteration 593 : loss : 0.255299, loss_ce: 0.054523
iteration 594 : loss : 0.215092, loss_ce: 0.041614
iteration 595 : loss : 0.220413, loss_ce: 0.037235
iteration 596 : loss : 0.284581, loss_ce: 0.065495
iteration 597 : loss : 0.245852, loss_ce: 0.052826
iteration 598 : loss : 0.233729, loss_ce: 0.051319
iteration 599 : loss : 0.237521, loss_ce: 0.062823
iteration 600 : loss : 0.261289, loss_ce: 0.078057
iteration 601 : loss : 0.256977, loss_ce: 0.076252
iteration 602 : loss : 0.246498, loss_ce: 0.071031
iteration 603 : loss : 0.272388, loss_ce: 0.069874
iteration 604 : loss : 0.255044, loss_ce: 0.046881
iteration 605 : loss : 0.224630, loss_ce: 0.048026
iteration 606 : loss : 0.276028, loss_ce: 0.066153
iteration 607 : loss : 0.234501, loss_ce: 0.041998
iteration 608 : loss : 0.245441, loss_ce: 0.053416
iteration 609 : loss : 0.245161, loss_ce: 0.064200
iteration 610 : loss : 0.238612, loss_ce: 0.060815
iteration 611 : loss : 0.264335, loss_ce: 0.074133
iteration 612 : loss : 0.254872, loss_ce: 0.061067
iteration 613 : loss : 0.242956, loss_ce: 0.053338
iteration 614 : loss : 0.230645, loss_ce: 0.054772
iteration 615 : loss : 0.236263, loss_ce: 0.064485
iteration 616 : loss : 0.258846, loss_ce: 0.060690
iteration 617 : loss : 0.262823, loss_ce: 0.053819
iteration 618 : loss : 0.244049, loss_ce: 0.060983
iteration 619 : loss : 0.263949, loss_ce: 0.098181
iteration 620 : loss : 0.219427, loss_ce: 0.042424
pred_sum 38865
gtsum tensor(38873, device='cuda:0')
iteration 621 : loss : 0.244719, loss_ce: 0.054191
iteration 622 : loss : 0.221852, loss_ce: 0.063663
iteration 623 : loss : 0.237114, loss_ce: 0.061781
iteration 624 : loss : 0.243701, loss_ce: 0.062653
iteration 625 : loss : 0.215882, loss_ce: 0.040343
iteration 626 : loss : 0.253412, loss_ce: 0.052879
iteration 627 : loss : 0.241619, loss_ce: 0.058924
iteration 628 : loss : 0.218377, loss_ce: 0.048473
iteration 629 : loss : 0.220649, loss_ce: 0.033406
iteration 630 : loss : 0.220496, loss_ce: 0.045305
iteration 631 : loss : 0.252226, loss_ce: 0.060580
iteration 632 : loss : 0.233246, loss_ce: 0.040943
iteration 633 : loss : 0.262190, loss_ce: 0.066170
iteration 634 : loss : 0.214918, loss_ce: 0.037378
iteration 635 : loss : 0.230408, loss_ce: 0.061612
iteration 636 : loss : 0.247205, loss_ce: 0.055181
iteration 637 : loss : 0.242423, loss_ce: 0.043953
iteration 638 : loss : 0.244528, loss_ce: 0.061362
iteration 639 : loss : 0.222995, loss_ce: 0.044598
iteration 640 : loss : 0.244850, loss_ce: 0.036451
iteration 641 : loss : 0.249409, loss_ce: 0.083690
iteration 642 : loss : 0.207584, loss_ce: 0.039522
iteration 643 : loss : 0.216689, loss_ce: 0.038489
iteration 644 : loss : 0.223072, loss_ce: 0.038894
iteration 645 : loss : 0.224960, loss_ce: 0.038284
iteration 646 : loss : 0.233305, loss_ce: 0.026312
iteration 647 : loss : 0.219850, loss_ce: 0.029962
iteration 648 : loss : 0.220307, loss_ce: 0.047856
iteration 649 : loss : 0.210078, loss_ce: 0.045351
iteration 650 : loss : 0.207105, loss_ce: 0.042714
iteration 651 : loss : 0.355007, loss_ce: 0.024606
  4%|█                              | 7/200 [06:14<2:53:22, 53.90s/it]pred_sum 20228
gtsum tensor(16980, device='cuda:0')
iteration 652 : loss : 0.197204, loss_ce: 0.040280
iteration 653 : loss : 0.240523, loss_ce: 0.067111
iteration 654 : loss : 0.217317, loss_ce: 0.050766
iteration 655 : loss : 0.209314, loss_ce: 0.056953
iteration 656 : loss : 0.200068, loss_ce: 0.037222
iteration 657 : loss : 0.220731, loss_ce: 0.047758
iteration 658 : loss : 0.197792, loss_ce: 0.037456
iteration 659 : loss : 0.214958, loss_ce: 0.048683
iteration 660 : loss : 0.215613, loss_ce: 0.047346
iteration 661 : loss : 0.210136, loss_ce: 0.040368
iteration 662 : loss : 0.213898, loss_ce: 0.048805
iteration 663 : loss : 0.204000, loss_ce: 0.051274
iteration 664 : loss : 0.205374, loss_ce: 0.057707
iteration 665 : loss : 0.258566, loss_ce: 0.041711
iteration 666 : loss : 0.198383, loss_ce: 0.046414
iteration 667 : loss : 0.206428, loss_ce: 0.054546
iteration 668 : loss : 0.209361, loss_ce: 0.042888
iteration 669 : loss : 0.211626, loss_ce: 0.055251
iteration 670 : loss : 0.189480, loss_ce: 0.041165
iteration 671 : loss : 0.204069, loss_ce: 0.045360
iteration 672 : loss : 0.192337, loss_ce: 0.045684
iteration 673 : loss : 0.205562, loss_ce: 0.039208
iteration 674 : loss : 0.208012, loss_ce: 0.057036
iteration 675 : loss : 0.177958, loss_ce: 0.032485
iteration 676 : loss : 0.194913, loss_ce: 0.042283
iteration 677 : loss : 0.197105, loss_ce: 0.070205
iteration 678 : loss : 0.193872, loss_ce: 0.051806
iteration 679 : loss : 0.200741, loss_ce: 0.041641
iteration 680 : loss : 0.177955, loss_ce: 0.048587
iteration 681 : loss : 0.185258, loss_ce: 0.037917
iteration 682 : loss : 0.172176, loss_ce: 0.036808
pred_sum 35530
gtsum tensor(28416, device='cuda:0')
iteration 683 : loss : 0.180972, loss_ce: 0.040001
iteration 684 : loss : 0.160203, loss_ce: 0.031517
iteration 685 : loss : 0.197673, loss_ce: 0.044048
iteration 686 : loss : 0.197563, loss_ce: 0.049767
iteration 687 : loss : 0.187633, loss_ce: 0.046228
iteration 688 : loss : 0.211517, loss_ce: 0.050335
iteration 689 : loss : 0.187225, loss_ce: 0.037299
iteration 690 : loss : 0.219850, loss_ce: 0.050683
iteration 691 : loss : 0.171089, loss_ce: 0.035610
iteration 692 : loss : 0.189286, loss_ce: 0.049325
iteration 693 : loss : 0.182343, loss_ce: 0.050467
iteration 694 : loss : 0.176480, loss_ce: 0.029877
iteration 695 : loss : 0.187351, loss_ce: 0.026532
iteration 696 : loss : 0.171580, loss_ce: 0.035824
iteration 697 : loss : 0.202086, loss_ce: 0.057915
iteration 698 : loss : 0.186298, loss_ce: 0.055678
iteration 699 : loss : 0.161219, loss_ce: 0.033249
iteration 700 : loss : 0.184624, loss_ce: 0.049918
iteration 701 : loss : 0.180566, loss_ce: 0.026588
iteration 702 : loss : 0.188303, loss_ce: 0.044274
iteration 703 : loss : 0.190977, loss_ce: 0.051560
iteration 704 : loss : 0.168479, loss_ce: 0.032905
iteration 705 : loss : 0.166917, loss_ce: 0.041363
iteration 706 : loss : 0.165837, loss_ce: 0.036862
iteration 707 : loss : 0.194349, loss_ce: 0.054305
iteration 708 : loss : 0.177046, loss_ce: 0.046612
iteration 709 : loss : 0.203201, loss_ce: 0.043297
iteration 710 : loss : 0.219900, loss_ce: 0.033266
iteration 711 : loss : 0.164355, loss_ce: 0.043495
iteration 712 : loss : 0.169817, loss_ce: 0.026367
iteration 713 : loss : 0.157121, loss_ce: 0.042568
pred_sum 50868
gtsum tensor(53678, device='cuda:0')
iteration 714 : loss : 0.170829, loss_ce: 0.030507
iteration 715 : loss : 0.158807, loss_ce: 0.031407
iteration 716 : loss : 0.186277, loss_ce: 0.051558
iteration 717 : loss : 0.160944, loss_ce: 0.033023
iteration 718 : loss : 0.166721, loss_ce: 0.039693
iteration 719 : loss : 0.158136, loss_ce: 0.041788
iteration 720 : loss : 0.161878, loss_ce: 0.031784
iteration 721 : loss : 0.211559, loss_ce: 0.052471
iteration 722 : loss : 0.161726, loss_ce: 0.033031
iteration 723 : loss : 0.181737, loss_ce: 0.024583
iteration 724 : loss : 0.178176, loss_ce: 0.047061
iteration 725 : loss : 0.165172, loss_ce: 0.037918
iteration 726 : loss : 0.148039, loss_ce: 0.031571
iteration 727 : loss : 0.171118, loss_ce: 0.045885
iteration 728 : loss : 0.167587, loss_ce: 0.048150
iteration 729 : loss : 0.175011, loss_ce: 0.047127
iteration 730 : loss : 0.156272, loss_ce: 0.038729
iteration 731 : loss : 0.179303, loss_ce: 0.038867
iteration 732 : loss : 0.147637, loss_ce: 0.039763
iteration 733 : loss : 0.127324, loss_ce: 0.024533
iteration 734 : loss : 0.174293, loss_ce: 0.043866
iteration 735 : loss : 0.168615, loss_ce: 0.047328
iteration 736 : loss : 0.137687, loss_ce: 0.040679
iteration 737 : loss : 0.173987, loss_ce: 0.066834
iteration 738 : loss : 0.152661, loss_ce: 0.036562
iteration 739 : loss : 0.128722, loss_ce: 0.046219
iteration 740 : loss : 0.139520, loss_ce: 0.035021
iteration 741 : loss : 0.144346, loss_ce: 0.035228
iteration 742 : loss : 0.124870, loss_ce: 0.041831
iteration 743 : loss : 0.117586, loss_ce: 0.028275
iteration 744 : loss : 0.409481, loss_ce: 0.026373
  4%|█▏                             | 8/200 [07:08<2:52:58, 54.06s/it]pred_sum 1378
gtsum tensor(173, device='cuda:0')
iteration 745 : loss : 0.149677, loss_ce: 0.059255
iteration 746 : loss : 0.153753, loss_ce: 0.057090
iteration 747 : loss : 0.180720, loss_ce: 0.031104
iteration 748 : loss : 0.139388, loss_ce: 0.050550
iteration 749 : loss : 0.176471, loss_ce: 0.027720
iteration 750 : loss : 0.124273, loss_ce: 0.039728
iteration 751 : loss : 0.160553, loss_ce: 0.035910
iteration 752 : loss : 0.135230, loss_ce: 0.041492
iteration 753 : loss : 0.131507, loss_ce: 0.045748
iteration 754 : loss : 0.130465, loss_ce: 0.035786
iteration 755 : loss : 0.155793, loss_ce: 0.045666
iteration 756 : loss : 0.139037, loss_ce: 0.036790
iteration 757 : loss : 0.153494, loss_ce: 0.032050
iteration 758 : loss : 0.132259, loss_ce: 0.039733
iteration 759 : loss : 0.143151, loss_ce: 0.044927
iteration 760 : loss : 0.145081, loss_ce: 0.046221
iteration 761 : loss : 0.112332, loss_ce: 0.034838
iteration 762 : loss : 0.156521, loss_ce: 0.050647
iteration 763 : loss : 0.157497, loss_ce: 0.041683
iteration 764 : loss : 0.153987, loss_ce: 0.035481
iteration 765 : loss : 0.135161, loss_ce: 0.047816
iteration 766 : loss : 0.113802, loss_ce: 0.030330
iteration 767 : loss : 0.128916, loss_ce: 0.033657
iteration 768 : loss : 0.134787, loss_ce: 0.043397
iteration 769 : loss : 0.126717, loss_ce: 0.037187
iteration 770 : loss : 0.135638, loss_ce: 0.031737
iteration 771 : loss : 0.138236, loss_ce: 0.046204
iteration 772 : loss : 0.129742, loss_ce: 0.040734
iteration 773 : loss : 0.158470, loss_ce: 0.037701
iteration 774 : loss : 0.093737, loss_ce: 0.023303
iteration 775 : loss : 0.118626, loss_ce: 0.049438
pred_sum 30600
gtsum tensor(32900, device='cuda:0')
iteration 776 : loss : 0.150049, loss_ce: 0.033942
iteration 777 : loss : 0.133629, loss_ce: 0.045039
iteration 778 : loss : 0.138732, loss_ce: 0.027490
iteration 779 : loss : 0.118932, loss_ce: 0.052754
iteration 780 : loss : 0.129686, loss_ce: 0.051221
iteration 781 : loss : 0.185058, loss_ce: 0.050093
iteration 782 : loss : 0.169142, loss_ce: 0.027976
iteration 783 : loss : 0.159429, loss_ce: 0.057358
iteration 784 : loss : 0.109369, loss_ce: 0.041784
iteration 785 : loss : 0.142882, loss_ce: 0.044860
iteration 786 : loss : 0.115828, loss_ce: 0.043522
iteration 787 : loss : 0.158943, loss_ce: 0.060237
iteration 788 : loss : 0.135770, loss_ce: 0.033383
iteration 789 : loss : 0.124856, loss_ce: 0.037005
iteration 790 : loss : 0.125653, loss_ce: 0.050466
iteration 791 : loss : 0.132178, loss_ce: 0.041371
iteration 792 : loss : 0.127352, loss_ce: 0.039985
iteration 793 : loss : 0.116287, loss_ce: 0.029214
iteration 794 : loss : 0.145252, loss_ce: 0.037081
iteration 795 : loss : 0.133351, loss_ce: 0.035511
iteration 796 : loss : 0.159354, loss_ce: 0.044003
iteration 797 : loss : 0.149481, loss_ce: 0.050523
iteration 798 : loss : 0.127166, loss_ce: 0.029447
iteration 799 : loss : 0.149864, loss_ce: 0.052560
iteration 800 : loss : 0.185763, loss_ce: 0.040815
iteration 801 : loss : 0.138353, loss_ce: 0.035805
iteration 802 : loss : 0.110734, loss_ce: 0.039094
iteration 803 : loss : 0.154013, loss_ce: 0.060256
iteration 804 : loss : 0.146484, loss_ce: 0.043291
iteration 805 : loss : 0.121654, loss_ce: 0.047259
iteration 806 : loss : 0.155366, loss_ce: 0.052679
pred_sum 49358
gtsum tensor(47223, device='cuda:0')
iteration 807 : loss : 0.173687, loss_ce: 0.051943
iteration 808 : loss : 0.150142, loss_ce: 0.052512
iteration 809 : loss : 0.147707, loss_ce: 0.046760
iteration 810 : loss : 0.112945, loss_ce: 0.023863
iteration 811 : loss : 0.144389, loss_ce: 0.052053
iteration 812 : loss : 0.154122, loss_ce: 0.024932
iteration 813 : loss : 0.126807, loss_ce: 0.036911
iteration 814 : loss : 0.150199, loss_ce: 0.030253
iteration 815 : loss : 0.146809, loss_ce: 0.033994
iteration 816 : loss : 0.129364, loss_ce: 0.043551
iteration 817 : loss : 0.115328, loss_ce: 0.037698
iteration 818 : loss : 0.128550, loss_ce: 0.049111
iteration 819 : loss : 0.143618, loss_ce: 0.040010
iteration 820 : loss : 0.138613, loss_ce: 0.036055
iteration 821 : loss : 0.100146, loss_ce: 0.046494
iteration 822 : loss : 0.140810, loss_ce: 0.044063
iteration 823 : loss : 0.155079, loss_ce: 0.037479
iteration 824 : loss : 0.160537, loss_ce: 0.055664
iteration 825 : loss : 0.095248, loss_ce: 0.029819
iteration 826 : loss : 0.163466, loss_ce: 0.030883
iteration 827 : loss : 0.149182, loss_ce: 0.040998
iteration 828 : loss : 0.121425, loss_ce: 0.032661
iteration 829 : loss : 0.129623, loss_ce: 0.031927
iteration 830 : loss : 0.160845, loss_ce: 0.026553
iteration 831 : loss : 0.166452, loss_ce: 0.061978
iteration 832 : loss : 0.178679, loss_ce: 0.027529
iteration 833 : loss : 0.153963, loss_ce: 0.063562
iteration 834 : loss : 0.126801, loss_ce: 0.036811
iteration 835 : loss : 0.108451, loss_ce: 0.036216
iteration 836 : loss : 0.146567, loss_ce: 0.047241
iteration 837 : loss : 0.204832, loss_ce: 0.103587
  4%|█▍                             | 9/200 [08:03<2:52:27, 54.18s/it]pred_sum 34407
gtsum tensor(35958, device='cuda:0')
iteration 838 : loss : 0.130398, loss_ce: 0.053384
iteration 839 : loss : 0.170080, loss_ce: 0.054467
iteration 840 : loss : 0.177176, loss_ce: 0.060721
iteration 841 : loss : 0.207685, loss_ce: 0.066007
iteration 842 : loss : 0.165675, loss_ce: 0.057838
iteration 843 : loss : 0.173643, loss_ce: 0.052417
iteration 844 : loss : 0.141142, loss_ce: 0.037482
iteration 845 : loss : 0.113286, loss_ce: 0.039333
iteration 846 : loss : 0.152057, loss_ce: 0.033994
iteration 847 : loss : 0.106553, loss_ce: 0.031367
iteration 848 : loss : 0.178534, loss_ce: 0.049410
iteration 849 : loss : 0.100387, loss_ce: 0.024035
iteration 850 : loss : 0.159017, loss_ce: 0.046783
iteration 851 : loss : 0.114344, loss_ce: 0.031693
iteration 852 : loss : 0.119161, loss_ce: 0.030595
iteration 853 : loss : 0.137908, loss_ce: 0.049507
iteration 854 : loss : 0.179445, loss_ce: 0.050633
iteration 855 : loss : 0.193614, loss_ce: 0.062484
iteration 856 : loss : 0.138365, loss_ce: 0.044798
iteration 857 : loss : 0.157383, loss_ce: 0.044192
iteration 858 : loss : 0.135573, loss_ce: 0.037532
iteration 859 : loss : 0.130475, loss_ce: 0.041178
iteration 860 : loss : 0.143099, loss_ce: 0.035017
iteration 861 : loss : 0.154680, loss_ce: 0.052281
iteration 862 : loss : 0.158379, loss_ce: 0.044951
iteration 863 : loss : 0.118023, loss_ce: 0.051465
iteration 864 : loss : 0.108380, loss_ce: 0.032539
iteration 865 : loss : 0.123686, loss_ce: 0.027025
iteration 866 : loss : 0.147915, loss_ce: 0.073347
iteration 867 : loss : 0.116400, loss_ce: 0.034957
iteration 868 : loss : 0.164542, loss_ce: 0.037050
pred_sum 161
gtsum tensor(141, device='cuda:0')
iteration 869 : loss : 0.158945, loss_ce: 0.024326
iteration 870 : loss : 0.159048, loss_ce: 0.058348
iteration 871 : loss : 0.127030, loss_ce: 0.039974
iteration 872 : loss : 0.142745, loss_ce: 0.044662
iteration 873 : loss : 0.145118, loss_ce: 0.042251
iteration 874 : loss : 0.127791, loss_ce: 0.043338
iteration 875 : loss : 0.114540, loss_ce: 0.034609
iteration 876 : loss : 0.158418, loss_ce: 0.038689
iteration 877 : loss : 0.119647, loss_ce: 0.047153
iteration 878 : loss : 0.117996, loss_ce: 0.043180
iteration 879 : loss : 0.118042, loss_ce: 0.036668
iteration 880 : loss : 0.140001, loss_ce: 0.047745
iteration 881 : loss : 0.118623, loss_ce: 0.026264
iteration 882 : loss : 0.112514, loss_ce: 0.038695
iteration 883 : loss : 0.128784, loss_ce: 0.039604
iteration 884 : loss : 0.103222, loss_ce: 0.030471
iteration 885 : loss : 0.102047, loss_ce: 0.036573
iteration 886 : loss : 0.151777, loss_ce: 0.037257
iteration 887 : loss : 0.137987, loss_ce: 0.027891
iteration 888 : loss : 0.146180, loss_ce: 0.052562
iteration 889 : loss : 0.142448, loss_ce: 0.035527
iteration 890 : loss : 0.139720, loss_ce: 0.046521
iteration 891 : loss : 0.130743, loss_ce: 0.033272
iteration 892 : loss : 0.110640, loss_ce: 0.037572
iteration 893 : loss : 0.094961, loss_ce: 0.025632
iteration 894 : loss : 0.160381, loss_ce: 0.026606
iteration 895 : loss : 0.143853, loss_ce: 0.047461
iteration 896 : loss : 0.141358, loss_ce: 0.034792
iteration 897 : loss : 0.131545, loss_ce: 0.035433
iteration 898 : loss : 0.103206, loss_ce: 0.029785
iteration 899 : loss : 0.120815, loss_ce: 0.030922
pred_sum 497
gtsum tensor(0, device='cuda:0')
iteration 900 : loss : 0.119197, loss_ce: 0.039565
iteration 901 : loss : 0.156507, loss_ce: 0.039735
iteration 902 : loss : 0.135818, loss_ce: 0.036804
iteration 903 : loss : 0.159951, loss_ce: 0.038500
iteration 904 : loss : 0.145099, loss_ce: 0.032141
iteration 905 : loss : 0.107325, loss_ce: 0.037168
iteration 906 : loss : 0.137208, loss_ce: 0.058396
iteration 907 : loss : 0.152321, loss_ce: 0.046190
iteration 908 : loss : 0.138034, loss_ce: 0.036043
iteration 909 : loss : 0.130038, loss_ce: 0.043181
iteration 910 : loss : 0.125924, loss_ce: 0.030336
iteration 911 : loss : 0.185109, loss_ce: 0.041854
iteration 912 : loss : 0.112489, loss_ce: 0.029627
iteration 913 : loss : 0.166645, loss_ce: 0.049210
iteration 914 : loss : 0.133839, loss_ce: 0.033509
iteration 915 : loss : 0.225063, loss_ce: 0.029445
iteration 916 : loss : 0.145061, loss_ce: 0.027616
iteration 917 : loss : 0.145249, loss_ce: 0.042210
iteration 918 : loss : 0.160918, loss_ce: 0.031814
iteration 919 : loss : 0.098451, loss_ce: 0.033205
iteration 920 : loss : 0.143955, loss_ce: 0.052048
iteration 921 : loss : 0.112731, loss_ce: 0.039480
iteration 922 : loss : 0.101856, loss_ce: 0.030328
iteration 923 : loss : 0.124621, loss_ce: 0.037644
iteration 924 : loss : 0.246214, loss_ce: 0.022185
iteration 925 : loss : 0.164204, loss_ce: 0.025743
iteration 926 : loss : 0.151788, loss_ce: 0.026047
iteration 927 : loss : 0.163586, loss_ce: 0.039442
iteration 928 : loss : 0.132797, loss_ce: 0.041748
iteration 929 : loss : 0.109824, loss_ce: 0.045894
iteration 930 : loss : 0.195315, loss_ce: 0.092874
  5%|█▌                            | 10/200 [08:57<2:51:49, 54.26s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 931 : loss : 0.119500, loss_ce: 0.032228
iteration 932 : loss : 0.161761, loss_ce: 0.050111
iteration 933 : loss : 0.155514, loss_ce: 0.045555
iteration 934 : loss : 0.146925, loss_ce: 0.051761
iteration 935 : loss : 0.103985, loss_ce: 0.033881
iteration 936 : loss : 0.142498, loss_ce: 0.036268
iteration 937 : loss : 0.147957, loss_ce: 0.047947
iteration 938 : loss : 0.128906, loss_ce: 0.037942
iteration 939 : loss : 0.113270, loss_ce: 0.036183
iteration 940 : loss : 0.141092, loss_ce: 0.054977
iteration 941 : loss : 0.145429, loss_ce: 0.034111
iteration 942 : loss : 0.109857, loss_ce: 0.031010
iteration 943 : loss : 0.133281, loss_ce: 0.042772
iteration 944 : loss : 0.121959, loss_ce: 0.039106
iteration 945 : loss : 0.091913, loss_ce: 0.027284
iteration 946 : loss : 0.145659, loss_ce: 0.044033
iteration 947 : loss : 0.115827, loss_ce: 0.037487
iteration 948 : loss : 0.161695, loss_ce: 0.037126
iteration 949 : loss : 0.120911, loss_ce: 0.034437
iteration 950 : loss : 0.119230, loss_ce: 0.030174
iteration 951 : loss : 0.146352, loss_ce: 0.033772
iteration 952 : loss : 0.120041, loss_ce: 0.022782
iteration 953 : loss : 0.139337, loss_ce: 0.031950
iteration 954 : loss : 0.132944, loss_ce: 0.030606
iteration 955 : loss : 0.140132, loss_ce: 0.034404
iteration 956 : loss : 0.105080, loss_ce: 0.031920
iteration 957 : loss : 0.103937, loss_ce: 0.036359
iteration 958 : loss : 0.102990, loss_ce: 0.025654
iteration 959 : loss : 0.116986, loss_ce: 0.032494
iteration 960 : loss : 0.105822, loss_ce: 0.035094
iteration 961 : loss : 0.131932, loss_ce: 0.044501
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 962 : loss : 0.158841, loss_ce: 0.027045
iteration 963 : loss : 0.136026, loss_ce: 0.046826
iteration 964 : loss : 0.126111, loss_ce: 0.031174
iteration 965 : loss : 0.103373, loss_ce: 0.044954
iteration 966 : loss : 0.165131, loss_ce: 0.055186
iteration 967 : loss : 0.131350, loss_ce: 0.039375
iteration 968 : loss : 0.116969, loss_ce: 0.042662
iteration 969 : loss : 0.153218, loss_ce: 0.038330
iteration 970 : loss : 0.101537, loss_ce: 0.040250
iteration 971 : loss : 0.132584, loss_ce: 0.042274
iteration 972 : loss : 0.154279, loss_ce: 0.035717
iteration 973 : loss : 0.132100, loss_ce: 0.033905
iteration 974 : loss : 0.125040, loss_ce: 0.028914
iteration 975 : loss : 0.102478, loss_ce: 0.034734
iteration 976 : loss : 0.119351, loss_ce: 0.046130
iteration 977 : loss : 0.105955, loss_ce: 0.034046
iteration 978 : loss : 0.120337, loss_ce: 0.029162
iteration 979 : loss : 0.173337, loss_ce: 0.026792
iteration 980 : loss : 0.118503, loss_ce: 0.034751
iteration 981 : loss : 0.128045, loss_ce: 0.041860
iteration 982 : loss : 0.117508, loss_ce: 0.023537
iteration 983 : loss : 0.092792, loss_ce: 0.043679
iteration 984 : loss : 0.117794, loss_ce: 0.032846
iteration 985 : loss : 0.129432, loss_ce: 0.045837
iteration 986 : loss : 0.197041, loss_ce: 0.035683
iteration 987 : loss : 0.101735, loss_ce: 0.029837
iteration 988 : loss : 0.122667, loss_ce: 0.040306
iteration 989 : loss : 0.133888, loss_ce: 0.032197
iteration 990 : loss : 0.098544, loss_ce: 0.030885
iteration 991 : loss : 0.125469, loss_ce: 0.036860
iteration 992 : loss : 0.089008, loss_ce: 0.028541
pred_sum 4670
gtsum tensor(5141, device='cuda:0')
iteration 993 : loss : 0.134822, loss_ce: 0.045237
iteration 994 : loss : 0.108500, loss_ce: 0.032907
iteration 995 : loss : 0.147442, loss_ce: 0.037641
iteration 996 : loss : 0.109064, loss_ce: 0.038081
iteration 997 : loss : 0.170772, loss_ce: 0.037930
iteration 998 : loss : 0.121980, loss_ce: 0.029424
iteration 999 : loss : 0.124886, loss_ce: 0.021205
iteration 1000 : loss : 0.164073, loss_ce: 0.046577
iteration 1001 : loss : 0.124882, loss_ce: 0.023484
iteration 1002 : loss : 0.117910, loss_ce: 0.026871
iteration 1003 : loss : 0.141290, loss_ce: 0.059109
iteration 1004 : loss : 0.114761, loss_ce: 0.031629
iteration 1005 : loss : 0.120682, loss_ce: 0.046032
iteration 1006 : loss : 0.119917, loss_ce: 0.025935
iteration 1007 : loss : 0.139458, loss_ce: 0.032331
iteration 1008 : loss : 0.127365, loss_ce: 0.056626
iteration 1009 : loss : 0.107773, loss_ce: 0.043416
iteration 1010 : loss : 0.126476, loss_ce: 0.030175
iteration 1011 : loss : 0.133324, loss_ce: 0.041839
iteration 1012 : loss : 0.101603, loss_ce: 0.039157
iteration 1013 : loss : 0.088488, loss_ce: 0.039480
iteration 1014 : loss : 0.113475, loss_ce: 0.035025
iteration 1015 : loss : 0.094943, loss_ce: 0.029799
iteration 1016 : loss : 0.129283, loss_ce: 0.034492
iteration 1017 : loss : 0.106320, loss_ce: 0.039335
iteration 1018 : loss : 0.130415, loss_ce: 0.049265
iteration 1019 : loss : 0.106567, loss_ce: 0.031279
iteration 1020 : loss : 0.120885, loss_ce: 0.024545
iteration 1021 : loss : 0.146304, loss_ce: 0.025431
iteration 1022 : loss : 0.119505, loss_ce: 0.029989
iteration 1023 : loss : 0.245943, loss_ce: 0.020303
  6%|█▋                            | 11/200 [09:52<2:51:10, 54.34s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 1024 : loss : 0.116559, loss_ce: 0.035253
iteration 1025 : loss : 0.153989, loss_ce: 0.047737
iteration 1026 : loss : 0.143724, loss_ce: 0.050112
iteration 1027 : loss : 0.146126, loss_ce: 0.052282
iteration 1028 : loss : 0.117466, loss_ce: 0.030333
iteration 1029 : loss : 0.136665, loss_ce: 0.048256
iteration 1030 : loss : 0.141817, loss_ce: 0.055127
iteration 1031 : loss : 0.146453, loss_ce: 0.038310
iteration 1032 : loss : 0.113109, loss_ce: 0.032143
iteration 1033 : loss : 0.137350, loss_ce: 0.027678
iteration 1034 : loss : 0.141481, loss_ce: 0.038953
iteration 1035 : loss : 0.137892, loss_ce: 0.038192
iteration 1036 : loss : 0.145421, loss_ce: 0.044859
iteration 1037 : loss : 0.115938, loss_ce: 0.028212
iteration 1038 : loss : 0.124314, loss_ce: 0.023403
iteration 1039 : loss : 0.088293, loss_ce: 0.025433
iteration 1040 : loss : 0.120756, loss_ce: 0.025290
iteration 1041 : loss : 0.132500, loss_ce: 0.033567
iteration 1042 : loss : 0.110899, loss_ce: 0.041729
iteration 1043 : loss : 0.124558, loss_ce: 0.023218
iteration 1044 : loss : 0.099296, loss_ce: 0.027431
iteration 1045 : loss : 0.113404, loss_ce: 0.039121
iteration 1046 : loss : 0.125294, loss_ce: 0.029841
iteration 1047 : loss : 0.083857, loss_ce: 0.024227
iteration 1048 : loss : 0.100659, loss_ce: 0.029085
iteration 1049 : loss : 0.106294, loss_ce: 0.046253
iteration 1050 : loss : 0.133866, loss_ce: 0.031105
iteration 1051 : loss : 0.142860, loss_ce: 0.031304
iteration 1052 : loss : 0.089530, loss_ce: 0.028750
iteration 1053 : loss : 0.110001, loss_ce: 0.031247
iteration 1054 : loss : 0.082928, loss_ce: 0.026916
pred_sum 145
gtsum tensor(135, device='cuda:0')
iteration 1055 : loss : 0.127340, loss_ce: 0.037006
iteration 1056 : loss : 0.067799, loss_ce: 0.025854
iteration 1057 : loss : 0.103998, loss_ce: 0.035773
iteration 1058 : loss : 0.109509, loss_ce: 0.035135
iteration 1059 : loss : 0.128183, loss_ce: 0.023083
iteration 1060 : loss : 0.113059, loss_ce: 0.033315
iteration 1061 : loss : 0.095838, loss_ce: 0.031555
iteration 1062 : loss : 0.103794, loss_ce: 0.034641
iteration 1063 : loss : 0.099554, loss_ce: 0.033596
iteration 1064 : loss : 0.107866, loss_ce: 0.040546
iteration 1065 : loss : 0.102610, loss_ce: 0.031190
iteration 1066 : loss : 0.095312, loss_ce: 0.030296
iteration 1067 : loss : 0.094606, loss_ce: 0.032181
iteration 1068 : loss : 0.138884, loss_ce: 0.029026
iteration 1069 : loss : 0.120962, loss_ce: 0.033217
iteration 1070 : loss : 0.108606, loss_ce: 0.026584
iteration 1071 : loss : 0.072111, loss_ce: 0.023348
iteration 1072 : loss : 0.123293, loss_ce: 0.019621
iteration 1073 : loss : 0.175147, loss_ce: 0.024058
iteration 1074 : loss : 0.134030, loss_ce: 0.043114
iteration 1075 : loss : 0.121135, loss_ce: 0.053997
iteration 1076 : loss : 0.191221, loss_ce: 0.022821
iteration 1077 : loss : 0.139718, loss_ce: 0.045614
iteration 1078 : loss : 0.121914, loss_ce: 0.047275
iteration 1079 : loss : 0.152894, loss_ce: 0.055058
iteration 1080 : loss : 0.105891, loss_ce: 0.039583
iteration 1081 : loss : 0.126032, loss_ce: 0.038040
iteration 1082 : loss : 0.172215, loss_ce: 0.043545
iteration 1083 : loss : 0.117346, loss_ce: 0.031868
iteration 1084 : loss : 0.125948, loss_ce: 0.039887
iteration 1085 : loss : 0.093843, loss_ce: 0.038222
pred_sum 11710
gtsum tensor(11431, device='cuda:0')
iteration 1086 : loss : 0.091325, loss_ce: 0.032787
iteration 1087 : loss : 0.116869, loss_ce: 0.043634
iteration 1088 : loss : 0.115597, loss_ce: 0.029428
iteration 1089 : loss : 0.091383, loss_ce: 0.026552
iteration 1090 : loss : 0.130384, loss_ce: 0.018928
iteration 1091 : loss : 0.131728, loss_ce: 0.029087
iteration 1092 : loss : 0.124629, loss_ce: 0.054052
iteration 1093 : loss : 0.119627, loss_ce: 0.033203
iteration 1094 : loss : 0.114026, loss_ce: 0.030197
iteration 1095 : loss : 0.089068, loss_ce: 0.034612
iteration 1096 : loss : 0.111772, loss_ce: 0.030820
iteration 1097 : loss : 0.101997, loss_ce: 0.032183
iteration 1098 : loss : 0.128215, loss_ce: 0.030784
iteration 1099 : loss : 0.125134, loss_ce: 0.017990
iteration 1100 : loss : 0.111816, loss_ce: 0.044193
iteration 1101 : loss : 0.134656, loss_ce: 0.028568
iteration 1102 : loss : 0.101217, loss_ce: 0.031345
iteration 1103 : loss : 0.096976, loss_ce: 0.027991
iteration 1104 : loss : 0.117391, loss_ce: 0.027313
iteration 1105 : loss : 0.106338, loss_ce: 0.035990
iteration 1106 : loss : 0.081415, loss_ce: 0.021497
iteration 1107 : loss : 0.116553, loss_ce: 0.029645
iteration 1108 : loss : 0.098099, loss_ce: 0.025405
iteration 1109 : loss : 0.107724, loss_ce: 0.028503
iteration 1110 : loss : 0.116343, loss_ce: 0.047840
iteration 1111 : loss : 0.086940, loss_ce: 0.040666
iteration 1112 : loss : 0.104041, loss_ce: 0.040044
iteration 1113 : loss : 0.123397, loss_ce: 0.030082
iteration 1114 : loss : 0.090964, loss_ce: 0.027147
iteration 1115 : loss : 0.138003, loss_ce: 0.022089
iteration 1116 : loss : 0.264536, loss_ce: 0.023707
  6%|█▊                            | 12/200 [10:46<2:50:25, 54.39s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 1117 : loss : 0.121173, loss_ce: 0.020086
iteration 1118 : loss : 0.118832, loss_ce: 0.029925
iteration 1119 : loss : 0.098278, loss_ce: 0.034241
iteration 1120 : loss : 0.137746, loss_ce: 0.026916
iteration 1121 : loss : 0.121391, loss_ce: 0.045479
iteration 1122 : loss : 0.102003, loss_ce: 0.027170
iteration 1123 : loss : 0.123009, loss_ce: 0.029607
iteration 1124 : loss : 0.081921, loss_ce: 0.040062
iteration 1125 : loss : 0.089843, loss_ce: 0.024485
iteration 1126 : loss : 0.096924, loss_ce: 0.024469
iteration 1127 : loss : 0.099341, loss_ce: 0.045709
iteration 1128 : loss : 0.094703, loss_ce: 0.025957
iteration 1129 : loss : 0.100709, loss_ce: 0.033276
iteration 1130 : loss : 0.083518, loss_ce: 0.032852
iteration 1131 : loss : 0.091310, loss_ce: 0.031695
iteration 1132 : loss : 0.107171, loss_ce: 0.017403
iteration 1133 : loss : 0.092429, loss_ce: 0.026795
iteration 1134 : loss : 0.093429, loss_ce: 0.024966
iteration 1135 : loss : 0.092033, loss_ce: 0.036474
iteration 1136 : loss : 0.069442, loss_ce: 0.022615
iteration 1137 : loss : 0.093518, loss_ce: 0.031505
iteration 1138 : loss : 0.205576, loss_ce: 0.019167
iteration 1139 : loss : 0.129240, loss_ce: 0.025371
iteration 1140 : loss : 0.101485, loss_ce: 0.032701
iteration 1141 : loss : 0.076839, loss_ce: 0.026663
iteration 1142 : loss : 0.108031, loss_ce: 0.038793
iteration 1143 : loss : 0.125598, loss_ce: 0.027003
iteration 1144 : loss : 0.091913, loss_ce: 0.038329
iteration 1145 : loss : 0.138681, loss_ce: 0.035787
iteration 1146 : loss : 0.137863, loss_ce: 0.030724
iteration 1147 : loss : 0.092136, loss_ce: 0.032855
pred_sum 48366
gtsum tensor(51656, device='cuda:0')
iteration 1148 : loss : 0.108441, loss_ce: 0.028170
iteration 1149 : loss : 0.081318, loss_ce: 0.026213
iteration 1150 : loss : 0.130016, loss_ce: 0.028667
iteration 1151 : loss : 0.118828, loss_ce: 0.025536
iteration 1152 : loss : 0.128036, loss_ce: 0.034125
iteration 1153 : loss : 0.107357, loss_ce: 0.039206
iteration 1154 : loss : 0.098363, loss_ce: 0.029245
iteration 1155 : loss : 0.099488, loss_ce: 0.023298
iteration 1156 : loss : 0.122650, loss_ce: 0.022281
iteration 1157 : loss : 0.111819, loss_ce: 0.035121
iteration 1158 : loss : 0.115944, loss_ce: 0.022608
iteration 1159 : loss : 0.124911, loss_ce: 0.043994
iteration 1160 : loss : 0.122293, loss_ce: 0.026950
iteration 1161 : loss : 0.113886, loss_ce: 0.031128
iteration 1162 : loss : 0.137378, loss_ce: 0.060150
iteration 1163 : loss : 0.115842, loss_ce: 0.020075
iteration 1164 : loss : 0.095067, loss_ce: 0.024260
iteration 1165 : loss : 0.091932, loss_ce: 0.021820
iteration 1166 : loss : 0.102985, loss_ce: 0.027694
iteration 1167 : loss : 0.081432, loss_ce: 0.024315
iteration 1168 : loss : 0.083789, loss_ce: 0.025431
iteration 1169 : loss : 0.105521, loss_ce: 0.022611
iteration 1170 : loss : 0.088874, loss_ce: 0.028026
iteration 1171 : loss : 0.088470, loss_ce: 0.022216
iteration 1172 : loss : 0.089992, loss_ce: 0.020107
iteration 1173 : loss : 0.130564, loss_ce: 0.035625
iteration 1174 : loss : 0.114363, loss_ce: 0.042065
iteration 1175 : loss : 0.117759, loss_ce: 0.037515
iteration 1176 : loss : 0.115052, loss_ce: 0.044453
iteration 1177 : loss : 0.107288, loss_ce: 0.027412
iteration 1178 : loss : 0.081775, loss_ce: 0.031696
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 1179 : loss : 0.076405, loss_ce: 0.022353
iteration 1180 : loss : 0.139038, loss_ce: 0.031454
iteration 1181 : loss : 0.093214, loss_ce: 0.038777
iteration 1182 : loss : 0.084498, loss_ce: 0.018853
iteration 1183 : loss : 0.088303, loss_ce: 0.025757
iteration 1184 : loss : 0.081472, loss_ce: 0.024696
iteration 1185 : loss : 0.134838, loss_ce: 0.028214
iteration 1186 : loss : 0.134506, loss_ce: 0.022648
iteration 1187 : loss : 0.084573, loss_ce: 0.021034
iteration 1188 : loss : 0.110549, loss_ce: 0.017355
iteration 1189 : loss : 0.155922, loss_ce: 0.037570
iteration 1190 : loss : 0.079110, loss_ce: 0.020970
iteration 1191 : loss : 0.136010, loss_ce: 0.026967
iteration 1192 : loss : 0.104612, loss_ce: 0.033613
iteration 1193 : loss : 0.096628, loss_ce: 0.019410
iteration 1194 : loss : 0.087094, loss_ce: 0.037537
iteration 1195 : loss : 0.132421, loss_ce: 0.027640
iteration 1196 : loss : 0.089931, loss_ce: 0.039941
iteration 1197 : loss : 0.103037, loss_ce: 0.021746
iteration 1198 : loss : 0.092531, loss_ce: 0.021121
iteration 1199 : loss : 0.119245, loss_ce: 0.042343
iteration 1200 : loss : 0.088700, loss_ce: 0.026121
iteration 1201 : loss : 0.107919, loss_ce: 0.046450
iteration 1202 : loss : 0.099928, loss_ce: 0.030700
iteration 1203 : loss : 0.067471, loss_ce: 0.016548
iteration 1204 : loss : 0.135423, loss_ce: 0.039266
iteration 1205 : loss : 0.106178, loss_ce: 0.040594
iteration 1206 : loss : 0.094860, loss_ce: 0.019327
iteration 1207 : loss : 0.132654, loss_ce: 0.036365
iteration 1208 : loss : 0.075806, loss_ce: 0.029200
iteration 1209 : loss : 0.243431, loss_ce: 0.031237
  6%|█▉                            | 13/200 [11:41<2:49:34, 54.41s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 1210 : loss : 0.097813, loss_ce: 0.020236
iteration 1211 : loss : 0.099970, loss_ce: 0.039196
iteration 1212 : loss : 0.116527, loss_ce: 0.041423
iteration 1213 : loss : 0.114474, loss_ce: 0.033115
iteration 1214 : loss : 0.086950, loss_ce: 0.029031
iteration 1215 : loss : 0.091636, loss_ce: 0.027938
iteration 1216 : loss : 0.071004, loss_ce: 0.029023
iteration 1217 : loss : 0.078469, loss_ce: 0.030214
iteration 1218 : loss : 0.107279, loss_ce: 0.034473
iteration 1219 : loss : 0.074330, loss_ce: 0.026409
iteration 1220 : loss : 0.077099, loss_ce: 0.024095
iteration 1221 : loss : 0.077274, loss_ce: 0.024289
iteration 1222 : loss : 0.093214, loss_ce: 0.032299
iteration 1223 : loss : 0.092698, loss_ce: 0.035040
iteration 1224 : loss : 0.093116, loss_ce: 0.034910
iteration 1225 : loss : 0.092829, loss_ce: 0.026933
iteration 1226 : loss : 0.094877, loss_ce: 0.030874
iteration 1227 : loss : 0.082967, loss_ce: 0.027798
iteration 1228 : loss : 0.083275, loss_ce: 0.031255
iteration 1229 : loss : 0.145931, loss_ce: 0.022597
iteration 1230 : loss : 0.112331, loss_ce: 0.025221
iteration 1231 : loss : 0.127781, loss_ce: 0.042608
iteration 1232 : loss : 0.084130, loss_ce: 0.018967
iteration 1233 : loss : 0.120434, loss_ce: 0.024365
iteration 1234 : loss : 0.106710, loss_ce: 0.030739
iteration 1235 : loss : 0.055142, loss_ce: 0.015278
iteration 1236 : loss : 0.075839, loss_ce: 0.021713
iteration 1237 : loss : 0.082234, loss_ce: 0.022039
iteration 1238 : loss : 0.097343, loss_ce: 0.021404
iteration 1239 : loss : 0.073620, loss_ce: 0.024811
iteration 1240 : loss : 0.077445, loss_ce: 0.023893
pred_sum 2445
gtsum tensor(5839, device='cuda:0')
iteration 1241 : loss : 0.087134, loss_ce: 0.039031
iteration 1242 : loss : 0.085381, loss_ce: 0.030839
iteration 1243 : loss : 0.116933, loss_ce: 0.032199
iteration 1244 : loss : 0.079191, loss_ce: 0.026887
iteration 1245 : loss : 0.088251, loss_ce: 0.023360
iteration 1246 : loss : 0.105784, loss_ce: 0.025368
iteration 1247 : loss : 0.107884, loss_ce: 0.029609
iteration 1248 : loss : 0.074684, loss_ce: 0.031332
iteration 1249 : loss : 0.081944, loss_ce: 0.019292
iteration 1250 : loss : 0.083736, loss_ce: 0.023863
iteration 1251 : loss : 0.074294, loss_ce: 0.030251
iteration 1252 : loss : 0.102225, loss_ce: 0.022675
iteration 1253 : loss : 0.079186, loss_ce: 0.025154
iteration 1254 : loss : 0.070436, loss_ce: 0.024315
iteration 1255 : loss : 0.081763, loss_ce: 0.024592
iteration 1256 : loss : 0.093208, loss_ce: 0.035589
iteration 1257 : loss : 0.075819, loss_ce: 0.025358
iteration 1258 : loss : 0.085868, loss_ce: 0.028154
iteration 1259 : loss : 0.091069, loss_ce: 0.024455
iteration 1260 : loss : 0.078839, loss_ce: 0.026898
iteration 1261 : loss : 0.093010, loss_ce: 0.033129
iteration 1262 : loss : 0.088442, loss_ce: 0.038265
iteration 1263 : loss : 0.102738, loss_ce: 0.024788
iteration 1264 : loss : 0.113913, loss_ce: 0.017281
iteration 1265 : loss : 0.086003, loss_ce: 0.024487
iteration 1266 : loss : 0.105520, loss_ce: 0.022223
iteration 1267 : loss : 0.070968, loss_ce: 0.027757
iteration 1268 : loss : 0.085153, loss_ce: 0.025953
iteration 1269 : loss : 0.086170, loss_ce: 0.019864
iteration 1270 : loss : 0.113128, loss_ce: 0.022623
iteration 1271 : loss : 0.095093, loss_ce: 0.021137
pred_sum 517
gtsum tensor(657, device='cuda:0')
iteration 1272 : loss : 0.083946, loss_ce: 0.028155
iteration 1273 : loss : 0.073583, loss_ce: 0.016754
iteration 1274 : loss : 0.079482, loss_ce: 0.029016
iteration 1275 : loss : 0.155372, loss_ce: 0.016185
iteration 1276 : loss : 0.082657, loss_ce: 0.025410
iteration 1277 : loss : 0.093883, loss_ce: 0.034309
iteration 1278 : loss : 0.092286, loss_ce: 0.023681
iteration 1279 : loss : 0.126146, loss_ce: 0.019552
iteration 1280 : loss : 0.110438, loss_ce: 0.030042
iteration 1281 : loss : 0.075432, loss_ce: 0.018679
iteration 1282 : loss : 0.105847, loss_ce: 0.022059
iteration 1283 : loss : 0.089902, loss_ce: 0.020180
iteration 1284 : loss : 0.194521, loss_ce: 0.014160
iteration 1285 : loss : 0.081761, loss_ce: 0.030350
iteration 1286 : loss : 0.136464, loss_ce: 0.015769
iteration 1287 : loss : 0.056439, loss_ce: 0.015840
iteration 1288 : loss : 0.137677, loss_ce: 0.015722
iteration 1289 : loss : 0.065135, loss_ce: 0.019759
iteration 1290 : loss : 0.087480, loss_ce: 0.045375
iteration 1291 : loss : 0.087061, loss_ce: 0.027375
iteration 1292 : loss : 0.101371, loss_ce: 0.042570
iteration 1293 : loss : 0.082095, loss_ce: 0.017105
iteration 1294 : loss : 0.158018, loss_ce: 0.041046
iteration 1295 : loss : 0.085437, loss_ce: 0.022168
iteration 1296 : loss : 0.093647, loss_ce: 0.028034
iteration 1297 : loss : 0.115833, loss_ce: 0.033554
iteration 1298 : loss : 0.094306, loss_ce: 0.029844
iteration 1299 : loss : 0.097378, loss_ce: 0.026908
iteration 1300 : loss : 0.081742, loss_ce: 0.025452
iteration 1301 : loss : 0.071702, loss_ce: 0.020724
iteration 1302 : loss : 0.396497, loss_ce: 0.009223
  7%|██                            | 14/200 [12:35<2:48:43, 54.43s/it]pred_sum 470
gtsum tensor(0, device='cuda:0')
iteration 1303 : loss : 0.083956, loss_ce: 0.022426
iteration 1304 : loss : 0.118045, loss_ce: 0.025243
iteration 1305 : loss : 0.092786, loss_ce: 0.028229
iteration 1306 : loss : 0.070194, loss_ce: 0.025521
iteration 1307 : loss : 0.088643, loss_ce: 0.026094
iteration 1308 : loss : 0.095533, loss_ce: 0.023268
iteration 1309 : loss : 0.102434, loss_ce: 0.048344
iteration 1310 : loss : 0.079716, loss_ce: 0.028723
iteration 1311 : loss : 0.051678, loss_ce: 0.017424
iteration 1312 : loss : 0.100571, loss_ce: 0.022968
iteration 1313 : loss : 0.102610, loss_ce: 0.033181
iteration 1314 : loss : 0.069278, loss_ce: 0.025503
iteration 1315 : loss : 0.071362, loss_ce: 0.025137
iteration 1316 : loss : 0.092201, loss_ce: 0.026929
iteration 1317 : loss : 0.105350, loss_ce: 0.032670
iteration 1318 : loss : 0.080035, loss_ce: 0.019427
iteration 1319 : loss : 0.088084, loss_ce: 0.032899
iteration 1320 : loss : 0.079077, loss_ce: 0.020372
iteration 1321 : loss : 0.067749, loss_ce: 0.019629
iteration 1322 : loss : 0.091895, loss_ce: 0.023753
iteration 1323 : loss : 0.064283, loss_ce: 0.014395
iteration 1324 : loss : 0.104294, loss_ce: 0.020805
iteration 1325 : loss : 0.087796, loss_ce: 0.028229
iteration 1326 : loss : 0.089673, loss_ce: 0.041290
iteration 1327 : loss : 0.072385, loss_ce: 0.018962
iteration 1328 : loss : 0.099066, loss_ce: 0.053991
iteration 1329 : loss : 0.077299, loss_ce: 0.025235
iteration 1330 : loss : 0.082896, loss_ce: 0.033090
iteration 1331 : loss : 0.118094, loss_ce: 0.029988
iteration 1332 : loss : 0.091072, loss_ce: 0.030498
iteration 1333 : loss : 0.095471, loss_ce: 0.026558
pred_sum 3722
gtsum tensor(4571, device='cuda:0')
iteration 1334 : loss : 0.071926, loss_ce: 0.026855
iteration 1335 : loss : 0.076768, loss_ce: 0.025546
iteration 1336 : loss : 0.112715, loss_ce: 0.028629
iteration 1337 : loss : 0.102245, loss_ce: 0.033863
iteration 1338 : loss : 0.089308, loss_ce: 0.021343
iteration 1339 : loss : 0.098974, loss_ce: 0.032872
iteration 1340 : loss : 0.092399, loss_ce: 0.023108
iteration 1341 : loss : 0.091991, loss_ce: 0.026456
iteration 1342 : loss : 0.089972, loss_ce: 0.029705
iteration 1343 : loss : 0.084509, loss_ce: 0.030637
iteration 1344 : loss : 0.098215, loss_ce: 0.032221
iteration 1345 : loss : 0.099825, loss_ce: 0.023000
iteration 1346 : loss : 0.088080, loss_ce: 0.029676
iteration 1347 : loss : 0.074500, loss_ce: 0.033308
iteration 1348 : loss : 0.089275, loss_ce: 0.038916
iteration 1349 : loss : 0.131952, loss_ce: 0.025728
iteration 1350 : loss : 0.066368, loss_ce: 0.022470
iteration 1351 : loss : 0.070428, loss_ce: 0.017774
iteration 1352 : loss : 0.062300, loss_ce: 0.014828
iteration 1353 : loss : 0.078166, loss_ce: 0.023493
iteration 1354 : loss : 0.060295, loss_ce: 0.015646
iteration 1355 : loss : 0.059773, loss_ce: 0.016857
iteration 1356 : loss : 0.097571, loss_ce: 0.023808
iteration 1357 : loss : 0.071120, loss_ce: 0.020447
iteration 1358 : loss : 0.067329, loss_ce: 0.015516
iteration 1359 : loss : 0.085905, loss_ce: 0.032800
iteration 1360 : loss : 0.079013, loss_ce: 0.032813
iteration 1361 : loss : 0.100149, loss_ce: 0.022395
iteration 1362 : loss : 0.078070, loss_ce: 0.024816
iteration 1363 : loss : 0.130172, loss_ce: 0.021518
iteration 1364 : loss : 0.057024, loss_ce: 0.021206
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 1365 : loss : 0.080975, loss_ce: 0.020742
iteration 1366 : loss : 0.079326, loss_ce: 0.027776
iteration 1367 : loss : 0.070252, loss_ce: 0.031403
iteration 1368 : loss : 0.115644, loss_ce: 0.026334
iteration 1369 : loss : 0.077658, loss_ce: 0.030764
iteration 1370 : loss : 0.072538, loss_ce: 0.018619
iteration 1371 : loss : 0.094899, loss_ce: 0.029554
iteration 1372 : loss : 0.105711, loss_ce: 0.018046
iteration 1373 : loss : 0.073270, loss_ce: 0.023691
iteration 1374 : loss : 0.099616, loss_ce: 0.018202
iteration 1375 : loss : 0.086723, loss_ce: 0.013288
iteration 1376 : loss : 0.070782, loss_ce: 0.017392
iteration 1377 : loss : 0.093362, loss_ce: 0.020194
iteration 1378 : loss : 0.100659, loss_ce: 0.046651
iteration 1379 : loss : 0.089654, loss_ce: 0.017696
iteration 1380 : loss : 0.110309, loss_ce: 0.015474
iteration 1381 : loss : 0.077233, loss_ce: 0.024056
iteration 1382 : loss : 0.095764, loss_ce: 0.021113
iteration 1383 : loss : 0.098628, loss_ce: 0.018584
iteration 1384 : loss : 0.080275, loss_ce: 0.022624
iteration 1385 : loss : 0.066540, loss_ce: 0.024174
iteration 1386 : loss : 0.089384, loss_ce: 0.030299
iteration 1387 : loss : 0.078215, loss_ce: 0.018745
iteration 1388 : loss : 0.130402, loss_ce: 0.024811
iteration 1389 : loss : 0.106626, loss_ce: 0.017471
iteration 1390 : loss : 0.103886, loss_ce: 0.025278
iteration 1391 : loss : 0.079633, loss_ce: 0.031906
iteration 1392 : loss : 0.081353, loss_ce: 0.023261
iteration 1393 : loss : 0.064978, loss_ce: 0.022342
iteration 1394 : loss : 0.065402, loss_ce: 0.024096
iteration 1395 : loss : 0.393668, loss_ce: 0.005040
  8%|██▎                           | 15/200 [13:30<2:47:53, 54.45s/it]pred_sum 975
gtsum tensor(0, device='cuda:0')
iteration 1396 : loss : 0.120823, loss_ce: 0.022335
iteration 1397 : loss : 0.081021, loss_ce: 0.019579
iteration 1398 : loss : 0.089744, loss_ce: 0.030610
iteration 1399 : loss : 0.080399, loss_ce: 0.018470
iteration 1400 : loss : 0.090716, loss_ce: 0.033117
iteration 1401 : loss : 0.072287, loss_ce: 0.030131
iteration 1402 : loss : 0.074947, loss_ce: 0.025390
iteration 1403 : loss : 0.098613, loss_ce: 0.032432
iteration 1404 : loss : 0.117704, loss_ce: 0.031966
iteration 1405 : loss : 0.092964, loss_ce: 0.022875
iteration 1406 : loss : 0.140543, loss_ce: 0.030836
iteration 1407 : loss : 0.071355, loss_ce: 0.037007
iteration 1408 : loss : 0.096567, loss_ce: 0.035110
iteration 1409 : loss : 0.109653, loss_ce: 0.020805
iteration 1410 : loss : 0.088815, loss_ce: 0.041959
iteration 1411 : loss : 0.073374, loss_ce: 0.019868
iteration 1412 : loss : 0.110462, loss_ce: 0.033013
iteration 1413 : loss : 0.136098, loss_ce: 0.023745
iteration 1414 : loss : 0.105815, loss_ce: 0.021366
iteration 1415 : loss : 0.080138, loss_ce: 0.034650
iteration 1416 : loss : 0.071395, loss_ce: 0.021605
iteration 1417 : loss : 0.075081, loss_ce: 0.027868
iteration 1418 : loss : 0.120961, loss_ce: 0.025466
iteration 1419 : loss : 0.109374, loss_ce: 0.035312
iteration 1420 : loss : 0.121983, loss_ce: 0.035518
iteration 1421 : loss : 0.072019, loss_ce: 0.027261
iteration 1422 : loss : 0.117918, loss_ce: 0.023675
iteration 1423 : loss : 0.111143, loss_ce: 0.025730
iteration 1424 : loss : 0.079610, loss_ce: 0.028637
iteration 1425 : loss : 0.094741, loss_ce: 0.026051
iteration 1426 : loss : 0.098358, loss_ce: 0.031412
pred_sum 34032
gtsum tensor(37192, device='cuda:0')
iteration 1427 : loss : 0.085130, loss_ce: 0.019406
iteration 1428 : loss : 0.087207, loss_ce: 0.026593
iteration 1429 : loss : 0.096871, loss_ce: 0.031500
iteration 1430 : loss : 0.094113, loss_ce: 0.034198
iteration 1431 : loss : 0.082839, loss_ce: 0.029704
iteration 1432 : loss : 0.078408, loss_ce: 0.028423
iteration 1433 : loss : 0.084586, loss_ce: 0.023414
iteration 1434 : loss : 0.083260, loss_ce: 0.022155
iteration 1435 : loss : 0.099275, loss_ce: 0.026574
iteration 1436 : loss : 0.069175, loss_ce: 0.017788
iteration 1437 : loss : 0.096506, loss_ce: 0.014916
iteration 1438 : loss : 0.098615, loss_ce: 0.019772
iteration 1439 : loss : 0.089105, loss_ce: 0.017516
iteration 1440 : loss : 0.122517, loss_ce: 0.024752
iteration 1441 : loss : 0.085672, loss_ce: 0.026193
iteration 1442 : loss : 0.094741, loss_ce: 0.025596
iteration 1443 : loss : 0.089768, loss_ce: 0.036658
iteration 1444 : loss : 0.077138, loss_ce: 0.018535
iteration 1445 : loss : 0.075343, loss_ce: 0.016189
iteration 1446 : loss : 0.088093, loss_ce: 0.020330
iteration 1447 : loss : 0.075666, loss_ce: 0.015873
iteration 1448 : loss : 0.096598, loss_ce: 0.022180
iteration 1449 : loss : 0.063002, loss_ce: 0.014413
iteration 1450 : loss : 0.064846, loss_ce: 0.016435
iteration 1451 : loss : 0.073399, loss_ce: 0.022228
iteration 1452 : loss : 0.073362, loss_ce: 0.028247
iteration 1453 : loss : 0.101470, loss_ce: 0.018129
iteration 1454 : loss : 0.133856, loss_ce: 0.017284
iteration 1455 : loss : 0.067267, loss_ce: 0.019238
iteration 1456 : loss : 0.097019, loss_ce: 0.021009
iteration 1457 : loss : 0.060315, loss_ce: 0.019068
pred_sum 166
gtsum tensor(133, device='cuda:0')
iteration 1458 : loss : 0.075895, loss_ce: 0.022851
iteration 1459 : loss : 0.083085, loss_ce: 0.013826
iteration 1460 : loss : 0.085275, loss_ce: 0.020916
iteration 1461 : loss : 0.078343, loss_ce: 0.027039
iteration 1462 : loss : 0.098272, loss_ce: 0.032923
iteration 1463 : loss : 0.080174, loss_ce: 0.024279
iteration 1464 : loss : 0.076529, loss_ce: 0.025244
iteration 1465 : loss : 0.066162, loss_ce: 0.028135
iteration 1466 : loss : 0.059156, loss_ce: 0.023226
iteration 1467 : loss : 0.119543, loss_ce: 0.017926
iteration 1468 : loss : 0.069081, loss_ce: 0.023836
iteration 1469 : loss : 0.073730, loss_ce: 0.033668
iteration 1470 : loss : 0.073217, loss_ce: 0.020226
iteration 1471 : loss : 0.081736, loss_ce: 0.027118
iteration 1472 : loss : 0.067385, loss_ce: 0.025731
iteration 1473 : loss : 0.097394, loss_ce: 0.041516
iteration 1474 : loss : 0.083067, loss_ce: 0.014092
iteration 1475 : loss : 0.085760, loss_ce: 0.035743
iteration 1476 : loss : 0.079751, loss_ce: 0.022485
iteration 1477 : loss : 0.068412, loss_ce: 0.025696
iteration 1478 : loss : 0.093743, loss_ce: 0.017709
iteration 1479 : loss : 0.125704, loss_ce: 0.022397
iteration 1480 : loss : 0.065997, loss_ce: 0.029400
iteration 1481 : loss : 0.085581, loss_ce: 0.029987
iteration 1482 : loss : 0.130147, loss_ce: 0.019668
iteration 1483 : loss : 0.074281, loss_ce: 0.028222
iteration 1484 : loss : 0.068398, loss_ce: 0.023025
iteration 1485 : loss : 0.119920, loss_ce: 0.016994
iteration 1486 : loss : 0.097611, loss_ce: 0.026333
iteration 1487 : loss : 0.064433, loss_ce: 0.022269
iteration 1488 : loss : 0.111264, loss_ce: 0.057900
  8%|██▍                           | 16/200 [14:24<2:47:00, 54.46s/it]pred_sum 27002
gtsum tensor(29944, device='cuda:0')
iteration 1489 : loss : 0.126506, loss_ce: 0.016781
iteration 1490 : loss : 0.073024, loss_ce: 0.022371
iteration 1491 : loss : 0.080696, loss_ce: 0.019403
iteration 1492 : loss : 0.092416, loss_ce: 0.026332
iteration 1493 : loss : 0.070584, loss_ce: 0.025412
iteration 1494 : loss : 0.073178, loss_ce: 0.020498
iteration 1495 : loss : 0.084483, loss_ce: 0.031556
iteration 1496 : loss : 0.080692, loss_ce: 0.033022
iteration 1497 : loss : 0.076738, loss_ce: 0.019512
iteration 1498 : loss : 0.055358, loss_ce: 0.016300
iteration 1499 : loss : 0.075290, loss_ce: 0.016354
iteration 1500 : loss : 0.106157, loss_ce: 0.016785
iteration 1501 : loss : 0.092647, loss_ce: 0.025864
iteration 1502 : loss : 0.100305, loss_ce: 0.034773
iteration 1503 : loss : 0.100419, loss_ce: 0.026472
iteration 1504 : loss : 0.088321, loss_ce: 0.024316
iteration 1505 : loss : 0.082870, loss_ce: 0.020901
iteration 1506 : loss : 0.086796, loss_ce: 0.027000
iteration 1507 : loss : 0.059932, loss_ce: 0.020604
iteration 1508 : loss : 0.065486, loss_ce: 0.019611
iteration 1509 : loss : 0.135833, loss_ce: 0.018575
iteration 1510 : loss : 0.080099, loss_ce: 0.035158
iteration 1511 : loss : 0.069073, loss_ce: 0.025616
iteration 1512 : loss : 0.062743, loss_ce: 0.021198
iteration 1513 : loss : 0.072048, loss_ce: 0.019382
iteration 1514 : loss : 0.081719, loss_ce: 0.026294
iteration 1515 : loss : 0.073932, loss_ce: 0.029170
iteration 1516 : loss : 0.062208, loss_ce: 0.017750
iteration 1517 : loss : 0.091981, loss_ce: 0.022212
iteration 1518 : loss : 0.066403, loss_ce: 0.030091
iteration 1519 : loss : 0.077279, loss_ce: 0.023447
pred_sum 24600
gtsum tensor(23532, device='cuda:0')
iteration 1520 : loss : 0.069715, loss_ce: 0.026057
iteration 1521 : loss : 0.063701, loss_ce: 0.024403
iteration 1522 : loss : 0.060454, loss_ce: 0.023306
iteration 1523 : loss : 0.060175, loss_ce: 0.019366
iteration 1524 : loss : 0.080245, loss_ce: 0.025820
iteration 1525 : loss : 0.100172, loss_ce: 0.020462
iteration 1526 : loss : 0.087612, loss_ce: 0.024575
iteration 1527 : loss : 0.097791, loss_ce: 0.035373
iteration 1528 : loss : 0.073991, loss_ce: 0.021891
iteration 1529 : loss : 0.067116, loss_ce: 0.020512
iteration 1530 : loss : 0.064476, loss_ce: 0.023400
iteration 1531 : loss : 0.084202, loss_ce: 0.022975
iteration 1532 : loss : 0.088334, loss_ce: 0.017029
iteration 1533 : loss : 0.075080, loss_ce: 0.019190
iteration 1534 : loss : 0.072685, loss_ce: 0.031398
iteration 1535 : loss : 0.057164, loss_ce: 0.018550
iteration 1536 : loss : 0.059760, loss_ce: 0.022156
iteration 1537 : loss : 0.079088, loss_ce: 0.021130
iteration 1538 : loss : 0.109803, loss_ce: 0.017191
iteration 1539 : loss : 0.087145, loss_ce: 0.014542
iteration 1540 : loss : 0.071391, loss_ce: 0.032754
iteration 1541 : loss : 0.071531, loss_ce: 0.018160
iteration 1542 : loss : 0.057427, loss_ce: 0.020133
iteration 1543 : loss : 0.054914, loss_ce: 0.023929
iteration 1544 : loss : 0.077797, loss_ce: 0.023032
iteration 1545 : loss : 0.071021, loss_ce: 0.026211
iteration 1546 : loss : 0.069698, loss_ce: 0.015684
iteration 1547 : loss : 0.090643, loss_ce: 0.031401
iteration 1548 : loss : 0.239621, loss_ce: 0.011076
iteration 1549 : loss : 0.102245, loss_ce: 0.027325
iteration 1550 : loss : 0.090923, loss_ce: 0.012175
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 1551 : loss : 0.103388, loss_ce: 0.033673
iteration 1552 : loss : 0.053184, loss_ce: 0.019556
iteration 1553 : loss : 0.068140, loss_ce: 0.026896
iteration 1554 : loss : 0.062444, loss_ce: 0.021254
iteration 1555 : loss : 0.099921, loss_ce: 0.014231
iteration 1556 : loss : 0.092742, loss_ce: 0.027024
iteration 1557 : loss : 0.076772, loss_ce: 0.024147
iteration 1558 : loss : 0.070091, loss_ce: 0.020194
iteration 1559 : loss : 0.103005, loss_ce: 0.020223
iteration 1560 : loss : 0.124242, loss_ce: 0.014877
iteration 1561 : loss : 0.124404, loss_ce: 0.026825
iteration 1562 : loss : 0.062351, loss_ce: 0.022436
iteration 1563 : loss : 0.079081, loss_ce: 0.027800
iteration 1564 : loss : 0.062860, loss_ce: 0.017779
iteration 1565 : loss : 0.086242, loss_ce: 0.016085
iteration 1566 : loss : 0.111337, loss_ce: 0.020163
iteration 1567 : loss : 0.120403, loss_ce: 0.013576
iteration 1568 : loss : 0.064389, loss_ce: 0.020197
iteration 1569 : loss : 0.069186, loss_ce: 0.020158
iteration 1570 : loss : 0.086329, loss_ce: 0.030569
iteration 1571 : loss : 0.127079, loss_ce: 0.040056
iteration 1572 : loss : 0.132320, loss_ce: 0.019118
iteration 1573 : loss : 0.114938, loss_ce: 0.025504
iteration 1574 : loss : 0.064308, loss_ce: 0.022010
iteration 1575 : loss : 0.076846, loss_ce: 0.035639
iteration 1576 : loss : 0.117488, loss_ce: 0.021100
iteration 1577 : loss : 0.083072, loss_ce: 0.026926
iteration 1578 : loss : 0.063909, loss_ce: 0.033345
iteration 1579 : loss : 0.075200, loss_ce: 0.035086
iteration 1580 : loss : 0.093770, loss_ce: 0.011606
iteration 1581 : loss : 0.111438, loss_ce: 0.018822
  8%|██▌                           | 17/200 [15:19<2:46:13, 54.50s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 1582 : loss : 0.059932, loss_ce: 0.021437
iteration 1583 : loss : 0.096299, loss_ce: 0.022484
iteration 1584 : loss : 0.104450, loss_ce: 0.017733
iteration 1585 : loss : 0.083096, loss_ce: 0.025852
iteration 1586 : loss : 0.071032, loss_ce: 0.029087
iteration 1587 : loss : 0.094512, loss_ce: 0.027497
iteration 1588 : loss : 0.078617, loss_ce: 0.027156
iteration 1589 : loss : 0.059352, loss_ce: 0.023981
iteration 1590 : loss : 0.061365, loss_ce: 0.029369
iteration 1591 : loss : 0.069392, loss_ce: 0.023923
iteration 1592 : loss : 0.103359, loss_ce: 0.016300
iteration 1593 : loss : 0.085660, loss_ce: 0.013102
iteration 1594 : loss : 0.068950, loss_ce: 0.026572
iteration 1595 : loss : 0.070007, loss_ce: 0.027317
iteration 1596 : loss : 0.115561, loss_ce: 0.016254
iteration 1597 : loss : 0.071504, loss_ce: 0.026568
iteration 1598 : loss : 0.106280, loss_ce: 0.013996
iteration 1599 : loss : 0.077587, loss_ce: 0.019549
iteration 1600 : loss : 0.059148, loss_ce: 0.024164
iteration 1601 : loss : 0.065906, loss_ce: 0.031729
iteration 1602 : loss : 0.068310, loss_ce: 0.016189
iteration 1603 : loss : 0.088152, loss_ce: 0.021354
iteration 1604 : loss : 0.056084, loss_ce: 0.016751
iteration 1605 : loss : 0.104169, loss_ce: 0.018603
iteration 1606 : loss : 0.101893, loss_ce: 0.017846
iteration 1607 : loss : 0.074040, loss_ce: 0.019829
iteration 1608 : loss : 0.059878, loss_ce: 0.020519
iteration 1609 : loss : 0.065727, loss_ce: 0.023311
iteration 1610 : loss : 0.064836, loss_ce: 0.024221
iteration 1611 : loss : 0.079291, loss_ce: 0.017988
iteration 1612 : loss : 0.068626, loss_ce: 0.016400
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 1613 : loss : 0.056522, loss_ce: 0.018119
iteration 1614 : loss : 0.108886, loss_ce: 0.020302
iteration 1615 : loss : 0.056896, loss_ce: 0.011745
iteration 1616 : loss : 0.077599, loss_ce: 0.024853
iteration 1617 : loss : 0.044996, loss_ce: 0.017537
iteration 1618 : loss : 0.091810, loss_ce: 0.021687
iteration 1619 : loss : 0.047260, loss_ce: 0.021103
iteration 1620 : loss : 0.072387, loss_ce: 0.023183
iteration 1621 : loss : 0.071041, loss_ce: 0.015203
iteration 1622 : loss : 0.056769, loss_ce: 0.010687
iteration 1623 : loss : 0.093481, loss_ce: 0.043768
iteration 1624 : loss : 0.090840, loss_ce: 0.021352
iteration 1625 : loss : 0.071526, loss_ce: 0.024780
iteration 1626 : loss : 0.098312, loss_ce: 0.021800
iteration 1627 : loss : 0.083277, loss_ce: 0.014818
iteration 1628 : loss : 0.067144, loss_ce: 0.019877
iteration 1629 : loss : 0.057966, loss_ce: 0.015056
iteration 1630 : loss : 0.102924, loss_ce: 0.024680
iteration 1631 : loss : 0.078548, loss_ce: 0.022740
iteration 1632 : loss : 0.068758, loss_ce: 0.035065
iteration 1633 : loss : 0.063668, loss_ce: 0.021233
iteration 1634 : loss : 0.113410, loss_ce: 0.027622
iteration 1635 : loss : 0.062376, loss_ce: 0.021074
iteration 1636 : loss : 0.072722, loss_ce: 0.019427
iteration 1637 : loss : 0.090993, loss_ce: 0.019638
iteration 1638 : loss : 0.107449, loss_ce: 0.018016
iteration 1639 : loss : 0.060704, loss_ce: 0.020652
iteration 1640 : loss : 0.067514, loss_ce: 0.023524
iteration 1641 : loss : 0.069166, loss_ce: 0.017706
iteration 1642 : loss : 0.192274, loss_ce: 0.008848
iteration 1643 : loss : 0.075848, loss_ce: 0.020658
pred_sum 10672
gtsum tensor(11313, device='cuda:0')
iteration 1644 : loss : 0.060019, loss_ce: 0.020545
iteration 1645 : loss : 0.130597, loss_ce: 0.030297
iteration 1646 : loss : 0.073248, loss_ce: 0.015312
iteration 1647 : loss : 0.077557, loss_ce: 0.017438
iteration 1648 : loss : 0.080070, loss_ce: 0.021707
iteration 1649 : loss : 0.071305, loss_ce: 0.019504
iteration 1650 : loss : 0.069916, loss_ce: 0.027598
iteration 1651 : loss : 0.086861, loss_ce: 0.015781
iteration 1652 : loss : 0.067993, loss_ce: 0.018223
iteration 1653 : loss : 0.069035, loss_ce: 0.023848
iteration 1654 : loss : 0.066332, loss_ce: 0.022943
iteration 1655 : loss : 0.079828, loss_ce: 0.011298
iteration 1656 : loss : 0.069928, loss_ce: 0.022343
iteration 1657 : loss : 0.063335, loss_ce: 0.034225
iteration 1658 : loss : 0.070150, loss_ce: 0.034563
iteration 1659 : loss : 0.088621, loss_ce: 0.023972
iteration 1660 : loss : 0.056186, loss_ce: 0.027847
iteration 1661 : loss : 0.114394, loss_ce: 0.026569
iteration 1662 : loss : 0.067845, loss_ce: 0.012681
iteration 1663 : loss : 0.083672, loss_ce: 0.029845
iteration 1664 : loss : 0.087212, loss_ce: 0.036071
iteration 1665 : loss : 0.053636, loss_ce: 0.014776
iteration 1666 : loss : 0.090937, loss_ce: 0.019974
iteration 1667 : loss : 0.076012, loss_ce: 0.019279
iteration 1668 : loss : 0.069849, loss_ce: 0.031980
iteration 1669 : loss : 0.081470, loss_ce: 0.022993
iteration 1670 : loss : 0.068744, loss_ce: 0.021125
iteration 1671 : loss : 0.075315, loss_ce: 0.026146
iteration 1672 : loss : 0.069796, loss_ce: 0.018329
iteration 1673 : loss : 0.117223, loss_ce: 0.017646
iteration 1674 : loss : 0.184640, loss_ce: 0.098402
  9%|██▋                           | 18/200 [16:13<2:45:17, 54.49s/it]pred_sum 3224
gtsum tensor(7081, device='cuda:0')
iteration 1675 : loss : 0.082955, loss_ce: 0.028348
iteration 1676 : loss : 0.098008, loss_ce: 0.028754
iteration 1677 : loss : 0.072838, loss_ce: 0.026636
iteration 1678 : loss : 0.073472, loss_ce: 0.021545
iteration 1679 : loss : 0.074223, loss_ce: 0.020033
iteration 1680 : loss : 0.078032, loss_ce: 0.025037
iteration 1681 : loss : 0.077910, loss_ce: 0.027822
iteration 1682 : loss : 0.070993, loss_ce: 0.017352
iteration 1683 : loss : 0.070684, loss_ce: 0.023714
iteration 1684 : loss : 0.070270, loss_ce: 0.028943
iteration 1685 : loss : 0.070316, loss_ce: 0.015444
iteration 1686 : loss : 0.062875, loss_ce: 0.020239
iteration 1687 : loss : 0.052205, loss_ce: 0.016981
iteration 1688 : loss : 0.092437, loss_ce: 0.020299
iteration 1689 : loss : 0.097114, loss_ce: 0.023143
iteration 1690 : loss : 0.062457, loss_ce: 0.018705
iteration 1691 : loss : 0.081329, loss_ce: 0.017108
iteration 1692 : loss : 0.083911, loss_ce: 0.020433
iteration 1693 : loss : 0.076158, loss_ce: 0.015582
iteration 1694 : loss : 0.082381, loss_ce: 0.028322
iteration 1695 : loss : 0.079166, loss_ce: 0.017786
iteration 1696 : loss : 0.092295, loss_ce: 0.049360
iteration 1697 : loss : 0.072475, loss_ce: 0.026115
iteration 1698 : loss : 0.071976, loss_ce: 0.025746
iteration 1699 : loss : 0.065756, loss_ce: 0.016193
iteration 1700 : loss : 0.083333, loss_ce: 0.034210
iteration 1701 : loss : 0.072856, loss_ce: 0.014738
iteration 1702 : loss : 0.069950, loss_ce: 0.016366
iteration 1703 : loss : 0.086439, loss_ce: 0.020785
iteration 1704 : loss : 0.057924, loss_ce: 0.016058
iteration 1705 : loss : 0.060582, loss_ce: 0.014628
pred_sum 702
gtsum tensor(705, device='cuda:0')
iteration 1706 : loss : 0.081716, loss_ce: 0.013970
iteration 1707 : loss : 0.129077, loss_ce: 0.021789
iteration 1708 : loss : 0.063434, loss_ce: 0.023589
iteration 1709 : loss : 0.069474, loss_ce: 0.027292
iteration 1710 : loss : 0.100993, loss_ce: 0.014096
iteration 1711 : loss : 0.084951, loss_ce: 0.025705
iteration 1712 : loss : 0.143848, loss_ce: 0.010302
iteration 1713 : loss : 0.066556, loss_ce: 0.018176
iteration 1714 : loss : 0.062815, loss_ce: 0.020117
iteration 1715 : loss : 0.065760, loss_ce: 0.019055
iteration 1716 : loss : 0.066035, loss_ce: 0.018242
iteration 1717 : loss : 0.062371, loss_ce: 0.021977
iteration 1718 : loss : 0.047725, loss_ce: 0.016773
iteration 1719 : loss : 0.051474, loss_ce: 0.015443
iteration 1720 : loss : 0.057630, loss_ce: 0.013095
iteration 1721 : loss : 0.061433, loss_ce: 0.015641
iteration 1722 : loss : 0.065093, loss_ce: 0.020134
iteration 1723 : loss : 0.074728, loss_ce: 0.015516
iteration 1724 : loss : 0.058586, loss_ce: 0.025714
iteration 1725 : loss : 0.092993, loss_ce: 0.026405
iteration 1726 : loss : 0.055751, loss_ce: 0.019146
iteration 1727 : loss : 0.073063, loss_ce: 0.029182
iteration 1728 : loss : 0.052188, loss_ce: 0.021038
iteration 1729 : loss : 0.068666, loss_ce: 0.016041
iteration 1730 : loss : 0.059357, loss_ce: 0.029272
iteration 1731 : loss : 0.062146, loss_ce: 0.013204
iteration 1732 : loss : 0.060316, loss_ce: 0.025968
iteration 1733 : loss : 0.099637, loss_ce: 0.014745
iteration 1734 : loss : 0.066089, loss_ce: 0.023917
iteration 1735 : loss : 0.055683, loss_ce: 0.017000
iteration 1736 : loss : 0.071787, loss_ce: 0.032331
pred_sum 8868
gtsum tensor(8560, device='cuda:0')
iteration 1737 : loss : 0.060289, loss_ce: 0.018138
iteration 1738 : loss : 0.056946, loss_ce: 0.021133
iteration 1739 : loss : 0.059946, loss_ce: 0.016653
iteration 1740 : loss : 0.078160, loss_ce: 0.014347
iteration 1741 : loss : 0.083255, loss_ce: 0.023318
iteration 1742 : loss : 0.060238, loss_ce: 0.019269
iteration 1743 : loss : 0.052429, loss_ce: 0.021733
iteration 1744 : loss : 0.114931, loss_ce: 0.020809
iteration 1745 : loss : 0.055422, loss_ce: 0.023281
iteration 1746 : loss : 0.074167, loss_ce: 0.023918
iteration 1747 : loss : 0.064970, loss_ce: 0.018652
iteration 1748 : loss : 0.070706, loss_ce: 0.024923
iteration 1749 : loss : 0.067273, loss_ce: 0.026616
iteration 1750 : loss : 0.054402, loss_ce: 0.017658
iteration 1751 : loss : 0.076002, loss_ce: 0.017417
iteration 1752 : loss : 0.146394, loss_ce: 0.011076
iteration 1753 : loss : 0.067717, loss_ce: 0.024458
iteration 1754 : loss : 0.103666, loss_ce: 0.015152
iteration 1755 : loss : 0.057751, loss_ce: 0.020257
iteration 1756 : loss : 0.063303, loss_ce: 0.023119
iteration 1757 : loss : 0.076918, loss_ce: 0.016843
iteration 1758 : loss : 0.060114, loss_ce: 0.018981
iteration 1759 : loss : 0.068684, loss_ce: 0.014770
iteration 1760 : loss : 0.072041, loss_ce: 0.029600
iteration 1761 : loss : 0.098177, loss_ce: 0.011499
iteration 1762 : loss : 0.057259, loss_ce: 0.019542
iteration 1763 : loss : 0.057658, loss_ce: 0.016128
iteration 1764 : loss : 0.052804, loss_ce: 0.015337
iteration 1765 : loss : 0.063992, loss_ce: 0.026119
iteration 1766 : loss : 0.059214, loss_ce: 0.021713
iteration 1767 : loss : 0.222522, loss_ce: 0.030218
 10%|██▊                           | 19/200 [17:08<2:44:22, 54.49s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 1768 : loss : 0.055059, loss_ce: 0.016638
iteration 1769 : loss : 0.065608, loss_ce: 0.023395
iteration 1770 : loss : 0.100502, loss_ce: 0.018304
iteration 1771 : loss : 0.071041, loss_ce: 0.022270
iteration 1772 : loss : 0.098847, loss_ce: 0.020421
iteration 1773 : loss : 0.073368, loss_ce: 0.022068
iteration 1774 : loss : 0.090180, loss_ce: 0.018993
iteration 1775 : loss : 0.080553, loss_ce: 0.010388
iteration 1776 : loss : 0.077485, loss_ce: 0.019547
iteration 1777 : loss : 0.059151, loss_ce: 0.015540
iteration 1778 : loss : 0.077076, loss_ce: 0.024913
iteration 1779 : loss : 0.091577, loss_ce: 0.021225
iteration 1780 : loss : 0.074703, loss_ce: 0.028691
iteration 1781 : loss : 0.097613, loss_ce: 0.009847
iteration 1782 : loss : 0.060525, loss_ce: 0.021333
iteration 1783 : loss : 0.073252, loss_ce: 0.036728
iteration 1784 : loss : 0.085392, loss_ce: 0.015459
iteration 1785 : loss : 0.082182, loss_ce: 0.017343
iteration 1786 : loss : 0.121410, loss_ce: 0.010447
iteration 1787 : loss : 0.070490, loss_ce: 0.013708
iteration 1788 : loss : 0.101523, loss_ce: 0.011707
iteration 1789 : loss : 0.084584, loss_ce: 0.017955
iteration 1790 : loss : 0.071287, loss_ce: 0.008308
iteration 1791 : loss : 0.077913, loss_ce: 0.023383
iteration 1792 : loss : 0.083989, loss_ce: 0.026850
iteration 1793 : loss : 0.050092, loss_ce: 0.021479
iteration 1794 : loss : 0.065337, loss_ce: 0.028224
iteration 1795 : loss : 0.062186, loss_ce: 0.025515
iteration 1796 : loss : 0.049008, loss_ce: 0.018140
iteration 1797 : loss : 0.053171, loss_ce: 0.024127
iteration 1798 : loss : 0.059732, loss_ce: 0.024383
pred_sum 2661
gtsum tensor(2938, device='cuda:0')
iteration 1799 : loss : 0.071492, loss_ce: 0.020014
iteration 1800 : loss : 0.060267, loss_ce: 0.018724
iteration 1801 : loss : 0.067724, loss_ce: 0.021721
iteration 1802 : loss : 0.082543, loss_ce: 0.016161
iteration 1803 : loss : 0.059007, loss_ce: 0.018698
iteration 1804 : loss : 0.063092, loss_ce: 0.021377
iteration 1805 : loss : 0.066594, loss_ce: 0.016230
iteration 1806 : loss : 0.108914, loss_ce: 0.017469
iteration 1807 : loss : 0.060671, loss_ce: 0.026796
iteration 1808 : loss : 0.062318, loss_ce: 0.019123
iteration 1809 : loss : 0.078004, loss_ce: 0.019211
iteration 1810 : loss : 0.100221, loss_ce: 0.015754
iteration 1811 : loss : 0.056873, loss_ce: 0.013658
iteration 1812 : loss : 0.069270, loss_ce: 0.015111
iteration 1813 : loss : 0.067325, loss_ce: 0.017652
iteration 1814 : loss : 0.060812, loss_ce: 0.024172
iteration 1815 : loss : 0.071130, loss_ce: 0.018440
iteration 1816 : loss : 0.092144, loss_ce: 0.023701
iteration 1817 : loss : 0.108622, loss_ce: 0.040329
iteration 1818 : loss : 0.087973, loss_ce: 0.023054
iteration 1819 : loss : 0.073124, loss_ce: 0.026205
iteration 1820 : loss : 0.054877, loss_ce: 0.022061
iteration 1821 : loss : 0.101009, loss_ce: 0.009483
iteration 1822 : loss : 0.096814, loss_ce: 0.020891
iteration 1823 : loss : 0.076065, loss_ce: 0.023814
iteration 1824 : loss : 0.081348, loss_ce: 0.020569
iteration 1825 : loss : 0.082349, loss_ce: 0.019870
iteration 1826 : loss : 0.072543, loss_ce: 0.031515
iteration 1827 : loss : 0.113192, loss_ce: 0.014777
iteration 1828 : loss : 0.072833, loss_ce: 0.024616
iteration 1829 : loss : 0.078982, loss_ce: 0.034693
pred_sum 50746
gtsum tensor(45576, device='cuda:0')
iteration 1830 : loss : 0.063644, loss_ce: 0.026560
iteration 1831 : loss : 0.062430, loss_ce: 0.017763
iteration 1832 : loss : 0.071141, loss_ce: 0.027472
iteration 1833 : loss : 0.072409, loss_ce: 0.030063
iteration 1834 : loss : 0.055487, loss_ce: 0.019196
iteration 1835 : loss : 0.120314, loss_ce: 0.021096
iteration 1836 : loss : 0.067379, loss_ce: 0.017993
iteration 1837 : loss : 0.065619, loss_ce: 0.017563
iteration 1838 : loss : 0.056013, loss_ce: 0.016992
iteration 1839 : loss : 0.065473, loss_ce: 0.016263
iteration 1840 : loss : 0.071935, loss_ce: 0.028227
iteration 1841 : loss : 0.080657, loss_ce: 0.019658
iteration 1842 : loss : 0.050914, loss_ce: 0.020103
iteration 1843 : loss : 0.107505, loss_ce: 0.010881
iteration 1844 : loss : 0.106956, loss_ce: 0.013742
iteration 1845 : loss : 0.069104, loss_ce: 0.028746
iteration 1846 : loss : 0.063095, loss_ce: 0.024398
iteration 1847 : loss : 0.071783, loss_ce: 0.017757
iteration 1848 : loss : 0.064880, loss_ce: 0.024821
iteration 1849 : loss : 0.068782, loss_ce: 0.028954
iteration 1850 : loss : 0.062975, loss_ce: 0.020852
iteration 1851 : loss : 0.077600, loss_ce: 0.013816
iteration 1852 : loss : 0.076163, loss_ce: 0.021225
iteration 1853 : loss : 0.122987, loss_ce: 0.026846
iteration 1854 : loss : 0.077984, loss_ce: 0.022769
iteration 1855 : loss : 0.062806, loss_ce: 0.023499
iteration 1856 : loss : 0.048311, loss_ce: 0.020861
iteration 1857 : loss : 0.058852, loss_ce: 0.025446
iteration 1858 : loss : 0.054551, loss_ce: 0.022507
iteration 1859 : loss : 0.065464, loss_ce: 0.023740
iteration 1860 : loss : 0.127448, loss_ce: 0.019438
 10%|███                           | 20/200 [18:02<2:43:30, 54.50s/it]pred_sum 4661
gtsum tensor(4951, device='cuda:0')
iteration 1861 : loss : 0.056120, loss_ce: 0.018929
iteration 1862 : loss : 0.062956, loss_ce: 0.016751
iteration 1863 : loss : 0.081730, loss_ce: 0.015881
iteration 1864 : loss : 0.065924, loss_ce: 0.029074
iteration 1865 : loss : 0.069637, loss_ce: 0.018251
iteration 1866 : loss : 0.053175, loss_ce: 0.016780
iteration 1867 : loss : 0.055084, loss_ce: 0.015601
iteration 1868 : loss : 0.056108, loss_ce: 0.017683
iteration 1869 : loss : 0.111631, loss_ce: 0.018039
iteration 1870 : loss : 0.050603, loss_ce: 0.026391
iteration 1871 : loss : 0.066823, loss_ce: 0.018863
iteration 1872 : loss : 0.068204, loss_ce: 0.024847
iteration 1873 : loss : 0.126546, loss_ce: 0.019211
iteration 1874 : loss : 0.072791, loss_ce: 0.023137
iteration 1875 : loss : 0.061588, loss_ce: 0.016898
iteration 1876 : loss : 0.082927, loss_ce: 0.022817
iteration 1877 : loss : 0.064859, loss_ce: 0.022561
iteration 1878 : loss : 0.090303, loss_ce: 0.022842
iteration 1879 : loss : 0.065321, loss_ce: 0.017622
iteration 1880 : loss : 0.109526, loss_ce: 0.032170
iteration 1881 : loss : 0.060645, loss_ce: 0.022729
iteration 1882 : loss : 0.117305, loss_ce: 0.013438
iteration 1883 : loss : 0.060275, loss_ce: 0.018727
iteration 1884 : loss : 0.055196, loss_ce: 0.020386
iteration 1885 : loss : 0.073093, loss_ce: 0.021189
iteration 1886 : loss : 0.052667, loss_ce: 0.016218
iteration 1887 : loss : 0.068241, loss_ce: 0.020060
iteration 1888 : loss : 0.077594, loss_ce: 0.020189
iteration 1889 : loss : 0.076421, loss_ce: 0.018750
iteration 1890 : loss : 0.090984, loss_ce: 0.021653
iteration 1891 : loss : 0.057740, loss_ce: 0.021857
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 1892 : loss : 0.058812, loss_ce: 0.020407
iteration 1893 : loss : 0.055609, loss_ce: 0.019972
iteration 1894 : loss : 0.068596, loss_ce: 0.020326
iteration 1895 : loss : 0.060620, loss_ce: 0.021220
iteration 1896 : loss : 0.066309, loss_ce: 0.022751
iteration 1897 : loss : 0.066101, loss_ce: 0.022331
iteration 1898 : loss : 0.059052, loss_ce: 0.023048
iteration 1899 : loss : 0.095270, loss_ce: 0.020959
iteration 1900 : loss : 0.094776, loss_ce: 0.019529
iteration 1901 : loss : 0.128527, loss_ce: 0.023733
iteration 1902 : loss : 0.058146, loss_ce: 0.025060
iteration 1903 : loss : 0.085248, loss_ce: 0.016088
iteration 1904 : loss : 0.059374, loss_ce: 0.023512
iteration 1905 : loss : 0.077516, loss_ce: 0.019826
iteration 1906 : loss : 0.116560, loss_ce: 0.017044
iteration 1907 : loss : 0.057780, loss_ce: 0.020961
iteration 1908 : loss : 0.086792, loss_ce: 0.025000
iteration 1909 : loss : 0.081203, loss_ce: 0.017582
iteration 1910 : loss : 0.070335, loss_ce: 0.026063
iteration 1911 : loss : 0.116268, loss_ce: 0.018069
iteration 1912 : loss : 0.075496, loss_ce: 0.016435
iteration 1913 : loss : 0.053778, loss_ce: 0.017093
iteration 1914 : loss : 0.065563, loss_ce: 0.019394
iteration 1915 : loss : 0.079471, loss_ce: 0.022939
iteration 1916 : loss : 0.069428, loss_ce: 0.018480
iteration 1917 : loss : 0.066002, loss_ce: 0.016502
iteration 1918 : loss : 0.078191, loss_ce: 0.028065
iteration 1919 : loss : 0.059663, loss_ce: 0.016356
iteration 1920 : loss : 0.101076, loss_ce: 0.026424
iteration 1921 : loss : 0.102188, loss_ce: 0.009533
iteration 1922 : loss : 0.088754, loss_ce: 0.027130
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 1923 : loss : 0.072298, loss_ce: 0.020052
iteration 1924 : loss : 0.117912, loss_ce: 0.013471
iteration 1925 : loss : 0.065609, loss_ce: 0.026058
iteration 1926 : loss : 0.077376, loss_ce: 0.019380
iteration 1927 : loss : 0.089279, loss_ce: 0.023548
iteration 1928 : loss : 0.084895, loss_ce: 0.019176
iteration 1929 : loss : 0.070877, loss_ce: 0.020991
iteration 1930 : loss : 0.081640, loss_ce: 0.017558
iteration 1931 : loss : 0.111866, loss_ce: 0.015201
iteration 1932 : loss : 0.099511, loss_ce: 0.019737
iteration 1933 : loss : 0.095762, loss_ce: 0.031171
iteration 1934 : loss : 0.061880, loss_ce: 0.028815
iteration 1935 : loss : 0.068631, loss_ce: 0.024915
iteration 1936 : loss : 0.047920, loss_ce: 0.013093
iteration 1937 : loss : 0.095572, loss_ce: 0.022687
iteration 1938 : loss : 0.071499, loss_ce: 0.031284
iteration 1939 : loss : 0.059977, loss_ce: 0.022719
iteration 1940 : loss : 0.085329, loss_ce: 0.031964
iteration 1941 : loss : 0.087538, loss_ce: 0.025685
iteration 1942 : loss : 0.061483, loss_ce: 0.016073
iteration 1943 : loss : 0.071827, loss_ce: 0.028150
iteration 1944 : loss : 0.070248, loss_ce: 0.025165
iteration 1945 : loss : 0.061325, loss_ce: 0.024941
iteration 1946 : loss : 0.063742, loss_ce: 0.022865
iteration 1947 : loss : 0.056927, loss_ce: 0.020045
iteration 1948 : loss : 0.075824, loss_ce: 0.029218
iteration 1949 : loss : 0.097477, loss_ce: 0.022266
iteration 1950 : loss : 0.061549, loss_ce: 0.020720
iteration 1951 : loss : 0.058344, loss_ce: 0.023426
iteration 1952 : loss : 0.052469, loss_ce: 0.020207
iteration 1953 : loss : 0.287164, loss_ce: 0.033675
 10%|███▏                          | 21/200 [18:57<2:42:37, 54.51s/it]pred_sum 4901
gtsum tensor(5785, device='cuda:0')
iteration 1954 : loss : 0.058063, loss_ce: 0.020509
iteration 1955 : loss : 0.062635, loss_ce: 0.022352
iteration 1956 : loss : 0.075749, loss_ce: 0.017471
iteration 1957 : loss : 0.102186, loss_ce: 0.015338
iteration 1958 : loss : 0.076000, loss_ce: 0.032303
iteration 1959 : loss : 0.073194, loss_ce: 0.029274
iteration 1960 : loss : 0.050788, loss_ce: 0.011046
iteration 1961 : loss : 0.057453, loss_ce: 0.021131
iteration 1962 : loss : 0.062176, loss_ce: 0.017573
iteration 1963 : loss : 0.062738, loss_ce: 0.028630
iteration 1964 : loss : 0.053237, loss_ce: 0.026180
iteration 1965 : loss : 0.056657, loss_ce: 0.021602
iteration 1966 : loss : 0.053761, loss_ce: 0.015664
iteration 1967 : loss : 0.062926, loss_ce: 0.018589
iteration 1968 : loss : 0.063868, loss_ce: 0.029221
iteration 1969 : loss : 0.072902, loss_ce: 0.026943
iteration 1970 : loss : 0.065505, loss_ce: 0.020510
iteration 1971 : loss : 0.076200, loss_ce: 0.020471
iteration 1972 : loss : 0.049063, loss_ce: 0.016830
iteration 1973 : loss : 0.055197, loss_ce: 0.018041
iteration 1974 : loss : 0.095847, loss_ce: 0.012490
iteration 1975 : loss : 0.064201, loss_ce: 0.024269
iteration 1976 : loss : 0.044034, loss_ce: 0.010702
iteration 1977 : loss : 0.067364, loss_ce: 0.018590
iteration 1978 : loss : 0.098350, loss_ce: 0.011930
iteration 1979 : loss : 0.054744, loss_ce: 0.013820
iteration 1980 : loss : 0.046154, loss_ce: 0.014554
iteration 1981 : loss : 0.064351, loss_ce: 0.020006
iteration 1982 : loss : 0.047973, loss_ce: 0.018301
iteration 1983 : loss : 0.070906, loss_ce: 0.023702
iteration 1984 : loss : 0.042754, loss_ce: 0.013722
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 1985 : loss : 0.063812, loss_ce: 0.017260
iteration 1986 : loss : 0.092454, loss_ce: 0.014980
iteration 1987 : loss : 0.052664, loss_ce: 0.020547
iteration 1988 : loss : 0.055893, loss_ce: 0.014279
iteration 1989 : loss : 0.055292, loss_ce: 0.018572
iteration 1990 : loss : 0.058115, loss_ce: 0.018392
iteration 1991 : loss : 0.051426, loss_ce: 0.015870
iteration 1992 : loss : 0.109367, loss_ce: 0.009521
iteration 1993 : loss : 0.058295, loss_ce: 0.028296
iteration 1994 : loss : 0.055882, loss_ce: 0.014246
iteration 1995 : loss : 0.068371, loss_ce: 0.017872
iteration 1996 : loss : 0.078585, loss_ce: 0.021281
iteration 1997 : loss : 0.094286, loss_ce: 0.018275
iteration 1998 : loss : 0.107291, loss_ce: 0.019190
iteration 1999 : loss : 0.066091, loss_ce: 0.014881
iteration 2000 : loss : 0.055658, loss_ce: 0.016175
iteration 2001 : loss : 0.068780, loss_ce: 0.022121
iteration 2002 : loss : 0.058916, loss_ce: 0.014941
iteration 2003 : loss : 0.053029, loss_ce: 0.018708
iteration 2004 : loss : 0.066660, loss_ce: 0.024131
iteration 2005 : loss : 0.075537, loss_ce: 0.016897
iteration 2006 : loss : 0.065923, loss_ce: 0.015209
iteration 2007 : loss : 0.065975, loss_ce: 0.027307
iteration 2008 : loss : 0.068862, loss_ce: 0.023048
iteration 2009 : loss : 0.057552, loss_ce: 0.018490
iteration 2010 : loss : 0.103599, loss_ce: 0.020829
iteration 2011 : loss : 0.055794, loss_ce: 0.017103
iteration 2012 : loss : 0.081555, loss_ce: 0.031428
iteration 2013 : loss : 0.065191, loss_ce: 0.026652
iteration 2014 : loss : 0.057493, loss_ce: 0.022202
iteration 2015 : loss : 0.040956, loss_ce: 0.015916
pred_sum 69
gtsum tensor(84, device='cuda:0')
iteration 2016 : loss : 0.083360, loss_ce: 0.020858
iteration 2017 : loss : 0.056436, loss_ce: 0.015762
iteration 2018 : loss : 0.102499, loss_ce: 0.022028
iteration 2019 : loss : 0.070427, loss_ce: 0.014202
iteration 2020 : loss : 0.062161, loss_ce: 0.020500
iteration 2021 : loss : 0.052435, loss_ce: 0.014541
iteration 2022 : loss : 0.061731, loss_ce: 0.021857
iteration 2023 : loss : 0.076284, loss_ce: 0.019221
iteration 2024 : loss : 0.058769, loss_ce: 0.017013
iteration 2025 : loss : 0.053097, loss_ce: 0.015711
iteration 2026 : loss : 0.062096, loss_ce: 0.021500
iteration 2027 : loss : 0.041957, loss_ce: 0.013270
iteration 2028 : loss : 0.061494, loss_ce: 0.015646
iteration 2029 : loss : 0.056906, loss_ce: 0.027646
iteration 2030 : loss : 0.043245, loss_ce: 0.014423
iteration 2031 : loss : 0.083786, loss_ce: 0.012463
iteration 2032 : loss : 0.060499, loss_ce: 0.014100
iteration 2033 : loss : 0.102439, loss_ce: 0.019650
iteration 2034 : loss : 0.098115, loss_ce: 0.016136
iteration 2035 : loss : 0.054186, loss_ce: 0.020906
iteration 2036 : loss : 0.073275, loss_ce: 0.030723
iteration 2037 : loss : 0.052120, loss_ce: 0.015011
iteration 2038 : loss : 0.067729, loss_ce: 0.022041
iteration 2039 : loss : 0.047882, loss_ce: 0.017820
iteration 2040 : loss : 0.071218, loss_ce: 0.018750
iteration 2041 : loss : 0.069081, loss_ce: 0.008806
iteration 2042 : loss : 0.061517, loss_ce: 0.020836
iteration 2043 : loss : 0.053261, loss_ce: 0.015716
iteration 2044 : loss : 0.048627, loss_ce: 0.022231
iteration 2045 : loss : 0.085580, loss_ce: 0.006255
iteration 2046 : loss : 0.117092, loss_ce: 0.019341
 11%|███▎                          | 22/200 [19:51<2:41:41, 54.50s/it]pred_sum 19914
gtsum tensor(20729, device='cuda:0')
iteration 2047 : loss : 0.103179, loss_ce: 0.018790
iteration 2048 : loss : 0.069336, loss_ce: 0.021222
iteration 2049 : loss : 0.047599, loss_ce: 0.014359
iteration 2050 : loss : 0.052501, loss_ce: 0.016379
iteration 2051 : loss : 0.070477, loss_ce: 0.037050
iteration 2052 : loss : 0.050237, loss_ce: 0.017847
iteration 2053 : loss : 0.083892, loss_ce: 0.014633
iteration 2054 : loss : 0.047066, loss_ce: 0.015647
iteration 2055 : loss : 0.051525, loss_ce: 0.014087
iteration 2056 : loss : 0.045851, loss_ce: 0.012315
iteration 2057 : loss : 0.088353, loss_ce: 0.021585
iteration 2058 : loss : 0.059967, loss_ce: 0.020007
iteration 2059 : loss : 0.080191, loss_ce: 0.021328
iteration 2060 : loss : 0.073843, loss_ce: 0.024530
iteration 2061 : loss : 0.075002, loss_ce: 0.032715
iteration 2062 : loss : 0.089739, loss_ce: 0.033981
iteration 2063 : loss : 0.066007, loss_ce: 0.017242
iteration 2064 : loss : 0.145347, loss_ce: 0.032156
iteration 2065 : loss : 0.064614, loss_ce: 0.028890
iteration 2066 : loss : 0.055452, loss_ce: 0.021202
iteration 2067 : loss : 0.080825, loss_ce: 0.015469
iteration 2068 : loss : 0.062303, loss_ce: 0.016630
iteration 2069 : loss : 0.073201, loss_ce: 0.027963
iteration 2070 : loss : 0.080439, loss_ce: 0.020137
iteration 2071 : loss : 0.064306, loss_ce: 0.020159
iteration 2072 : loss : 0.105857, loss_ce: 0.023693
iteration 2073 : loss : 0.092308, loss_ce: 0.045161
iteration 2074 : loss : 0.065686, loss_ce: 0.019885
iteration 2075 : loss : 0.068141, loss_ce: 0.023271
iteration 2076 : loss : 0.078547, loss_ce: 0.038596
iteration 2077 : loss : 0.062660, loss_ce: 0.027363
pred_sum 17942
gtsum tensor(20852, device='cuda:0')
iteration 2078 : loss : 0.079414, loss_ce: 0.027962
iteration 2079 : loss : 0.062692, loss_ce: 0.017607
iteration 2080 : loss : 0.064462, loss_ce: 0.023725
iteration 2081 : loss : 0.060065, loss_ce: 0.022158
iteration 2082 : loss : 0.097005, loss_ce: 0.012207
iteration 2083 : loss : 0.086774, loss_ce: 0.023530
iteration 2084 : loss : 0.101674, loss_ce: 0.015153
iteration 2085 : loss : 0.057959, loss_ce: 0.018417
iteration 2086 : loss : 0.070000, loss_ce: 0.013507
iteration 2087 : loss : 0.064403, loss_ce: 0.028160
iteration 2088 : loss : 0.069018, loss_ce: 0.028803
iteration 2089 : loss : 0.060078, loss_ce: 0.025956
iteration 2090 : loss : 0.106657, loss_ce: 0.019564
iteration 2091 : loss : 0.065553, loss_ce: 0.009718
iteration 2092 : loss : 0.063042, loss_ce: 0.019300
iteration 2093 : loss : 0.053998, loss_ce: 0.017436
iteration 2094 : loss : 0.079724, loss_ce: 0.017167
iteration 2095 : loss : 0.061796, loss_ce: 0.022336
iteration 2096 : loss : 0.113276, loss_ce: 0.015653
iteration 2097 : loss : 0.072018, loss_ce: 0.014579
iteration 2098 : loss : 0.058327, loss_ce: 0.018472
iteration 2099 : loss : 0.057877, loss_ce: 0.014642
iteration 2100 : loss : 0.059229, loss_ce: 0.022138
iteration 2101 : loss : 0.054356, loss_ce: 0.012203
iteration 2102 : loss : 0.057794, loss_ce: 0.017468
iteration 2103 : loss : 0.092961, loss_ce: 0.012128
iteration 2104 : loss : 0.051198, loss_ce: 0.018130
iteration 2105 : loss : 0.049035, loss_ce: 0.016826
iteration 2106 : loss : 0.067414, loss_ce: 0.025680
iteration 2107 : loss : 0.058072, loss_ce: 0.017083
iteration 2108 : loss : 0.067146, loss_ce: 0.022631
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 2109 : loss : 0.083645, loss_ce: 0.019714
iteration 2110 : loss : 0.066944, loss_ce: 0.026023
iteration 2111 : loss : 0.055549, loss_ce: 0.010901
iteration 2112 : loss : 0.115333, loss_ce: 0.016658
iteration 2113 : loss : 0.056587, loss_ce: 0.024509
iteration 2114 : loss : 0.070426, loss_ce: 0.020420
iteration 2115 : loss : 0.066463, loss_ce: 0.020205
iteration 2116 : loss : 0.056405, loss_ce: 0.012643
iteration 2117 : loss : 0.071461, loss_ce: 0.024189
iteration 2118 : loss : 0.146054, loss_ce: 0.009167
iteration 2119 : loss : 0.075337, loss_ce: 0.021766
iteration 2120 : loss : 0.063931, loss_ce: 0.016061
iteration 2121 : loss : 0.065377, loss_ce: 0.018505
iteration 2122 : loss : 0.071389, loss_ce: 0.018882
iteration 2123 : loss : 0.063448, loss_ce: 0.023480
iteration 2124 : loss : 0.066576, loss_ce: 0.017494
iteration 2125 : loss : 0.068826, loss_ce: 0.018304
iteration 2126 : loss : 0.065393, loss_ce: 0.020394
iteration 2127 : loss : 0.067935, loss_ce: 0.016148
iteration 2128 : loss : 0.061962, loss_ce: 0.012969
iteration 2129 : loss : 0.059034, loss_ce: 0.016403
iteration 2130 : loss : 0.050414, loss_ce: 0.020260
iteration 2131 : loss : 0.054820, loss_ce: 0.025678
iteration 2132 : loss : 0.076084, loss_ce: 0.022957
iteration 2133 : loss : 0.072085, loss_ce: 0.019742
iteration 2134 : loss : 0.061494, loss_ce: 0.019311
iteration 2135 : loss : 0.075874, loss_ce: 0.013817
iteration 2136 : loss : 0.057820, loss_ce: 0.016101
iteration 2137 : loss : 0.048873, loss_ce: 0.018749
iteration 2138 : loss : 0.064721, loss_ce: 0.018451
iteration 2139 : loss : 0.256930, loss_ce: 0.045648
 12%|███▍                          | 23/200 [20:46<2:40:41, 54.47s/it]pred_sum 114
gtsum tensor(105, device='cuda:0')
iteration 2140 : loss : 0.063831, loss_ce: 0.020500
iteration 2141 : loss : 0.075733, loss_ce: 0.027627
iteration 2142 : loss : 0.062984, loss_ce: 0.018535
iteration 2143 : loss : 0.061301, loss_ce: 0.026810
iteration 2144 : loss : 0.102303, loss_ce: 0.018374
iteration 2145 : loss : 0.062539, loss_ce: 0.024031
iteration 2146 : loss : 0.071035, loss_ce: 0.022308
iteration 2147 : loss : 0.054918, loss_ce: 0.021485
iteration 2148 : loss : 0.103086, loss_ce: 0.013437
iteration 2149 : loss : 0.056943, loss_ce: 0.023617
iteration 2150 : loss : 0.102344, loss_ce: 0.012901
iteration 2151 : loss : 0.049770, loss_ce: 0.015334
iteration 2152 : loss : 0.061367, loss_ce: 0.015486
iteration 2153 : loss : 0.075285, loss_ce: 0.024801
iteration 2154 : loss : 0.066774, loss_ce: 0.019837
iteration 2155 : loss : 0.080463, loss_ce: 0.038498
iteration 2156 : loss : 0.055505, loss_ce: 0.017310
iteration 2157 : loss : 0.048408, loss_ce: 0.018401
iteration 2158 : loss : 0.069676, loss_ce: 0.017943
iteration 2159 : loss : 0.061972, loss_ce: 0.024638
iteration 2160 : loss : 0.065068, loss_ce: 0.023039
iteration 2161 : loss : 0.046879, loss_ce: 0.018421
iteration 2162 : loss : 0.062287, loss_ce: 0.018634
iteration 2163 : loss : 0.056163, loss_ce: 0.015403
iteration 2164 : loss : 0.062189, loss_ce: 0.015041
iteration 2165 : loss : 0.110578, loss_ce: 0.013097
iteration 2166 : loss : 0.055379, loss_ce: 0.022976
iteration 2167 : loss : 0.061240, loss_ce: 0.029066
iteration 2168 : loss : 0.090613, loss_ce: 0.011455
iteration 2169 : loss : 0.050938, loss_ce: 0.014034
iteration 2170 : loss : 0.045511, loss_ce: 0.013339
pred_sum 12469
gtsum tensor(11798, device='cuda:0')
iteration 2171 : loss : 0.056870, loss_ce: 0.013811
iteration 2172 : loss : 0.099421, loss_ce: 0.017340
iteration 2173 : loss : 0.071345, loss_ce: 0.009512
iteration 2174 : loss : 0.071619, loss_ce: 0.032290
iteration 2175 : loss : 0.059294, loss_ce: 0.014807
iteration 2176 : loss : 0.070034, loss_ce: 0.031186
iteration 2177 : loss : 0.048677, loss_ce: 0.021428
iteration 2178 : loss : 0.072977, loss_ce: 0.020709
iteration 2179 : loss : 0.073675, loss_ce: 0.018716
iteration 2180 : loss : 0.049013, loss_ce: 0.014080
iteration 2181 : loss : 0.105838, loss_ce: 0.017775
iteration 2182 : loss : 0.053898, loss_ce: 0.019597
iteration 2183 : loss : 0.058301, loss_ce: 0.017984
iteration 2184 : loss : 0.057404, loss_ce: 0.017752
iteration 2185 : loss : 0.067407, loss_ce: 0.014776
iteration 2186 : loss : 0.083303, loss_ce: 0.014165
iteration 2187 : loss : 0.059718, loss_ce: 0.020439
iteration 2188 : loss : 0.059262, loss_ce: 0.016312
iteration 2189 : loss : 0.067379, loss_ce: 0.017510
iteration 2190 : loss : 0.102182, loss_ce: 0.017439
iteration 2191 : loss : 0.059611, loss_ce: 0.022581
iteration 2192 : loss : 0.059488, loss_ce: 0.016860
iteration 2193 : loss : 0.067421, loss_ce: 0.023393
iteration 2194 : loss : 0.059236, loss_ce: 0.012329
iteration 2195 : loss : 0.049826, loss_ce: 0.013109
iteration 2196 : loss : 0.059670, loss_ce: 0.016821
iteration 2197 : loss : 0.051001, loss_ce: 0.013233
iteration 2198 : loss : 0.103423, loss_ce: 0.022656
iteration 2199 : loss : 0.066609, loss_ce: 0.021067
iteration 2200 : loss : 0.107430, loss_ce: 0.014603
iteration 2201 : loss : 0.055331, loss_ce: 0.019587
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 2202 : loss : 0.056111, loss_ce: 0.019186
iteration 2203 : loss : 0.044461, loss_ce: 0.015615
iteration 2204 : loss : 0.076557, loss_ce: 0.018538
iteration 2205 : loss : 0.066364, loss_ce: 0.022067
iteration 2206 : loss : 0.050050, loss_ce: 0.020032
iteration 2207 : loss : 0.046034, loss_ce: 0.018485
iteration 2208 : loss : 0.062258, loss_ce: 0.011206
iteration 2209 : loss : 0.100402, loss_ce: 0.012918
iteration 2210 : loss : 0.063718, loss_ce: 0.026254
iteration 2211 : loss : 0.093683, loss_ce: 0.023454
iteration 2212 : loss : 0.049449, loss_ce: 0.011331
iteration 2213 : loss : 0.044894, loss_ce: 0.020222
iteration 2214 : loss : 0.074666, loss_ce: 0.014327
iteration 2215 : loss : 0.065587, loss_ce: 0.022747
iteration 2216 : loss : 0.059241, loss_ce: 0.012701
iteration 2217 : loss : 0.061455, loss_ce: 0.024867
iteration 2218 : loss : 0.058029, loss_ce: 0.028405
iteration 2219 : loss : 0.076434, loss_ce: 0.023789
iteration 2220 : loss : 0.056727, loss_ce: 0.020265
iteration 2221 : loss : 0.052953, loss_ce: 0.017621
iteration 2222 : loss : 0.068356, loss_ce: 0.023167
iteration 2223 : loss : 0.099969, loss_ce: 0.011119
iteration 2224 : loss : 0.051025, loss_ce: 0.023310
iteration 2225 : loss : 0.046163, loss_ce: 0.012471
iteration 2226 : loss : 0.114696, loss_ce: 0.010759
iteration 2227 : loss : 0.039711, loss_ce: 0.016460
iteration 2228 : loss : 0.113508, loss_ce: 0.019417
iteration 2229 : loss : 0.054161, loss_ce: 0.022396
iteration 2230 : loss : 0.062185, loss_ce: 0.023004
iteration 2231 : loss : 0.085071, loss_ce: 0.017654
iteration 2232 : loss : 0.214701, loss_ce: 0.019153
 12%|███▌                          | 24/200 [21:40<2:39:46, 54.47s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 2233 : loss : 0.128979, loss_ce: 0.015382
iteration 2234 : loss : 0.044480, loss_ce: 0.019544
iteration 2235 : loss : 0.061977, loss_ce: 0.018353
iteration 2236 : loss : 0.063442, loss_ce: 0.019866
iteration 2237 : loss : 0.105569, loss_ce: 0.009893
iteration 2238 : loss : 0.065088, loss_ce: 0.012971
iteration 2239 : loss : 0.055348, loss_ce: 0.010356
iteration 2240 : loss : 0.060749, loss_ce: 0.031590
iteration 2241 : loss : 0.057243, loss_ce: 0.017990
iteration 2242 : loss : 0.066563, loss_ce: 0.019642
iteration 2243 : loss : 0.075194, loss_ce: 0.024172
iteration 2244 : loss : 0.055538, loss_ce: 0.014537
iteration 2245 : loss : 0.073712, loss_ce: 0.024386
iteration 2246 : loss : 0.058507, loss_ce: 0.022358
iteration 2247 : loss : 0.107153, loss_ce: 0.016408
iteration 2248 : loss : 0.058533, loss_ce: 0.021182
iteration 2249 : loss : 0.045992, loss_ce: 0.018492
iteration 2250 : loss : 0.051173, loss_ce: 0.019918
iteration 2251 : loss : 0.050923, loss_ce: 0.017894
iteration 2252 : loss : 0.053732, loss_ce: 0.015217
iteration 2253 : loss : 0.078774, loss_ce: 0.020241
iteration 2254 : loss : 0.041484, loss_ce: 0.014045
iteration 2255 : loss : 0.097028, loss_ce: 0.012496
iteration 2256 : loss : 0.059327, loss_ce: 0.020853
iteration 2257 : loss : 0.043130, loss_ce: 0.016159
iteration 2258 : loss : 0.060712, loss_ce: 0.029482
iteration 2259 : loss : 0.059876, loss_ce: 0.022722
iteration 2260 : loss : 0.062246, loss_ce: 0.026122
iteration 2261 : loss : 0.119649, loss_ce: 0.017342
iteration 2262 : loss : 0.051924, loss_ce: 0.015079
iteration 2263 : loss : 0.050785, loss_ce: 0.026761
pred_sum 30671
gtsum tensor(31751, device='cuda:0')
iteration 2264 : loss : 0.054415, loss_ce: 0.021065
iteration 2265 : loss : 0.060000, loss_ce: 0.022412
iteration 2266 : loss : 0.102963, loss_ce: 0.007317
iteration 2267 : loss : 0.071526, loss_ce: 0.015951
iteration 2268 : loss : 0.072882, loss_ce: 0.031832
iteration 2269 : loss : 0.060694, loss_ce: 0.018013
iteration 2270 : loss : 0.086493, loss_ce: 0.021838
iteration 2271 : loss : 0.074473, loss_ce: 0.028562
iteration 2272 : loss : 0.058641, loss_ce: 0.014219
iteration 2273 : loss : 0.084913, loss_ce: 0.028953
iteration 2274 : loss : 0.069526, loss_ce: 0.026900
iteration 2275 : loss : 0.063539, loss_ce: 0.018679
iteration 2276 : loss : 0.080066, loss_ce: 0.016431
iteration 2277 : loss : 0.067561, loss_ce: 0.021165
iteration 2278 : loss : 0.054249, loss_ce: 0.013385
iteration 2279 : loss : 0.051844, loss_ce: 0.014856
iteration 2280 : loss : 0.057892, loss_ce: 0.023456
iteration 2281 : loss : 0.075690, loss_ce: 0.015229
iteration 2282 : loss : 0.059753, loss_ce: 0.019555
iteration 2283 : loss : 0.062337, loss_ce: 0.021357
iteration 2284 : loss : 0.103509, loss_ce: 0.017443
iteration 2285 : loss : 0.064758, loss_ce: 0.026187
iteration 2286 : loss : 0.059062, loss_ce: 0.017014
iteration 2287 : loss : 0.071195, loss_ce: 0.021109
iteration 2288 : loss : 0.075387, loss_ce: 0.018880
iteration 2289 : loss : 0.068970, loss_ce: 0.015707
iteration 2290 : loss : 0.056909, loss_ce: 0.019694
iteration 2291 : loss : 0.071386, loss_ce: 0.026507
iteration 2292 : loss : 0.056402, loss_ce: 0.017367
iteration 2293 : loss : 0.054959, loss_ce: 0.019110
iteration 2294 : loss : 0.074807, loss_ce: 0.014266
pred_sum 37118
gtsum tensor(37317, device='cuda:0')
iteration 2295 : loss : 0.071132, loss_ce: 0.026073
iteration 2296 : loss : 0.047545, loss_ce: 0.010344
iteration 2297 : loss : 0.091202, loss_ce: 0.013688
iteration 2298 : loss : 0.054315, loss_ce: 0.022368
iteration 2299 : loss : 0.052584, loss_ce: 0.015063
iteration 2300 : loss : 0.063249, loss_ce: 0.028370
iteration 2301 : loss : 0.064955, loss_ce: 0.023386
iteration 2302 : loss : 0.043928, loss_ce: 0.015411
iteration 2303 : loss : 0.051482, loss_ce: 0.018315
iteration 2304 : loss : 0.104818, loss_ce: 0.017115
iteration 2305 : loss : 0.058061, loss_ce: 0.019766
iteration 2306 : loss : 0.053204, loss_ce: 0.016705
iteration 2307 : loss : 0.045684, loss_ce: 0.012244
iteration 2308 : loss : 0.092385, loss_ce: 0.014330
iteration 2309 : loss : 0.058196, loss_ce: 0.010463
iteration 2310 : loss : 0.052625, loss_ce: 0.013685
iteration 2311 : loss : 0.114167, loss_ce: 0.010830
iteration 2312 : loss : 0.077163, loss_ce: 0.019427
iteration 2313 : loss : 0.052066, loss_ce: 0.012860
iteration 2314 : loss : 0.064342, loss_ce: 0.017511
iteration 2315 : loss : 0.055941, loss_ce: 0.022765
iteration 2316 : loss : 0.071962, loss_ce: 0.016758
iteration 2317 : loss : 0.064978, loss_ce: 0.015529
iteration 2318 : loss : 0.049168, loss_ce: 0.014420
iteration 2319 : loss : 0.054757, loss_ce: 0.021943
iteration 2320 : loss : 0.072362, loss_ce: 0.027771
iteration 2321 : loss : 0.065923, loss_ce: 0.017861
iteration 2322 : loss : 0.055579, loss_ce: 0.020418
iteration 2323 : loss : 0.051686, loss_ce: 0.019460
iteration 2324 : loss : 0.064395, loss_ce: 0.014749
iteration 2325 : loss : 0.121454, loss_ce: 0.038797
 12%|███▊                          | 25/200 [22:35<2:38:55, 54.49s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 2326 : loss : 0.096768, loss_ce: 0.014795
iteration 2327 : loss : 0.054864, loss_ce: 0.012109
iteration 2328 : loss : 0.053877, loss_ce: 0.020389
iteration 2329 : loss : 0.103992, loss_ce: 0.018675
iteration 2330 : loss : 0.055888, loss_ce: 0.009742
iteration 2331 : loss : 0.048214, loss_ce: 0.019596
iteration 2332 : loss : 0.169063, loss_ce: 0.012605
iteration 2333 : loss : 0.040296, loss_ce: 0.017328
iteration 2334 : loss : 0.063831, loss_ce: 0.017158
iteration 2335 : loss : 0.063746, loss_ce: 0.028638
iteration 2336 : loss : 0.065524, loss_ce: 0.015581
iteration 2337 : loss : 0.059956, loss_ce: 0.018879
iteration 2338 : loss : 0.087124, loss_ce: 0.018684
iteration 2339 : loss : 0.045931, loss_ce: 0.016663
iteration 2340 : loss : 0.067319, loss_ce: 0.016591
iteration 2341 : loss : 0.058825, loss_ce: 0.020402
iteration 2342 : loss : 0.055619, loss_ce: 0.016058
iteration 2343 : loss : 0.061396, loss_ce: 0.016767
iteration 2344 : loss : 0.077527, loss_ce: 0.015055
iteration 2345 : loss : 0.067766, loss_ce: 0.017512
iteration 2346 : loss : 0.052335, loss_ce: 0.010205
iteration 2347 : loss : 0.052267, loss_ce: 0.018175
iteration 2348 : loss : 0.099721, loss_ce: 0.019022
iteration 2349 : loss : 0.089088, loss_ce: 0.029655
iteration 2350 : loss : 0.056746, loss_ce: 0.016131
iteration 2351 : loss : 0.070921, loss_ce: 0.008897
iteration 2352 : loss : 0.084392, loss_ce: 0.016964
iteration 2353 : loss : 0.055417, loss_ce: 0.019956
iteration 2354 : loss : 0.054232, loss_ce: 0.012778
iteration 2355 : loss : 0.069995, loss_ce: 0.019601
iteration 2356 : loss : 0.053243, loss_ce: 0.024288
pred_sum 420
gtsum tensor(370, device='cuda:0')
iteration 2357 : loss : 0.064142, loss_ce: 0.026752
iteration 2358 : loss : 0.055974, loss_ce: 0.016376
iteration 2359 : loss : 0.061138, loss_ce: 0.013486
iteration 2360 : loss : 0.066348, loss_ce: 0.029715
iteration 2361 : loss : 0.060653, loss_ce: 0.027152
iteration 2362 : loss : 0.073771, loss_ce: 0.009838
iteration 2363 : loss : 0.060779, loss_ce: 0.013136
iteration 2364 : loss : 0.064614, loss_ce: 0.011406
iteration 2365 : loss : 0.059460, loss_ce: 0.014441
iteration 2366 : loss : 0.077843, loss_ce: 0.017592
iteration 2367 : loss : 0.056949, loss_ce: 0.020862
iteration 2368 : loss : 0.057990, loss_ce: 0.012570
iteration 2369 : loss : 0.053523, loss_ce: 0.017676
iteration 2370 : loss : 0.054598, loss_ce: 0.016177
iteration 2371 : loss : 0.053835, loss_ce: 0.019288
iteration 2372 : loss : 0.051088, loss_ce: 0.024123
iteration 2373 : loss : 0.061245, loss_ce: 0.016468
iteration 2374 : loss : 0.063586, loss_ce: 0.021635
iteration 2375 : loss : 0.056408, loss_ce: 0.014126
iteration 2376 : loss : 0.057481, loss_ce: 0.026626
iteration 2377 : loss : 0.097393, loss_ce: 0.015086
iteration 2378 : loss : 0.062385, loss_ce: 0.020930
iteration 2379 : loss : 0.056426, loss_ce: 0.028712
iteration 2380 : loss : 0.053734, loss_ce: 0.019804
iteration 2381 : loss : 0.059159, loss_ce: 0.017440
iteration 2382 : loss : 0.050118, loss_ce: 0.015054
iteration 2383 : loss : 0.061371, loss_ce: 0.027160
iteration 2384 : loss : 0.047701, loss_ce: 0.012254
iteration 2385 : loss : 0.050712, loss_ce: 0.024384
iteration 2386 : loss : 0.049865, loss_ce: 0.015402
iteration 2387 : loss : 0.061513, loss_ce: 0.025208
pred_sum 472
gtsum tensor(408, device='cuda:0')
iteration 2388 : loss : 0.057751, loss_ce: 0.026583
iteration 2389 : loss : 0.050191, loss_ce: 0.019366
iteration 2390 : loss : 0.097710, loss_ce: 0.011174
iteration 2391 : loss : 0.055748, loss_ce: 0.012862
iteration 2392 : loss : 0.055623, loss_ce: 0.012302
iteration 2393 : loss : 0.050615, loss_ce: 0.013571
iteration 2394 : loss : 0.094872, loss_ce: 0.016121
iteration 2395 : loss : 0.046050, loss_ce: 0.016167
iteration 2396 : loss : 0.055472, loss_ce: 0.015803
iteration 2397 : loss : 0.040986, loss_ce: 0.017528
iteration 2398 : loss : 0.051304, loss_ce: 0.013662
iteration 2399 : loss : 0.046379, loss_ce: 0.015133
iteration 2400 : loss : 0.090633, loss_ce: 0.011984
iteration 2401 : loss : 0.055601, loss_ce: 0.027930
iteration 2402 : loss : 0.042258, loss_ce: 0.009926
iteration 2403 : loss : 0.101338, loss_ce: 0.019227
iteration 2404 : loss : 0.102749, loss_ce: 0.009966
iteration 2405 : loss : 0.055440, loss_ce: 0.015385
iteration 2406 : loss : 0.049394, loss_ce: 0.018802
iteration 2407 : loss : 0.046234, loss_ce: 0.016791
iteration 2408 : loss : 0.055512, loss_ce: 0.014212
iteration 2409 : loss : 0.056025, loss_ce: 0.021992
iteration 2410 : loss : 0.035416, loss_ce: 0.011518
iteration 2411 : loss : 0.041748, loss_ce: 0.016752
iteration 2412 : loss : 0.055870, loss_ce: 0.019191
iteration 2413 : loss : 0.091467, loss_ce: 0.012590
iteration 2414 : loss : 0.056474, loss_ce: 0.020752
iteration 2415 : loss : 0.064220, loss_ce: 0.012290
iteration 2416 : loss : 0.050963, loss_ce: 0.017170
iteration 2417 : loss : 0.039668, loss_ce: 0.009996
iteration 2418 : loss : 0.292425, loss_ce: 0.010123
 13%|███▉                          | 26/200 [23:29<2:37:57, 54.47s/it]pred_sum 479
gtsum tensor(563, device='cuda:0')
iteration 2419 : loss : 0.040952, loss_ce: 0.011002
iteration 2420 : loss : 0.052290, loss_ce: 0.021989
iteration 2421 : loss : 0.096048, loss_ce: 0.011105
iteration 2422 : loss : 0.061837, loss_ce: 0.013514
iteration 2423 : loss : 0.042858, loss_ce: 0.013670
iteration 2424 : loss : 0.053587, loss_ce: 0.029021
iteration 2425 : loss : 0.056763, loss_ce: 0.015653
iteration 2426 : loss : 0.036742, loss_ce: 0.013223
iteration 2427 : loss : 0.055064, loss_ce: 0.021724
iteration 2428 : loss : 0.092891, loss_ce: 0.017673
iteration 2429 : loss : 0.048437, loss_ce: 0.020466
iteration 2430 : loss : 0.047774, loss_ce: 0.018847
iteration 2431 : loss : 0.060658, loss_ce: 0.023169
iteration 2432 : loss : 0.050603, loss_ce: 0.013055
iteration 2433 : loss : 0.059201, loss_ce: 0.013814
iteration 2434 : loss : 0.045654, loss_ce: 0.015429
iteration 2435 : loss : 0.053737, loss_ce: 0.025813
iteration 2436 : loss : 0.039414, loss_ce: 0.014522
iteration 2437 : loss : 0.058931, loss_ce: 0.021724
iteration 2438 : loss : 0.040218, loss_ce: 0.017351
iteration 2439 : loss : 0.091325, loss_ce: 0.011903
iteration 2440 : loss : 0.058385, loss_ce: 0.012212
iteration 2441 : loss : 0.072233, loss_ce: 0.015863
iteration 2442 : loss : 0.047784, loss_ce: 0.014643
iteration 2443 : loss : 0.072022, loss_ce: 0.010241
iteration 2444 : loss : 0.130746, loss_ce: 0.008831
iteration 2445 : loss : 0.054055, loss_ce: 0.018655
iteration 2446 : loss : 0.061945, loss_ce: 0.030124
iteration 2447 : loss : 0.056973, loss_ce: 0.017060
iteration 2448 : loss : 0.096670, loss_ce: 0.011711
iteration 2449 : loss : 0.060955, loss_ce: 0.015173
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 2450 : loss : 0.048430, loss_ce: 0.015825
iteration 2451 : loss : 0.050729, loss_ce: 0.019563
iteration 2452 : loss : 0.071357, loss_ce: 0.016324
iteration 2453 : loss : 0.063917, loss_ce: 0.026570
iteration 2454 : loss : 0.055923, loss_ce: 0.015441
iteration 2455 : loss : 0.059959, loss_ce: 0.027336
iteration 2456 : loss : 0.060448, loss_ce: 0.012563
iteration 2457 : loss : 0.050719, loss_ce: 0.023558
iteration 2458 : loss : 0.099674, loss_ce: 0.013220
iteration 2459 : loss : 0.049024, loss_ce: 0.013051
iteration 2460 : loss : 0.044514, loss_ce: 0.014193
iteration 2461 : loss : 0.043933, loss_ce: 0.014028
iteration 2462 : loss : 0.055249, loss_ce: 0.023666
iteration 2463 : loss : 0.059617, loss_ce: 0.019540
iteration 2464 : loss : 0.060458, loss_ce: 0.012339
iteration 2465 : loss : 0.066583, loss_ce: 0.009865
iteration 2466 : loss : 0.046658, loss_ce: 0.014296
iteration 2467 : loss : 0.047295, loss_ce: 0.020023
iteration 2468 : loss : 0.047282, loss_ce: 0.017146
iteration 2469 : loss : 0.058394, loss_ce: 0.018208
iteration 2470 : loss : 0.046452, loss_ce: 0.016412
iteration 2471 : loss : 0.061803, loss_ce: 0.017321
iteration 2472 : loss : 0.046550, loss_ce: 0.020834
iteration 2473 : loss : 0.039681, loss_ce: 0.009652
iteration 2474 : loss : 0.047296, loss_ce: 0.017366
iteration 2475 : loss : 0.049058, loss_ce: 0.012778
iteration 2476 : loss : 0.088390, loss_ce: 0.014510
iteration 2477 : loss : 0.101510, loss_ce: 0.016146
iteration 2478 : loss : 0.074781, loss_ce: 0.012642
iteration 2479 : loss : 0.076150, loss_ce: 0.018700
iteration 2480 : loss : 0.053821, loss_ce: 0.014828
pred_sum 35923
gtsum tensor(36564, device='cuda:0')
iteration 2481 : loss : 0.088583, loss_ce: 0.015381
iteration 2482 : loss : 0.057140, loss_ce: 0.014065
iteration 2483 : loss : 0.046212, loss_ce: 0.010715
iteration 2484 : loss : 0.049269, loss_ce: 0.016962
iteration 2485 : loss : 0.056671, loss_ce: 0.018116
iteration 2486 : loss : 0.058008, loss_ce: 0.020217
iteration 2487 : loss : 0.090952, loss_ce: 0.007903
iteration 2488 : loss : 0.040059, loss_ce: 0.013229
iteration 2489 : loss : 0.146853, loss_ce: 0.006181
iteration 2490 : loss : 0.060027, loss_ce: 0.012049
iteration 2491 : loss : 0.048516, loss_ce: 0.012904
iteration 2492 : loss : 0.052315, loss_ce: 0.031128
iteration 2493 : loss : 0.052824, loss_ce: 0.017619
iteration 2494 : loss : 0.055251, loss_ce: 0.015607
iteration 2495 : loss : 0.054716, loss_ce: 0.010032
iteration 2496 : loss : 0.058254, loss_ce: 0.021793
iteration 2497 : loss : 0.059430, loss_ce: 0.016905
iteration 2498 : loss : 0.050849, loss_ce: 0.011283
iteration 2499 : loss : 0.067089, loss_ce: 0.014786
iteration 2500 : loss : 0.052511, loss_ce: 0.019276
iteration 2501 : loss : 0.056569, loss_ce: 0.017681
iteration 2502 : loss : 0.051536, loss_ce: 0.020083
iteration 2503 : loss : 0.051264, loss_ce: 0.019190
iteration 2504 : loss : 0.044818, loss_ce: 0.011532
iteration 2505 : loss : 0.055518, loss_ce: 0.019731
iteration 2506 : loss : 0.070003, loss_ce: 0.021105
iteration 2507 : loss : 0.055167, loss_ce: 0.016235
iteration 2508 : loss : 0.048912, loss_ce: 0.022594
iteration 2509 : loss : 0.068043, loss_ce: 0.011369
iteration 2510 : loss : 0.092053, loss_ce: 0.011797
iteration 2511 : loss : 0.055439, loss_ce: 0.022038
 14%|████                          | 27/200 [24:23<2:37:00, 54.46s/it]pred_sum 5492
gtsum tensor(5839, device='cuda:0')
iteration 2512 : loss : 0.090455, loss_ce: 0.011816
iteration 2513 : loss : 0.047510, loss_ce: 0.022713
iteration 2514 : loss : 0.069676, loss_ce: 0.013838
iteration 2515 : loss : 0.046388, loss_ce: 0.014726
iteration 2516 : loss : 0.062774, loss_ce: 0.021153
iteration 2517 : loss : 0.146828, loss_ce: 0.019183
iteration 2518 : loss : 0.054844, loss_ce: 0.014171
iteration 2519 : loss : 0.050589, loss_ce: 0.019617
iteration 2520 : loss : 0.062928, loss_ce: 0.015495
iteration 2521 : loss : 0.041129, loss_ce: 0.013147
iteration 2522 : loss : 0.094153, loss_ce: 0.015525
iteration 2523 : loss : 0.040241, loss_ce: 0.016165
iteration 2524 : loss : 0.046564, loss_ce: 0.018034
iteration 2525 : loss : 0.039010, loss_ce: 0.009076
iteration 2526 : loss : 0.051791, loss_ce: 0.014719
iteration 2527 : loss : 0.052530, loss_ce: 0.021530
iteration 2528 : loss : 0.049608, loss_ce: 0.015706
iteration 2529 : loss : 0.054201, loss_ce: 0.013238
iteration 2530 : loss : 0.096492, loss_ce: 0.015216
iteration 2531 : loss : 0.065562, loss_ce: 0.019645
iteration 2532 : loss : 0.046537, loss_ce: 0.016267
iteration 2533 : loss : 0.043092, loss_ce: 0.014772
iteration 2534 : loss : 0.068562, loss_ce: 0.007619
iteration 2535 : loss : 0.072764, loss_ce: 0.017154
iteration 2536 : loss : 0.073839, loss_ce: 0.016991
iteration 2537 : loss : 0.058085, loss_ce: 0.019678
iteration 2538 : loss : 0.055081, loss_ce: 0.016778
iteration 2539 : loss : 0.076127, loss_ce: 0.021762
iteration 2540 : loss : 0.060456, loss_ce: 0.013183
iteration 2541 : loss : 0.043020, loss_ce: 0.014823
iteration 2542 : loss : 0.049374, loss_ce: 0.016343
pred_sum 54227
gtsum tensor(52758, device='cuda:0')
iteration 2543 : loss : 0.043484, loss_ce: 0.014948
iteration 2544 : loss : 0.044276, loss_ce: 0.011902
iteration 2545 : loss : 0.090605, loss_ce: 0.008593
iteration 2546 : loss : 0.081716, loss_ce: 0.013923
iteration 2547 : loss : 0.041980, loss_ce: 0.016003
iteration 2548 : loss : 0.044608, loss_ce: 0.013780
iteration 2549 : loss : 0.059385, loss_ce: 0.016747
iteration 2550 : loss : 0.058220, loss_ce: 0.017821
iteration 2551 : loss : 0.050869, loss_ce: 0.020188
iteration 2552 : loss : 0.057570, loss_ce: 0.014702
iteration 2553 : loss : 0.051475, loss_ce: 0.022719
iteration 2554 : loss : 0.056624, loss_ce: 0.016714
iteration 2555 : loss : 0.054534, loss_ce: 0.018219
iteration 2556 : loss : 0.042654, loss_ce: 0.013566
iteration 2557 : loss : 0.047442, loss_ce: 0.019588
iteration 2558 : loss : 0.065731, loss_ce: 0.014898
iteration 2559 : loss : 0.052836, loss_ce: 0.019273
iteration 2560 : loss : 0.062301, loss_ce: 0.024646
iteration 2561 : loss : 0.046809, loss_ce: 0.018101
iteration 2562 : loss : 0.087230, loss_ce: 0.017294
iteration 2563 : loss : 0.050466, loss_ce: 0.022799
iteration 2564 : loss : 0.055814, loss_ce: 0.017871
iteration 2565 : loss : 0.048537, loss_ce: 0.015446
iteration 2566 : loss : 0.089602, loss_ce: 0.008583
iteration 2567 : loss : 0.052059, loss_ce: 0.014358
iteration 2568 : loss : 0.048175, loss_ce: 0.017220
iteration 2569 : loss : 0.055041, loss_ce: 0.021686
iteration 2570 : loss : 0.059130, loss_ce: 0.022770
iteration 2571 : loss : 0.059959, loss_ce: 0.010547
iteration 2572 : loss : 0.041625, loss_ce: 0.018325
iteration 2573 : loss : 0.041401, loss_ce: 0.010974
pred_sum 22954
gtsum tensor(22812, device='cuda:0')
iteration 2574 : loss : 0.039420, loss_ce: 0.016366
iteration 2575 : loss : 0.065011, loss_ce: 0.016758
iteration 2576 : loss : 0.039149, loss_ce: 0.013881
iteration 2577 : loss : 0.048314, loss_ce: 0.014971
iteration 2578 : loss : 0.056860, loss_ce: 0.020958
iteration 2579 : loss : 0.105394, loss_ce: 0.009725
iteration 2580 : loss : 0.067848, loss_ce: 0.016810
iteration 2581 : loss : 0.050590, loss_ce: 0.020641
iteration 2582 : loss : 0.044167, loss_ce: 0.018098
iteration 2583 : loss : 0.049207, loss_ce: 0.017175
iteration 2584 : loss : 0.061496, loss_ce: 0.016780
iteration 2585 : loss : 0.056942, loss_ce: 0.015763
iteration 2586 : loss : 0.060262, loss_ce: 0.015387
iteration 2587 : loss : 0.051154, loss_ce: 0.022057
iteration 2588 : loss : 0.050096, loss_ce: 0.020426
iteration 2589 : loss : 0.048399, loss_ce: 0.017453
iteration 2590 : loss : 0.045797, loss_ce: 0.014617
iteration 2591 : loss : 0.046860, loss_ce: 0.012470
iteration 2592 : loss : 0.053981, loss_ce: 0.015089
iteration 2593 : loss : 0.073898, loss_ce: 0.012376
iteration 2594 : loss : 0.047984, loss_ce: 0.012225
iteration 2595 : loss : 0.045960, loss_ce: 0.009242
iteration 2596 : loss : 0.052357, loss_ce: 0.014924
iteration 2597 : loss : 0.094590, loss_ce: 0.014441
iteration 2598 : loss : 0.064358, loss_ce: 0.020346
iteration 2599 : loss : 0.054942, loss_ce: 0.018246
iteration 2600 : loss : 0.089438, loss_ce: 0.009332
iteration 2601 : loss : 0.050660, loss_ce: 0.018143
iteration 2602 : loss : 0.049412, loss_ce: 0.018447
iteration 2603 : loss : 0.042039, loss_ce: 0.014313
iteration 2604 : loss : 0.195884, loss_ce: 0.026916
 14%|████▏                         | 28/200 [25:18<2:36:04, 54.45s/it]pred_sum 2553
gtsum tensor(3476, device='cuda:0')
iteration 2605 : loss : 0.040817, loss_ce: 0.014406
iteration 2606 : loss : 0.054317, loss_ce: 0.011604
iteration 2607 : loss : 0.048634, loss_ce: 0.019046
iteration 2608 : loss : 0.056769, loss_ce: 0.015112
iteration 2609 : loss : 0.087725, loss_ce: 0.024911
iteration 2610 : loss : 0.046228, loss_ce: 0.013781
iteration 2611 : loss : 0.056092, loss_ce: 0.015197
iteration 2612 : loss : 0.067159, loss_ce: 0.015441
iteration 2613 : loss : 0.041718, loss_ce: 0.012050
iteration 2614 : loss : 0.040193, loss_ce: 0.009803
iteration 2615 : loss : 0.037790, loss_ce: 0.019691
iteration 2616 : loss : 0.045180, loss_ce: 0.016723
iteration 2617 : loss : 0.064770, loss_ce: 0.025883
iteration 2618 : loss : 0.038406, loss_ce: 0.012965
iteration 2619 : loss : 0.059529, loss_ce: 0.013948
iteration 2620 : loss : 0.044562, loss_ce: 0.010807
iteration 2621 : loss : 0.050565, loss_ce: 0.015014
iteration 2622 : loss : 0.104272, loss_ce: 0.016009
iteration 2623 : loss : 0.061415, loss_ce: 0.015637
iteration 2624 : loss : 0.039175, loss_ce: 0.014613
iteration 2625 : loss : 0.059550, loss_ce: 0.023632
iteration 2626 : loss : 0.051543, loss_ce: 0.017304
iteration 2627 : loss : 0.050698, loss_ce: 0.014447
iteration 2628 : loss : 0.062944, loss_ce: 0.021908
iteration 2629 : loss : 0.051041, loss_ce: 0.020156
iteration 2630 : loss : 0.039252, loss_ce: 0.013186
iteration 2631 : loss : 0.055342, loss_ce: 0.025369
iteration 2632 : loss : 0.053232, loss_ce: 0.012307
iteration 2633 : loss : 0.039671, loss_ce: 0.009293
iteration 2634 : loss : 0.051222, loss_ce: 0.023460
iteration 2635 : loss : 0.051275, loss_ce: 0.015572
pred_sum 772
gtsum tensor(824, device='cuda:0')
iteration 2636 : loss : 0.057697, loss_ce: 0.011577
iteration 2637 : loss : 0.079786, loss_ce: 0.019905
iteration 2638 : loss : 0.046770, loss_ce: 0.018366
iteration 2639 : loss : 0.055892, loss_ce: 0.011745
iteration 2640 : loss : 0.090051, loss_ce: 0.015424
iteration 2641 : loss : 0.051243, loss_ce: 0.014209
iteration 2642 : loss : 0.061215, loss_ce: 0.018311
iteration 2643 : loss : 0.053804, loss_ce: 0.025594
iteration 2644 : loss : 0.037024, loss_ce: 0.015000
iteration 2645 : loss : 0.061396, loss_ce: 0.015600
iteration 2646 : loss : 0.039941, loss_ce: 0.012753
iteration 2647 : loss : 0.047489, loss_ce: 0.021112
iteration 2648 : loss : 0.039934, loss_ce: 0.013065
iteration 2649 : loss : 0.042117, loss_ce: 0.015056
iteration 2650 : loss : 0.052802, loss_ce: 0.016544
iteration 2651 : loss : 0.047723, loss_ce: 0.025056
iteration 2652 : loss : 0.050117, loss_ce: 0.023813
iteration 2653 : loss : 0.068504, loss_ce: 0.019063
iteration 2654 : loss : 0.043610, loss_ce: 0.012592
iteration 2655 : loss : 0.058599, loss_ce: 0.012519
iteration 2656 : loss : 0.047279, loss_ce: 0.017923
iteration 2657 : loss : 0.045046, loss_ce: 0.016604
iteration 2658 : loss : 0.046542, loss_ce: 0.012196
iteration 2659 : loss : 0.077968, loss_ce: 0.020549
iteration 2660 : loss : 0.059689, loss_ce: 0.014633
iteration 2661 : loss : 0.081343, loss_ce: 0.009477
iteration 2662 : loss : 0.053289, loss_ce: 0.015786
iteration 2663 : loss : 0.062832, loss_ce: 0.013743
iteration 2664 : loss : 0.047480, loss_ce: 0.015717
iteration 2665 : loss : 0.055109, loss_ce: 0.017426
iteration 2666 : loss : 0.045707, loss_ce: 0.021712
pred_sum 33300
gtsum tensor(33367, device='cuda:0')
iteration 2667 : loss : 0.059565, loss_ce: 0.011557
iteration 2668 : loss : 0.049678, loss_ce: 0.023050
iteration 2669 : loss : 0.048627, loss_ce: 0.020209
iteration 2670 : loss : 0.054105, loss_ce: 0.013936
iteration 2671 : loss : 0.096517, loss_ce: 0.012806
iteration 2672 : loss : 0.086347, loss_ce: 0.011831
iteration 2673 : loss : 0.058677, loss_ce: 0.015222
iteration 2674 : loss : 0.051082, loss_ce: 0.019609
iteration 2675 : loss : 0.038843, loss_ce: 0.010292
iteration 2676 : loss : 0.050349, loss_ce: 0.012969
iteration 2677 : loss : 0.108796, loss_ce: 0.006184
iteration 2678 : loss : 0.051436, loss_ce: 0.018982
iteration 2679 : loss : 0.052152, loss_ce: 0.016193
iteration 2680 : loss : 0.095555, loss_ce: 0.012258
iteration 2681 : loss : 0.062726, loss_ce: 0.015536
iteration 2682 : loss : 0.045415, loss_ce: 0.012847
iteration 2683 : loss : 0.057009, loss_ce: 0.016065
iteration 2684 : loss : 0.055245, loss_ce: 0.012475
iteration 2685 : loss : 0.042381, loss_ce: 0.007285
iteration 2686 : loss : 0.051383, loss_ce: 0.012354
iteration 2687 : loss : 0.063279, loss_ce: 0.019220
iteration 2688 : loss : 0.048787, loss_ce: 0.018362
iteration 2689 : loss : 0.059154, loss_ce: 0.019986
iteration 2690 : loss : 0.046041, loss_ce: 0.016973
iteration 2691 : loss : 0.058470, loss_ce: 0.020250
iteration 2692 : loss : 0.085828, loss_ce: 0.016393
iteration 2693 : loss : 0.055573, loss_ce: 0.018073
iteration 2694 : loss : 0.051146, loss_ce: 0.022544
iteration 2695 : loss : 0.060066, loss_ce: 0.016943
iteration 2696 : loss : 0.047826, loss_ce: 0.015715
iteration 2697 : loss : 0.107845, loss_ce: 0.039360
 14%|████▎                         | 29/200 [26:12<2:35:15, 54.47s/it]pred_sum 39368
gtsum tensor(42303, device='cuda:0')
iteration 2698 : loss : 0.050621, loss_ce: 0.020479
iteration 2699 : loss : 0.057291, loss_ce: 0.016817
iteration 2700 : loss : 0.053639, loss_ce: 0.012774
iteration 2701 : loss : 0.043683, loss_ce: 0.015300
iteration 2702 : loss : 0.066485, loss_ce: 0.028747
iteration 2703 : loss : 0.044414, loss_ce: 0.013266
iteration 2704 : loss : 0.052943, loss_ce: 0.026274
iteration 2705 : loss : 0.048060, loss_ce: 0.016078
iteration 2706 : loss : 0.048364, loss_ce: 0.016715
iteration 2707 : loss : 0.043261, loss_ce: 0.019989
iteration 2708 : loss : 0.042747, loss_ce: 0.013612
iteration 2709 : loss : 0.044409, loss_ce: 0.009437
iteration 2710 : loss : 0.047398, loss_ce: 0.012711
iteration 2711 : loss : 0.045388, loss_ce: 0.012651
iteration 2712 : loss : 0.078267, loss_ce: 0.014935
iteration 2713 : loss : 0.046246, loss_ce: 0.013493
iteration 2714 : loss : 0.043235, loss_ce: 0.013261
iteration 2715 : loss : 0.053576, loss_ce: 0.021634
iteration 2716 : loss : 0.043268, loss_ce: 0.010739
iteration 2717 : loss : 0.032267, loss_ce: 0.011314
iteration 2718 : loss : 0.095351, loss_ce: 0.015759
iteration 2719 : loss : 0.047589, loss_ce: 0.021920
iteration 2720 : loss : 0.047875, loss_ce: 0.016532
iteration 2721 : loss : 0.049611, loss_ce: 0.016454
iteration 2722 : loss : 0.037239, loss_ce: 0.015834
iteration 2723 : loss : 0.048915, loss_ce: 0.021412
iteration 2724 : loss : 0.042093, loss_ce: 0.013775
iteration 2725 : loss : 0.041842, loss_ce: 0.014140
iteration 2726 : loss : 0.047966, loss_ce: 0.015013
iteration 2727 : loss : 0.091532, loss_ce: 0.013145
iteration 2728 : loss : 0.042916, loss_ce: 0.021265
pred_sum 17020
gtsum tensor(17940, device='cuda:0')
iteration 2729 : loss : 0.045431, loss_ce: 0.016532
iteration 2730 : loss : 0.093260, loss_ce: 0.017094
iteration 2731 : loss : 0.046803, loss_ce: 0.014307
iteration 2732 : loss : 0.051550, loss_ce: 0.019524
iteration 2733 : loss : 0.049628, loss_ce: 0.013036
iteration 2734 : loss : 0.056538, loss_ce: 0.011821
iteration 2735 : loss : 0.055813, loss_ce: 0.015597
iteration 2736 : loss : 0.093289, loss_ce: 0.011842
iteration 2737 : loss : 0.092362, loss_ce: 0.010421
iteration 2738 : loss : 0.052245, loss_ce: 0.009081
iteration 2739 : loss : 0.055656, loss_ce: 0.018501
iteration 2740 : loss : 0.044287, loss_ce: 0.014556
iteration 2741 : loss : 0.036153, loss_ce: 0.012785
iteration 2742 : loss : 0.240315, loss_ce: 0.005731
iteration 2743 : loss : 0.043025, loss_ce: 0.016703
iteration 2744 : loss : 0.060930, loss_ce: 0.019707
iteration 2745 : loss : 0.047946, loss_ce: 0.022189
iteration 2746 : loss : 0.088879, loss_ce: 0.009198
iteration 2747 : loss : 0.055573, loss_ce: 0.011309
iteration 2748 : loss : 0.056875, loss_ce: 0.020527
iteration 2749 : loss : 0.051390, loss_ce: 0.014197
iteration 2750 : loss : 0.055815, loss_ce: 0.010564
iteration 2751 : loss : 0.044472, loss_ce: 0.010533
iteration 2752 : loss : 0.058564, loss_ce: 0.016622
iteration 2753 : loss : 0.069495, loss_ce: 0.021866
iteration 2754 : loss : 0.097720, loss_ce: 0.017818
iteration 2755 : loss : 0.044602, loss_ce: 0.012169
iteration 2756 : loss : 0.049925, loss_ce: 0.015284
iteration 2757 : loss : 0.060257, loss_ce: 0.014730
iteration 2758 : loss : 0.053344, loss_ce: 0.021057
iteration 2759 : loss : 0.047515, loss_ce: 0.011242
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 2760 : loss : 0.050282, loss_ce: 0.018545
iteration 2761 : loss : 0.101290, loss_ce: 0.022950
iteration 2762 : loss : 0.067256, loss_ce: 0.017015
iteration 2763 : loss : 0.045702, loss_ce: 0.015724
iteration 2764 : loss : 0.049673, loss_ce: 0.019156
iteration 2765 : loss : 0.040409, loss_ce: 0.019130
iteration 2766 : loss : 0.047316, loss_ce: 0.013729
iteration 2767 : loss : 0.061326, loss_ce: 0.017778
iteration 2768 : loss : 0.038860, loss_ce: 0.009173
iteration 2769 : loss : 0.042571, loss_ce: 0.008813
iteration 2770 : loss : 0.047802, loss_ce: 0.016379
iteration 2771 : loss : 0.047712, loss_ce: 0.016858
iteration 2772 : loss : 0.047376, loss_ce: 0.013286
iteration 2773 : loss : 0.062284, loss_ce: 0.014787
iteration 2774 : loss : 0.041130, loss_ce: 0.015322
iteration 2775 : loss : 0.049988, loss_ce: 0.022248
iteration 2776 : loss : 0.046784, loss_ce: 0.009314
iteration 2777 : loss : 0.045999, loss_ce: 0.020391
iteration 2778 : loss : 0.032005, loss_ce: 0.008213
iteration 2779 : loss : 0.052053, loss_ce: 0.019135
iteration 2780 : loss : 0.043674, loss_ce: 0.010985
iteration 2781 : loss : 0.051520, loss_ce: 0.018155
iteration 2782 : loss : 0.055039, loss_ce: 0.016020
iteration 2783 : loss : 0.044455, loss_ce: 0.011854
iteration 2784 : loss : 0.047755, loss_ce: 0.014256
iteration 2785 : loss : 0.046621, loss_ce: 0.012691
iteration 2786 : loss : 0.045085, loss_ce: 0.014848
iteration 2787 : loss : 0.090756, loss_ce: 0.011237
iteration 2788 : loss : 0.053585, loss_ce: 0.011869
iteration 2789 : loss : 0.041549, loss_ce: 0.021880
iteration 2790 : loss : 0.236581, loss_ce: 0.011210
 15%|████▌                         | 30/200 [27:07<2:34:21, 54.48s/it]pred_sum 114
gtsum tensor(93, device='cuda:0')
iteration 2791 : loss : 0.041183, loss_ce: 0.018370
iteration 2792 : loss : 0.071113, loss_ce: 0.024931
iteration 2793 : loss : 0.051182, loss_ce: 0.021161
iteration 2794 : loss : 0.099511, loss_ce: 0.008722
iteration 2795 : loss : 0.050576, loss_ce: 0.018574
iteration 2796 : loss : 0.047114, loss_ce: 0.013001
iteration 2797 : loss : 0.048191, loss_ce: 0.018999
iteration 2798 : loss : 0.042735, loss_ce: 0.020506
iteration 2799 : loss : 0.085534, loss_ce: 0.009260
iteration 2800 : loss : 0.050857, loss_ce: 0.012507
iteration 2801 : loss : 0.036763, loss_ce: 0.015979
iteration 2802 : loss : 0.054617, loss_ce: 0.012169
iteration 2803 : loss : 0.052669, loss_ce: 0.011407
iteration 2804 : loss : 0.098028, loss_ce: 0.012412
iteration 2805 : loss : 0.039319, loss_ce: 0.017134
iteration 2806 : loss : 0.131604, loss_ce: 0.009808
iteration 2807 : loss : 0.040645, loss_ce: 0.017880
iteration 2808 : loss : 0.062845, loss_ce: 0.017822
iteration 2809 : loss : 0.038159, loss_ce: 0.013513
iteration 2810 : loss : 0.048385, loss_ce: 0.011108
iteration 2811 : loss : 0.035312, loss_ce: 0.012711
iteration 2812 : loss : 0.039145, loss_ce: 0.012353
iteration 2813 : loss : 0.049638, loss_ce: 0.019843
iteration 2814 : loss : 0.086368, loss_ce: 0.006656
iteration 2815 : loss : 0.091302, loss_ce: 0.010966
iteration 2816 : loss : 0.055456, loss_ce: 0.015024
iteration 2817 : loss : 0.036803, loss_ce: 0.007774
iteration 2818 : loss : 0.052307, loss_ce: 0.021648
iteration 2819 : loss : 0.046291, loss_ce: 0.016276
iteration 2820 : loss : 0.049721, loss_ce: 0.007483
iteration 2821 : loss : 0.042872, loss_ce: 0.010773
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 2822 : loss : 0.047936, loss_ce: 0.016597
iteration 2823 : loss : 0.065330, loss_ce: 0.011860
iteration 2824 : loss : 0.040742, loss_ce: 0.013487
iteration 2825 : loss : 0.037956, loss_ce: 0.011395
iteration 2826 : loss : 0.052257, loss_ce: 0.020666
iteration 2827 : loss : 0.055354, loss_ce: 0.010107
iteration 2828 : loss : 0.046794, loss_ce: 0.020043
iteration 2829 : loss : 0.042035, loss_ce: 0.011240
iteration 2830 : loss : 0.041726, loss_ce: 0.013835
iteration 2831 : loss : 0.056251, loss_ce: 0.021400
iteration 2832 : loss : 0.047758, loss_ce: 0.010402
iteration 2833 : loss : 0.039590, loss_ce: 0.021302
iteration 2834 : loss : 0.043945, loss_ce: 0.015035
iteration 2835 : loss : 0.042871, loss_ce: 0.012398
iteration 2836 : loss : 0.101928, loss_ce: 0.011419
iteration 2837 : loss : 0.036216, loss_ce: 0.012881
iteration 2838 : loss : 0.050683, loss_ce: 0.014418
iteration 2839 : loss : 0.043587, loss_ce: 0.014577
iteration 2840 : loss : 0.042191, loss_ce: 0.018191
iteration 2841 : loss : 0.039060, loss_ce: 0.012334
iteration 2842 : loss : 0.042823, loss_ce: 0.012388
iteration 2843 : loss : 0.049264, loss_ce: 0.017527
iteration 2844 : loss : 0.043033, loss_ce: 0.020217
iteration 2845 : loss : 0.042566, loss_ce: 0.014840
iteration 2846 : loss : 0.137617, loss_ce: 0.015053
iteration 2847 : loss : 0.046901, loss_ce: 0.014352
iteration 2848 : loss : 0.050532, loss_ce: 0.032436
iteration 2849 : loss : 0.043269, loss_ce: 0.010425
iteration 2850 : loss : 0.041149, loss_ce: 0.016653
iteration 2851 : loss : 0.067721, loss_ce: 0.012401
iteration 2852 : loss : 0.049471, loss_ce: 0.014097
pred_sum 6166
gtsum tensor(5770, device='cuda:0')
iteration 2853 : loss : 0.059111, loss_ce: 0.017148
iteration 2854 : loss : 0.049125, loss_ce: 0.015239
iteration 2855 : loss : 0.106220, loss_ce: 0.011683
iteration 2856 : loss : 0.042238, loss_ce: 0.013947
iteration 2857 : loss : 0.051098, loss_ce: 0.013339
iteration 2858 : loss : 0.045352, loss_ce: 0.017004
iteration 2859 : loss : 0.053587, loss_ce: 0.011223
iteration 2860 : loss : 0.044617, loss_ce: 0.015676
iteration 2861 : loss : 0.039321, loss_ce: 0.017014
iteration 2862 : loss : 0.036264, loss_ce: 0.010465
iteration 2863 : loss : 0.036528, loss_ce: 0.016319
iteration 2864 : loss : 0.044899, loss_ce: 0.016066
iteration 2865 : loss : 0.043710, loss_ce: 0.011916
iteration 2866 : loss : 0.075857, loss_ce: 0.015845
iteration 2867 : loss : 0.098100, loss_ce: 0.016583
iteration 2868 : loss : 0.039423, loss_ce: 0.011141
iteration 2869 : loss : 0.048534, loss_ce: 0.013766
iteration 2870 : loss : 0.049371, loss_ce: 0.020113
iteration 2871 : loss : 0.061107, loss_ce: 0.017678
iteration 2872 : loss : 0.042241, loss_ce: 0.009833
iteration 2873 : loss : 0.064304, loss_ce: 0.012938
iteration 2874 : loss : 0.064505, loss_ce: 0.019909
iteration 2875 : loss : 0.051680, loss_ce: 0.017087
iteration 2876 : loss : 0.052584, loss_ce: 0.021677
iteration 2877 : loss : 0.083339, loss_ce: 0.009174
iteration 2878 : loss : 0.052918, loss_ce: 0.018150
iteration 2879 : loss : 0.054127, loss_ce: 0.018903
iteration 2880 : loss : 0.058622, loss_ce: 0.014020
iteration 2881 : loss : 0.054731, loss_ce: 0.012117
iteration 2882 : loss : 0.050193, loss_ce: 0.019393
iteration 2883 : loss : 0.343904, loss_ce: 0.008513
 16%|████▋                         | 31/200 [28:01<2:33:25, 54.47s/it]pred_sum 996
gtsum tensor(1226, device='cuda:0')
iteration 2884 : loss : 0.059337, loss_ce: 0.017395
iteration 2885 : loss : 0.054714, loss_ce: 0.020915
iteration 2886 : loss : 0.044358, loss_ce: 0.018761
iteration 2887 : loss : 0.095220, loss_ce: 0.012462
iteration 2888 : loss : 0.044330, loss_ce: 0.015872
iteration 2889 : loss : 0.048557, loss_ce: 0.015312
iteration 2890 : loss : 0.064677, loss_ce: 0.022592
iteration 2891 : loss : 0.057492, loss_ce: 0.015132
iteration 2892 : loss : 0.037778, loss_ce: 0.011227
iteration 2893 : loss : 0.064871, loss_ce: 0.021817
iteration 2894 : loss : 0.060152, loss_ce: 0.022553
iteration 2895 : loss : 0.047338, loss_ce: 0.014990
iteration 2896 : loss : 0.050871, loss_ce: 0.011105
iteration 2897 : loss : 0.044735, loss_ce: 0.017578
iteration 2898 : loss : 0.042674, loss_ce: 0.014858
iteration 2899 : loss : 0.048924, loss_ce: 0.010039
iteration 2900 : loss : 0.047591, loss_ce: 0.017995
iteration 2901 : loss : 0.045873, loss_ce: 0.010703
iteration 2902 : loss : 0.145579, loss_ce: 0.006853
iteration 2903 : loss : 0.085230, loss_ce: 0.008139
iteration 2904 : loss : 0.044060, loss_ce: 0.015446
iteration 2905 : loss : 0.061349, loss_ce: 0.016227
iteration 2906 : loss : 0.077309, loss_ce: 0.018060
iteration 2907 : loss : 0.057470, loss_ce: 0.013400
iteration 2908 : loss : 0.045804, loss_ce: 0.023549
iteration 2909 : loss : 0.044524, loss_ce: 0.012575
iteration 2910 : loss : 0.052016, loss_ce: 0.020389
iteration 2911 : loss : 0.059520, loss_ce: 0.020335
iteration 2912 : loss : 0.053353, loss_ce: 0.020091
iteration 2913 : loss : 0.065194, loss_ce: 0.015995
iteration 2914 : loss : 0.074732, loss_ce: 0.020884
pred_sum 53871
gtsum tensor(51524, device='cuda:0')
iteration 2915 : loss : 0.096694, loss_ce: 0.014375
iteration 2916 : loss : 0.038542, loss_ce: 0.015915
iteration 2917 : loss : 0.057229, loss_ce: 0.018323
iteration 2918 : loss : 0.054875, loss_ce: 0.018814
iteration 2919 : loss : 0.043891, loss_ce: 0.011617
iteration 2920 : loss : 0.053874, loss_ce: 0.012170
iteration 2921 : loss : 0.057621, loss_ce: 0.013547
iteration 2922 : loss : 0.059084, loss_ce: 0.012158
iteration 2923 : loss : 0.084225, loss_ce: 0.027175
iteration 2924 : loss : 0.054121, loss_ce: 0.018032
iteration 2925 : loss : 0.045310, loss_ce: 0.011962
iteration 2926 : loss : 0.040848, loss_ce: 0.017492
iteration 2927 : loss : 0.042005, loss_ce: 0.014065
iteration 2928 : loss : 0.091144, loss_ce: 0.019345
iteration 2929 : loss : 0.071756, loss_ce: 0.017708
iteration 2930 : loss : 0.057041, loss_ce: 0.014463
iteration 2931 : loss : 0.047710, loss_ce: 0.024221
iteration 2932 : loss : 0.073180, loss_ce: 0.014917
iteration 2933 : loss : 0.054115, loss_ce: 0.024526
iteration 2934 : loss : 0.049560, loss_ce: 0.019698
iteration 2935 : loss : 0.093118, loss_ce: 0.011866
iteration 2936 : loss : 0.056743, loss_ce: 0.019330
iteration 2937 : loss : 0.048900, loss_ce: 0.018417
iteration 2938 : loss : 0.051304, loss_ce: 0.015757
iteration 2939 : loss : 0.060647, loss_ce: 0.016136
iteration 2940 : loss : 0.042257, loss_ce: 0.011352
iteration 2941 : loss : 0.042126, loss_ce: 0.014712
iteration 2942 : loss : 0.051920, loss_ce: 0.018610
iteration 2943 : loss : 0.046660, loss_ce: 0.011599
iteration 2944 : loss : 0.036094, loss_ce: 0.013886
iteration 2945 : loss : 0.055470, loss_ce: 0.016315
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 2946 : loss : 0.042494, loss_ce: 0.015540
iteration 2947 : loss : 0.045974, loss_ce: 0.014284
iteration 2948 : loss : 0.041219, loss_ce: 0.013573
iteration 2949 : loss : 0.038325, loss_ce: 0.014719
iteration 2950 : loss : 0.049807, loss_ce: 0.021207
iteration 2951 : loss : 0.050778, loss_ce: 0.013582
iteration 2952 : loss : 0.055978, loss_ce: 0.007092
iteration 2953 : loss : 0.042090, loss_ce: 0.021938
iteration 2954 : loss : 0.050127, loss_ce: 0.017031
iteration 2955 : loss : 0.047891, loss_ce: 0.015028
iteration 2956 : loss : 0.044486, loss_ce: 0.015625
iteration 2957 : loss : 0.051460, loss_ce: 0.018122
iteration 2958 : loss : 0.045427, loss_ce: 0.016441
iteration 2959 : loss : 0.039228, loss_ce: 0.014462
iteration 2960 : loss : 0.027259, loss_ce: 0.009643
iteration 2961 : loss : 0.043494, loss_ce: 0.010317
iteration 2962 : loss : 0.043401, loss_ce: 0.015242
iteration 2963 : loss : 0.044919, loss_ce: 0.013964
iteration 2964 : loss : 0.044314, loss_ce: 0.012362
iteration 2965 : loss : 0.053772, loss_ce: 0.016227
iteration 2966 : loss : 0.051299, loss_ce: 0.015996
iteration 2967 : loss : 0.038844, loss_ce: 0.011051
iteration 2968 : loss : 0.036007, loss_ce: 0.014855
iteration 2969 : loss : 0.046818, loss_ce: 0.014226
iteration 2970 : loss : 0.038060, loss_ce: 0.011995
iteration 2971 : loss : 0.047606, loss_ce: 0.011964
iteration 2972 : loss : 0.040453, loss_ce: 0.013165
iteration 2973 : loss : 0.053274, loss_ce: 0.017450
iteration 2974 : loss : 0.052778, loss_ce: 0.018315
iteration 2975 : loss : 0.041718, loss_ce: 0.013746
iteration 2976 : loss : 0.239104, loss_ce: 0.013496
 16%|████▊                         | 32/200 [28:56<2:32:32, 54.48s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 2977 : loss : 0.058214, loss_ce: 0.012743
iteration 2978 : loss : 0.060092, loss_ce: 0.012037
iteration 2979 : loss : 0.044357, loss_ce: 0.012829
iteration 2980 : loss : 0.047672, loss_ce: 0.011064
iteration 2981 : loss : 0.039762, loss_ce: 0.021597
iteration 2982 : loss : 0.042089, loss_ce: 0.017982
iteration 2983 : loss : 0.040874, loss_ce: 0.012712
iteration 2984 : loss : 0.044009, loss_ce: 0.010992
iteration 2985 : loss : 0.049133, loss_ce: 0.014173
iteration 2986 : loss : 0.033823, loss_ce: 0.012009
iteration 2987 : loss : 0.066814, loss_ce: 0.015606
iteration 2988 : loss : 0.043417, loss_ce: 0.011643
iteration 2989 : loss : 0.047585, loss_ce: 0.011109
iteration 2990 : loss : 0.039885, loss_ce: 0.012914
iteration 2991 : loss : 0.097118, loss_ce: 0.014189
iteration 2992 : loss : 0.043484, loss_ce: 0.016118
iteration 2993 : loss : 0.055375, loss_ce: 0.022620
iteration 2994 : loss : 0.045597, loss_ce: 0.019375
iteration 2995 : loss : 0.039754, loss_ce: 0.011932
iteration 2996 : loss : 0.088572, loss_ce: 0.013063
iteration 2997 : loss : 0.039850, loss_ce: 0.014091
iteration 2998 : loss : 0.039447, loss_ce: 0.015467
iteration 2999 : loss : 0.053024, loss_ce: 0.011685
iteration 3000 : loss : 0.041339, loss_ce: 0.017270
iteration 3001 : loss : 0.038732, loss_ce: 0.011525
iteration 3002 : loss : 0.044567, loss_ce: 0.014816
iteration 3003 : loss : 0.046076, loss_ce: 0.015443
iteration 3004 : loss : 0.045128, loss_ce: 0.013892
iteration 3005 : loss : 0.071125, loss_ce: 0.015039
iteration 3006 : loss : 0.088879, loss_ce: 0.007284
iteration 3007 : loss : 0.043324, loss_ce: 0.017829
pred_sum 34733
gtsum tensor(34486, device='cuda:0')
iteration 3008 : loss : 0.046915, loss_ce: 0.022904
iteration 3009 : loss : 0.057464, loss_ce: 0.014738
iteration 3010 : loss : 0.051838, loss_ce: 0.019259
iteration 3011 : loss : 0.087755, loss_ce: 0.013245
iteration 3012 : loss : 0.039023, loss_ce: 0.014936
iteration 3013 : loss : 0.043448, loss_ce: 0.018076
iteration 3014 : loss : 0.046239, loss_ce: 0.021784
iteration 3015 : loss : 0.052295, loss_ce: 0.017606
iteration 3016 : loss : 0.051381, loss_ce: 0.019528
iteration 3017 : loss : 0.038329, loss_ce: 0.011055
iteration 3018 : loss : 0.048852, loss_ce: 0.014798
iteration 3019 : loss : 0.038880, loss_ce: 0.013155
iteration 3020 : loss : 0.048233, loss_ce: 0.018856
iteration 3021 : loss : 0.038955, loss_ce: 0.012354
iteration 3022 : loss : 0.054867, loss_ce: 0.017286
iteration 3023 : loss : 0.081477, loss_ce: 0.006741
iteration 3024 : loss : 0.039754, loss_ce: 0.010250
iteration 3025 : loss : 0.054360, loss_ce: 0.024720
iteration 3026 : loss : 0.132235, loss_ce: 0.010109
iteration 3027 : loss : 0.062204, loss_ce: 0.019043
iteration 3028 : loss : 0.048666, loss_ce: 0.013415
iteration 3029 : loss : 0.044646, loss_ce: 0.010006
iteration 3030 : loss : 0.050373, loss_ce: 0.011241
iteration 3031 : loss : 0.052174, loss_ce: 0.017549
iteration 3032 : loss : 0.045761, loss_ce: 0.018380
iteration 3033 : loss : 0.089247, loss_ce: 0.010017
iteration 3034 : loss : 0.068229, loss_ce: 0.012191
iteration 3035 : loss : 0.044934, loss_ce: 0.017540
iteration 3036 : loss : 0.040191, loss_ce: 0.012905
iteration 3037 : loss : 0.049541, loss_ce: 0.012645
iteration 3038 : loss : 0.043838, loss_ce: 0.011352
pred_sum 54010
gtsum tensor(53917, device='cuda:0')
iteration 3039 : loss : 0.058480, loss_ce: 0.015236
iteration 3040 : loss : 0.039749, loss_ce: 0.009981
iteration 3041 : loss : 0.042197, loss_ce: 0.018024
iteration 3042 : loss : 0.092426, loss_ce: 0.008030
iteration 3043 : loss : 0.037011, loss_ce: 0.012243
iteration 3044 : loss : 0.042470, loss_ce: 0.010929
iteration 3045 : loss : 0.040200, loss_ce: 0.013254
iteration 3046 : loss : 0.090065, loss_ce: 0.013087
iteration 3047 : loss : 0.058383, loss_ce: 0.016717
iteration 3048 : loss : 0.053998, loss_ce: 0.015031
iteration 3049 : loss : 0.067432, loss_ce: 0.012243
iteration 3050 : loss : 0.045095, loss_ce: 0.011841
iteration 3051 : loss : 0.104789, loss_ce: 0.010948
iteration 3052 : loss : 0.037015, loss_ce: 0.012668
iteration 3053 : loss : 0.043354, loss_ce: 0.017483
iteration 3054 : loss : 0.084348, loss_ce: 0.014269
iteration 3055 : loss : 0.075818, loss_ce: 0.010829
iteration 3056 : loss : 0.050659, loss_ce: 0.015125
iteration 3057 : loss : 0.041653, loss_ce: 0.019685
iteration 3058 : loss : 0.063293, loss_ce: 0.012562
iteration 3059 : loss : 0.042554, loss_ce: 0.013103
iteration 3060 : loss : 0.046580, loss_ce: 0.024648
iteration 3061 : loss : 0.043437, loss_ce: 0.018205
iteration 3062 : loss : 0.037065, loss_ce: 0.010393
iteration 3063 : loss : 0.042197, loss_ce: 0.013281
iteration 3064 : loss : 0.045438, loss_ce: 0.015139
iteration 3065 : loss : 0.049864, loss_ce: 0.014844
iteration 3066 : loss : 0.046239, loss_ce: 0.012740
iteration 3067 : loss : 0.044767, loss_ce: 0.015228
iteration 3068 : loss : 0.081744, loss_ce: 0.011174
iteration 3069 : loss : 0.340453, loss_ce: 0.004408
 16%|████▉                         | 33/200 [29:50<2:31:38, 54.48s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 3070 : loss : 0.034659, loss_ce: 0.010767
iteration 3071 : loss : 0.047818, loss_ce: 0.014711
iteration 3072 : loss : 0.046023, loss_ce: 0.015777
iteration 3073 : loss : 0.048776, loss_ce: 0.013590
iteration 3074 : loss : 0.045917, loss_ce: 0.019379
iteration 3075 : loss : 0.084958, loss_ce: 0.008893
iteration 3076 : loss : 0.040577, loss_ce: 0.014509
iteration 3077 : loss : 0.039489, loss_ce: 0.013769
iteration 3078 : loss : 0.041629, loss_ce: 0.018935
iteration 3079 : loss : 0.048304, loss_ce: 0.013941
iteration 3080 : loss : 0.033978, loss_ce: 0.010703
iteration 3081 : loss : 0.053794, loss_ce: 0.018987
iteration 3082 : loss : 0.043069, loss_ce: 0.013459
iteration 3083 : loss : 0.054920, loss_ce: 0.011834
iteration 3084 : loss : 0.051465, loss_ce: 0.014697
iteration 3085 : loss : 0.042618, loss_ce: 0.012003
iteration 3086 : loss : 0.032887, loss_ce: 0.012668
iteration 3087 : loss : 0.044272, loss_ce: 0.019153
iteration 3088 : loss : 0.074017, loss_ce: 0.012173
iteration 3089 : loss : 0.045050, loss_ce: 0.008572
iteration 3090 : loss : 0.059639, loss_ce: 0.011964
iteration 3091 : loss : 0.045228, loss_ce: 0.015699
iteration 3092 : loss : 0.042195, loss_ce: 0.017666
iteration 3093 : loss : 0.053017, loss_ce: 0.018115
iteration 3094 : loss : 0.048806, loss_ce: 0.018613
iteration 3095 : loss : 0.087750, loss_ce: 0.012248
iteration 3096 : loss : 0.045361, loss_ce: 0.014918
iteration 3097 : loss : 0.035782, loss_ce: 0.013505
iteration 3098 : loss : 0.087876, loss_ce: 0.007496
iteration 3099 : loss : 0.048364, loss_ce: 0.016507
iteration 3100 : loss : 0.062755, loss_ce: 0.022041
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 3101 : loss : 0.098467, loss_ce: 0.012842
iteration 3102 : loss : 0.026587, loss_ce: 0.008524
iteration 3103 : loss : 0.056022, loss_ce: 0.018452
iteration 3104 : loss : 0.046335, loss_ce: 0.021885
iteration 3105 : loss : 0.046711, loss_ce: 0.011178
iteration 3106 : loss : 0.044624, loss_ce: 0.012484
iteration 3107 : loss : 0.044227, loss_ce: 0.017967
iteration 3108 : loss : 0.044135, loss_ce: 0.014111
iteration 3109 : loss : 0.046413, loss_ce: 0.016746
iteration 3110 : loss : 0.051480, loss_ce: 0.018833
iteration 3111 : loss : 0.090183, loss_ce: 0.008077
iteration 3112 : loss : 0.049093, loss_ce: 0.015637
iteration 3113 : loss : 0.055896, loss_ce: 0.016604
iteration 3114 : loss : 0.082804, loss_ce: 0.012085
iteration 3115 : loss : 0.086125, loss_ce: 0.014813
iteration 3116 : loss : 0.032587, loss_ce: 0.010989
iteration 3117 : loss : 0.028882, loss_ce: 0.011607
iteration 3118 : loss : 0.041721, loss_ce: 0.015372
iteration 3119 : loss : 0.040988, loss_ce: 0.012907
iteration 3120 : loss : 0.045037, loss_ce: 0.010456
iteration 3121 : loss : 0.050001, loss_ce: 0.012104
iteration 3122 : loss : 0.040872, loss_ce: 0.009056
iteration 3123 : loss : 0.070501, loss_ce: 0.015800
iteration 3124 : loss : 0.033774, loss_ce: 0.010129
iteration 3125 : loss : 0.064347, loss_ce: 0.010855
iteration 3126 : loss : 0.044433, loss_ce: 0.015467
iteration 3127 : loss : 0.039920, loss_ce: 0.016078
iteration 3128 : loss : 0.064872, loss_ce: 0.018034
iteration 3129 : loss : 0.038082, loss_ce: 0.016346
iteration 3130 : loss : 0.034070, loss_ce: 0.010288
iteration 3131 : loss : 0.050874, loss_ce: 0.022799
pred_sum 27850
gtsum tensor(27070, device='cuda:0')
iteration 3132 : loss : 0.048760, loss_ce: 0.016057
iteration 3133 : loss : 0.048681, loss_ce: 0.016687
iteration 3134 : loss : 0.043020, loss_ce: 0.017941
iteration 3135 : loss : 0.049988, loss_ce: 0.010960
iteration 3136 : loss : 0.038592, loss_ce: 0.015063
iteration 3137 : loss : 0.055047, loss_ce: 0.010115
iteration 3138 : loss : 0.044740, loss_ce: 0.012641
iteration 3139 : loss : 0.039798, loss_ce: 0.014534
iteration 3140 : loss : 0.041938, loss_ce: 0.017441
iteration 3141 : loss : 0.049412, loss_ce: 0.017333
iteration 3142 : loss : 0.045760, loss_ce: 0.011027
iteration 3143 : loss : 0.050154, loss_ce: 0.024015
iteration 3144 : loss : 0.137444, loss_ce: 0.006315
iteration 3145 : loss : 0.089721, loss_ce: 0.010610
iteration 3146 : loss : 0.052778, loss_ce: 0.014705
iteration 3147 : loss : 0.045089, loss_ce: 0.014286
iteration 3148 : loss : 0.091386, loss_ce: 0.009582
iteration 3149 : loss : 0.048947, loss_ce: 0.015046
iteration 3150 : loss : 0.040947, loss_ce: 0.013107
iteration 3151 : loss : 0.051406, loss_ce: 0.021996
iteration 3152 : loss : 0.046339, loss_ce: 0.006995
iteration 3153 : loss : 0.051544, loss_ce: 0.012608
iteration 3154 : loss : 0.074710, loss_ce: 0.007887
iteration 3155 : loss : 0.073160, loss_ce: 0.013462
iteration 3156 : loss : 0.053084, loss_ce: 0.016719
iteration 3157 : loss : 0.046625, loss_ce: 0.018350
iteration 3158 : loss : 0.048947, loss_ce: 0.014298
iteration 3159 : loss : 0.091665, loss_ce: 0.012350
iteration 3160 : loss : 0.047384, loss_ce: 0.013790
iteration 3161 : loss : 0.040549, loss_ce: 0.011719
iteration 3162 : loss : 0.264225, loss_ce: 0.037755
 17%|█████                         | 34/200 [30:45<2:30:42, 54.47s/it]pred_sum 43423
gtsum tensor(43993, device='cuda:0')
iteration 3163 : loss : 0.040638, loss_ce: 0.012770
iteration 3164 : loss : 0.044031, loss_ce: 0.020704
iteration 3165 : loss : 0.044361, loss_ce: 0.016856
iteration 3166 : loss : 0.060485, loss_ce: 0.019337
iteration 3167 : loss : 0.052042, loss_ce: 0.017311
iteration 3168 : loss : 0.046437, loss_ce: 0.016301
iteration 3169 : loss : 0.042131, loss_ce: 0.016408
iteration 3170 : loss : 0.064247, loss_ce: 0.013902
iteration 3171 : loss : 0.040739, loss_ce: 0.012684
iteration 3172 : loss : 0.040097, loss_ce: 0.011854
iteration 3173 : loss : 0.039552, loss_ce: 0.010975
iteration 3174 : loss : 0.042913, loss_ce: 0.013976
iteration 3175 : loss : 0.049221, loss_ce: 0.008456
iteration 3176 : loss : 0.064820, loss_ce: 0.017503
iteration 3177 : loss : 0.047920, loss_ce: 0.015691
iteration 3178 : loss : 0.056205, loss_ce: 0.015822
iteration 3179 : loss : 0.046112, loss_ce: 0.014680
iteration 3180 : loss : 0.050613, loss_ce: 0.014156
iteration 3181 : loss : 0.036174, loss_ce: 0.012523
iteration 3182 : loss : 0.041750, loss_ce: 0.009194
iteration 3183 : loss : 0.048018, loss_ce: 0.014724
iteration 3184 : loss : 0.040278, loss_ce: 0.013284
iteration 3185 : loss : 0.043794, loss_ce: 0.013844
iteration 3186 : loss : 0.040308, loss_ce: 0.018330
iteration 3187 : loss : 0.038777, loss_ce: 0.013852
iteration 3188 : loss : 0.040352, loss_ce: 0.015087
iteration 3189 : loss : 0.044284, loss_ce: 0.015297
iteration 3190 : loss : 0.052623, loss_ce: 0.024789
iteration 3191 : loss : 0.041937, loss_ce: 0.020289
iteration 3192 : loss : 0.056307, loss_ce: 0.022395
iteration 3193 : loss : 0.056615, loss_ce: 0.014007
pred_sum 338
gtsum tensor(196, device='cuda:0')
iteration 3194 : loss : 0.032382, loss_ce: 0.010957
iteration 3195 : loss : 0.036358, loss_ce: 0.012924
iteration 3196 : loss : 0.044658, loss_ce: 0.013146
iteration 3197 : loss : 0.039851, loss_ce: 0.011512
iteration 3198 : loss : 0.047526, loss_ce: 0.016423
iteration 3199 : loss : 0.062105, loss_ce: 0.019585
iteration 3200 : loss : 0.039820, loss_ce: 0.019012
iteration 3201 : loss : 0.053184, loss_ce: 0.016529
iteration 3202 : loss : 0.041175, loss_ce: 0.012171
iteration 3203 : loss : 0.049022, loss_ce: 0.013274
iteration 3204 : loss : 0.036393, loss_ce: 0.018340
iteration 3205 : loss : 0.040971, loss_ce: 0.012457
iteration 3206 : loss : 0.039253, loss_ce: 0.020894
iteration 3207 : loss : 0.046568, loss_ce: 0.011338
iteration 3208 : loss : 0.035480, loss_ce: 0.007664
iteration 3209 : loss : 0.034334, loss_ce: 0.012032
iteration 3210 : loss : 0.039285, loss_ce: 0.009763
iteration 3211 : loss : 0.083245, loss_ce: 0.011455
iteration 3212 : loss : 0.034059, loss_ce: 0.009688
iteration 3213 : loss : 0.042312, loss_ce: 0.013932
iteration 3214 : loss : 0.045044, loss_ce: 0.012536
iteration 3215 : loss : 0.067350, loss_ce: 0.017293
iteration 3216 : loss : 0.039014, loss_ce: 0.014765
iteration 3217 : loss : 0.033612, loss_ce: 0.011240
iteration 3218 : loss : 0.091706, loss_ce: 0.016016
iteration 3219 : loss : 0.048244, loss_ce: 0.018047
iteration 3220 : loss : 0.057503, loss_ce: 0.009553
iteration 3221 : loss : 0.040765, loss_ce: 0.008758
iteration 3222 : loss : 0.079729, loss_ce: 0.008390
iteration 3223 : loss : 0.043895, loss_ce: 0.013956
iteration 3224 : loss : 0.041604, loss_ce: 0.012712
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 3225 : loss : 0.040927, loss_ce: 0.013279
iteration 3226 : loss : 0.052815, loss_ce: 0.021615
iteration 3227 : loss : 0.067678, loss_ce: 0.024753
iteration 3228 : loss : 0.050738, loss_ce: 0.011823
iteration 3229 : loss : 0.066319, loss_ce: 0.021568
iteration 3230 : loss : 0.094553, loss_ce: 0.009413
iteration 3231 : loss : 0.044765, loss_ce: 0.013644
iteration 3232 : loss : 0.046714, loss_ce: 0.011258
iteration 3233 : loss : 0.056760, loss_ce: 0.013247
iteration 3234 : loss : 0.064592, loss_ce: 0.017250
iteration 3235 : loss : 0.055070, loss_ce: 0.017475
iteration 3236 : loss : 0.043847, loss_ce: 0.020403
iteration 3237 : loss : 0.060305, loss_ce: 0.011403
iteration 3238 : loss : 0.038930, loss_ce: 0.016449
iteration 3239 : loss : 0.039336, loss_ce: 0.018845
iteration 3240 : loss : 0.048038, loss_ce: 0.019799
iteration 3241 : loss : 0.045709, loss_ce: 0.014555
iteration 3242 : loss : 0.091737, loss_ce: 0.008944
iteration 3243 : loss : 0.050595, loss_ce: 0.018516
iteration 3244 : loss : 0.042914, loss_ce: 0.015235
iteration 3245 : loss : 0.087495, loss_ce: 0.008756
iteration 3246 : loss : 0.052512, loss_ce: 0.016841
iteration 3247 : loss : 0.035445, loss_ce: 0.010338
iteration 3248 : loss : 0.044049, loss_ce: 0.011322
iteration 3249 : loss : 0.048160, loss_ce: 0.018010
iteration 3250 : loss : 0.044003, loss_ce: 0.008564
iteration 3251 : loss : 0.043974, loss_ce: 0.013914
iteration 3252 : loss : 0.039303, loss_ce: 0.015584
iteration 3253 : loss : 0.048937, loss_ce: 0.011805
iteration 3254 : loss : 0.042334, loss_ce: 0.011288
iteration 3255 : loss : 0.238147, loss_ce: 0.012792
 18%|█████▎                        | 35/200 [31:39<2:29:50, 54.49s/it]pred_sum 50271
gtsum tensor(50774, device='cuda:0')
iteration 3256 : loss : 0.035484, loss_ce: 0.010177
iteration 3257 : loss : 0.132917, loss_ce: 0.008535
iteration 3258 : loss : 0.043870, loss_ce: 0.015170
iteration 3259 : loss : 0.089669, loss_ce: 0.010366
iteration 3260 : loss : 0.039843, loss_ce: 0.010904
iteration 3261 : loss : 0.041332, loss_ce: 0.014097
iteration 3262 : loss : 0.053801, loss_ce: 0.015701
iteration 3263 : loss : 0.046253, loss_ce: 0.012351
iteration 3264 : loss : 0.046226, loss_ce: 0.013520
iteration 3265 : loss : 0.046379, loss_ce: 0.016545
iteration 3266 : loss : 0.037012, loss_ce: 0.010435
iteration 3267 : loss : 0.035666, loss_ce: 0.008761
iteration 3268 : loss : 0.046503, loss_ce: 0.013367
iteration 3269 : loss : 0.037167, loss_ce: 0.012317
iteration 3270 : loss : 0.041165, loss_ce: 0.015471
iteration 3271 : loss : 0.035089, loss_ce: 0.009069
iteration 3272 : loss : 0.051739, loss_ce: 0.017650
iteration 3273 : loss : 0.044053, loss_ce: 0.017723
iteration 3274 : loss : 0.039296, loss_ce: 0.016096
iteration 3275 : loss : 0.036992, loss_ce: 0.012507
iteration 3276 : loss : 0.037399, loss_ce: 0.014941
iteration 3277 : loss : 0.044763, loss_ce: 0.014076
iteration 3278 : loss : 0.049187, loss_ce: 0.018515
iteration 3279 : loss : 0.047079, loss_ce: 0.014234
iteration 3280 : loss : 0.050643, loss_ce: 0.017392
iteration 3281 : loss : 0.032129, loss_ce: 0.011262
iteration 3282 : loss : 0.050976, loss_ce: 0.016401
iteration 3283 : loss : 0.054921, loss_ce: 0.018597
iteration 3284 : loss : 0.040631, loss_ce: 0.006885
iteration 3285 : loss : 0.037113, loss_ce: 0.012530
iteration 3286 : loss : 0.044044, loss_ce: 0.014829
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 3287 : loss : 0.042436, loss_ce: 0.017384
iteration 3288 : loss : 0.051820, loss_ce: 0.013122
iteration 3289 : loss : 0.041187, loss_ce: 0.015742
iteration 3290 : loss : 0.051150, loss_ce: 0.008506
iteration 3291 : loss : 0.054815, loss_ce: 0.018286
iteration 3292 : loss : 0.032525, loss_ce: 0.011452
iteration 3293 : loss : 0.083597, loss_ce: 0.011419
iteration 3294 : loss : 0.048977, loss_ce: 0.018800
iteration 3295 : loss : 0.035281, loss_ce: 0.013099
iteration 3296 : loss : 0.039911, loss_ce: 0.015367
iteration 3297 : loss : 0.038842, loss_ce: 0.007856
iteration 3298 : loss : 0.043883, loss_ce: 0.012203
iteration 3299 : loss : 0.037176, loss_ce: 0.015934
iteration 3300 : loss : 0.047518, loss_ce: 0.014414
iteration 3301 : loss : 0.046877, loss_ce: 0.014167
iteration 3302 : loss : 0.044895, loss_ce: 0.022364
iteration 3303 : loss : 0.091495, loss_ce: 0.009584
iteration 3304 : loss : 0.090739, loss_ce: 0.015916
iteration 3305 : loss : 0.042929, loss_ce: 0.013350
iteration 3306 : loss : 0.046151, loss_ce: 0.015435
iteration 3307 : loss : 0.040332, loss_ce: 0.015084
iteration 3308 : loss : 0.036363, loss_ce: 0.011887
iteration 3309 : loss : 0.053579, loss_ce: 0.011850
iteration 3310 : loss : 0.044409, loss_ce: 0.014827
iteration 3311 : loss : 0.034098, loss_ce: 0.009062
iteration 3312 : loss : 0.032764, loss_ce: 0.007980
iteration 3313 : loss : 0.053547, loss_ce: 0.013745
iteration 3314 : loss : 0.048966, loss_ce: 0.019221
iteration 3315 : loss : 0.049939, loss_ce: 0.020353
iteration 3316 : loss : 0.181556, loss_ce: 0.005670
iteration 3317 : loss : 0.094763, loss_ce: 0.013341
pred_sum 34768
gtsum tensor(34524, device='cuda:0')
iteration 3318 : loss : 0.038031, loss_ce: 0.011612
iteration 3319 : loss : 0.054153, loss_ce: 0.025209
iteration 3320 : loss : 0.048198, loss_ce: 0.021889
iteration 3321 : loss : 0.056079, loss_ce: 0.017422
iteration 3322 : loss : 0.039613, loss_ce: 0.021519
iteration 3323 : loss : 0.045366, loss_ce: 0.011960
iteration 3324 : loss : 0.056288, loss_ce: 0.014320
iteration 3325 : loss : 0.045345, loss_ce: 0.016379
iteration 3326 : loss : 0.043532, loss_ce: 0.015453
iteration 3327 : loss : 0.065421, loss_ce: 0.015172
iteration 3328 : loss : 0.039082, loss_ce: 0.013343
iteration 3329 : loss : 0.047806, loss_ce: 0.010662
iteration 3330 : loss : 0.039071, loss_ce: 0.010489
iteration 3331 : loss : 0.051641, loss_ce: 0.008936
iteration 3332 : loss : 0.040878, loss_ce: 0.019672
iteration 3333 : loss : 0.042848, loss_ce: 0.011559
iteration 3334 : loss : 0.047564, loss_ce: 0.018304
iteration 3335 : loss : 0.046636, loss_ce: 0.016880
iteration 3336 : loss : 0.038302, loss_ce: 0.010988
iteration 3337 : loss : 0.041679, loss_ce: 0.015313
iteration 3338 : loss : 0.136927, loss_ce: 0.003599
iteration 3339 : loss : 0.049462, loss_ce: 0.015733
iteration 3340 : loss : 0.064340, loss_ce: 0.012041
iteration 3341 : loss : 0.044366, loss_ce: 0.019620
iteration 3342 : loss : 0.038266, loss_ce: 0.016022
iteration 3343 : loss : 0.059773, loss_ce: 0.017206
iteration 3344 : loss : 0.040723, loss_ce: 0.013417
iteration 3345 : loss : 0.088194, loss_ce: 0.005141
iteration 3346 : loss : 0.047966, loss_ce: 0.008237
iteration 3347 : loss : 0.038576, loss_ce: 0.015225
iteration 3348 : loss : 0.246965, loss_ce: 0.027989
 18%|█████▍                        | 36/200 [32:34<2:28:55, 54.49s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 3349 : loss : 0.038150, loss_ce: 0.012667
iteration 3350 : loss : 0.047319, loss_ce: 0.017318
iteration 3351 : loss : 0.043783, loss_ce: 0.014346
iteration 3352 : loss : 0.030878, loss_ce: 0.011126
iteration 3353 : loss : 0.060553, loss_ce: 0.013119
iteration 3354 : loss : 0.057671, loss_ce: 0.020307
iteration 3355 : loss : 0.052616, loss_ce: 0.013572
iteration 3356 : loss : 0.033005, loss_ce: 0.009740
iteration 3357 : loss : 0.094607, loss_ce: 0.010987
iteration 3358 : loss : 0.047739, loss_ce: 0.014985
iteration 3359 : loss : 0.055085, loss_ce: 0.016644
iteration 3360 : loss : 0.042387, loss_ce: 0.009766
iteration 3361 : loss : 0.082365, loss_ce: 0.007720
iteration 3362 : loss : 0.045540, loss_ce: 0.014558
iteration 3363 : loss : 0.031734, loss_ce: 0.009212
iteration 3364 : loss : 0.086608, loss_ce: 0.012307
iteration 3365 : loss : 0.038977, loss_ce: 0.012050
iteration 3366 : loss : 0.048631, loss_ce: 0.013009
iteration 3367 : loss : 0.038238, loss_ce: 0.010175
iteration 3368 : loss : 0.039122, loss_ce: 0.011497
iteration 3369 : loss : 0.037333, loss_ce: 0.008967
iteration 3370 : loss : 0.048292, loss_ce: 0.012839
iteration 3371 : loss : 0.043938, loss_ce: 0.010583
iteration 3372 : loss : 0.042126, loss_ce: 0.012907
iteration 3373 : loss : 0.053993, loss_ce: 0.016887
iteration 3374 : loss : 0.038354, loss_ce: 0.015124
iteration 3375 : loss : 0.048246, loss_ce: 0.021287
iteration 3376 : loss : 0.049629, loss_ce: 0.014737
iteration 3377 : loss : 0.037353, loss_ce: 0.008004
iteration 3378 : loss : 0.085267, loss_ce: 0.007440
iteration 3379 : loss : 0.040750, loss_ce: 0.014657
pred_sum 2665
gtsum tensor(2525, device='cuda:0')
iteration 3380 : loss : 0.043575, loss_ce: 0.010631
iteration 3381 : loss : 0.054408, loss_ce: 0.014242
iteration 3382 : loss : 0.129220, loss_ce: 0.006801
iteration 3383 : loss : 0.043424, loss_ce: 0.018223
iteration 3384 : loss : 0.043989, loss_ce: 0.017484
iteration 3385 : loss : 0.038193, loss_ce: 0.013913
iteration 3386 : loss : 0.054146, loss_ce: 0.016455
iteration 3387 : loss : 0.089972, loss_ce: 0.013145
iteration 3388 : loss : 0.047230, loss_ce: 0.015132
iteration 3389 : loss : 0.039135, loss_ce: 0.005484
iteration 3390 : loss : 0.045902, loss_ce: 0.017206
iteration 3391 : loss : 0.035973, loss_ce: 0.016776
iteration 3392 : loss : 0.036348, loss_ce: 0.017398
iteration 3393 : loss : 0.049028, loss_ce: 0.017029
iteration 3394 : loss : 0.042436, loss_ce: 0.018024
iteration 3395 : loss : 0.033167, loss_ce: 0.013361
iteration 3396 : loss : 0.043846, loss_ce: 0.016143
iteration 3397 : loss : 0.072835, loss_ce: 0.015053
iteration 3398 : loss : 0.045288, loss_ce: 0.012079
iteration 3399 : loss : 0.040729, loss_ce: 0.015524
iteration 3400 : loss : 0.040950, loss_ce: 0.015205
iteration 3401 : loss : 0.036126, loss_ce: 0.014677
iteration 3402 : loss : 0.042543, loss_ce: 0.012621
iteration 3403 : loss : 0.039391, loss_ce: 0.014070
iteration 3404 : loss : 0.038551, loss_ce: 0.018381
iteration 3405 : loss : 0.088505, loss_ce: 0.010860
iteration 3406 : loss : 0.042191, loss_ce: 0.008666
iteration 3407 : loss : 0.063550, loss_ce: 0.011740
iteration 3408 : loss : 0.059868, loss_ce: 0.020359
iteration 3409 : loss : 0.053593, loss_ce: 0.019838
iteration 3410 : loss : 0.052467, loss_ce: 0.012439
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 3411 : loss : 0.034806, loss_ce: 0.013688
iteration 3412 : loss : 0.050381, loss_ce: 0.010854
iteration 3413 : loss : 0.037529, loss_ce: 0.012348
iteration 3414 : loss : 0.042663, loss_ce: 0.011068
iteration 3415 : loss : 0.047294, loss_ce: 0.017502
iteration 3416 : loss : 0.040809, loss_ce: 0.017520
iteration 3417 : loss : 0.038509, loss_ce: 0.015825
iteration 3418 : loss : 0.076368, loss_ce: 0.014027
iteration 3419 : loss : 0.097595, loss_ce: 0.010818
iteration 3420 : loss : 0.040108, loss_ce: 0.018082
iteration 3421 : loss : 0.047219, loss_ce: 0.014609
iteration 3422 : loss : 0.035054, loss_ce: 0.012119
iteration 3423 : loss : 0.057255, loss_ce: 0.017813
iteration 3424 : loss : 0.052608, loss_ce: 0.015368
iteration 3425 : loss : 0.055729, loss_ce: 0.015495
iteration 3426 : loss : 0.052256, loss_ce: 0.010689
iteration 3427 : loss : 0.038315, loss_ce: 0.011501
iteration 3428 : loss : 0.038338, loss_ce: 0.010766
iteration 3429 : loss : 0.045956, loss_ce: 0.018145
iteration 3430 : loss : 0.040276, loss_ce: 0.018879
iteration 3431 : loss : 0.089338, loss_ce: 0.010011
iteration 3432 : loss : 0.046283, loss_ce: 0.014944
iteration 3433 : loss : 0.042900, loss_ce: 0.017940
iteration 3434 : loss : 0.045806, loss_ce: 0.018932
iteration 3435 : loss : 0.047097, loss_ce: 0.013344
iteration 3436 : loss : 0.039489, loss_ce: 0.010371
iteration 3437 : loss : 0.040189, loss_ce: 0.015149
iteration 3438 : loss : 0.044458, loss_ce: 0.022205
iteration 3439 : loss : 0.041082, loss_ce: 0.017556
iteration 3440 : loss : 0.039579, loss_ce: 0.014305
iteration 3441 : loss : 0.141475, loss_ce: 0.016479
 18%|█████▌                        | 37/200 [33:28<2:28:01, 54.49s/it]pred_sum 31191
gtsum tensor(30929, device='cuda:0')
iteration 3442 : loss : 0.105969, loss_ce: 0.007764
iteration 3443 : loss : 0.041675, loss_ce: 0.011272
iteration 3444 : loss : 0.038714, loss_ce: 0.018665
iteration 3445 : loss : 0.089889, loss_ce: 0.013626
iteration 3446 : loss : 0.047608, loss_ce: 0.017412
iteration 3447 : loss : 0.045494, loss_ce: 0.016143
iteration 3448 : loss : 0.044627, loss_ce: 0.011571
iteration 3449 : loss : 0.086915, loss_ce: 0.012345
iteration 3450 : loss : 0.043733, loss_ce: 0.016812
iteration 3451 : loss : 0.039692, loss_ce: 0.010528
iteration 3452 : loss : 0.041354, loss_ce: 0.014858
iteration 3453 : loss : 0.046390, loss_ce: 0.020633
iteration 3454 : loss : 0.040123, loss_ce: 0.014955
iteration 3455 : loss : 0.039014, loss_ce: 0.010155
iteration 3456 : loss : 0.035463, loss_ce: 0.014243
iteration 3457 : loss : 0.045414, loss_ce: 0.017157
iteration 3458 : loss : 0.037766, loss_ce: 0.015044
iteration 3459 : loss : 0.051893, loss_ce: 0.009572
iteration 3460 : loss : 0.034396, loss_ce: 0.009437
iteration 3461 : loss : 0.037141, loss_ce: 0.011622
iteration 3462 : loss : 0.093920, loss_ce: 0.013013
iteration 3463 : loss : 0.042620, loss_ce: 0.005490
iteration 3464 : loss : 0.038353, loss_ce: 0.012263
iteration 3465 : loss : 0.039983, loss_ce: 0.018337
iteration 3466 : loss : 0.051803, loss_ce: 0.020056
iteration 3467 : loss : 0.034189, loss_ce: 0.013031
iteration 3468 : loss : 0.042915, loss_ce: 0.012111
iteration 3469 : loss : 0.036263, loss_ce: 0.015484
iteration 3470 : loss : 0.047691, loss_ce: 0.017621
iteration 3471 : loss : 0.050487, loss_ce: 0.008178
iteration 3472 : loss : 0.048503, loss_ce: 0.029465
pred_sum 45741
gtsum tensor(51117, device='cuda:0')
iteration 3473 : loss : 0.046821, loss_ce: 0.014349
iteration 3474 : loss : 0.040379, loss_ce: 0.013113
iteration 3475 : loss : 0.053664, loss_ce: 0.018288
iteration 3476 : loss : 0.050730, loss_ce: 0.016599
iteration 3477 : loss : 0.049390, loss_ce: 0.017835
iteration 3478 : loss : 0.035532, loss_ce: 0.014713
iteration 3479 : loss : 0.032932, loss_ce: 0.009748
iteration 3480 : loss : 0.048790, loss_ce: 0.012616
iteration 3481 : loss : 0.044079, loss_ce: 0.008001
iteration 3482 : loss : 0.041695, loss_ce: 0.013735
iteration 3483 : loss : 0.046923, loss_ce: 0.016539
iteration 3484 : loss : 0.052564, loss_ce: 0.022234
iteration 3485 : loss : 0.031886, loss_ce: 0.008414
iteration 3486 : loss : 0.049604, loss_ce: 0.015536
iteration 3487 : loss : 0.084945, loss_ce: 0.006587
iteration 3488 : loss : 0.099191, loss_ce: 0.006944
iteration 3489 : loss : 0.053716, loss_ce: 0.009156
iteration 3490 : loss : 0.037885, loss_ce: 0.013987
iteration 3491 : loss : 0.047358, loss_ce: 0.012293
iteration 3492 : loss : 0.070013, loss_ce: 0.008262
iteration 3493 : loss : 0.038526, loss_ce: 0.013426
iteration 3494 : loss : 0.038612, loss_ce: 0.013830
iteration 3495 : loss : 0.038244, loss_ce: 0.012181
iteration 3496 : loss : 0.039006, loss_ce: 0.009714
iteration 3497 : loss : 0.047693, loss_ce: 0.015298
iteration 3498 : loss : 0.051829, loss_ce: 0.014688
iteration 3499 : loss : 0.041136, loss_ce: 0.011996
iteration 3500 : loss : 0.114664, loss_ce: 0.007578
iteration 3501 : loss : 0.027633, loss_ce: 0.008659
iteration 3502 : loss : 0.086522, loss_ce: 0.009198
iteration 3503 : loss : 0.045686, loss_ce: 0.017550
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 3504 : loss : 0.041778, loss_ce: 0.010007
iteration 3505 : loss : 0.038869, loss_ce: 0.013649
iteration 3506 : loss : 0.048752, loss_ce: 0.017858
iteration 3507 : loss : 0.046646, loss_ce: 0.010858
iteration 3508 : loss : 0.053697, loss_ce: 0.023613
iteration 3509 : loss : 0.051670, loss_ce: 0.013709
iteration 3510 : loss : 0.038864, loss_ce: 0.013773
iteration 3511 : loss : 0.064007, loss_ce: 0.013419
iteration 3512 : loss : 0.042471, loss_ce: 0.013474
iteration 3513 : loss : 0.042063, loss_ce: 0.016721
iteration 3514 : loss : 0.049710, loss_ce: 0.012782
iteration 3515 : loss : 0.100868, loss_ce: 0.010952
iteration 3516 : loss : 0.040422, loss_ce: 0.015944
iteration 3517 : loss : 0.096354, loss_ce: 0.008833
iteration 3518 : loss : 0.061413, loss_ce: 0.013243
iteration 3519 : loss : 0.089434, loss_ce: 0.016226
iteration 3520 : loss : 0.070092, loss_ce: 0.011773
iteration 3521 : loss : 0.036829, loss_ce: 0.011859
iteration 3522 : loss : 0.052558, loss_ce: 0.022199
iteration 3523 : loss : 0.055557, loss_ce: 0.023183
iteration 3524 : loss : 0.052100, loss_ce: 0.014904
iteration 3525 : loss : 0.054339, loss_ce: 0.015405
iteration 3526 : loss : 0.037930, loss_ce: 0.017606
iteration 3527 : loss : 0.036875, loss_ce: 0.014143
iteration 3528 : loss : 0.046672, loss_ce: 0.019199
iteration 3529 : loss : 0.038941, loss_ce: 0.012238
iteration 3530 : loss : 0.053516, loss_ce: 0.023145
iteration 3531 : loss : 0.048317, loss_ce: 0.015537
iteration 3532 : loss : 0.050349, loss_ce: 0.014020
iteration 3533 : loss : 0.040750, loss_ce: 0.012811
iteration 3534 : loss : 0.238121, loss_ce: 0.011682
 19%|█████▋                        | 38/200 [34:23<2:27:09, 54.50s/it]pred_sum 153
gtsum tensor(144, device='cuda:0')
iteration 3535 : loss : 0.038399, loss_ce: 0.011002
iteration 3536 : loss : 0.057409, loss_ce: 0.017019
iteration 3537 : loss : 0.047555, loss_ce: 0.021223
iteration 3538 : loss : 0.043687, loss_ce: 0.013793
iteration 3539 : loss : 0.090935, loss_ce: 0.011761
iteration 3540 : loss : 0.037683, loss_ce: 0.013851
iteration 3541 : loss : 0.031384, loss_ce: 0.008644
iteration 3542 : loss : 0.044164, loss_ce: 0.018060
iteration 3543 : loss : 0.040089, loss_ce: 0.016611
iteration 3544 : loss : 0.036359, loss_ce: 0.011080
iteration 3545 : loss : 0.084759, loss_ce: 0.009662
iteration 3546 : loss : 0.055183, loss_ce: 0.015718
iteration 3547 : loss : 0.046452, loss_ce: 0.022973
iteration 3548 : loss : 0.039498, loss_ce: 0.016051
iteration 3549 : loss : 0.048429, loss_ce: 0.017447
iteration 3550 : loss : 0.037874, loss_ce: 0.013131
iteration 3551 : loss : 0.047828, loss_ce: 0.019338
iteration 3552 : loss : 0.037817, loss_ce: 0.015978
iteration 3553 : loss : 0.036420, loss_ce: 0.015839
iteration 3554 : loss : 0.026851, loss_ce: 0.007691
iteration 3555 : loss : 0.046157, loss_ce: 0.009020
iteration 3556 : loss : 0.044984, loss_ce: 0.010185
iteration 3557 : loss : 0.101686, loss_ce: 0.008695
iteration 3558 : loss : 0.040081, loss_ce: 0.014812
iteration 3559 : loss : 0.043474, loss_ce: 0.014691
iteration 3560 : loss : 0.030875, loss_ce: 0.013114
iteration 3561 : loss : 0.034983, loss_ce: 0.013345
iteration 3562 : loss : 0.049625, loss_ce: 0.019589
iteration 3563 : loss : 0.042726, loss_ce: 0.015567
iteration 3564 : loss : 0.041289, loss_ce: 0.010647
iteration 3565 : loss : 0.094251, loss_ce: 0.007983
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 3566 : loss : 0.036455, loss_ce: 0.013018
iteration 3567 : loss : 0.095075, loss_ce: 0.011661
iteration 3568 : loss : 0.081282, loss_ce: 0.014927
iteration 3569 : loss : 0.053086, loss_ce: 0.015733
iteration 3570 : loss : 0.067807, loss_ce: 0.015602
iteration 3571 : loss : 0.043682, loss_ce: 0.018079
iteration 3572 : loss : 0.052895, loss_ce: 0.013357
iteration 3573 : loss : 0.051161, loss_ce: 0.025532
iteration 3574 : loss : 0.037346, loss_ce: 0.011059
iteration 3575 : loss : 0.059300, loss_ce: 0.016452
iteration 3576 : loss : 0.074735, loss_ce: 0.015499
iteration 3577 : loss : 0.046835, loss_ce: 0.014641
iteration 3578 : loss : 0.091437, loss_ce: 0.006588
iteration 3579 : loss : 0.053833, loss_ce: 0.005488
iteration 3580 : loss : 0.050220, loss_ce: 0.010906
iteration 3581 : loss : 0.034437, loss_ce: 0.011880
iteration 3582 : loss : 0.041022, loss_ce: 0.013074
iteration 3583 : loss : 0.035361, loss_ce: 0.014979
iteration 3584 : loss : 0.047226, loss_ce: 0.014035
iteration 3585 : loss : 0.050307, loss_ce: 0.017552
iteration 3586 : loss : 0.039219, loss_ce: 0.009153
iteration 3587 : loss : 0.042752, loss_ce: 0.014327
iteration 3588 : loss : 0.037505, loss_ce: 0.013038
iteration 3589 : loss : 0.038162, loss_ce: 0.011833
iteration 3590 : loss : 0.046493, loss_ce: 0.013403
iteration 3591 : loss : 0.041024, loss_ce: 0.013278
iteration 3592 : loss : 0.105684, loss_ce: 0.008080
iteration 3593 : loss : 0.090550, loss_ce: 0.012891
iteration 3594 : loss : 0.043902, loss_ce: 0.019502
iteration 3595 : loss : 0.040039, loss_ce: 0.013930
iteration 3596 : loss : 0.043866, loss_ce: 0.016827
pred_sum 1369
gtsum tensor(1155, device='cuda:0')
iteration 3597 : loss : 0.069804, loss_ce: 0.015316
iteration 3598 : loss : 0.055143, loss_ce: 0.022268
iteration 3599 : loss : 0.039689, loss_ce: 0.014304
iteration 3600 : loss : 0.046639, loss_ce: 0.017275
iteration 3601 : loss : 0.041605, loss_ce: 0.014713
iteration 3602 : loss : 0.046155, loss_ce: 0.011075
iteration 3603 : loss : 0.037856, loss_ce: 0.008617
iteration 3604 : loss : 0.036444, loss_ce: 0.012566
iteration 3605 : loss : 0.028891, loss_ce: 0.007013
iteration 3606 : loss : 0.044077, loss_ce: 0.019590
iteration 3607 : loss : 0.037199, loss_ce: 0.016232
iteration 3608 : loss : 0.033337, loss_ce: 0.007915
iteration 3609 : loss : 0.041177, loss_ce: 0.016090
iteration 3610 : loss : 0.056956, loss_ce: 0.016723
iteration 3611 : loss : 0.042823, loss_ce: 0.013075
iteration 3612 : loss : 0.037801, loss_ce: 0.013342
iteration 3613 : loss : 0.039091, loss_ce: 0.012586
iteration 3614 : loss : 0.046320, loss_ce: 0.013227
iteration 3615 : loss : 0.041941, loss_ce: 0.009530
iteration 3616 : loss : 0.045690, loss_ce: 0.013177
iteration 3617 : loss : 0.085243, loss_ce: 0.011387
iteration 3618 : loss : 0.038584, loss_ce: 0.011235
iteration 3619 : loss : 0.037299, loss_ce: 0.012979
iteration 3620 : loss : 0.037876, loss_ce: 0.010124
iteration 3621 : loss : 0.065310, loss_ce: 0.015460
iteration 3622 : loss : 0.032404, loss_ce: 0.012017
iteration 3623 : loss : 0.036972, loss_ce: 0.013697
iteration 3624 : loss : 0.050706, loss_ce: 0.018080
iteration 3625 : loss : 0.084814, loss_ce: 0.015635
iteration 3626 : loss : 0.047234, loss_ce: 0.015958
iteration 3627 : loss : 0.445255, loss_ce: 0.001710
 20%|█████▊                        | 39/200 [35:17<2:26:14, 54.50s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 3628 : loss : 0.036036, loss_ce: 0.012231
iteration 3629 : loss : 0.092663, loss_ce: 0.012126
iteration 3630 : loss : 0.037657, loss_ce: 0.015042
iteration 3631 : loss : 0.047582, loss_ce: 0.011269
iteration 3632 : loss : 0.041583, loss_ce: 0.016437
iteration 3633 : loss : 0.039252, loss_ce: 0.013981
iteration 3634 : loss : 0.044958, loss_ce: 0.014680
iteration 3635 : loss : 0.037241, loss_ce: 0.010770
iteration 3636 : loss : 0.035914, loss_ce: 0.013740
iteration 3637 : loss : 0.040037, loss_ce: 0.018107
iteration 3638 : loss : 0.041667, loss_ce: 0.015898
iteration 3639 : loss : 0.039203, loss_ce: 0.016797
iteration 3640 : loss : 0.086319, loss_ce: 0.009603
iteration 3641 : loss : 0.023549, loss_ce: 0.007789
iteration 3642 : loss : 0.043639, loss_ce: 0.007461
iteration 3643 : loss : 0.037799, loss_ce: 0.017828
iteration 3644 : loss : 0.033837, loss_ce: 0.014870
iteration 3645 : loss : 0.039694, loss_ce: 0.016505
iteration 3646 : loss : 0.036055, loss_ce: 0.008934
iteration 3647 : loss : 0.037581, loss_ce: 0.011159
iteration 3648 : loss : 0.037336, loss_ce: 0.007233
iteration 3649 : loss : 0.048381, loss_ce: 0.012037
iteration 3650 : loss : 0.038233, loss_ce: 0.012433
iteration 3651 : loss : 0.038196, loss_ce: 0.014403
iteration 3652 : loss : 0.082733, loss_ce: 0.006955
iteration 3653 : loss : 0.044455, loss_ce: 0.009114
iteration 3654 : loss : 0.034973, loss_ce: 0.015125
iteration 3655 : loss : 0.084383, loss_ce: 0.007878
iteration 3656 : loss : 0.038933, loss_ce: 0.008969
iteration 3657 : loss : 0.040554, loss_ce: 0.009703
iteration 3658 : loss : 0.042467, loss_ce: 0.013905
pred_sum 19267
gtsum tensor(20285, device='cuda:0')
iteration 3659 : loss : 0.037809, loss_ce: 0.014737
iteration 3660 : loss : 0.039767, loss_ce: 0.011836
iteration 3661 : loss : 0.051318, loss_ce: 0.010714
iteration 3662 : loss : 0.036709, loss_ce: 0.012522
iteration 3663 : loss : 0.085917, loss_ce: 0.009505
iteration 3664 : loss : 0.035207, loss_ce: 0.013426
iteration 3665 : loss : 0.047698, loss_ce: 0.009348
iteration 3666 : loss : 0.069317, loss_ce: 0.013893
iteration 3667 : loss : 0.044405, loss_ce: 0.022171
iteration 3668 : loss : 0.044386, loss_ce: 0.014881
iteration 3669 : loss : 0.034900, loss_ce: 0.016445
iteration 3670 : loss : 0.059969, loss_ce: 0.022680
iteration 3671 : loss : 0.040894, loss_ce: 0.011661
iteration 3672 : loss : 0.042183, loss_ce: 0.006889
iteration 3673 : loss : 0.077961, loss_ce: 0.014887
iteration 3674 : loss : 0.039408, loss_ce: 0.013869
iteration 3675 : loss : 0.054088, loss_ce: 0.016417
iteration 3676 : loss : 0.043895, loss_ce: 0.016331
iteration 3677 : loss : 0.042691, loss_ce: 0.017242
iteration 3678 : loss : 0.046494, loss_ce: 0.016396
iteration 3679 : loss : 0.049873, loss_ce: 0.018002
iteration 3680 : loss : 0.042372, loss_ce: 0.012125
iteration 3681 : loss : 0.046477, loss_ce: 0.017953
iteration 3682 : loss : 0.050701, loss_ce: 0.013815
iteration 3683 : loss : 0.041768, loss_ce: 0.013986
iteration 3684 : loss : 0.042800, loss_ce: 0.014741
iteration 3685 : loss : 0.193317, loss_ce: 0.003566
iteration 3686 : loss : 0.059669, loss_ce: 0.016813
iteration 3687 : loss : 0.036952, loss_ce: 0.008660
iteration 3688 : loss : 0.037905, loss_ce: 0.013992
iteration 3689 : loss : 0.039281, loss_ce: 0.016622
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 3690 : loss : 0.042949, loss_ce: 0.013003
iteration 3691 : loss : 0.041535, loss_ce: 0.015193
iteration 3692 : loss : 0.039823, loss_ce: 0.013377
iteration 3693 : loss : 0.073986, loss_ce: 0.013808
iteration 3694 : loss : 0.043191, loss_ce: 0.016608
iteration 3695 : loss : 0.040424, loss_ce: 0.011959
iteration 3696 : loss : 0.049591, loss_ce: 0.013517
iteration 3697 : loss : 0.044699, loss_ce: 0.013371
iteration 3698 : loss : 0.033501, loss_ce: 0.011756
iteration 3699 : loss : 0.040162, loss_ce: 0.012152
iteration 3700 : loss : 0.035952, loss_ce: 0.014340
iteration 3701 : loss : 0.046905, loss_ce: 0.015057
iteration 3702 : loss : 0.133907, loss_ce: 0.008461
iteration 3703 : loss : 0.089976, loss_ce: 0.011640
iteration 3704 : loss : 0.038552, loss_ce: 0.012907
iteration 3705 : loss : 0.039068, loss_ce: 0.018819
iteration 3706 : loss : 0.048015, loss_ce: 0.012727
iteration 3707 : loss : 0.047650, loss_ce: 0.011433
iteration 3708 : loss : 0.037030, loss_ce: 0.008879
iteration 3709 : loss : 0.038246, loss_ce: 0.011976
iteration 3710 : loss : 0.038813, loss_ce: 0.011098
iteration 3711 : loss : 0.085416, loss_ce: 0.008458
iteration 3712 : loss : 0.048268, loss_ce: 0.020284
iteration 3713 : loss : 0.034847, loss_ce: 0.012965
iteration 3714 : loss : 0.034202, loss_ce: 0.007878
iteration 3715 : loss : 0.042115, loss_ce: 0.017769
iteration 3716 : loss : 0.036160, loss_ce: 0.012515
iteration 3717 : loss : 0.035802, loss_ce: 0.012035
iteration 3718 : loss : 0.041879, loss_ce: 0.021365
iteration 3719 : loss : 0.028976, loss_ce: 0.008524
iteration 3720 : loss : 0.290960, loss_ce: 0.008584
 20%|██████                        | 40/200 [36:12<2:25:20, 54.50s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 3721 : loss : 0.050471, loss_ce: 0.009757
iteration 3722 : loss : 0.040702, loss_ce: 0.014741
iteration 3723 : loss : 0.038779, loss_ce: 0.015310
iteration 3724 : loss : 0.040616, loss_ce: 0.015568
iteration 3725 : loss : 0.030065, loss_ce: 0.009603
iteration 3726 : loss : 0.040378, loss_ce: 0.015800
iteration 3727 : loss : 0.046340, loss_ce: 0.016787
iteration 3728 : loss : 0.055734, loss_ce: 0.007562
iteration 3729 : loss : 0.035136, loss_ce: 0.008229
iteration 3730 : loss : 0.038458, loss_ce: 0.010954
iteration 3731 : loss : 0.087154, loss_ce: 0.013328
iteration 3732 : loss : 0.075419, loss_ce: 0.015786
iteration 3733 : loss : 0.036642, loss_ce: 0.010613
iteration 3734 : loss : 0.038086, loss_ce: 0.014242
iteration 3735 : loss : 0.046630, loss_ce: 0.018292
iteration 3736 : loss : 0.042302, loss_ce: 0.014017
iteration 3737 : loss : 0.046658, loss_ce: 0.018933
iteration 3738 : loss : 0.096839, loss_ce: 0.017210
iteration 3739 : loss : 0.037315, loss_ce: 0.013629
iteration 3740 : loss : 0.037272, loss_ce: 0.007920
iteration 3741 : loss : 0.032919, loss_ce: 0.013704
iteration 3742 : loss : 0.040356, loss_ce: 0.016683
iteration 3743 : loss : 0.043399, loss_ce: 0.015310
iteration 3744 : loss : 0.043081, loss_ce: 0.018714
iteration 3745 : loss : 0.038882, loss_ce: 0.013144
iteration 3746 : loss : 0.039620, loss_ce: 0.012176
iteration 3747 : loss : 0.036564, loss_ce: 0.015778
iteration 3748 : loss : 0.061154, loss_ce: 0.009787
iteration 3749 : loss : 0.037066, loss_ce: 0.015216
iteration 3750 : loss : 0.047121, loss_ce: 0.020617
iteration 3751 : loss : 0.086842, loss_ce: 0.006313
pred_sum 6822
gtsum tensor(7292, device='cuda:0')
iteration 3752 : loss : 0.037320, loss_ce: 0.010561
iteration 3753 : loss : 0.073466, loss_ce: 0.006828
iteration 3754 : loss : 0.034776, loss_ce: 0.009854
iteration 3755 : loss : 0.044550, loss_ce: 0.011744
iteration 3756 : loss : 0.051852, loss_ce: 0.022714
iteration 3757 : loss : 0.042523, loss_ce: 0.008900
iteration 3758 : loss : 0.055315, loss_ce: 0.015082
iteration 3759 : loss : 0.044260, loss_ce: 0.020623
iteration 3760 : loss : 0.038011, loss_ce: 0.014114
iteration 3761 : loss : 0.088209, loss_ce: 0.014106
iteration 3762 : loss : 0.034689, loss_ce: 0.009699
iteration 3763 : loss : 0.041324, loss_ce: 0.012651
iteration 3764 : loss : 0.047733, loss_ce: 0.009510
iteration 3765 : loss : 0.031282, loss_ce: 0.012176
iteration 3766 : loss : 0.075573, loss_ce: 0.017285
iteration 3767 : loss : 0.045253, loss_ce: 0.016652
iteration 3768 : loss : 0.032056, loss_ce: 0.016994
iteration 3769 : loss : 0.051621, loss_ce: 0.014289
iteration 3770 : loss : 0.032965, loss_ce: 0.007035
iteration 3771 : loss : 0.037967, loss_ce: 0.016445
iteration 3772 : loss : 0.041278, loss_ce: 0.010118
iteration 3773 : loss : 0.096915, loss_ce: 0.006253
iteration 3774 : loss : 0.046385, loss_ce: 0.014921
iteration 3775 : loss : 0.040461, loss_ce: 0.016375
iteration 3776 : loss : 0.042589, loss_ce: 0.010593
iteration 3777 : loss : 0.043504, loss_ce: 0.008499
iteration 3778 : loss : 0.038875, loss_ce: 0.013577
iteration 3779 : loss : 0.040123, loss_ce: 0.015015
iteration 3780 : loss : 0.046550, loss_ce: 0.010960
iteration 3781 : loss : 0.085010, loss_ce: 0.011919
iteration 3782 : loss : 0.041260, loss_ce: 0.018141
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 3783 : loss : 0.036785, loss_ce: 0.008703
iteration 3784 : loss : 0.133977, loss_ce: 0.005196
iteration 3785 : loss : 0.088912, loss_ce: 0.012321
iteration 3786 : loss : 0.033415, loss_ce: 0.010581
iteration 3787 : loss : 0.047125, loss_ce: 0.017835
iteration 3788 : loss : 0.038908, loss_ce: 0.013888
iteration 3789 : loss : 0.046913, loss_ce: 0.020174
iteration 3790 : loss : 0.035601, loss_ce: 0.012277
iteration 3791 : loss : 0.045268, loss_ce: 0.014170
iteration 3792 : loss : 0.047028, loss_ce: 0.016474
iteration 3793 : loss : 0.124139, loss_ce: 0.005312
iteration 3794 : loss : 0.033287, loss_ce: 0.008344
iteration 3795 : loss : 0.040489, loss_ce: 0.010124
iteration 3796 : loss : 0.038337, loss_ce: 0.013701
iteration 3797 : loss : 0.034897, loss_ce: 0.012970
iteration 3798 : loss : 0.041420, loss_ce: 0.016313
iteration 3799 : loss : 0.040764, loss_ce: 0.010870
iteration 3800 : loss : 0.034084, loss_ce: 0.013436
iteration 3801 : loss : 0.040559, loss_ce: 0.013049
iteration 3802 : loss : 0.039897, loss_ce: 0.011038
iteration 3803 : loss : 0.036685, loss_ce: 0.010366
iteration 3804 : loss : 0.038992, loss_ce: 0.011484
iteration 3805 : loss : 0.051855, loss_ce: 0.022677
iteration 3806 : loss : 0.036712, loss_ce: 0.010079
iteration 3807 : loss : 0.047892, loss_ce: 0.010441
iteration 3808 : loss : 0.037879, loss_ce: 0.007917
iteration 3809 : loss : 0.034742, loss_ce: 0.016491
iteration 3810 : loss : 0.037219, loss_ce: 0.015448
iteration 3811 : loss : 0.042262, loss_ce: 0.009737
iteration 3812 : loss : 0.097783, loss_ce: 0.007652
iteration 3813 : loss : 0.445343, loss_ce: 0.002349
 20%|██████▏                       | 41/200 [37:06<2:24:29, 54.52s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 3814 : loss : 0.083207, loss_ce: 0.011491
iteration 3815 : loss : 0.039053, loss_ce: 0.010195
iteration 3816 : loss : 0.056473, loss_ce: 0.017510
iteration 3817 : loss : 0.046973, loss_ce: 0.011983
iteration 3818 : loss : 0.051707, loss_ce: 0.012954
iteration 3819 : loss : 0.039988, loss_ce: 0.016450
iteration 3820 : loss : 0.037930, loss_ce: 0.010299
iteration 3821 : loss : 0.041449, loss_ce: 0.015973
iteration 3822 : loss : 0.086244, loss_ce: 0.011569
iteration 3823 : loss : 0.036624, loss_ce: 0.009454
iteration 3824 : loss : 0.088475, loss_ce: 0.008400
iteration 3825 : loss : 0.034311, loss_ce: 0.012385
iteration 3826 : loss : 0.086279, loss_ce: 0.009140
iteration 3827 : loss : 0.045697, loss_ce: 0.011031
iteration 3828 : loss : 0.043346, loss_ce: 0.010949
iteration 3829 : loss : 0.038672, loss_ce: 0.007976
iteration 3830 : loss : 0.039655, loss_ce: 0.014441
iteration 3831 : loss : 0.041619, loss_ce: 0.013917
iteration 3832 : loss : 0.036142, loss_ce: 0.012821
iteration 3833 : loss : 0.031862, loss_ce: 0.011105
iteration 3834 : loss : 0.042070, loss_ce: 0.016803
iteration 3835 : loss : 0.049246, loss_ce: 0.011860
iteration 3836 : loss : 0.049358, loss_ce: 0.023516
iteration 3837 : loss : 0.037501, loss_ce: 0.013210
iteration 3838 : loss : 0.063022, loss_ce: 0.008476
iteration 3839 : loss : 0.042302, loss_ce: 0.010015
iteration 3840 : loss : 0.037516, loss_ce: 0.017132
iteration 3841 : loss : 0.046630, loss_ce: 0.015749
iteration 3842 : loss : 0.062987, loss_ce: 0.014492
iteration 3843 : loss : 0.058896, loss_ce: 0.014659
iteration 3844 : loss : 0.069667, loss_ce: 0.013836
pred_sum 325
gtsum tensor(330, device='cuda:0')
iteration 3845 : loss : 0.056396, loss_ce: 0.012873
iteration 3846 : loss : 0.049969, loss_ce: 0.013152
iteration 3847 : loss : 0.031731, loss_ce: 0.007769
iteration 3848 : loss : 0.054645, loss_ce: 0.015905
iteration 3849 : loss : 0.067539, loss_ce: 0.017242
iteration 3850 : loss : 0.051425, loss_ce: 0.016953
iteration 3851 : loss : 0.084092, loss_ce: 0.018572
iteration 3852 : loss : 0.054259, loss_ce: 0.021214
iteration 3853 : loss : 0.090944, loss_ce: 0.016790
iteration 3854 : loss : 0.103380, loss_ce: 0.019163
iteration 3855 : loss : 0.060312, loss_ce: 0.014935
iteration 3856 : loss : 0.061887, loss_ce: 0.016006
iteration 3857 : loss : 0.061327, loss_ce: 0.014448
iteration 3858 : loss : 0.056390, loss_ce: 0.018817
iteration 3859 : loss : 0.063415, loss_ce: 0.013360
iteration 3860 : loss : 0.039156, loss_ce: 0.017072
iteration 3861 : loss : 0.034895, loss_ce: 0.016050
iteration 3862 : loss : 0.050026, loss_ce: 0.017769
iteration 3863 : loss : 0.091819, loss_ce: 0.015454
iteration 3864 : loss : 0.042408, loss_ce: 0.018698
iteration 3865 : loss : 0.066623, loss_ce: 0.014689
iteration 3866 : loss : 0.059832, loss_ce: 0.009874
iteration 3867 : loss : 0.046684, loss_ce: 0.016386
iteration 3868 : loss : 0.040010, loss_ce: 0.018055
iteration 3869 : loss : 0.044279, loss_ce: 0.012935
iteration 3870 : loss : 0.035020, loss_ce: 0.012158
iteration 3871 : loss : 0.043249, loss_ce: 0.014709
iteration 3872 : loss : 0.073185, loss_ce: 0.014622
iteration 3873 : loss : 0.063954, loss_ce: 0.009881
iteration 3874 : loss : 0.100206, loss_ce: 0.014489
iteration 3875 : loss : 0.043311, loss_ce: 0.016309
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 3876 : loss : 0.043950, loss_ce: 0.014693
iteration 3877 : loss : 0.058632, loss_ce: 0.013170
iteration 3878 : loss : 0.059607, loss_ce: 0.028173
iteration 3879 : loss : 0.070909, loss_ce: 0.015094
iteration 3880 : loss : 0.044291, loss_ce: 0.012411
iteration 3881 : loss : 0.061338, loss_ce: 0.024613
iteration 3882 : loss : 0.068143, loss_ce: 0.015675
iteration 3883 : loss : 0.094252, loss_ce: 0.013907
iteration 3884 : loss : 0.043810, loss_ce: 0.016786
iteration 3885 : loss : 0.064699, loss_ce: 0.024956
iteration 3886 : loss : 0.054594, loss_ce: 0.018713
iteration 3887 : loss : 0.042248, loss_ce: 0.010698
iteration 3888 : loss : 0.044870, loss_ce: 0.013928
iteration 3889 : loss : 0.053187, loss_ce: 0.022639
iteration 3890 : loss : 0.054327, loss_ce: 0.018457
iteration 3891 : loss : 0.054162, loss_ce: 0.014812
iteration 3892 : loss : 0.050753, loss_ce: 0.021599
iteration 3893 : loss : 0.098616, loss_ce: 0.009972
iteration 3894 : loss : 0.050480, loss_ce: 0.020913
iteration 3895 : loss : 0.058842, loss_ce: 0.013037
iteration 3896 : loss : 0.052767, loss_ce: 0.016007
iteration 3897 : loss : 0.060619, loss_ce: 0.013302
iteration 3898 : loss : 0.046700, loss_ce: 0.013922
iteration 3899 : loss : 0.046833, loss_ce: 0.014238
iteration 3900 : loss : 0.057497, loss_ce: 0.010656
iteration 3901 : loss : 0.046369, loss_ce: 0.017081
iteration 3902 : loss : 0.100105, loss_ce: 0.011590
iteration 3903 : loss : 0.039970, loss_ce: 0.010699
iteration 3904 : loss : 0.044926, loss_ce: 0.012696
iteration 3905 : loss : 0.043555, loss_ce: 0.019725
iteration 3906 : loss : 0.091051, loss_ce: 0.023802
 21%|██████▎                       | 42/200 [38:01<2:23:35, 54.53s/it]pred_sum 35668
gtsum tensor(41006, device='cuda:0')
iteration 3907 : loss : 0.047426, loss_ce: 0.014304
iteration 3908 : loss : 0.050045, loss_ce: 0.017023
iteration 3909 : loss : 0.054899, loss_ce: 0.019932
iteration 3910 : loss : 0.048507, loss_ce: 0.018370
iteration 3911 : loss : 0.053373, loss_ce: 0.023786
iteration 3912 : loss : 0.101402, loss_ce: 0.018009
iteration 3913 : loss : 0.040202, loss_ce: 0.014145
iteration 3914 : loss : 0.050654, loss_ce: 0.021700
iteration 3915 : loss : 0.053796, loss_ce: 0.022619
iteration 3916 : loss : 0.051537, loss_ce: 0.011776
iteration 3917 : loss : 0.035445, loss_ce: 0.009446
iteration 3918 : loss : 0.055249, loss_ce: 0.013804
iteration 3919 : loss : 0.103755, loss_ce: 0.015413
iteration 3920 : loss : 0.042690, loss_ce: 0.015383
iteration 3921 : loss : 0.080547, loss_ce: 0.019497
iteration 3922 : loss : 0.046335, loss_ce: 0.018068
iteration 3923 : loss : 0.054568, loss_ce: 0.015365
iteration 3924 : loss : 0.056259, loss_ce: 0.012118
iteration 3925 : loss : 0.036586, loss_ce: 0.013713
iteration 3926 : loss : 0.044841, loss_ce: 0.015525
iteration 3927 : loss : 0.094739, loss_ce: 0.010887
iteration 3928 : loss : 0.034889, loss_ce: 0.012117
iteration 3929 : loss : 0.038955, loss_ce: 0.012591
iteration 3930 : loss : 0.044824, loss_ce: 0.010310
iteration 3931 : loss : 0.091240, loss_ce: 0.010426
iteration 3932 : loss : 0.048448, loss_ce: 0.020018
iteration 3933 : loss : 0.053049, loss_ce: 0.014049
iteration 3934 : loss : 0.043366, loss_ce: 0.010536
iteration 3935 : loss : 0.043030, loss_ce: 0.013568
iteration 3936 : loss : 0.039712, loss_ce: 0.015820
iteration 3937 : loss : 0.035797, loss_ce: 0.016215
pred_sum 22572
gtsum tensor(23033, device='cuda:0')
iteration 3938 : loss : 0.042539, loss_ce: 0.010382
iteration 3939 : loss : 0.109425, loss_ce: 0.007975
iteration 3940 : loss : 0.034030, loss_ce: 0.008871
iteration 3941 : loss : 0.050445, loss_ce: 0.021117
iteration 3942 : loss : 0.092142, loss_ce: 0.006280
iteration 3943 : loss : 0.073224, loss_ce: 0.011919
iteration 3944 : loss : 0.050466, loss_ce: 0.014440
iteration 3945 : loss : 0.071749, loss_ce: 0.016215
iteration 3946 : loss : 0.059344, loss_ce: 0.018204
iteration 3947 : loss : 0.044780, loss_ce: 0.017729
iteration 3948 : loss : 0.042132, loss_ce: 0.012125
iteration 3949 : loss : 0.060307, loss_ce: 0.017998
iteration 3950 : loss : 0.040741, loss_ce: 0.011488
iteration 3951 : loss : 0.044315, loss_ce: 0.021648
iteration 3952 : loss : 0.045171, loss_ce: 0.012939
iteration 3953 : loss : 0.045325, loss_ce: 0.015819
iteration 3954 : loss : 0.041265, loss_ce: 0.019079
iteration 3955 : loss : 0.101663, loss_ce: 0.008657
iteration 3956 : loss : 0.066494, loss_ce: 0.018782
iteration 3957 : loss : 0.063232, loss_ce: 0.016528
iteration 3958 : loss : 0.043110, loss_ce: 0.017974
iteration 3959 : loss : 0.048961, loss_ce: 0.014213
iteration 3960 : loss : 0.045275, loss_ce: 0.022561
iteration 3961 : loss : 0.036042, loss_ce: 0.017412
iteration 3962 : loss : 0.111020, loss_ce: 0.016724
iteration 3963 : loss : 0.096312, loss_ce: 0.019907
iteration 3964 : loss : 0.041050, loss_ce: 0.010852
iteration 3965 : loss : 0.052067, loss_ce: 0.018873
iteration 3966 : loss : 0.089568, loss_ce: 0.014815
iteration 3967 : loss : 0.046255, loss_ce: 0.014210
iteration 3968 : loss : 0.044536, loss_ce: 0.015712
pred_sum 46721
gtsum tensor(48618, device='cuda:0')
iteration 3969 : loss : 0.066189, loss_ce: 0.015227
iteration 3970 : loss : 0.053672, loss_ce: 0.010113
iteration 3971 : loss : 0.034231, loss_ce: 0.011770
iteration 3972 : loss : 0.041421, loss_ce: 0.013458
iteration 3973 : loss : 0.055379, loss_ce: 0.007735
iteration 3974 : loss : 0.042472, loss_ce: 0.013528
iteration 3975 : loss : 0.040564, loss_ce: 0.010474
iteration 3976 : loss : 0.033648, loss_ce: 0.010976
iteration 3977 : loss : 0.040923, loss_ce: 0.012553
iteration 3978 : loss : 0.086125, loss_ce: 0.006452
iteration 3979 : loss : 0.051077, loss_ce: 0.017042
iteration 3980 : loss : 0.042368, loss_ce: 0.013614
iteration 3981 : loss : 0.051059, loss_ce: 0.019922
iteration 3982 : loss : 0.039618, loss_ce: 0.019107
iteration 3983 : loss : 0.037178, loss_ce: 0.016183
iteration 3984 : loss : 0.048732, loss_ce: 0.021100
iteration 3985 : loss : 0.096522, loss_ce: 0.011627
iteration 3986 : loss : 0.047855, loss_ce: 0.019481
iteration 3987 : loss : 0.041833, loss_ce: 0.017902
iteration 3988 : loss : 0.034286, loss_ce: 0.010134
iteration 3989 : loss : 0.049182, loss_ce: 0.015403
iteration 3990 : loss : 0.041957, loss_ce: 0.017200
iteration 3991 : loss : 0.050947, loss_ce: 0.020745
iteration 3992 : loss : 0.036981, loss_ce: 0.013261
iteration 3993 : loss : 0.044640, loss_ce: 0.015676
iteration 3994 : loss : 0.043629, loss_ce: 0.010143
iteration 3995 : loss : 0.042282, loss_ce: 0.012183
iteration 3996 : loss : 0.066193, loss_ce: 0.011889
iteration 3997 : loss : 0.039557, loss_ce: 0.012473
iteration 3998 : loss : 0.032392, loss_ce: 0.011520
iteration 3999 : loss : 0.204717, loss_ce: 0.010896
 22%|██████▍                       | 43/200 [38:55<2:22:38, 54.51s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 4000 : loss : 0.032411, loss_ce: 0.005958
iteration 4001 : loss : 0.042544, loss_ce: 0.014369
iteration 4002 : loss : 0.054961, loss_ce: 0.020656
iteration 4003 : loss : 0.045155, loss_ce: 0.016837
iteration 4004 : loss : 0.037676, loss_ce: 0.010295
iteration 4005 : loss : 0.035669, loss_ce: 0.013817
iteration 4006 : loss : 0.098241, loss_ce: 0.008319
iteration 4007 : loss : 0.048099, loss_ce: 0.016114
iteration 4008 : loss : 0.042067, loss_ce: 0.010341
iteration 4009 : loss : 0.044987, loss_ce: 0.018348
iteration 4010 : loss : 0.087213, loss_ce: 0.014883
iteration 4011 : loss : 0.052995, loss_ce: 0.012059
iteration 4012 : loss : 0.046508, loss_ce: 0.009455
iteration 4013 : loss : 0.037514, loss_ce: 0.020140
iteration 4014 : loss : 0.042754, loss_ce: 0.017652
iteration 4015 : loss : 0.043419, loss_ce: 0.010304
iteration 4016 : loss : 0.081570, loss_ce: 0.011725
iteration 4017 : loss : 0.049528, loss_ce: 0.016952
iteration 4018 : loss : 0.051520, loss_ce: 0.023800
iteration 4019 : loss : 0.048115, loss_ce: 0.010139
iteration 4020 : loss : 0.042145, loss_ce: 0.014921
iteration 4021 : loss : 0.085401, loss_ce: 0.010836
iteration 4022 : loss : 0.053343, loss_ce: 0.021956
iteration 4023 : loss : 0.036905, loss_ce: 0.013800
iteration 4024 : loss : 0.034765, loss_ce: 0.010850
iteration 4025 : loss : 0.045905, loss_ce: 0.016603
iteration 4026 : loss : 0.038472, loss_ce: 0.008340
iteration 4027 : loss : 0.052033, loss_ce: 0.012906
iteration 4028 : loss : 0.048676, loss_ce: 0.012215
iteration 4029 : loss : 0.035800, loss_ce: 0.013250
iteration 4030 : loss : 0.044336, loss_ce: 0.015382
pred_sum 8404
gtsum tensor(7807, device='cuda:0')
iteration 4031 : loss : 0.079197, loss_ce: 0.005744
iteration 4032 : loss : 0.038746, loss_ce: 0.011000
iteration 4033 : loss : 0.040692, loss_ce: 0.013839
iteration 4034 : loss : 0.045089, loss_ce: 0.018737
iteration 4035 : loss : 0.055810, loss_ce: 0.016514
iteration 4036 : loss : 0.047482, loss_ce: 0.021946
iteration 4037 : loss : 0.033698, loss_ce: 0.007894
iteration 4038 : loss : 0.102446, loss_ce: 0.010880
iteration 4039 : loss : 0.039149, loss_ce: 0.012386
iteration 4040 : loss : 0.038877, loss_ce: 0.012216
iteration 4041 : loss : 0.040973, loss_ce: 0.013481
iteration 4042 : loss : 0.090894, loss_ce: 0.015679
iteration 4043 : loss : 0.039838, loss_ce: 0.013288
iteration 4044 : loss : 0.042796, loss_ce: 0.010400
iteration 4045 : loss : 0.037547, loss_ce: 0.015722
iteration 4046 : loss : 0.034338, loss_ce: 0.009005
iteration 4047 : loss : 0.039240, loss_ce: 0.011522
iteration 4048 : loss : 0.046683, loss_ce: 0.020484
iteration 4049 : loss : 0.038910, loss_ce: 0.017658
iteration 4050 : loss : 0.033106, loss_ce: 0.013178
iteration 4051 : loss : 0.042441, loss_ce: 0.012710
iteration 4052 : loss : 0.082061, loss_ce: 0.008787
iteration 4053 : loss : 0.040608, loss_ce: 0.013622
iteration 4054 : loss : 0.037142, loss_ce: 0.014434
iteration 4055 : loss : 0.051441, loss_ce: 0.008676
iteration 4056 : loss : 0.034271, loss_ce: 0.011894
iteration 4057 : loss : 0.038574, loss_ce: 0.011702
iteration 4058 : loss : 0.038213, loss_ce: 0.014078
iteration 4059 : loss : 0.043382, loss_ce: 0.015715
iteration 4060 : loss : 0.032687, loss_ce: 0.012766
iteration 4061 : loss : 0.040624, loss_ce: 0.017514
pred_sum 74761
gtsum tensor(75991, device='cuda:0')
iteration 4062 : loss : 0.052586, loss_ce: 0.016097
iteration 4063 : loss : 0.041505, loss_ce: 0.015271
iteration 4064 : loss : 0.049278, loss_ce: 0.009107
iteration 4065 : loss : 0.036757, loss_ce: 0.012322
iteration 4066 : loss : 0.046261, loss_ce: 0.017057
iteration 4067 : loss : 0.048300, loss_ce: 0.014183
iteration 4068 : loss : 0.090959, loss_ce: 0.012022
iteration 4069 : loss : 0.045963, loss_ce: 0.011026
iteration 4070 : loss : 0.054850, loss_ce: 0.012880
iteration 4071 : loss : 0.035313, loss_ce: 0.011851
iteration 4072 : loss : 0.043806, loss_ce: 0.017787
iteration 4073 : loss : 0.040430, loss_ce: 0.014905
iteration 4074 : loss : 0.041894, loss_ce: 0.012113
iteration 4075 : loss : 0.045849, loss_ce: 0.013673
iteration 4076 : loss : 0.053491, loss_ce: 0.018788
iteration 4077 : loss : 0.050059, loss_ce: 0.014883
iteration 4078 : loss : 0.042375, loss_ce: 0.011921
iteration 4079 : loss : 0.034917, loss_ce: 0.011229
iteration 4080 : loss : 0.038243, loss_ce: 0.012219
iteration 4081 : loss : 0.046330, loss_ce: 0.008591
iteration 4082 : loss : 0.054205, loss_ce: 0.018534
iteration 4083 : loss : 0.036810, loss_ce: 0.006989
iteration 4084 : loss : 0.038766, loss_ce: 0.016948
iteration 4085 : loss : 0.048060, loss_ce: 0.013222
iteration 4086 : loss : 0.047054, loss_ce: 0.017139
iteration 4087 : loss : 0.040755, loss_ce: 0.011096
iteration 4088 : loss : 0.035507, loss_ce: 0.012326
iteration 4089 : loss : 0.092848, loss_ce: 0.011654
iteration 4090 : loss : 0.035623, loss_ce: 0.011494
iteration 4091 : loss : 0.088266, loss_ce: 0.009173
iteration 4092 : loss : 0.097818, loss_ce: 0.014864
 22%|██████▌                       | 44/200 [39:50<2:21:50, 54.55s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 4093 : loss : 0.088062, loss_ce: 0.008023
iteration 4094 : loss : 0.040998, loss_ce: 0.016603
iteration 4095 : loss : 0.035879, loss_ce: 0.012623
iteration 4096 : loss : 0.041971, loss_ce: 0.013268
iteration 4097 : loss : 0.037937, loss_ce: 0.007989
iteration 4098 : loss : 0.082293, loss_ce: 0.008404
iteration 4099 : loss : 0.049358, loss_ce: 0.010688
iteration 4100 : loss : 0.035003, loss_ce: 0.013902
iteration 4101 : loss : 0.040137, loss_ce: 0.011672
iteration 4102 : loss : 0.064308, loss_ce: 0.012723
iteration 4103 : loss : 0.039024, loss_ce: 0.010211
iteration 4104 : loss : 0.088137, loss_ce: 0.010785
iteration 4105 : loss : 0.029597, loss_ce: 0.007816
iteration 4106 : loss : 0.087884, loss_ce: 0.015340
iteration 4107 : loss : 0.047176, loss_ce: 0.017204
iteration 4108 : loss : 0.037511, loss_ce: 0.011199
iteration 4109 : loss : 0.056944, loss_ce: 0.009442
iteration 4110 : loss : 0.040238, loss_ce: 0.010353
iteration 4111 : loss : 0.044293, loss_ce: 0.011729
iteration 4112 : loss : 0.035110, loss_ce: 0.012742
iteration 4113 : loss : 0.060011, loss_ce: 0.011849
iteration 4114 : loss : 0.030815, loss_ce: 0.010049
iteration 4115 : loss : 0.067906, loss_ce: 0.017732
iteration 4116 : loss : 0.041155, loss_ce: 0.007994
iteration 4117 : loss : 0.091633, loss_ce: 0.017113
iteration 4118 : loss : 0.042374, loss_ce: 0.016698
iteration 4119 : loss : 0.034142, loss_ce: 0.012720
iteration 4120 : loss : 0.053040, loss_ce: 0.015589
iteration 4121 : loss : 0.050546, loss_ce: 0.015376
iteration 4122 : loss : 0.094953, loss_ce: 0.021743
iteration 4123 : loss : 0.043368, loss_ce: 0.018494
pred_sum 8187
gtsum tensor(7807, device='cuda:0')
iteration 4124 : loss : 0.034661, loss_ce: 0.013247
iteration 4125 : loss : 0.036434, loss_ce: 0.014796
iteration 4126 : loss : 0.043055, loss_ce: 0.016059
iteration 4127 : loss : 0.042339, loss_ce: 0.012851
iteration 4128 : loss : 0.036057, loss_ce: 0.013817
iteration 4129 : loss : 0.038464, loss_ce: 0.012887
iteration 4130 : loss : 0.048322, loss_ce: 0.013607
iteration 4131 : loss : 0.068320, loss_ce: 0.014179
iteration 4132 : loss : 0.035893, loss_ce: 0.014109
iteration 4133 : loss : 0.039686, loss_ce: 0.016408
iteration 4134 : loss : 0.035815, loss_ce: 0.013018
iteration 4135 : loss : 0.042530, loss_ce: 0.014906
iteration 4136 : loss : 0.049468, loss_ce: 0.008855
iteration 4137 : loss : 0.046331, loss_ce: 0.015876
iteration 4138 : loss : 0.038644, loss_ce: 0.019184
iteration 4139 : loss : 0.045454, loss_ce: 0.018003
iteration 4140 : loss : 0.042579, loss_ce: 0.018337
iteration 4141 : loss : 0.044669, loss_ce: 0.015282
iteration 4142 : loss : 0.048649, loss_ce: 0.012192
iteration 4143 : loss : 0.048517, loss_ce: 0.012007
iteration 4144 : loss : 0.035808, loss_ce: 0.010062
iteration 4145 : loss : 0.045486, loss_ce: 0.011150
iteration 4146 : loss : 0.049387, loss_ce: 0.011068
iteration 4147 : loss : 0.051292, loss_ce: 0.013982
iteration 4148 : loss : 0.083773, loss_ce: 0.009833
iteration 4149 : loss : 0.036941, loss_ce: 0.010230
iteration 4150 : loss : 0.091990, loss_ce: 0.011600
iteration 4151 : loss : 0.048475, loss_ce: 0.009070
iteration 4152 : loss : 0.037171, loss_ce: 0.020411
iteration 4153 : loss : 0.038991, loss_ce: 0.020304
iteration 4154 : loss : 0.035160, loss_ce: 0.015592
pred_sum 2660
gtsum tensor(2628, device='cuda:0')
iteration 4155 : loss : 0.037259, loss_ce: 0.015450
iteration 4156 : loss : 0.049352, loss_ce: 0.009944
iteration 4157 : loss : 0.053104, loss_ce: 0.015789
iteration 4158 : loss : 0.055118, loss_ce: 0.011440
iteration 4159 : loss : 0.038183, loss_ce: 0.010209
iteration 4160 : loss : 0.044937, loss_ce: 0.009817
iteration 4161 : loss : 0.033879, loss_ce: 0.014678
iteration 4162 : loss : 0.037201, loss_ce: 0.013484
iteration 4163 : loss : 0.044317, loss_ce: 0.008704
iteration 4164 : loss : 0.050145, loss_ce: 0.022150
iteration 4165 : loss : 0.041064, loss_ce: 0.014248
iteration 4166 : loss : 0.079853, loss_ce: 0.008451
iteration 4167 : loss : 0.041525, loss_ce: 0.017941
iteration 4168 : loss : 0.030963, loss_ce: 0.006067
iteration 4169 : loss : 0.092798, loss_ce: 0.013812
iteration 4170 : loss : 0.037092, loss_ce: 0.011696
iteration 4171 : loss : 0.089397, loss_ce: 0.013337
iteration 4172 : loss : 0.041368, loss_ce: 0.007823
iteration 4173 : loss : 0.033623, loss_ce: 0.008995
iteration 4174 : loss : 0.034890, loss_ce: 0.008022
iteration 4175 : loss : 0.040993, loss_ce: 0.014008
iteration 4176 : loss : 0.042100, loss_ce: 0.009815
iteration 4177 : loss : 0.045814, loss_ce: 0.016664
iteration 4178 : loss : 0.049809, loss_ce: 0.017539
iteration 4179 : loss : 0.035472, loss_ce: 0.010114
iteration 4180 : loss : 0.035372, loss_ce: 0.016027
iteration 4181 : loss : 0.047854, loss_ce: 0.023384
iteration 4182 : loss : 0.039545, loss_ce: 0.013512
iteration 4183 : loss : 0.037062, loss_ce: 0.014338
iteration 4184 : loss : 0.043540, loss_ce: 0.012610
iteration 4185 : loss : 0.155233, loss_ce: 0.024463
 22%|██████▊                       | 45/200 [40:45<2:20:56, 54.56s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 4186 : loss : 0.031783, loss_ce: 0.010180
iteration 4187 : loss : 0.047656, loss_ce: 0.017855
iteration 4188 : loss : 0.040703, loss_ce: 0.011573
iteration 4189 : loss : 0.047033, loss_ce: 0.012510
iteration 4190 : loss : 0.041345, loss_ce: 0.017437
iteration 4191 : loss : 0.091403, loss_ce: 0.012745
iteration 4192 : loss : 0.043313, loss_ce: 0.019589
iteration 4193 : loss : 0.047294, loss_ce: 0.014845
iteration 4194 : loss : 0.044259, loss_ce: 0.013078
iteration 4195 : loss : 0.089577, loss_ce: 0.008791
iteration 4196 : loss : 0.032883, loss_ce: 0.012417
iteration 4197 : loss : 0.046994, loss_ce: 0.012731
iteration 4198 : loss : 0.047625, loss_ce: 0.010734
iteration 4199 : loss : 0.041382, loss_ce: 0.014174
iteration 4200 : loss : 0.043280, loss_ce: 0.017250
iteration 4201 : loss : 0.093930, loss_ce: 0.008045
iteration 4202 : loss : 0.046162, loss_ce: 0.015184
iteration 4203 : loss : 0.079037, loss_ce: 0.014986
iteration 4204 : loss : 0.037776, loss_ce: 0.014549
iteration 4205 : loss : 0.028753, loss_ce: 0.008780
iteration 4206 : loss : 0.085685, loss_ce: 0.008413
iteration 4207 : loss : 0.039458, loss_ce: 0.010792
iteration 4208 : loss : 0.129407, loss_ce: 0.006947
iteration 4209 : loss : 0.041000, loss_ce: 0.011823
iteration 4210 : loss : 0.045430, loss_ce: 0.020882
iteration 4211 : loss : 0.026760, loss_ce: 0.008771
iteration 4212 : loss : 0.065555, loss_ce: 0.010990
iteration 4213 : loss : 0.064654, loss_ce: 0.008620
iteration 4214 : loss : 0.042049, loss_ce: 0.010497
iteration 4215 : loss : 0.033342, loss_ce: 0.011790
iteration 4216 : loss : 0.039654, loss_ce: 0.016274
pred_sum 34228
gtsum tensor(33095, device='cuda:0')
iteration 4217 : loss : 0.048131, loss_ce: 0.013292
iteration 4218 : loss : 0.033077, loss_ce: 0.012500
iteration 4219 : loss : 0.039624, loss_ce: 0.011565
iteration 4220 : loss : 0.064150, loss_ce: 0.016450
iteration 4221 : loss : 0.035055, loss_ce: 0.012586
iteration 4222 : loss : 0.049673, loss_ce: 0.016473
iteration 4223 : loss : 0.042468, loss_ce: 0.012324
iteration 4224 : loss : 0.043085, loss_ce: 0.010465
iteration 4225 : loss : 0.046860, loss_ce: 0.016756
iteration 4226 : loss : 0.055218, loss_ce: 0.021105
iteration 4227 : loss : 0.053769, loss_ce: 0.012064
iteration 4228 : loss : 0.036815, loss_ce: 0.012474
iteration 4229 : loss : 0.041880, loss_ce: 0.011984
iteration 4230 : loss : 0.034780, loss_ce: 0.011451
iteration 4231 : loss : 0.051858, loss_ce: 0.017942
iteration 4232 : loss : 0.052838, loss_ce: 0.015370
iteration 4233 : loss : 0.034109, loss_ce: 0.011847
iteration 4234 : loss : 0.050762, loss_ce: 0.009956
iteration 4235 : loss : 0.039648, loss_ce: 0.012623
iteration 4236 : loss : 0.046086, loss_ce: 0.011038
iteration 4237 : loss : 0.049053, loss_ce: 0.020095
iteration 4238 : loss : 0.046635, loss_ce: 0.011310
iteration 4239 : loss : 0.030861, loss_ce: 0.011487
iteration 4240 : loss : 0.046052, loss_ce: 0.016888
iteration 4241 : loss : 0.045923, loss_ce: 0.014381
iteration 4242 : loss : 0.040773, loss_ce: 0.012798
iteration 4243 : loss : 0.039612, loss_ce: 0.015891
iteration 4244 : loss : 0.091643, loss_ce: 0.010399
iteration 4245 : loss : 0.093473, loss_ce: 0.009414
iteration 4246 : loss : 0.035997, loss_ce: 0.013712
iteration 4247 : loss : 0.046639, loss_ce: 0.010692
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 4248 : loss : 0.070354, loss_ce: 0.014783
iteration 4249 : loss : 0.048200, loss_ce: 0.017329
iteration 4250 : loss : 0.038956, loss_ce: 0.013385
iteration 4251 : loss : 0.046244, loss_ce: 0.014472
iteration 4252 : loss : 0.038290, loss_ce: 0.012565
iteration 4253 : loss : 0.043152, loss_ce: 0.015475
iteration 4254 : loss : 0.036345, loss_ce: 0.013180
iteration 4255 : loss : 0.031741, loss_ce: 0.012726
iteration 4256 : loss : 0.033688, loss_ce: 0.014827
iteration 4257 : loss : 0.046113, loss_ce: 0.018368
iteration 4258 : loss : 0.038468, loss_ce: 0.009420
iteration 4259 : loss : 0.049192, loss_ce: 0.012843
iteration 4260 : loss : 0.033132, loss_ce: 0.013370
iteration 4261 : loss : 0.033407, loss_ce: 0.010046
iteration 4262 : loss : 0.035281, loss_ce: 0.015774
iteration 4263 : loss : 0.088736, loss_ce: 0.007988
iteration 4264 : loss : 0.041035, loss_ce: 0.016860
iteration 4265 : loss : 0.039917, loss_ce: 0.009458
iteration 4266 : loss : 0.035123, loss_ce: 0.011449
iteration 4267 : loss : 0.038847, loss_ce: 0.014710
iteration 4268 : loss : 0.034758, loss_ce: 0.010475
iteration 4269 : loss : 0.040056, loss_ce: 0.023063
iteration 4270 : loss : 0.033432, loss_ce: 0.014167
iteration 4271 : loss : 0.040731, loss_ce: 0.014424
iteration 4272 : loss : 0.042631, loss_ce: 0.014058
iteration 4273 : loss : 0.039679, loss_ce: 0.012568
iteration 4274 : loss : 0.035669, loss_ce: 0.012111
iteration 4275 : loss : 0.042112, loss_ce: 0.017679
iteration 4276 : loss : 0.035924, loss_ce: 0.013864
iteration 4277 : loss : 0.087073, loss_ce: 0.012962
iteration 4278 : loss : 0.152611, loss_ce: 0.022849
 23%|██████▉                       | 46/200 [41:39<2:20:03, 54.56s/it]pred_sum 44214
gtsum tensor(41390, device='cuda:0')
iteration 4279 : loss : 0.049454, loss_ce: 0.013917
iteration 4280 : loss : 0.037371, loss_ce: 0.009387
iteration 4281 : loss : 0.039373, loss_ce: 0.013346
iteration 4282 : loss : 0.032712, loss_ce: 0.013685
iteration 4283 : loss : 0.096891, loss_ce: 0.006472
iteration 4284 : loss : 0.040315, loss_ce: 0.009123
iteration 4285 : loss : 0.030786, loss_ce: 0.006262
iteration 4286 : loss : 0.041720, loss_ce: 0.018145
iteration 4287 : loss : 0.045079, loss_ce: 0.017732
iteration 4288 : loss : 0.051731, loss_ce: 0.011271
iteration 4289 : loss : 0.037102, loss_ce: 0.011326
iteration 4290 : loss : 0.056529, loss_ce: 0.009298
iteration 4291 : loss : 0.049422, loss_ce: 0.008940
iteration 4292 : loss : 0.037756, loss_ce: 0.018087
iteration 4293 : loss : 0.081247, loss_ce: 0.014515
iteration 4294 : loss : 0.036950, loss_ce: 0.013941
iteration 4295 : loss : 0.037894, loss_ce: 0.009395
iteration 4296 : loss : 0.046814, loss_ce: 0.014389
iteration 4297 : loss : 0.035899, loss_ce: 0.012847
iteration 4298 : loss : 0.037635, loss_ce: 0.008479
iteration 4299 : loss : 0.045398, loss_ce: 0.010973
iteration 4300 : loss : 0.057610, loss_ce: 0.014172
iteration 4301 : loss : 0.030166, loss_ce: 0.010734
iteration 4302 : loss : 0.032744, loss_ce: 0.010660
iteration 4303 : loss : 0.102606, loss_ce: 0.012971
iteration 4304 : loss : 0.090096, loss_ce: 0.009177
iteration 4305 : loss : 0.030232, loss_ce: 0.011027
iteration 4306 : loss : 0.044837, loss_ce: 0.021078
iteration 4307 : loss : 0.035136, loss_ce: 0.009670
iteration 4308 : loss : 0.027898, loss_ce: 0.007741
iteration 4309 : loss : 0.042385, loss_ce: 0.010103
pred_sum 4445
gtsum tensor(4467, device='cuda:0')
iteration 4310 : loss : 0.038181, loss_ce: 0.009647
iteration 4311 : loss : 0.085731, loss_ce: 0.011478
iteration 4312 : loss : 0.037564, loss_ce: 0.010274
iteration 4313 : loss : 0.040457, loss_ce: 0.020019
iteration 4314 : loss : 0.069050, loss_ce: 0.013881
iteration 4315 : loss : 0.045216, loss_ce: 0.015992
iteration 4316 : loss : 0.043923, loss_ce: 0.014498
iteration 4317 : loss : 0.037185, loss_ce: 0.010910
iteration 4318 : loss : 0.038118, loss_ce: 0.011782
iteration 4319 : loss : 0.033944, loss_ce: 0.013234
iteration 4320 : loss : 0.052927, loss_ce: 0.008108
iteration 4321 : loss : 0.063975, loss_ce: 0.004520
iteration 4322 : loss : 0.041739, loss_ce: 0.017320
iteration 4323 : loss : 0.047973, loss_ce: 0.012613
iteration 4324 : loss : 0.039832, loss_ce: 0.013504
iteration 4325 : loss : 0.047365, loss_ce: 0.015972
iteration 4326 : loss : 0.035339, loss_ce: 0.015517
iteration 4327 : loss : 0.038067, loss_ce: 0.008862
iteration 4328 : loss : 0.046289, loss_ce: 0.015549
iteration 4329 : loss : 0.040567, loss_ce: 0.010381
iteration 4330 : loss : 0.045402, loss_ce: 0.010853
iteration 4331 : loss : 0.089865, loss_ce: 0.009961
iteration 4332 : loss : 0.038103, loss_ce: 0.023784
iteration 4333 : loss : 0.031768, loss_ce: 0.012143
iteration 4334 : loss : 0.038975, loss_ce: 0.008070
iteration 4335 : loss : 0.045272, loss_ce: 0.009016
iteration 4336 : loss : 0.040103, loss_ce: 0.020942
iteration 4337 : loss : 0.044374, loss_ce: 0.027152
iteration 4338 : loss : 0.042754, loss_ce: 0.013399
iteration 4339 : loss : 0.034532, loss_ce: 0.009378
iteration 4340 : loss : 0.035130, loss_ce: 0.014356
pred_sum 464
gtsum tensor(436, device='cuda:0')
iteration 4341 : loss : 0.032959, loss_ce: 0.011995
iteration 4342 : loss : 0.040924, loss_ce: 0.014443
iteration 4343 : loss : 0.091186, loss_ce: 0.009873
iteration 4344 : loss : 0.046523, loss_ce: 0.012324
iteration 4345 : loss : 0.091357, loss_ce: 0.015614
iteration 4346 : loss : 0.043219, loss_ce: 0.009746
iteration 4347 : loss : 0.039057, loss_ce: 0.021067
iteration 4348 : loss : 0.040068, loss_ce: 0.016656
iteration 4349 : loss : 0.041026, loss_ce: 0.013908
iteration 4350 : loss : 0.034810, loss_ce: 0.010984
iteration 4351 : loss : 0.094914, loss_ce: 0.011916
iteration 4352 : loss : 0.042431, loss_ce: 0.011163
iteration 4353 : loss : 0.043722, loss_ce: 0.015578
iteration 4354 : loss : 0.040325, loss_ce: 0.012155
iteration 4355 : loss : 0.044546, loss_ce: 0.021711
iteration 4356 : loss : 0.035372, loss_ce: 0.015984
iteration 4357 : loss : 0.043245, loss_ce: 0.009539
iteration 4358 : loss : 0.058193, loss_ce: 0.004392
iteration 4359 : loss : 0.052704, loss_ce: 0.011996
iteration 4360 : loss : 0.035474, loss_ce: 0.013864
iteration 4361 : loss : 0.041303, loss_ce: 0.015396
iteration 4362 : loss : 0.040060, loss_ce: 0.009197
iteration 4363 : loss : 0.038261, loss_ce: 0.017921
iteration 4364 : loss : 0.057089, loss_ce: 0.009166
iteration 4365 : loss : 0.103327, loss_ce: 0.004456
iteration 4366 : loss : 0.089670, loss_ce: 0.014538
iteration 4367 : loss : 0.039912, loss_ce: 0.009980
iteration 4368 : loss : 0.033372, loss_ce: 0.011541
iteration 4369 : loss : 0.038523, loss_ce: 0.009690
iteration 4370 : loss : 0.035111, loss_ce: 0.009430
iteration 4371 : loss : 0.093044, loss_ce: 0.026709
 24%|███████                       | 47/200 [42:34<2:19:29, 54.70s/it]pred_sum 22521
gtsum tensor(23169, device='cuda:0')
iteration 4372 : loss : 0.036605, loss_ce: 0.013505
iteration 4373 : loss : 0.037792, loss_ce: 0.014465
iteration 4374 : loss : 0.035264, loss_ce: 0.006346
iteration 4375 : loss : 0.035817, loss_ce: 0.012300
iteration 4376 : loss : 0.039166, loss_ce: 0.013545
iteration 4377 : loss : 0.053939, loss_ce: 0.016869
iteration 4378 : loss : 0.034306, loss_ce: 0.013452
iteration 4379 : loss : 0.048674, loss_ce: 0.018601
iteration 4380 : loss : 0.036221, loss_ce: 0.015187
iteration 4381 : loss : 0.044363, loss_ce: 0.014109
iteration 4382 : loss : 0.045644, loss_ce: 0.008875
iteration 4383 : loss : 0.036675, loss_ce: 0.011783
iteration 4384 : loss : 0.040473, loss_ce: 0.013274
iteration 4385 : loss : 0.042728, loss_ce: 0.009072
iteration 4386 : loss : 0.036053, loss_ce: 0.012659
iteration 4387 : loss : 0.044246, loss_ce: 0.013539
iteration 4388 : loss : 0.040317, loss_ce: 0.012766
iteration 4389 : loss : 0.040599, loss_ce: 0.015094
iteration 4390 : loss : 0.034703, loss_ce: 0.018830
iteration 4391 : loss : 0.032981, loss_ce: 0.010000
iteration 4392 : loss : 0.036575, loss_ce: 0.015703
iteration 4393 : loss : 0.044211, loss_ce: 0.012217
iteration 4394 : loss : 0.046166, loss_ce: 0.014313
iteration 4395 : loss : 0.035865, loss_ce: 0.011534
iteration 4396 : loss : 0.037364, loss_ce: 0.014292
iteration 4397 : loss : 0.035392, loss_ce: 0.011114
iteration 4398 : loss : 0.140961, loss_ce: 0.009771
iteration 4399 : loss : 0.042937, loss_ce: 0.016047
iteration 4400 : loss : 0.029891, loss_ce: 0.007114
iteration 4401 : loss : 0.035063, loss_ce: 0.016510
iteration 4402 : loss : 0.047949, loss_ce: 0.010646
pred_sum 328
gtsum tensor(385, device='cuda:0')
iteration 4403 : loss : 0.041365, loss_ce: 0.012659
iteration 4404 : loss : 0.033778, loss_ce: 0.011961
iteration 4405 : loss : 0.032240, loss_ce: 0.008142
iteration 4406 : loss : 0.087589, loss_ce: 0.008126
iteration 4407 : loss : 0.086806, loss_ce: 0.009601
iteration 4408 : loss : 0.043295, loss_ce: 0.011391
iteration 4409 : loss : 0.033774, loss_ce: 0.005687
iteration 4410 : loss : 0.091186, loss_ce: 0.014202
iteration 4411 : loss : 0.038294, loss_ce: 0.015067
iteration 4412 : loss : 0.044606, loss_ce: 0.014583
iteration 4413 : loss : 0.037124, loss_ce: 0.014767
iteration 4414 : loss : 0.035671, loss_ce: 0.012352
iteration 4415 : loss : 0.035612, loss_ce: 0.012815
iteration 4416 : loss : 0.035266, loss_ce: 0.010876
iteration 4417 : loss : 0.037483, loss_ce: 0.018306
iteration 4418 : loss : 0.040106, loss_ce: 0.013597
iteration 4419 : loss : 0.035570, loss_ce: 0.013676
iteration 4420 : loss : 0.036385, loss_ce: 0.011069
iteration 4421 : loss : 0.051164, loss_ce: 0.008595
iteration 4422 : loss : 0.039987, loss_ce: 0.008468
iteration 4423 : loss : 0.035585, loss_ce: 0.009504
iteration 4424 : loss : 0.081964, loss_ce: 0.006634
iteration 4425 : loss : 0.049074, loss_ce: 0.012509
iteration 4426 : loss : 0.077149, loss_ce: 0.004331
iteration 4427 : loss : 0.030239, loss_ce: 0.009977
iteration 4428 : loss : 0.041277, loss_ce: 0.016592
iteration 4429 : loss : 0.037690, loss_ce: 0.015388
iteration 4430 : loss : 0.032586, loss_ce: 0.011551
iteration 4431 : loss : 0.038152, loss_ce: 0.009542
iteration 4432 : loss : 0.079624, loss_ce: 0.006908
iteration 4433 : loss : 0.034977, loss_ce: 0.013222
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 4434 : loss : 0.032363, loss_ce: 0.012318
iteration 4435 : loss : 0.043131, loss_ce: 0.014764
iteration 4436 : loss : 0.042744, loss_ce: 0.018880
iteration 4437 : loss : 0.038444, loss_ce: 0.011778
iteration 4438 : loss : 0.035146, loss_ce: 0.015021
iteration 4439 : loss : 0.042417, loss_ce: 0.014806
iteration 4440 : loss : 0.028397, loss_ce: 0.012186
iteration 4441 : loss : 0.050945, loss_ce: 0.009615
iteration 4442 : loss : 0.036704, loss_ce: 0.013097
iteration 4443 : loss : 0.039146, loss_ce: 0.009265
iteration 4444 : loss : 0.044077, loss_ce: 0.017320
iteration 4445 : loss : 0.033520, loss_ce: 0.013140
iteration 4446 : loss : 0.039332, loss_ce: 0.012505
iteration 4447 : loss : 0.129320, loss_ce: 0.003777
iteration 4448 : loss : 0.145229, loss_ce: 0.006526
iteration 4449 : loss : 0.037987, loss_ce: 0.013616
iteration 4450 : loss : 0.033460, loss_ce: 0.013035
iteration 4451 : loss : 0.086970, loss_ce: 0.014213
iteration 4452 : loss : 0.034641, loss_ce: 0.012386
iteration 4453 : loss : 0.035393, loss_ce: 0.023733
iteration 4454 : loss : 0.041988, loss_ce: 0.018900
iteration 4455 : loss : 0.034652, loss_ce: 0.011399
iteration 4456 : loss : 0.039900, loss_ce: 0.020805
iteration 4457 : loss : 0.037860, loss_ce: 0.008670
iteration 4458 : loss : 0.044374, loss_ce: 0.011627
iteration 4459 : loss : 0.044357, loss_ce: 0.014164
iteration 4460 : loss : 0.037670, loss_ce: 0.012418
iteration 4461 : loss : 0.039935, loss_ce: 0.017389
iteration 4462 : loss : 0.039995, loss_ce: 0.013498
iteration 4463 : loss : 0.032291, loss_ce: 0.010064
iteration 4464 : loss : 0.098967, loss_ce: 0.025773
 24%|███████▏                      | 48/200 [43:29<2:18:49, 54.80s/it]pred_sum 2008
gtsum tensor(2477, device='cuda:0')
iteration 4465 : loss : 0.031960, loss_ce: 0.012109
iteration 4466 : loss : 0.036459, loss_ce: 0.011367
iteration 4467 : loss : 0.036429, loss_ce: 0.006125
iteration 4468 : loss : 0.032096, loss_ce: 0.012155
iteration 4469 : loss : 0.043282, loss_ce: 0.018902
iteration 4470 : loss : 0.045188, loss_ce: 0.013899
iteration 4471 : loss : 0.054163, loss_ce: 0.009034
iteration 4472 : loss : 0.031259, loss_ce: 0.014109
iteration 4473 : loss : 0.034780, loss_ce: 0.014139
iteration 4474 : loss : 0.034698, loss_ce: 0.014253
iteration 4475 : loss : 0.041501, loss_ce: 0.015882
iteration 4476 : loss : 0.033437, loss_ce: 0.016557
iteration 4477 : loss : 0.029869, loss_ce: 0.013414
iteration 4478 : loss : 0.035861, loss_ce: 0.009949
iteration 4479 : loss : 0.033171, loss_ce: 0.013683
iteration 4480 : loss : 0.036378, loss_ce: 0.013068
iteration 4481 : loss : 0.042085, loss_ce: 0.018712
iteration 4482 : loss : 0.029529, loss_ce: 0.008996
iteration 4483 : loss : 0.039677, loss_ce: 0.006793
iteration 4484 : loss : 0.038172, loss_ce: 0.013791
iteration 4485 : loss : 0.040303, loss_ce: 0.009226
iteration 4486 : loss : 0.041144, loss_ce: 0.013834
iteration 4487 : loss : 0.029417, loss_ce: 0.010870
iteration 4488 : loss : 0.083866, loss_ce: 0.009168
iteration 4489 : loss : 0.037122, loss_ce: 0.011598
iteration 4490 : loss : 0.036049, loss_ce: 0.011284
iteration 4491 : loss : 0.034097, loss_ce: 0.010438
iteration 4492 : loss : 0.035444, loss_ce: 0.013210
iteration 4493 : loss : 0.041129, loss_ce: 0.009559
iteration 4494 : loss : 0.034250, loss_ce: 0.016374
iteration 4495 : loss : 0.043483, loss_ce: 0.011113
pred_sum 53340
gtsum tensor(52182, device='cuda:0')
iteration 4496 : loss : 0.040907, loss_ce: 0.016051
iteration 4497 : loss : 0.033575, loss_ce: 0.011474
iteration 4498 : loss : 0.029321, loss_ce: 0.008622
iteration 4499 : loss : 0.039761, loss_ce: 0.012712
iteration 4500 : loss : 0.029560, loss_ce: 0.008726
iteration 4501 : loss : 0.037522, loss_ce: 0.011262
iteration 4502 : loss : 0.028300, loss_ce: 0.006239
iteration 4503 : loss : 0.034111, loss_ce: 0.012823
iteration 4504 : loss : 0.033857, loss_ce: 0.009528
iteration 4505 : loss : 0.038790, loss_ce: 0.017364
iteration 4506 : loss : 0.031621, loss_ce: 0.009153
iteration 4507 : loss : 0.032561, loss_ce: 0.011551
iteration 4508 : loss : 0.041511, loss_ce: 0.014294
iteration 4509 : loss : 0.038941, loss_ce: 0.012469
iteration 4510 : loss : 0.033405, loss_ce: 0.009536
iteration 4511 : loss : 0.037312, loss_ce: 0.005885
iteration 4512 : loss : 0.034691, loss_ce: 0.007319
iteration 4513 : loss : 0.045009, loss_ce: 0.013806
iteration 4514 : loss : 0.034252, loss_ce: 0.014795
iteration 4515 : loss : 0.041141, loss_ce: 0.010974
iteration 4516 : loss : 0.047396, loss_ce: 0.014672
iteration 4517 : loss : 0.067501, loss_ce: 0.011952
iteration 4518 : loss : 0.037829, loss_ce: 0.007518
iteration 4519 : loss : 0.027751, loss_ce: 0.008500
iteration 4520 : loss : 0.037183, loss_ce: 0.012594
iteration 4521 : loss : 0.084378, loss_ce: 0.011413
iteration 4522 : loss : 0.035897, loss_ce: 0.014378
iteration 4523 : loss : 0.055071, loss_ce: 0.011772
iteration 4524 : loss : 0.033267, loss_ce: 0.008903
iteration 4525 : loss : 0.033078, loss_ce: 0.010786
iteration 4526 : loss : 0.048764, loss_ce: 0.016899
pred_sum 754
gtsum tensor(732, device='cuda:0')
iteration 4527 : loss : 0.089757, loss_ce: 0.007558
iteration 4528 : loss : 0.035767, loss_ce: 0.017303
iteration 4529 : loss : 0.054442, loss_ce: 0.007299
iteration 4530 : loss : 0.038914, loss_ce: 0.020220
iteration 4531 : loss : 0.043112, loss_ce: 0.011572
iteration 4532 : loss : 0.050148, loss_ce: 0.009889
iteration 4533 : loss : 0.032979, loss_ce: 0.016112
iteration 4534 : loss : 0.035956, loss_ce: 0.019761
iteration 4535 : loss : 0.035613, loss_ce: 0.012143
iteration 4536 : loss : 0.032742, loss_ce: 0.009429
iteration 4537 : loss : 0.034398, loss_ce: 0.013920
iteration 4538 : loss : 0.037469, loss_ce: 0.010423
iteration 4539 : loss : 0.048055, loss_ce: 0.018139
iteration 4540 : loss : 0.031449, loss_ce: 0.013282
iteration 4541 : loss : 0.039741, loss_ce: 0.011256
iteration 4542 : loss : 0.038794, loss_ce: 0.019503
iteration 4543 : loss : 0.034817, loss_ce: 0.009229
iteration 4544 : loss : 0.033128, loss_ce: 0.014915
iteration 4545 : loss : 0.028498, loss_ce: 0.006306
iteration 4546 : loss : 0.036161, loss_ce: 0.008811
iteration 4547 : loss : 0.088056, loss_ce: 0.006971
iteration 4548 : loss : 0.031984, loss_ce: 0.006987
iteration 4549 : loss : 0.036412, loss_ce: 0.014499
iteration 4550 : loss : 0.034541, loss_ce: 0.013501
iteration 4551 : loss : 0.040607, loss_ce: 0.012506
iteration 4552 : loss : 0.040277, loss_ce: 0.009793
iteration 4553 : loss : 0.046942, loss_ce: 0.010445
iteration 4554 : loss : 0.081269, loss_ce: 0.007228
iteration 4555 : loss : 0.029676, loss_ce: 0.010903
iteration 4556 : loss : 0.041398, loss_ce: 0.017435
iteration 4557 : loss : 0.290025, loss_ce: 0.008709
 24%|███████▎                      | 49/200 [44:24<2:18:01, 54.85s/it]pred_sum 17686
gtsum tensor(17977, device='cuda:0')
iteration 4558 : loss : 0.043691, loss_ce: 0.020007
iteration 4559 : loss : 0.046872, loss_ce: 0.010598
iteration 4560 : loss : 0.038755, loss_ce: 0.017885
iteration 4561 : loss : 0.033662, loss_ce: 0.017176
iteration 4562 : loss : 0.041918, loss_ce: 0.008938
iteration 4563 : loss : 0.031563, loss_ce: 0.011967
iteration 4564 : loss : 0.042569, loss_ce: 0.008536
iteration 4565 : loss : 0.036084, loss_ce: 0.011716
iteration 4566 : loss : 0.040639, loss_ce: 0.008910
iteration 4567 : loss : 0.033246, loss_ce: 0.011421
iteration 4568 : loss : 0.031481, loss_ce: 0.012500
iteration 4569 : loss : 0.038165, loss_ce: 0.010763
iteration 4570 : loss : 0.055940, loss_ce: 0.013794
iteration 4571 : loss : 0.035400, loss_ce: 0.009587
iteration 4572 : loss : 0.032421, loss_ce: 0.015103
iteration 4573 : loss : 0.035931, loss_ce: 0.013253
iteration 4574 : loss : 0.034917, loss_ce: 0.012970
iteration 4575 : loss : 0.026395, loss_ce: 0.007995
iteration 4576 : loss : 0.038214, loss_ce: 0.011372
iteration 4577 : loss : 0.036346, loss_ce: 0.012253
iteration 4578 : loss : 0.040201, loss_ce: 0.012284
iteration 4579 : loss : 0.033453, loss_ce: 0.015737
iteration 4580 : loss : 0.040277, loss_ce: 0.013750
iteration 4581 : loss : 0.039176, loss_ce: 0.017986
iteration 4582 : loss : 0.027637, loss_ce: 0.006786
iteration 4583 : loss : 0.039347, loss_ce: 0.010354
iteration 4584 : loss : 0.046147, loss_ce: 0.007394
iteration 4585 : loss : 0.037787, loss_ce: 0.017293
iteration 4586 : loss : 0.033225, loss_ce: 0.006923
iteration 4587 : loss : 0.027205, loss_ce: 0.009567
iteration 4588 : loss : 0.033968, loss_ce: 0.010421
pred_sum 2660
gtsum tensor(2581, device='cuda:0')
iteration 4589 : loss : 0.033870, loss_ce: 0.010967
iteration 4590 : loss : 0.029951, loss_ce: 0.010195
iteration 4591 : loss : 0.033457, loss_ce: 0.010077
iteration 4592 : loss : 0.038308, loss_ce: 0.010055
iteration 4593 : loss : 0.037056, loss_ce: 0.018795
iteration 4594 : loss : 0.055519, loss_ce: 0.010396
iteration 4595 : loss : 0.031204, loss_ce: 0.007161
iteration 4596 : loss : 0.050422, loss_ce: 0.010382
iteration 4597 : loss : 0.032225, loss_ce: 0.015384
iteration 4598 : loss : 0.040895, loss_ce: 0.016391
iteration 4599 : loss : 0.039702, loss_ce: 0.015901
iteration 4600 : loss : 0.041045, loss_ce: 0.018510
iteration 4601 : loss : 0.035209, loss_ce: 0.011914
iteration 4602 : loss : 0.086799, loss_ce: 0.005501
iteration 4603 : loss : 0.036166, loss_ce: 0.011761
iteration 4604 : loss : 0.035188, loss_ce: 0.014306
iteration 4605 : loss : 0.038523, loss_ce: 0.016745
iteration 4606 : loss : 0.080219, loss_ce: 0.006173
iteration 4607 : loss : 0.037081, loss_ce: 0.011851
iteration 4608 : loss : 0.030318, loss_ce: 0.013698
iteration 4609 : loss : 0.082290, loss_ce: 0.012326
iteration 4610 : loss : 0.031660, loss_ce: 0.011621
iteration 4611 : loss : 0.030220, loss_ce: 0.009558
iteration 4612 : loss : 0.045145, loss_ce: 0.011387
iteration 4613 : loss : 0.029157, loss_ce: 0.009546
iteration 4614 : loss : 0.039081, loss_ce: 0.015577
iteration 4615 : loss : 0.124739, loss_ce: 0.004472
iteration 4616 : loss : 0.088765, loss_ce: 0.005406
iteration 4617 : loss : 0.046004, loss_ce: 0.024739
iteration 4618 : loss : 0.030619, loss_ce: 0.011617
iteration 4619 : loss : 0.083851, loss_ce: 0.012561
pred_sum 5538
gtsum tensor(5371, device='cuda:0')
iteration 4620 : loss : 0.040823, loss_ce: 0.009028
iteration 4621 : loss : 0.133656, loss_ce: 0.011796
iteration 4622 : loss : 0.042800, loss_ce: 0.011453
iteration 4623 : loss : 0.039897, loss_ce: 0.009547
iteration 4624 : loss : 0.034013, loss_ce: 0.011991
iteration 4625 : loss : 0.032431, loss_ce: 0.010340
iteration 4626 : loss : 0.040214, loss_ce: 0.011189
iteration 4627 : loss : 0.051219, loss_ce: 0.007403
iteration 4628 : loss : 0.027827, loss_ce: 0.004496
iteration 4629 : loss : 0.078355, loss_ce: 0.011668
iteration 4630 : loss : 0.087454, loss_ce: 0.008360
iteration 4631 : loss : 0.040932, loss_ce: 0.016994
iteration 4632 : loss : 0.027560, loss_ce: 0.009960
iteration 4633 : loss : 0.036786, loss_ce: 0.010116
iteration 4634 : loss : 0.035327, loss_ce: 0.014945
iteration 4635 : loss : 0.045125, loss_ce: 0.012214
iteration 4636 : loss : 0.046386, loss_ce: 0.006662
iteration 4637 : loss : 0.037743, loss_ce: 0.011783
iteration 4638 : loss : 0.080152, loss_ce: 0.012923
iteration 4639 : loss : 0.036038, loss_ce: 0.011680
iteration 4640 : loss : 0.078780, loss_ce: 0.007335
iteration 4641 : loss : 0.033362, loss_ce: 0.012052
iteration 4642 : loss : 0.038988, loss_ce: 0.010728
iteration 4643 : loss : 0.032771, loss_ce: 0.011738
iteration 4644 : loss : 0.032007, loss_ce: 0.013481
iteration 4645 : loss : 0.032935, loss_ce: 0.008882
iteration 4646 : loss : 0.038276, loss_ce: 0.013034
iteration 4647 : loss : 0.037068, loss_ce: 0.015594
iteration 4648 : loss : 0.036936, loss_ce: 0.017293
iteration 4649 : loss : 0.036187, loss_ce: 0.014435
iteration 4650 : loss : 0.138399, loss_ce: 0.011198
 25%|███████▌                      | 50/200 [45:19<2:16:48, 54.72s/it]pred_sum 334
gtsum tensor(334, device='cuda:0')
iteration 4651 : loss : 0.042099, loss_ce: 0.013794
iteration 4652 : loss : 0.048025, loss_ce: 0.020767
iteration 4653 : loss : 0.032625, loss_ce: 0.015301
iteration 4654 : loss : 0.032058, loss_ce: 0.010608
iteration 4655 : loss : 0.042428, loss_ce: 0.009442
iteration 4656 : loss : 0.032984, loss_ce: 0.010812
iteration 4657 : loss : 0.027186, loss_ce: 0.009421
iteration 4658 : loss : 0.042449, loss_ce: 0.010929
iteration 4659 : loss : 0.036262, loss_ce: 0.010095
iteration 4660 : loss : 0.030964, loss_ce: 0.005842
iteration 4661 : loss : 0.028959, loss_ce: 0.007547
iteration 4662 : loss : 0.033248, loss_ce: 0.014740
iteration 4663 : loss : 0.055948, loss_ce: 0.011323
iteration 4664 : loss : 0.033667, loss_ce: 0.007634
iteration 4665 : loss : 0.070341, loss_ce: 0.015446
iteration 4666 : loss : 0.029921, loss_ce: 0.010216
iteration 4667 : loss : 0.045321, loss_ce: 0.014225
iteration 4668 : loss : 0.038527, loss_ce: 0.011221
iteration 4669 : loss : 0.079954, loss_ce: 0.006311
iteration 4670 : loss : 0.033939, loss_ce: 0.008913
iteration 4671 : loss : 0.040243, loss_ce: 0.014283
iteration 4672 : loss : 0.079727, loss_ce: 0.010115
iteration 4673 : loss : 0.035159, loss_ce: 0.014583
iteration 4674 : loss : 0.032447, loss_ce: 0.012057
iteration 4675 : loss : 0.036006, loss_ce: 0.010950
iteration 4676 : loss : 0.044149, loss_ce: 0.013941
iteration 4677 : loss : 0.033828, loss_ce: 0.010426
iteration 4678 : loss : 0.034442, loss_ce: 0.013302
iteration 4679 : loss : 0.058719, loss_ce: 0.009461
iteration 4680 : loss : 0.039675, loss_ce: 0.006333
iteration 4681 : loss : 0.046000, loss_ce: 0.010430
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 4682 : loss : 0.046661, loss_ce: 0.010607
iteration 4683 : loss : 0.051066, loss_ce: 0.016366
iteration 4684 : loss : 0.045324, loss_ce: 0.010864
iteration 4685 : loss : 0.090886, loss_ce: 0.023025
iteration 4686 : loss : 0.048637, loss_ce: 0.013988
iteration 4687 : loss : 0.088689, loss_ce: 0.024340
iteration 4688 : loss : 0.060360, loss_ce: 0.013849
iteration 4689 : loss : 0.052684, loss_ce: 0.020968
iteration 4690 : loss : 0.055128, loss_ce: 0.019171
iteration 4691 : loss : 0.065021, loss_ce: 0.011691
iteration 4692 : loss : 0.047357, loss_ce: 0.010214
iteration 4693 : loss : 0.058770, loss_ce: 0.011029
iteration 4694 : loss : 0.059054, loss_ce: 0.019261
iteration 4695 : loss : 0.047721, loss_ce: 0.019145
iteration 4696 : loss : 0.049953, loss_ce: 0.019241
iteration 4697 : loss : 0.060971, loss_ce: 0.012652
iteration 4698 : loss : 0.033011, loss_ce: 0.013288
iteration 4699 : loss : 0.030005, loss_ce: 0.006912
iteration 4700 : loss : 0.090063, loss_ce: 0.010072
iteration 4701 : loss : 0.069826, loss_ce: 0.019074
iteration 4702 : loss : 0.059497, loss_ce: 0.013135
iteration 4703 : loss : 0.039605, loss_ce: 0.011370
iteration 4704 : loss : 0.046016, loss_ce: 0.015293
iteration 4705 : loss : 0.054394, loss_ce: 0.010794
iteration 4706 : loss : 0.042849, loss_ce: 0.018572
iteration 4707 : loss : 0.044850, loss_ce: 0.019122
iteration 4708 : loss : 0.036381, loss_ce: 0.013079
iteration 4709 : loss : 0.042025, loss_ce: 0.018902
iteration 4710 : loss : 0.034294, loss_ce: 0.014540
iteration 4711 : loss : 0.055441, loss_ce: 0.013073
iteration 4712 : loss : 0.048901, loss_ce: 0.022421
pred_sum 27672
gtsum tensor(33205, device='cuda:0')
iteration 4713 : loss : 0.068762, loss_ce: 0.015357
iteration 4714 : loss : 0.050054, loss_ce: 0.017410
iteration 4715 : loss : 0.055452, loss_ce: 0.017462
iteration 4716 : loss : 0.038243, loss_ce: 0.013501
iteration 4717 : loss : 0.049618, loss_ce: 0.013042
iteration 4718 : loss : 0.041158, loss_ce: 0.013527
iteration 4719 : loss : 0.045643, loss_ce: 0.018179
iteration 4720 : loss : 0.046693, loss_ce: 0.012171
iteration 4721 : loss : 0.047587, loss_ce: 0.020282
iteration 4722 : loss : 0.046560, loss_ce: 0.014981
iteration 4723 : loss : 0.036672, loss_ce: 0.011794
iteration 4724 : loss : 0.035464, loss_ce: 0.012195
iteration 4725 : loss : 0.070273, loss_ce: 0.006891
iteration 4726 : loss : 0.035334, loss_ce: 0.011551
iteration 4727 : loss : 0.032342, loss_ce: 0.013409
iteration 4728 : loss : 0.041655, loss_ce: 0.014318
iteration 4729 : loss : 0.082287, loss_ce: 0.008305
iteration 4730 : loss : 0.036097, loss_ce: 0.009151
iteration 4731 : loss : 0.045314, loss_ce: 0.021211
iteration 4732 : loss : 0.055000, loss_ce: 0.017315
iteration 4733 : loss : 0.045130, loss_ce: 0.022275
iteration 4734 : loss : 0.086337, loss_ce: 0.007551
iteration 4735 : loss : 0.044322, loss_ce: 0.010403
iteration 4736 : loss : 0.035846, loss_ce: 0.013770
iteration 4737 : loss : 0.038467, loss_ce: 0.019921
iteration 4738 : loss : 0.038921, loss_ce: 0.011648
iteration 4739 : loss : 0.036673, loss_ce: 0.010866
iteration 4740 : loss : 0.037514, loss_ce: 0.011968
iteration 4741 : loss : 0.082407, loss_ce: 0.007088
iteration 4742 : loss : 0.083067, loss_ce: 0.007981
iteration 4743 : loss : 0.238380, loss_ce: 0.011910
 26%|███████▋                      | 51/200 [46:13<2:15:42, 54.65s/it]pred_sum 51133
gtsum tensor(53140, device='cuda:0')
iteration 4744 : loss : 0.037999, loss_ce: 0.011232
iteration 4745 : loss : 0.056183, loss_ce: 0.012286
iteration 4746 : loss : 0.037066, loss_ce: 0.013836
iteration 4747 : loss : 0.043433, loss_ce: 0.009712
iteration 4748 : loss : 0.086940, loss_ce: 0.011103
iteration 4749 : loss : 0.080971, loss_ce: 0.007765
iteration 4750 : loss : 0.036875, loss_ce: 0.009723
iteration 4751 : loss : 0.036577, loss_ce: 0.014160
iteration 4752 : loss : 0.032854, loss_ce: 0.010385
iteration 4753 : loss : 0.036290, loss_ce: 0.013376
iteration 4754 : loss : 0.037111, loss_ce: 0.013081
iteration 4755 : loss : 0.035242, loss_ce: 0.012729
iteration 4756 : loss : 0.042108, loss_ce: 0.011654
iteration 4757 : loss : 0.044886, loss_ce: 0.010316
iteration 4758 : loss : 0.038648, loss_ce: 0.015791
iteration 4759 : loss : 0.039928, loss_ce: 0.014939
iteration 4760 : loss : 0.042247, loss_ce: 0.012270
iteration 4761 : loss : 0.042905, loss_ce: 0.016618
iteration 4762 : loss : 0.033962, loss_ce: 0.010107
iteration 4763 : loss : 0.029305, loss_ce: 0.012519
iteration 4764 : loss : 0.050322, loss_ce: 0.010061
iteration 4765 : loss : 0.038125, loss_ce: 0.018474
iteration 4766 : loss : 0.041087, loss_ce: 0.014167
iteration 4767 : loss : 0.045935, loss_ce: 0.014434
iteration 4768 : loss : 0.041001, loss_ce: 0.014847
iteration 4769 : loss : 0.032384, loss_ce: 0.014142
iteration 4770 : loss : 0.040043, loss_ce: 0.010783
iteration 4771 : loss : 0.087522, loss_ce: 0.009927
iteration 4772 : loss : 0.034039, loss_ce: 0.012774
iteration 4773 : loss : 0.035335, loss_ce: 0.016494
iteration 4774 : loss : 0.033205, loss_ce: 0.011937
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 4775 : loss : 0.041394, loss_ce: 0.017976
iteration 4776 : loss : 0.032559, loss_ce: 0.013425
iteration 4777 : loss : 0.030061, loss_ce: 0.009026
iteration 4778 : loss : 0.034892, loss_ce: 0.013388
iteration 4779 : loss : 0.040154, loss_ce: 0.011026
iteration 4780 : loss : 0.038632, loss_ce: 0.016609
iteration 4781 : loss : 0.035581, loss_ce: 0.014501
iteration 4782 : loss : 0.041118, loss_ce: 0.012186
iteration 4783 : loss : 0.041243, loss_ce: 0.014108
iteration 4784 : loss : 0.037794, loss_ce: 0.015828
iteration 4785 : loss : 0.041549, loss_ce: 0.010830
iteration 4786 : loss : 0.043722, loss_ce: 0.012171
iteration 4787 : loss : 0.035700, loss_ce: 0.012002
iteration 4788 : loss : 0.028910, loss_ce: 0.009685
iteration 4789 : loss : 0.048559, loss_ce: 0.011281
iteration 4790 : loss : 0.037190, loss_ce: 0.012551
iteration 4791 : loss : 0.079516, loss_ce: 0.010104
iteration 4792 : loss : 0.050167, loss_ce: 0.013120
iteration 4793 : loss : 0.037637, loss_ce: 0.015521
iteration 4794 : loss : 0.036503, loss_ce: 0.010311
iteration 4795 : loss : 0.035983, loss_ce: 0.011020
iteration 4796 : loss : 0.033223, loss_ce: 0.013147
iteration 4797 : loss : 0.041500, loss_ce: 0.007245
iteration 4798 : loss : 0.030127, loss_ce: 0.011763
iteration 4799 : loss : 0.038469, loss_ce: 0.012502
iteration 4800 : loss : 0.040471, loss_ce: 0.011808
iteration 4801 : loss : 0.041167, loss_ce: 0.011130
iteration 4802 : loss : 0.033726, loss_ce: 0.011311
iteration 4803 : loss : 0.030606, loss_ce: 0.011597
iteration 4804 : loss : 0.033416, loss_ce: 0.010770
iteration 4805 : loss : 0.067151, loss_ce: 0.006337
pred_sum 2145
gtsum tensor(1810, device='cuda:0')
iteration 4806 : loss : 0.092962, loss_ce: 0.008943
iteration 4807 : loss : 0.040372, loss_ce: 0.014112
iteration 4808 : loss : 0.055514, loss_ce: 0.012529
iteration 4809 : loss : 0.040572, loss_ce: 0.008498
iteration 4810 : loss : 0.037323, loss_ce: 0.014389
iteration 4811 : loss : 0.042103, loss_ce: 0.011977
iteration 4812 : loss : 0.037051, loss_ce: 0.013226
iteration 4813 : loss : 0.083345, loss_ce: 0.008892
iteration 4814 : loss : 0.066637, loss_ce: 0.006758
iteration 4815 : loss : 0.089868, loss_ce: 0.011771
iteration 4816 : loss : 0.037362, loss_ce: 0.012503
iteration 4817 : loss : 0.029234, loss_ce: 0.011600
iteration 4818 : loss : 0.042785, loss_ce: 0.012026
iteration 4819 : loss : 0.025009, loss_ce: 0.012071
iteration 4820 : loss : 0.042202, loss_ce: 0.016341
iteration 4821 : loss : 0.045578, loss_ce: 0.012720
iteration 4822 : loss : 0.038933, loss_ce: 0.015301
iteration 4823 : loss : 0.037535, loss_ce: 0.011332
iteration 4824 : loss : 0.084330, loss_ce: 0.006267
iteration 4825 : loss : 0.042902, loss_ce: 0.009740
iteration 4826 : loss : 0.042640, loss_ce: 0.007473
iteration 4827 : loss : 0.039687, loss_ce: 0.013011
iteration 4828 : loss : 0.091838, loss_ce: 0.009773
iteration 4829 : loss : 0.036792, loss_ce: 0.015366
iteration 4830 : loss : 0.035678, loss_ce: 0.009333
iteration 4831 : loss : 0.032622, loss_ce: 0.012566
iteration 4832 : loss : 0.034709, loss_ce: 0.011690
iteration 4833 : loss : 0.040760, loss_ce: 0.012500
iteration 4834 : loss : 0.039938, loss_ce: 0.014184
iteration 4835 : loss : 0.081123, loss_ce: 0.014889
iteration 4836 : loss : 0.208097, loss_ce: 0.047583
 26%|███████▊                      | 52/200 [47:08<2:14:40, 54.60s/it]pred_sum 7117
gtsum tensor(8381, device='cuda:0')
iteration 4837 : loss : 0.032719, loss_ce: 0.011044
iteration 4838 : loss : 0.037629, loss_ce: 0.012447
iteration 4839 : loss : 0.066315, loss_ce: 0.012989
iteration 4840 : loss : 0.039337, loss_ce: 0.018077
iteration 4841 : loss : 0.041415, loss_ce: 0.019088
iteration 4842 : loss : 0.086414, loss_ce: 0.009207
iteration 4843 : loss : 0.037820, loss_ce: 0.016478
iteration 4844 : loss : 0.040853, loss_ce: 0.011517
iteration 4845 : loss : 0.045419, loss_ce: 0.014608
iteration 4846 : loss : 0.046240, loss_ce: 0.010929
iteration 4847 : loss : 0.038858, loss_ce: 0.008692
iteration 4848 : loss : 0.045796, loss_ce: 0.009413
iteration 4849 : loss : 0.087792, loss_ce: 0.012669
iteration 4850 : loss : 0.064005, loss_ce: 0.009310
iteration 4851 : loss : 0.033448, loss_ce: 0.009810
iteration 4852 : loss : 0.044871, loss_ce: 0.019343
iteration 4853 : loss : 0.042911, loss_ce: 0.021489
iteration 4854 : loss : 0.082929, loss_ce: 0.010016
iteration 4855 : loss : 0.032954, loss_ce: 0.009387
iteration 4856 : loss : 0.035327, loss_ce: 0.012663
iteration 4857 : loss : 0.037177, loss_ce: 0.007398
iteration 4858 : loss : 0.028381, loss_ce: 0.013190
iteration 4859 : loss : 0.037670, loss_ce: 0.012626
iteration 4860 : loss : 0.040816, loss_ce: 0.010549
iteration 4861 : loss : 0.053211, loss_ce: 0.012184
iteration 4862 : loss : 0.029856, loss_ce: 0.011448
iteration 4863 : loss : 0.038949, loss_ce: 0.013669
iteration 4864 : loss : 0.035624, loss_ce: 0.012181
iteration 4865 : loss : 0.031829, loss_ce: 0.007401
iteration 4866 : loss : 0.032527, loss_ce: 0.008853
iteration 4867 : loss : 0.041076, loss_ce: 0.012645
pred_sum 6773
gtsum tensor(7596, device='cuda:0')
iteration 4868 : loss : 0.082070, loss_ce: 0.007589
iteration 4869 : loss : 0.041673, loss_ce: 0.011769
iteration 4870 : loss : 0.037222, loss_ce: 0.014273
iteration 4871 : loss : 0.039806, loss_ce: 0.013767
iteration 4872 : loss : 0.034539, loss_ce: 0.012879
iteration 4873 : loss : 0.032112, loss_ce: 0.013665
iteration 4874 : loss : 0.039015, loss_ce: 0.011656
iteration 4875 : loss : 0.042835, loss_ce: 0.008624
iteration 4876 : loss : 0.030290, loss_ce: 0.011809
iteration 4877 : loss : 0.041713, loss_ce: 0.010425
iteration 4878 : loss : 0.075994, loss_ce: 0.005823
iteration 4879 : loss : 0.078563, loss_ce: 0.010321
iteration 4880 : loss : 0.041221, loss_ce: 0.007655
iteration 4881 : loss : 0.034125, loss_ce: 0.012943
iteration 4882 : loss : 0.043004, loss_ce: 0.013881
iteration 4883 : loss : 0.032215, loss_ce: 0.014099
iteration 4884 : loss : 0.034419, loss_ce: 0.007277
iteration 4885 : loss : 0.039274, loss_ce: 0.016911
iteration 4886 : loss : 0.047734, loss_ce: 0.011326
iteration 4887 : loss : 0.045896, loss_ce: 0.007548
iteration 4888 : loss : 0.048364, loss_ce: 0.012572
iteration 4889 : loss : 0.035863, loss_ce: 0.013325
iteration 4890 : loss : 0.036096, loss_ce: 0.014731
iteration 4891 : loss : 0.039604, loss_ce: 0.008967
iteration 4892 : loss : 0.089711, loss_ce: 0.014232
iteration 4893 : loss : 0.031293, loss_ce: 0.014541
iteration 4894 : loss : 0.036013, loss_ce: 0.013767
iteration 4895 : loss : 0.033657, loss_ce: 0.009114
iteration 4896 : loss : 0.035761, loss_ce: 0.014465
iteration 4897 : loss : 0.029660, loss_ce: 0.010180
iteration 4898 : loss : 0.036072, loss_ce: 0.014053
pred_sum 2159
gtsum tensor(2606, device='cuda:0')
iteration 4899 : loss : 0.037768, loss_ce: 0.017434
iteration 4900 : loss : 0.048755, loss_ce: 0.010182
iteration 4901 : loss : 0.032992, loss_ce: 0.006980
iteration 4902 : loss : 0.030357, loss_ce: 0.009984
iteration 4903 : loss : 0.035384, loss_ce: 0.013885
iteration 4904 : loss : 0.041582, loss_ce: 0.013007
iteration 4905 : loss : 0.035504, loss_ce: 0.008378
iteration 4906 : loss : 0.031640, loss_ce: 0.012271
iteration 4907 : loss : 0.083554, loss_ce: 0.008330
iteration 4908 : loss : 0.037023, loss_ce: 0.012760
iteration 4909 : loss : 0.034205, loss_ce: 0.017282
iteration 4910 : loss : 0.029220, loss_ce: 0.010605
iteration 4911 : loss : 0.037454, loss_ce: 0.010863
iteration 4912 : loss : 0.032321, loss_ce: 0.012583
iteration 4913 : loss : 0.036477, loss_ce: 0.013389
iteration 4914 : loss : 0.031087, loss_ce: 0.008865
iteration 4915 : loss : 0.033241, loss_ce: 0.013496
iteration 4916 : loss : 0.036628, loss_ce: 0.013686
iteration 4917 : loss : 0.036132, loss_ce: 0.011595
iteration 4918 : loss : 0.051278, loss_ce: 0.012485
iteration 4919 : loss : 0.097229, loss_ce: 0.008314
iteration 4920 : loss : 0.083789, loss_ce: 0.010475
iteration 4921 : loss : 0.033084, loss_ce: 0.011788
iteration 4922 : loss : 0.036071, loss_ce: 0.014904
iteration 4923 : loss : 0.031759, loss_ce: 0.011234
iteration 4924 : loss : 0.025703, loss_ce: 0.008392
iteration 4925 : loss : 0.041149, loss_ce: 0.013082
iteration 4926 : loss : 0.039143, loss_ce: 0.012161
iteration 4927 : loss : 0.035109, loss_ce: 0.011577
iteration 4928 : loss : 0.027730, loss_ce: 0.011802
iteration 4929 : loss : 0.099067, loss_ce: 0.012424
 26%|███████▉                      | 53/200 [48:02<2:13:40, 54.56s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 4930 : loss : 0.031745, loss_ce: 0.012225
iteration 4931 : loss : 0.087850, loss_ce: 0.007399
iteration 4932 : loss : 0.033341, loss_ce: 0.016366
iteration 4933 : loss : 0.076214, loss_ce: 0.004966
iteration 4934 : loss : 0.046829, loss_ce: 0.011265
iteration 4935 : loss : 0.030233, loss_ce: 0.009793
iteration 4936 : loss : 0.038892, loss_ce: 0.009029
iteration 4937 : loss : 0.034699, loss_ce: 0.012959
iteration 4938 : loss : 0.083198, loss_ce: 0.013159
iteration 4939 : loss : 0.034549, loss_ce: 0.014049
iteration 4940 : loss : 0.039713, loss_ce: 0.009532
iteration 4941 : loss : 0.040030, loss_ce: 0.014279
iteration 4942 : loss : 0.112081, loss_ce: 0.006535
iteration 4943 : loss : 0.047651, loss_ce: 0.013433
iteration 4944 : loss : 0.042722, loss_ce: 0.009281
iteration 4945 : loss : 0.033618, loss_ce: 0.012555
iteration 4946 : loss : 0.034293, loss_ce: 0.009728
iteration 4947 : loss : 0.030627, loss_ce: 0.010360
iteration 4948 : loss : 0.030724, loss_ce: 0.012234
iteration 4949 : loss : 0.029991, loss_ce: 0.008958
iteration 4950 : loss : 0.034545, loss_ce: 0.009525
iteration 4951 : loss : 0.034893, loss_ce: 0.013081
iteration 4952 : loss : 0.079414, loss_ce: 0.010090
iteration 4953 : loss : 0.044256, loss_ce: 0.017113
iteration 4954 : loss : 0.039905, loss_ce: 0.015441
iteration 4955 : loss : 0.039788, loss_ce: 0.011645
iteration 4956 : loss : 0.040470, loss_ce: 0.014902
iteration 4957 : loss : 0.041072, loss_ce: 0.019889
iteration 4958 : loss : 0.038631, loss_ce: 0.014987
iteration 4959 : loss : 0.040525, loss_ce: 0.009985
iteration 4960 : loss : 0.040796, loss_ce: 0.016863
pred_sum 376
gtsum tensor(356, device='cuda:0')
iteration 4961 : loss : 0.042922, loss_ce: 0.019548
iteration 4962 : loss : 0.071208, loss_ce: 0.012559
iteration 4963 : loss : 0.040214, loss_ce: 0.015634
iteration 4964 : loss : 0.040339, loss_ce: 0.019228
iteration 4965 : loss : 0.083953, loss_ce: 0.007839
iteration 4966 : loss : 0.031059, loss_ce: 0.012019
iteration 4967 : loss : 0.030758, loss_ce: 0.007897
iteration 4968 : loss : 0.048864, loss_ce: 0.015771
iteration 4969 : loss : 0.035747, loss_ce: 0.010111
iteration 4970 : loss : 0.045727, loss_ce: 0.009103
iteration 4971 : loss : 0.087031, loss_ce: 0.013029
iteration 4972 : loss : 0.048863, loss_ce: 0.016287
iteration 4973 : loss : 0.035340, loss_ce: 0.016577
iteration 4974 : loss : 0.039072, loss_ce: 0.009194
iteration 4975 : loss : 0.041829, loss_ce: 0.012759
iteration 4976 : loss : 0.028433, loss_ce: 0.008945
iteration 4977 : loss : 0.030683, loss_ce: 0.007726
iteration 4978 : loss : 0.039039, loss_ce: 0.016298
iteration 4979 : loss : 0.035025, loss_ce: 0.017025
iteration 4980 : loss : 0.039025, loss_ce: 0.012937
iteration 4981 : loss : 0.035680, loss_ce: 0.013367
iteration 4982 : loss : 0.031534, loss_ce: 0.010705
iteration 4983 : loss : 0.035804, loss_ce: 0.015046
iteration 4984 : loss : 0.129845, loss_ce: 0.004549
iteration 4985 : loss : 0.039249, loss_ce: 0.015238
iteration 4986 : loss : 0.029580, loss_ce: 0.007445
iteration 4987 : loss : 0.034683, loss_ce: 0.009843
iteration 4988 : loss : 0.035685, loss_ce: 0.016382
iteration 4989 : loss : 0.030205, loss_ce: 0.013852
iteration 4990 : loss : 0.031950, loss_ce: 0.008839
iteration 4991 : loss : 0.045292, loss_ce: 0.007447
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 4992 : loss : 0.035906, loss_ce: 0.011283
iteration 4993 : loss : 0.076433, loss_ce: 0.007912
iteration 4994 : loss : 0.038409, loss_ce: 0.015630
iteration 4995 : loss : 0.080027, loss_ce: 0.005444
iteration 4996 : loss : 0.039237, loss_ce: 0.015011
iteration 4997 : loss : 0.071931, loss_ce: 0.004137
iteration 4998 : loss : 0.029324, loss_ce: 0.012187
iteration 4999 : loss : 0.034841, loss_ce: 0.009822
iteration 5000 : loss : 0.036911, loss_ce: 0.014836
iteration 5001 : loss : 0.032084, loss_ce: 0.010294
iteration 5002 : loss : 0.039974, loss_ce: 0.010356
iteration 5003 : loss : 0.031264, loss_ce: 0.014795
iteration 5004 : loss : 0.035903, loss_ce: 0.015408
iteration 5005 : loss : 0.040020, loss_ce: 0.013632
iteration 5006 : loss : 0.084986, loss_ce: 0.009386
iteration 5007 : loss : 0.041397, loss_ce: 0.006929
iteration 5008 : loss : 0.083897, loss_ce: 0.014080
iteration 5009 : loss : 0.041731, loss_ce: 0.017618
iteration 5010 : loss : 0.048783, loss_ce: 0.007595
iteration 5011 : loss : 0.036746, loss_ce: 0.009841
iteration 5012 : loss : 0.042294, loss_ce: 0.012704
iteration 5013 : loss : 0.048359, loss_ce: 0.006682
iteration 5014 : loss : 0.082207, loss_ce: 0.007979
iteration 5015 : loss : 0.039258, loss_ce: 0.019092
iteration 5016 : loss : 0.032428, loss_ce: 0.009770
iteration 5017 : loss : 0.022872, loss_ce: 0.005250
iteration 5018 : loss : 0.028382, loss_ce: 0.010373
iteration 5019 : loss : 0.039605, loss_ce: 0.009659
iteration 5020 : loss : 0.038808, loss_ce: 0.016089
iteration 5021 : loss : 0.049972, loss_ce: 0.013333
iteration 5022 : loss : 0.413804, loss_ce: 0.008923
 27%|████████                      | 54/200 [48:57<2:12:43, 54.55s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 5023 : loss : 0.039465, loss_ce: 0.008288
iteration 5024 : loss : 0.037823, loss_ce: 0.010312
iteration 5025 : loss : 0.034775, loss_ce: 0.008887
iteration 5026 : loss : 0.058747, loss_ce: 0.016710
iteration 5027 : loss : 0.036323, loss_ce: 0.013485
iteration 5028 : loss : 0.039323, loss_ce: 0.011467
iteration 5029 : loss : 0.037456, loss_ce: 0.020066
iteration 5030 : loss : 0.035068, loss_ce: 0.018889
iteration 5031 : loss : 0.041028, loss_ce: 0.017596
iteration 5032 : loss : 0.030985, loss_ce: 0.013434
iteration 5033 : loss : 0.042623, loss_ce: 0.014566
iteration 5034 : loss : 0.036747, loss_ce: 0.014466
iteration 5035 : loss : 0.090488, loss_ce: 0.013067
iteration 5036 : loss : 0.034858, loss_ce: 0.013881
iteration 5037 : loss : 0.034549, loss_ce: 0.011934
iteration 5038 : loss : 0.028285, loss_ce: 0.007845
iteration 5039 : loss : 0.035325, loss_ce: 0.011402
iteration 5040 : loss : 0.055023, loss_ce: 0.010345
iteration 5041 : loss : 0.033964, loss_ce: 0.010322
iteration 5042 : loss : 0.029560, loss_ce: 0.008914
iteration 5043 : loss : 0.026514, loss_ce: 0.009199
iteration 5044 : loss : 0.035362, loss_ce: 0.011753
iteration 5045 : loss : 0.037784, loss_ce: 0.015473
iteration 5046 : loss : 0.086678, loss_ce: 0.012616
iteration 5047 : loss : 0.036486, loss_ce: 0.009515
iteration 5048 : loss : 0.038889, loss_ce: 0.011888
iteration 5049 : loss : 0.038726, loss_ce: 0.015825
iteration 5050 : loss : 0.104157, loss_ce: 0.007123
iteration 5051 : loss : 0.035696, loss_ce: 0.012793
iteration 5052 : loss : 0.034532, loss_ce: 0.015743
iteration 5053 : loss : 0.037840, loss_ce: 0.011292
pred_sum 178
gtsum tensor(235, device='cuda:0')
iteration 5054 : loss : 0.033182, loss_ce: 0.009780
iteration 5055 : loss : 0.055681, loss_ce: 0.011886
iteration 5056 : loss : 0.076955, loss_ce: 0.007215
iteration 5057 : loss : 0.047254, loss_ce: 0.014909
iteration 5058 : loss : 0.034714, loss_ce: 0.010527
iteration 5059 : loss : 0.046430, loss_ce: 0.014217
iteration 5060 : loss : 0.038884, loss_ce: 0.014625
iteration 5061 : loss : 0.035514, loss_ce: 0.009271
iteration 5062 : loss : 0.028518, loss_ce: 0.010028
iteration 5063 : loss : 0.032304, loss_ce: 0.013877
iteration 5064 : loss : 0.033905, loss_ce: 0.007117
iteration 5065 : loss : 0.043659, loss_ce: 0.006903
iteration 5066 : loss : 0.035988, loss_ce: 0.015477
iteration 5067 : loss : 0.088110, loss_ce: 0.009199
iteration 5068 : loss : 0.038782, loss_ce: 0.012215
iteration 5069 : loss : 0.034595, loss_ce: 0.012597
iteration 5070 : loss : 0.037736, loss_ce: 0.006705
iteration 5071 : loss : 0.040466, loss_ce: 0.017644
iteration 5072 : loss : 0.038795, loss_ce: 0.015666
iteration 5073 : loss : 0.046242, loss_ce: 0.016377
iteration 5074 : loss : 0.040444, loss_ce: 0.010578
iteration 5075 : loss : 0.041809, loss_ce: 0.015478
iteration 5076 : loss : 0.023348, loss_ce: 0.007623
iteration 5077 : loss : 0.028229, loss_ce: 0.011508
iteration 5078 : loss : 0.031002, loss_ce: 0.011533
iteration 5079 : loss : 0.089501, loss_ce: 0.008972
iteration 5080 : loss : 0.031986, loss_ce: 0.010801
iteration 5081 : loss : 0.037490, loss_ce: 0.010344
iteration 5082 : loss : 0.035596, loss_ce: 0.012433
iteration 5083 : loss : 0.032293, loss_ce: 0.013218
iteration 5084 : loss : 0.039085, loss_ce: 0.015388
pred_sum 175
gtsum tensor(184, device='cuda:0')
iteration 5085 : loss : 0.029537, loss_ce: 0.011168
iteration 5086 : loss : 0.044222, loss_ce: 0.012817
iteration 5087 : loss : 0.032199, loss_ce: 0.006299
iteration 5088 : loss : 0.028433, loss_ce: 0.008578
iteration 5089 : loss : 0.081790, loss_ce: 0.009738
iteration 5090 : loss : 0.025571, loss_ce: 0.008071
iteration 5091 : loss : 0.039033, loss_ce: 0.012737
iteration 5092 : loss : 0.037536, loss_ce: 0.018021
iteration 5093 : loss : 0.033395, loss_ce: 0.011358
iteration 5094 : loss : 0.034785, loss_ce: 0.011089
iteration 5095 : loss : 0.131880, loss_ce: 0.007360
iteration 5096 : loss : 0.032116, loss_ce: 0.013225
iteration 5097 : loss : 0.033470, loss_ce: 0.006660
iteration 5098 : loss : 0.026766, loss_ce: 0.008714
iteration 5099 : loss : 0.026947, loss_ce: 0.011201
iteration 5100 : loss : 0.031295, loss_ce: 0.008788
iteration 5101 : loss : 0.039580, loss_ce: 0.016043
iteration 5102 : loss : 0.048304, loss_ce: 0.011198
iteration 5103 : loss : 0.039092, loss_ce: 0.011744
iteration 5104 : loss : 0.043210, loss_ce: 0.012922
iteration 5105 : loss : 0.037810, loss_ce: 0.014428
iteration 5106 : loss : 0.054731, loss_ce: 0.010189
iteration 5107 : loss : 0.035235, loss_ce: 0.014923
iteration 5108 : loss : 0.032925, loss_ce: 0.008322
iteration 5109 : loss : 0.032439, loss_ce: 0.007780
iteration 5110 : loss : 0.024903, loss_ce: 0.007220
iteration 5111 : loss : 0.040052, loss_ce: 0.010550
iteration 5112 : loss : 0.033474, loss_ce: 0.013461
iteration 5113 : loss : 0.035296, loss_ce: 0.003782
iteration 5114 : loss : 0.043154, loss_ce: 0.012713
iteration 5115 : loss : 0.144518, loss_ce: 0.008129
 28%|████████▎                     | 55/200 [49:51<2:11:54, 54.58s/it]pred_sum 31343
gtsum tensor(32088, device='cuda:0')
iteration 5116 : loss : 0.040245, loss_ce: 0.014011
iteration 5117 : loss : 0.035199, loss_ce: 0.009239
iteration 5118 : loss : 0.038212, loss_ce: 0.019331
iteration 5119 : loss : 0.056227, loss_ce: 0.007950
iteration 5120 : loss : 0.038905, loss_ce: 0.017141
iteration 5121 : loss : 0.038527, loss_ce: 0.012701
iteration 5122 : loss : 0.043065, loss_ce: 0.018102
iteration 5123 : loss : 0.038558, loss_ce: 0.009272
iteration 5124 : loss : 0.049061, loss_ce: 0.019363
iteration 5125 : loss : 0.038058, loss_ce: 0.015960
iteration 5126 : loss : 0.041451, loss_ce: 0.014728
iteration 5127 : loss : 0.031293, loss_ce: 0.008336
iteration 5128 : loss : 0.034742, loss_ce: 0.008382
iteration 5129 : loss : 0.043087, loss_ce: 0.014057
iteration 5130 : loss : 0.080915, loss_ce: 0.008731
iteration 5131 : loss : 0.039681, loss_ce: 0.015003
iteration 5132 : loss : 0.039059, loss_ce: 0.016079
iteration 5133 : loss : 0.037958, loss_ce: 0.009179
iteration 5134 : loss : 0.031968, loss_ce: 0.013702
iteration 5135 : loss : 0.029512, loss_ce: 0.007797
iteration 5136 : loss : 0.046770, loss_ce: 0.008493
iteration 5137 : loss : 0.034021, loss_ce: 0.014417
iteration 5138 : loss : 0.036867, loss_ce: 0.013182
iteration 5139 : loss : 0.032873, loss_ce: 0.011497
iteration 5140 : loss : 0.046033, loss_ce: 0.020314
iteration 5141 : loss : 0.033292, loss_ce: 0.010789
iteration 5142 : loss : 0.032910, loss_ce: 0.010195
iteration 5143 : loss : 0.044006, loss_ce: 0.013678
iteration 5144 : loss : 0.045759, loss_ce: 0.010732
iteration 5145 : loss : 0.040184, loss_ce: 0.012663
iteration 5146 : loss : 0.036824, loss_ce: 0.009673
pred_sum 2507
gtsum tensor(2999, device='cuda:0')
iteration 5147 : loss : 0.040405, loss_ce: 0.015907
iteration 5148 : loss : 0.037533, loss_ce: 0.011374
iteration 5149 : loss : 0.032442, loss_ce: 0.008643
iteration 5150 : loss : 0.042039, loss_ce: 0.016256
iteration 5151 : loss : 0.029085, loss_ce: 0.010059
iteration 5152 : loss : 0.035013, loss_ce: 0.013170
iteration 5153 : loss : 0.034843, loss_ce: 0.010377
iteration 5154 : loss : 0.076417, loss_ce: 0.015257
iteration 5155 : loss : 0.037079, loss_ce: 0.013924
iteration 5156 : loss : 0.028262, loss_ce: 0.008315
iteration 5157 : loss : 0.032028, loss_ce: 0.006786
iteration 5158 : loss : 0.031012, loss_ce: 0.011723
iteration 5159 : loss : 0.031786, loss_ce: 0.013770
iteration 5160 : loss : 0.035630, loss_ce: 0.010350
iteration 5161 : loss : 0.030407, loss_ce: 0.010945
iteration 5162 : loss : 0.084307, loss_ce: 0.010361
iteration 5163 : loss : 0.036491, loss_ce: 0.011825
iteration 5164 : loss : 0.082794, loss_ce: 0.014462
iteration 5165 : loss : 0.042751, loss_ce: 0.010832
iteration 5166 : loss : 0.027259, loss_ce: 0.009864
iteration 5167 : loss : 0.084445, loss_ce: 0.011778
iteration 5168 : loss : 0.041336, loss_ce: 0.016158
iteration 5169 : loss : 0.032413, loss_ce: 0.013366
iteration 5170 : loss : 0.036843, loss_ce: 0.012665
iteration 5171 : loss : 0.030954, loss_ce: 0.010014
iteration 5172 : loss : 0.032579, loss_ce: 0.010026
iteration 5173 : loss : 0.040803, loss_ce: 0.009327
iteration 5174 : loss : 0.025315, loss_ce: 0.005098
iteration 5175 : loss : 0.026297, loss_ce: 0.007395
iteration 5176 : loss : 0.036421, loss_ce: 0.014005
iteration 5177 : loss : 0.048435, loss_ce: 0.012019
pred_sum 20921
gtsum tensor(22324, device='cuda:0')
iteration 5178 : loss : 0.087114, loss_ce: 0.012371
iteration 5179 : loss : 0.028671, loss_ce: 0.011026
iteration 5180 : loss : 0.035541, loss_ce: 0.011254
iteration 5181 : loss : 0.103124, loss_ce: 0.010073
iteration 5182 : loss : 0.035941, loss_ce: 0.014967
iteration 5183 : loss : 0.034038, loss_ce: 0.016913
iteration 5184 : loss : 0.034547, loss_ce: 0.011915
iteration 5185 : loss : 0.032723, loss_ce: 0.010816
iteration 5186 : loss : 0.044354, loss_ce: 0.015302
iteration 5187 : loss : 0.036667, loss_ce: 0.008572
iteration 5188 : loss : 0.030860, loss_ce: 0.012743
iteration 5189 : loss : 0.041119, loss_ce: 0.011072
iteration 5190 : loss : 0.078887, loss_ce: 0.008842
iteration 5191 : loss : 0.079213, loss_ce: 0.004712
iteration 5192 : loss : 0.033292, loss_ce: 0.015247
iteration 5193 : loss : 0.097820, loss_ce: 0.007689
iteration 5194 : loss : 0.036255, loss_ce: 0.010856
iteration 5195 : loss : 0.035344, loss_ce: 0.011034
iteration 5196 : loss : 0.045267, loss_ce: 0.009641
iteration 5197 : loss : 0.032308, loss_ce: 0.008316
iteration 5198 : loss : 0.054433, loss_ce: 0.009804
iteration 5199 : loss : 0.038215, loss_ce: 0.013416
iteration 5200 : loss : 0.086182, loss_ce: 0.006494
iteration 5201 : loss : 0.033845, loss_ce: 0.010129
iteration 5202 : loss : 0.035359, loss_ce: 0.007966
iteration 5203 : loss : 0.032807, loss_ce: 0.009983
iteration 5204 : loss : 0.033181, loss_ce: 0.012419
iteration 5205 : loss : 0.035922, loss_ce: 0.008768
iteration 5206 : loss : 0.032743, loss_ce: 0.011759
iteration 5207 : loss : 0.042977, loss_ce: 0.008871
iteration 5208 : loss : 0.057259, loss_ce: 0.028957
 28%|████████▍                     | 56/200 [50:46<2:11:05, 54.62s/it]pred_sum 46605
gtsum tensor(47839, device='cuda:0')
iteration 5209 : loss : 0.029836, loss_ce: 0.010684
iteration 5210 : loss : 0.037879, loss_ce: 0.014737
iteration 5211 : loss : 0.040248, loss_ce: 0.008850
iteration 5212 : loss : 0.029197, loss_ce: 0.014001
iteration 5213 : loss : 0.083506, loss_ce: 0.005986
iteration 5214 : loss : 0.088881, loss_ce: 0.011111
iteration 5215 : loss : 0.035314, loss_ce: 0.008322
iteration 5216 : loss : 0.037015, loss_ce: 0.010803
iteration 5217 : loss : 0.057135, loss_ce: 0.008184
iteration 5218 : loss : 0.031955, loss_ce: 0.009545
iteration 5219 : loss : 0.032182, loss_ce: 0.008228
iteration 5220 : loss : 0.037940, loss_ce: 0.010079
iteration 5221 : loss : 0.032514, loss_ce: 0.012441
iteration 5222 : loss : 0.034759, loss_ce: 0.007320
iteration 5223 : loss : 0.041812, loss_ce: 0.005388
iteration 5224 : loss : 0.032250, loss_ce: 0.009784
iteration 5225 : loss : 0.037527, loss_ce: 0.013502
iteration 5226 : loss : 0.044490, loss_ce: 0.010030
iteration 5227 : loss : 0.031704, loss_ce: 0.008987
iteration 5228 : loss : 0.035485, loss_ce: 0.009534
iteration 5229 : loss : 0.036782, loss_ce: 0.011870
iteration 5230 : loss : 0.027055, loss_ce: 0.013134
iteration 5231 : loss : 0.038953, loss_ce: 0.014649
iteration 5232 : loss : 0.034652, loss_ce: 0.011797
iteration 5233 : loss : 0.046745, loss_ce: 0.014149
iteration 5234 : loss : 0.031724, loss_ce: 0.009657
iteration 5235 : loss : 0.039617, loss_ce: 0.010168
iteration 5236 : loss : 0.034655, loss_ce: 0.011885
iteration 5237 : loss : 0.031638, loss_ce: 0.011422
iteration 5238 : loss : 0.032349, loss_ce: 0.011645
iteration 5239 : loss : 0.084166, loss_ce: 0.011591
pred_sum 18533
gtsum tensor(18336, device='cuda:0')
iteration 5240 : loss : 0.029912, loss_ce: 0.013122
iteration 5241 : loss : 0.064727, loss_ce: 0.014709
iteration 5242 : loss : 0.036877, loss_ce: 0.013456
iteration 5243 : loss : 0.051533, loss_ce: 0.009133
iteration 5244 : loss : 0.027243, loss_ce: 0.007553
iteration 5245 : loss : 0.065824, loss_ce: 0.013459
iteration 5246 : loss : 0.053713, loss_ce: 0.019169
iteration 5247 : loss : 0.045203, loss_ce: 0.008558
iteration 5248 : loss : 0.038232, loss_ce: 0.009952
iteration 5249 : loss : 0.032058, loss_ce: 0.011445
iteration 5250 : loss : 0.031671, loss_ce: 0.009738
iteration 5251 : loss : 0.042747, loss_ce: 0.009902
iteration 5252 : loss : 0.034345, loss_ce: 0.009698
iteration 5253 : loss : 0.041232, loss_ce: 0.011561
iteration 5254 : loss : 0.029076, loss_ce: 0.009085
iteration 5255 : loss : 0.030535, loss_ce: 0.011388
iteration 5256 : loss : 0.041137, loss_ce: 0.007868
iteration 5257 : loss : 0.035333, loss_ce: 0.008406
iteration 5258 : loss : 0.036257, loss_ce: 0.009721
iteration 5259 : loss : 0.039093, loss_ce: 0.019623
iteration 5260 : loss : 0.032165, loss_ce: 0.009803
iteration 5261 : loss : 0.042384, loss_ce: 0.011246
iteration 5262 : loss : 0.034847, loss_ce: 0.014289
iteration 5263 : loss : 0.037475, loss_ce: 0.013107
iteration 5264 : loss : 0.081047, loss_ce: 0.004673
iteration 5265 : loss : 0.033937, loss_ce: 0.017021
iteration 5266 : loss : 0.035220, loss_ce: 0.009339
iteration 5267 : loss : 0.039086, loss_ce: 0.014564
iteration 5268 : loss : 0.040511, loss_ce: 0.008686
iteration 5269 : loss : 0.079076, loss_ce: 0.007615
iteration 5270 : loss : 0.030863, loss_ce: 0.009686
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 5271 : loss : 0.037792, loss_ce: 0.009393
iteration 5272 : loss : 0.031375, loss_ce: 0.008438
iteration 5273 : loss : 0.036597, loss_ce: 0.011871
iteration 5274 : loss : 0.033267, loss_ce: 0.010247
iteration 5275 : loss : 0.039046, loss_ce: 0.010617
iteration 5276 : loss : 0.187421, loss_ce: 0.003690
iteration 5277 : loss : 0.027738, loss_ce: 0.010002
iteration 5278 : loss : 0.031254, loss_ce: 0.015451
iteration 5279 : loss : 0.027792, loss_ce: 0.009423
iteration 5280 : loss : 0.029120, loss_ce: 0.011061
iteration 5281 : loss : 0.040537, loss_ce: 0.013341
iteration 5282 : loss : 0.037631, loss_ce: 0.018386
iteration 5283 : loss : 0.038776, loss_ce: 0.011897
iteration 5284 : loss : 0.037290, loss_ce: 0.013142
iteration 5285 : loss : 0.032661, loss_ce: 0.012755
iteration 5286 : loss : 0.032013, loss_ce: 0.008356
iteration 5287 : loss : 0.039528, loss_ce: 0.016981
iteration 5288 : loss : 0.036297, loss_ce: 0.012484
iteration 5289 : loss : 0.041048, loss_ce: 0.013758
iteration 5290 : loss : 0.031676, loss_ce: 0.013856
iteration 5291 : loss : 0.043786, loss_ce: 0.008146
iteration 5292 : loss : 0.034272, loss_ce: 0.015217
iteration 5293 : loss : 0.032342, loss_ce: 0.012047
iteration 5294 : loss : 0.035141, loss_ce: 0.013541
iteration 5295 : loss : 0.038229, loss_ce: 0.015454
iteration 5296 : loss : 0.030259, loss_ce: 0.013321
iteration 5297 : loss : 0.032181, loss_ce: 0.011509
iteration 5298 : loss : 0.032810, loss_ce: 0.006423
iteration 5299 : loss : 0.034321, loss_ce: 0.015180
iteration 5300 : loss : 0.035321, loss_ce: 0.015122
iteration 5301 : loss : 0.444326, loss_ce: 0.001170
 28%|████████▌                     | 57/200 [51:41<2:10:10, 54.62s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 5302 : loss : 0.030719, loss_ce: 0.013477
iteration 5303 : loss : 0.048918, loss_ce: 0.011402
iteration 5304 : loss : 0.080373, loss_ce: 0.011818
iteration 5305 : loss : 0.045182, loss_ce: 0.012235
iteration 5306 : loss : 0.037663, loss_ce: 0.008857
iteration 5307 : loss : 0.024381, loss_ce: 0.008674
iteration 5308 : loss : 0.050147, loss_ce: 0.011141
iteration 5309 : loss : 0.031571, loss_ce: 0.015619
iteration 5310 : loss : 0.032146, loss_ce: 0.007974
iteration 5311 : loss : 0.032470, loss_ce: 0.015556
iteration 5312 : loss : 0.029368, loss_ce: 0.013304
iteration 5313 : loss : 0.031587, loss_ce: 0.009129
iteration 5314 : loss : 0.037183, loss_ce: 0.006803
iteration 5315 : loss : 0.032330, loss_ce: 0.010205
iteration 5316 : loss : 0.033348, loss_ce: 0.015149
iteration 5317 : loss : 0.030634, loss_ce: 0.011464
iteration 5318 : loss : 0.029991, loss_ce: 0.009664
iteration 5319 : loss : 0.027496, loss_ce: 0.013382
iteration 5320 : loss : 0.036714, loss_ce: 0.009300
iteration 5321 : loss : 0.031159, loss_ce: 0.005647
iteration 5322 : loss : 0.042425, loss_ce: 0.009877
iteration 5323 : loss : 0.027178, loss_ce: 0.006400
iteration 5324 : loss : 0.039252, loss_ce: 0.009942
iteration 5325 : loss : 0.041177, loss_ce: 0.012424
iteration 5326 : loss : 0.028458, loss_ce: 0.012990
iteration 5327 : loss : 0.033213, loss_ce: 0.012062
iteration 5328 : loss : 0.063184, loss_ce: 0.008505
iteration 5329 : loss : 0.031294, loss_ce: 0.013585
iteration 5330 : loss : 0.033650, loss_ce: 0.017294
iteration 5331 : loss : 0.027758, loss_ce: 0.006378
iteration 5332 : loss : 0.037212, loss_ce: 0.009903
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 5333 : loss : 0.026758, loss_ce: 0.010578
iteration 5334 : loss : 0.032882, loss_ce: 0.011564
iteration 5335 : loss : 0.034581, loss_ce: 0.012895
iteration 5336 : loss : 0.033630, loss_ce: 0.013428
iteration 5337 : loss : 0.035713, loss_ce: 0.011917
iteration 5338 : loss : 0.026646, loss_ce: 0.008629
iteration 5339 : loss : 0.039644, loss_ce: 0.016497
iteration 5340 : loss : 0.052692, loss_ce: 0.014165
iteration 5341 : loss : 0.034146, loss_ce: 0.012408
iteration 5342 : loss : 0.036749, loss_ce: 0.013870
iteration 5343 : loss : 0.037981, loss_ce: 0.013500
iteration 5344 : loss : 0.038719, loss_ce: 0.013615
iteration 5345 : loss : 0.028659, loss_ce: 0.007218
iteration 5346 : loss : 0.035485, loss_ce: 0.009424
iteration 5347 : loss : 0.034992, loss_ce: 0.011622
iteration 5348 : loss : 0.030239, loss_ce: 0.013864
iteration 5349 : loss : 0.033399, loss_ce: 0.011225
iteration 5350 : loss : 0.035700, loss_ce: 0.011673
iteration 5351 : loss : 0.061159, loss_ce: 0.007634
iteration 5352 : loss : 0.034754, loss_ce: 0.012545
iteration 5353 : loss : 0.035480, loss_ce: 0.010805
iteration 5354 : loss : 0.039787, loss_ce: 0.008251
iteration 5355 : loss : 0.068966, loss_ce: 0.006630
iteration 5356 : loss : 0.039734, loss_ce: 0.005920
iteration 5357 : loss : 0.036459, loss_ce: 0.013777
iteration 5358 : loss : 0.081523, loss_ce: 0.006292
iteration 5359 : loss : 0.082189, loss_ce: 0.010706
iteration 5360 : loss : 0.038624, loss_ce: 0.011596
iteration 5361 : loss : 0.036445, loss_ce: 0.014188
iteration 5362 : loss : 0.037598, loss_ce: 0.015591
iteration 5363 : loss : 0.038306, loss_ce: 0.008123
pred_sum 8496
gtsum tensor(9325, device='cuda:0')
iteration 5364 : loss : 0.034724, loss_ce: 0.016026
iteration 5365 : loss : 0.040414, loss_ce: 0.011512
iteration 5366 : loss : 0.031895, loss_ce: 0.008338
iteration 5367 : loss : 0.037769, loss_ce: 0.018349
iteration 5368 : loss : 0.038328, loss_ce: 0.011359
iteration 5369 : loss : 0.028536, loss_ce: 0.008796
iteration 5370 : loss : 0.031442, loss_ce: 0.010654
iteration 5371 : loss : 0.031908, loss_ce: 0.014878
iteration 5372 : loss : 0.035976, loss_ce: 0.015372
iteration 5373 : loss : 0.031311, loss_ce: 0.009513
iteration 5374 : loss : 0.083027, loss_ce: 0.011650
iteration 5375 : loss : 0.027229, loss_ce: 0.005413
iteration 5376 : loss : 0.030397, loss_ce: 0.006431
iteration 5377 : loss : 0.038319, loss_ce: 0.018968
iteration 5378 : loss : 0.039455, loss_ce: 0.011013
iteration 5379 : loss : 0.030654, loss_ce: 0.010454
iteration 5380 : loss : 0.041181, loss_ce: 0.007853
iteration 5381 : loss : 0.040084, loss_ce: 0.008994
iteration 5382 : loss : 0.029881, loss_ce: 0.009854
iteration 5383 : loss : 0.030610, loss_ce: 0.007098
iteration 5384 : loss : 0.034909, loss_ce: 0.008296
iteration 5385 : loss : 0.039263, loss_ce: 0.007613
iteration 5386 : loss : 0.034263, loss_ce: 0.012017
iteration 5387 : loss : 0.027209, loss_ce: 0.009145
iteration 5388 : loss : 0.029839, loss_ce: 0.011942
iteration 5389 : loss : 0.031443, loss_ce: 0.010195
iteration 5390 : loss : 0.038918, loss_ce: 0.008536
iteration 5391 : loss : 0.032927, loss_ce: 0.008739
iteration 5392 : loss : 0.033067, loss_ce: 0.013325
iteration 5393 : loss : 0.126252, loss_ce: 0.005985
iteration 5394 : loss : 0.097601, loss_ce: 0.013420
 29%|████████▋                     | 58/200 [52:35<2:09:14, 54.61s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 5395 : loss : 0.032291, loss_ce: 0.012619
iteration 5396 : loss : 0.036975, loss_ce: 0.014191
iteration 5397 : loss : 0.082274, loss_ce: 0.006247
iteration 5398 : loss : 0.045292, loss_ce: 0.006790
iteration 5399 : loss : 0.081272, loss_ce: 0.007524
iteration 5400 : loss : 0.085287, loss_ce: 0.010401
iteration 5401 : loss : 0.047900, loss_ce: 0.009368
iteration 5402 : loss : 0.035941, loss_ce: 0.015976
iteration 5403 : loss : 0.031427, loss_ce: 0.007969
iteration 5404 : loss : 0.029686, loss_ce: 0.009919
iteration 5405 : loss : 0.032846, loss_ce: 0.011858
iteration 5406 : loss : 0.032436, loss_ce: 0.011213
iteration 5407 : loss : 0.039583, loss_ce: 0.014535
iteration 5408 : loss : 0.036606, loss_ce: 0.015046
iteration 5409 : loss : 0.052901, loss_ce: 0.015014
iteration 5410 : loss : 0.036904, loss_ce: 0.010007
iteration 5411 : loss : 0.036304, loss_ce: 0.008321
iteration 5412 : loss : 0.031096, loss_ce: 0.009903
iteration 5413 : loss : 0.081707, loss_ce: 0.008684
iteration 5414 : loss : 0.030154, loss_ce: 0.006461
iteration 5415 : loss : 0.031076, loss_ce: 0.009964
iteration 5416 : loss : 0.029807, loss_ce: 0.009407
iteration 5417 : loss : 0.032670, loss_ce: 0.012735
iteration 5418 : loss : 0.036612, loss_ce: 0.010256
iteration 5419 : loss : 0.039981, loss_ce: 0.012038
iteration 5420 : loss : 0.034801, loss_ce: 0.016334
iteration 5421 : loss : 0.033826, loss_ce: 0.012359
iteration 5422 : loss : 0.045275, loss_ce: 0.016335
iteration 5423 : loss : 0.030648, loss_ce: 0.014076
iteration 5424 : loss : 0.037793, loss_ce: 0.008897
iteration 5425 : loss : 0.033121, loss_ce: 0.008848
pred_sum 54284
gtsum tensor(54654, device='cuda:0')
iteration 5426 : loss : 0.032664, loss_ce: 0.011178
iteration 5427 : loss : 0.037342, loss_ce: 0.014541
iteration 5428 : loss : 0.025930, loss_ce: 0.011722
iteration 5429 : loss : 0.034361, loss_ce: 0.013304
iteration 5430 : loss : 0.041748, loss_ce: 0.011926
iteration 5431 : loss : 0.031276, loss_ce: 0.013169
iteration 5432 : loss : 0.036825, loss_ce: 0.015462
iteration 5433 : loss : 0.030744, loss_ce: 0.012922
iteration 5434 : loss : 0.033226, loss_ce: 0.007187
iteration 5435 : loss : 0.030524, loss_ce: 0.012563
iteration 5436 : loss : 0.032515, loss_ce: 0.006961
iteration 5437 : loss : 0.040947, loss_ce: 0.010762
iteration 5438 : loss : 0.038040, loss_ce: 0.010589
iteration 5439 : loss : 0.029756, loss_ce: 0.009052
iteration 5440 : loss : 0.035439, loss_ce: 0.007757
iteration 5441 : loss : 0.037707, loss_ce: 0.012937
iteration 5442 : loss : 0.032412, loss_ce: 0.010303
iteration 5443 : loss : 0.031833, loss_ce: 0.010562
iteration 5444 : loss : 0.080011, loss_ce: 0.008453
iteration 5445 : loss : 0.038194, loss_ce: 0.009853
iteration 5446 : loss : 0.033575, loss_ce: 0.011076
iteration 5447 : loss : 0.037697, loss_ce: 0.012328
iteration 5448 : loss : 0.029712, loss_ce: 0.009498
iteration 5449 : loss : 0.035272, loss_ce: 0.009729
iteration 5450 : loss : 0.046695, loss_ce: 0.008139
iteration 5451 : loss : 0.038331, loss_ce: 0.019365
iteration 5452 : loss : 0.084495, loss_ce: 0.007488
iteration 5453 : loss : 0.035982, loss_ce: 0.012287
iteration 5454 : loss : 0.085294, loss_ce: 0.011268
iteration 5455 : loss : 0.079267, loss_ce: 0.006822
iteration 5456 : loss : 0.034434, loss_ce: 0.009060
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 5457 : loss : 0.039071, loss_ce: 0.013993
iteration 5458 : loss : 0.029098, loss_ce: 0.011620
iteration 5459 : loss : 0.084117, loss_ce: 0.014254
iteration 5460 : loss : 0.080005, loss_ce: 0.007282
iteration 5461 : loss : 0.086845, loss_ce: 0.010825
iteration 5462 : loss : 0.039665, loss_ce: 0.008410
iteration 5463 : loss : 0.069568, loss_ce: 0.011004
iteration 5464 : loss : 0.035506, loss_ce: 0.011707
iteration 5465 : loss : 0.035800, loss_ce: 0.009504
iteration 5466 : loss : 0.026637, loss_ce: 0.010180
iteration 5467 : loss : 0.025385, loss_ce: 0.006918
iteration 5468 : loss : 0.042249, loss_ce: 0.019357
iteration 5469 : loss : 0.031470, loss_ce: 0.011796
iteration 5470 : loss : 0.038624, loss_ce: 0.011535
iteration 5471 : loss : 0.027104, loss_ce: 0.009614
iteration 5472 : loss : 0.032012, loss_ce: 0.013669
iteration 5473 : loss : 0.033267, loss_ce: 0.009006
iteration 5474 : loss : 0.039942, loss_ce: 0.012942
iteration 5475 : loss : 0.033191, loss_ce: 0.012835
iteration 5476 : loss : 0.030492, loss_ce: 0.010340
iteration 5477 : loss : 0.039828, loss_ce: 0.011490
iteration 5478 : loss : 0.034976, loss_ce: 0.010202
iteration 5479 : loss : 0.028494, loss_ce: 0.011298
iteration 5480 : loss : 0.033435, loss_ce: 0.011558
iteration 5481 : loss : 0.030751, loss_ce: 0.007757
iteration 5482 : loss : 0.027425, loss_ce: 0.009965
iteration 5483 : loss : 0.025303, loss_ce: 0.007364
iteration 5484 : loss : 0.040099, loss_ce: 0.009088
iteration 5485 : loss : 0.082236, loss_ce: 0.013189
iteration 5486 : loss : 0.031683, loss_ce: 0.011839
iteration 5487 : loss : 0.149257, loss_ce: 0.023522
 30%|████████▊                     | 59/200 [53:30<2:08:13, 54.56s/it]pred_sum 6428
gtsum tensor(6708, device='cuda:0')
iteration 5488 : loss : 0.029858, loss_ce: 0.008406
iteration 5489 : loss : 0.031252, loss_ce: 0.010693
iteration 5490 : loss : 0.028464, loss_ce: 0.009509
iteration 5491 : loss : 0.083053, loss_ce: 0.011281
iteration 5492 : loss : 0.037526, loss_ce: 0.014972
iteration 5493 : loss : 0.031570, loss_ce: 0.013190
iteration 5494 : loss : 0.036681, loss_ce: 0.015061
iteration 5495 : loss : 0.029307, loss_ce: 0.014159
iteration 5496 : loss : 0.032356, loss_ce: 0.008253
iteration 5497 : loss : 0.031672, loss_ce: 0.010288
iteration 5498 : loss : 0.086236, loss_ce: 0.009189
iteration 5499 : loss : 0.028400, loss_ce: 0.012126
iteration 5500 : loss : 0.044378, loss_ce: 0.016044
iteration 5501 : loss : 0.034105, loss_ce: 0.009232
iteration 5502 : loss : 0.048610, loss_ce: 0.011777
iteration 5503 : loss : 0.043079, loss_ce: 0.014099
iteration 5504 : loss : 0.027528, loss_ce: 0.010110
iteration 5505 : loss : 0.032089, loss_ce: 0.010335
iteration 5506 : loss : 0.031594, loss_ce: 0.011608
iteration 5507 : loss : 0.027581, loss_ce: 0.012350
iteration 5508 : loss : 0.029838, loss_ce: 0.012213
iteration 5509 : loss : 0.027442, loss_ce: 0.011487
iteration 5510 : loss : 0.032031, loss_ce: 0.010315
iteration 5511 : loss : 0.033357, loss_ce: 0.013776
iteration 5512 : loss : 0.037894, loss_ce: 0.009819
iteration 5513 : loss : 0.033930, loss_ce: 0.010765
iteration 5514 : loss : 0.030475, loss_ce: 0.013630
iteration 5515 : loss : 0.037100, loss_ce: 0.009466
iteration 5516 : loss : 0.028343, loss_ce: 0.010017
iteration 5517 : loss : 0.035910, loss_ce: 0.012297
iteration 5518 : loss : 0.092737, loss_ce: 0.009802
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 5519 : loss : 0.033217, loss_ce: 0.011157
iteration 5520 : loss : 0.025289, loss_ce: 0.005228
iteration 5521 : loss : 0.025351, loss_ce: 0.006164
iteration 5522 : loss : 0.032100, loss_ce: 0.010504
iteration 5523 : loss : 0.034742, loss_ce: 0.012157
iteration 5524 : loss : 0.079691, loss_ce: 0.004393
iteration 5525 : loss : 0.032149, loss_ce: 0.009375
iteration 5526 : loss : 0.034569, loss_ce: 0.007773
iteration 5527 : loss : 0.031898, loss_ce: 0.010835
iteration 5528 : loss : 0.032848, loss_ce: 0.008484
iteration 5529 : loss : 0.047309, loss_ce: 0.010983
iteration 5530 : loss : 0.032439, loss_ce: 0.011527
iteration 5531 : loss : 0.029334, loss_ce: 0.009560
iteration 5532 : loss : 0.038962, loss_ce: 0.010033
iteration 5533 : loss : 0.098231, loss_ce: 0.004522
iteration 5534 : loss : 0.034580, loss_ce: 0.013067
iteration 5535 : loss : 0.032589, loss_ce: 0.012973
iteration 5536 : loss : 0.058475, loss_ce: 0.010736
iteration 5537 : loss : 0.080303, loss_ce: 0.006709
iteration 5538 : loss : 0.041617, loss_ce: 0.020231
iteration 5539 : loss : 0.055411, loss_ce: 0.010895
iteration 5540 : loss : 0.028503, loss_ce: 0.005886
iteration 5541 : loss : 0.028872, loss_ce: 0.009871
iteration 5542 : loss : 0.043119, loss_ce: 0.014331
iteration 5543 : loss : 0.082109, loss_ce: 0.004870
iteration 5544 : loss : 0.034022, loss_ce: 0.015419
iteration 5545 : loss : 0.032074, loss_ce: 0.009874
iteration 5546 : loss : 0.032358, loss_ce: 0.010282
iteration 5547 : loss : 0.040141, loss_ce: 0.011500
iteration 5548 : loss : 0.088684, loss_ce: 0.009937
iteration 5549 : loss : 0.031268, loss_ce: 0.011644
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 5550 : loss : 0.040090, loss_ce: 0.009310
iteration 5551 : loss : 0.041899, loss_ce: 0.022533
iteration 5552 : loss : 0.040871, loss_ce: 0.013482
iteration 5553 : loss : 0.030626, loss_ce: 0.008073
iteration 5554 : loss : 0.033483, loss_ce: 0.009696
iteration 5555 : loss : 0.037818, loss_ce: 0.015325
iteration 5556 : loss : 0.035334, loss_ce: 0.011910
iteration 5557 : loss : 0.033023, loss_ce: 0.010293
iteration 5558 : loss : 0.032490, loss_ce: 0.008440
iteration 5559 : loss : 0.029222, loss_ce: 0.011276
iteration 5560 : loss : 0.041022, loss_ce: 0.008703
iteration 5561 : loss : 0.032742, loss_ce: 0.007844
iteration 5562 : loss : 0.031109, loss_ce: 0.008638
iteration 5563 : loss : 0.032103, loss_ce: 0.008484
iteration 5564 : loss : 0.028712, loss_ce: 0.012473
iteration 5565 : loss : 0.031669, loss_ce: 0.011274
iteration 5566 : loss : 0.035019, loss_ce: 0.015744
iteration 5567 : loss : 0.049213, loss_ce: 0.011867
iteration 5568 : loss : 0.037749, loss_ce: 0.012547
iteration 5569 : loss : 0.031199, loss_ce: 0.012542
iteration 5570 : loss : 0.040159, loss_ce: 0.009947
iteration 5571 : loss : 0.089082, loss_ce: 0.006804
iteration 5572 : loss : 0.040956, loss_ce: 0.007196
iteration 5573 : loss : 0.035700, loss_ce: 0.012526
iteration 5574 : loss : 0.036784, loss_ce: 0.012260
iteration 5575 : loss : 0.028526, loss_ce: 0.007807
iteration 5576 : loss : 0.031821, loss_ce: 0.014603
iteration 5577 : loss : 0.038300, loss_ce: 0.013985
iteration 5578 : loss : 0.030699, loss_ce: 0.012470
iteration 5579 : loss : 0.027942, loss_ce: 0.009862
iteration 5580 : loss : 0.301435, loss_ce: 0.006620
 30%|█████████                     | 60/200 [54:24<2:07:20, 54.57s/it]pred_sum 145
gtsum tensor(142, device='cuda:0')
iteration 5581 : loss : 0.026118, loss_ce: 0.005039
iteration 5582 : loss : 0.039552, loss_ce: 0.015494
iteration 5583 : loss : 0.033077, loss_ce: 0.011385
iteration 5584 : loss : 0.055944, loss_ce: 0.012917
iteration 5585 : loss : 0.038649, loss_ce: 0.018648
iteration 5586 : loss : 0.039474, loss_ce: 0.017324
iteration 5587 : loss : 0.037576, loss_ce: 0.011227
iteration 5588 : loss : 0.026577, loss_ce: 0.006193
iteration 5589 : loss : 0.037408, loss_ce: 0.012499
iteration 5590 : loss : 0.033708, loss_ce: 0.008581
iteration 5591 : loss : 0.085363, loss_ce: 0.010072
iteration 5592 : loss : 0.043146, loss_ce: 0.015589
iteration 5593 : loss : 0.036237, loss_ce: 0.008585
iteration 5594 : loss : 0.044389, loss_ce: 0.009300
iteration 5595 : loss : 0.031031, loss_ce: 0.007819
iteration 5596 : loss : 0.038689, loss_ce: 0.014332
iteration 5597 : loss : 0.027141, loss_ce: 0.009543
iteration 5598 : loss : 0.033358, loss_ce: 0.014748
iteration 5599 : loss : 0.027667, loss_ce: 0.011131
iteration 5600 : loss : 0.029456, loss_ce: 0.006999
iteration 5601 : loss : 0.086299, loss_ce: 0.009550
iteration 5602 : loss : 0.082358, loss_ce: 0.011193
iteration 5603 : loss : 0.036651, loss_ce: 0.010944
iteration 5604 : loss : 0.029198, loss_ce: 0.012833
iteration 5605 : loss : 0.029400, loss_ce: 0.010578
iteration 5606 : loss : 0.045682, loss_ce: 0.007527
iteration 5607 : loss : 0.023443, loss_ce: 0.005957
iteration 5608 : loss : 0.040979, loss_ce: 0.011694
iteration 5609 : loss : 0.028469, loss_ce: 0.008802
iteration 5610 : loss : 0.040944, loss_ce: 0.010778
iteration 5611 : loss : 0.031508, loss_ce: 0.010827
pred_sum 139
gtsum tensor(133, device='cuda:0')
iteration 5612 : loss : 0.079836, loss_ce: 0.005682
iteration 5613 : loss : 0.084036, loss_ce: 0.011935
iteration 5614 : loss : 0.037076, loss_ce: 0.014688
iteration 5615 : loss : 0.038590, loss_ce: 0.015842
iteration 5616 : loss : 0.042621, loss_ce: 0.017740
iteration 5617 : loss : 0.027685, loss_ce: 0.008161
iteration 5618 : loss : 0.041135, loss_ce: 0.013866
iteration 5619 : loss : 0.080064, loss_ce: 0.011265
iteration 5620 : loss : 0.041237, loss_ce: 0.009561
iteration 5621 : loss : 0.028943, loss_ce: 0.009743
iteration 5622 : loss : 0.039415, loss_ce: 0.014786
iteration 5623 : loss : 0.032371, loss_ce: 0.012718
iteration 5624 : loss : 0.031703, loss_ce: 0.014887
iteration 5625 : loss : 0.030266, loss_ce: 0.016527
iteration 5626 : loss : 0.033098, loss_ce: 0.013317
iteration 5627 : loss : 0.032401, loss_ce: 0.009656
iteration 5628 : loss : 0.031042, loss_ce: 0.011945
iteration 5629 : loss : 0.039222, loss_ce: 0.015685
iteration 5630 : loss : 0.031331, loss_ce: 0.013835
iteration 5631 : loss : 0.032207, loss_ce: 0.012113
iteration 5632 : loss : 0.025593, loss_ce: 0.005646
iteration 5633 : loss : 0.028289, loss_ce: 0.008848
iteration 5634 : loss : 0.047756, loss_ce: 0.015344
iteration 5635 : loss : 0.029201, loss_ce: 0.007924
iteration 5636 : loss : 0.038432, loss_ce: 0.017234
iteration 5637 : loss : 0.028317, loss_ce: 0.010069
iteration 5638 : loss : 0.033322, loss_ce: 0.012222
iteration 5639 : loss : 0.034303, loss_ce: 0.008223
iteration 5640 : loss : 0.045670, loss_ce: 0.008610
iteration 5641 : loss : 0.086499, loss_ce: 0.005133
iteration 5642 : loss : 0.028091, loss_ce: 0.011192
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 5643 : loss : 0.038625, loss_ce: 0.016115
iteration 5644 : loss : 0.027783, loss_ce: 0.012749
iteration 5645 : loss : 0.036404, loss_ce: 0.011974
iteration 5646 : loss : 0.039185, loss_ce: 0.009653
iteration 5647 : loss : 0.029427, loss_ce: 0.008934
iteration 5648 : loss : 0.035022, loss_ce: 0.014364
iteration 5649 : loss : 0.030932, loss_ce: 0.009878
iteration 5650 : loss : 0.032488, loss_ce: 0.010294
iteration 5651 : loss : 0.032299, loss_ce: 0.010350
iteration 5652 : loss : 0.025697, loss_ce: 0.007689
iteration 5653 : loss : 0.038884, loss_ce: 0.010587
iteration 5654 : loss : 0.035576, loss_ce: 0.011074
iteration 5655 : loss : 0.034892, loss_ce: 0.006743
iteration 5656 : loss : 0.033015, loss_ce: 0.009081
iteration 5657 : loss : 0.030826, loss_ce: 0.015099
iteration 5658 : loss : 0.040245, loss_ce: 0.018974
iteration 5659 : loss : 0.041552, loss_ce: 0.012419
iteration 5660 : loss : 0.032138, loss_ce: 0.009570
iteration 5661 : loss : 0.038657, loss_ce: 0.013464
iteration 5662 : loss : 0.081048, loss_ce: 0.009545
iteration 5663 : loss : 0.032129, loss_ce: 0.013044
iteration 5664 : loss : 0.029805, loss_ce: 0.010049
iteration 5665 : loss : 0.034259, loss_ce: 0.014029
iteration 5666 : loss : 0.025075, loss_ce: 0.005729
iteration 5667 : loss : 0.035820, loss_ce: 0.010090
iteration 5668 : loss : 0.037060, loss_ce: 0.006983
iteration 5669 : loss : 0.034998, loss_ce: 0.013890
iteration 5670 : loss : 0.033099, loss_ce: 0.009448
iteration 5671 : loss : 0.025762, loss_ce: 0.009126
iteration 5672 : loss : 0.035773, loss_ce: 0.008823
iteration 5673 : loss : 0.091740, loss_ce: 0.020662
 30%|█████████▏                    | 61/200 [55:19<2:06:34, 54.64s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 5674 : loss : 0.027012, loss_ce: 0.007677
iteration 5675 : loss : 0.062070, loss_ce: 0.012789
iteration 5676 : loss : 0.043278, loss_ce: 0.016543
iteration 5677 : loss : 0.120656, loss_ce: 0.007042
iteration 5678 : loss : 0.033417, loss_ce: 0.011572
iteration 5679 : loss : 0.036738, loss_ce: 0.009471
iteration 5680 : loss : 0.043558, loss_ce: 0.018483
iteration 5681 : loss : 0.038852, loss_ce: 0.012004
iteration 5682 : loss : 0.029419, loss_ce: 0.014828
iteration 5683 : loss : 0.034118, loss_ce: 0.008314
iteration 5684 : loss : 0.026864, loss_ce: 0.007176
iteration 5685 : loss : 0.076222, loss_ce: 0.007390
iteration 5686 : loss : 0.032794, loss_ce: 0.013388
iteration 5687 : loss : 0.035473, loss_ce: 0.011249
iteration 5688 : loss : 0.032543, loss_ce: 0.008095
iteration 5689 : loss : 0.035332, loss_ce: 0.013401
iteration 5690 : loss : 0.030466, loss_ce: 0.010482
iteration 5691 : loss : 0.039774, loss_ce: 0.011255
iteration 5692 : loss : 0.053092, loss_ce: 0.014519
iteration 5693 : loss : 0.039248, loss_ce: 0.011152
iteration 5694 : loss : 0.039986, loss_ce: 0.011277
iteration 5695 : loss : 0.038968, loss_ce: 0.021413
iteration 5696 : loss : 0.058201, loss_ce: 0.008844
iteration 5697 : loss : 0.032434, loss_ce: 0.009636
iteration 5698 : loss : 0.031897, loss_ce: 0.010932
iteration 5699 : loss : 0.031354, loss_ce: 0.013637
iteration 5700 : loss : 0.041924, loss_ce: 0.008759
iteration 5701 : loss : 0.038667, loss_ce: 0.017535
iteration 5702 : loss : 0.030116, loss_ce: 0.008939
iteration 5703 : loss : 0.055167, loss_ce: 0.009580
iteration 5704 : loss : 0.048623, loss_ce: 0.005934
pred_sum 4412
gtsum tensor(3935, device='cuda:0')
iteration 5705 : loss : 0.033362, loss_ce: 0.010634
iteration 5706 : loss : 0.035625, loss_ce: 0.015757
iteration 5707 : loss : 0.032226, loss_ce: 0.014565
iteration 5708 : loss : 0.033508, loss_ce: 0.015108
iteration 5709 : loss : 0.044757, loss_ce: 0.010074
iteration 5710 : loss : 0.081597, loss_ce: 0.009557
iteration 5711 : loss : 0.043659, loss_ce: 0.007143
iteration 5712 : loss : 0.033291, loss_ce: 0.005556
iteration 5713 : loss : 0.033712, loss_ce: 0.010613
iteration 5714 : loss : 0.032464, loss_ce: 0.013406
iteration 5715 : loss : 0.038598, loss_ce: 0.014161
iteration 5716 : loss : 0.040247, loss_ce: 0.009024
iteration 5717 : loss : 0.047885, loss_ce: 0.014002
iteration 5718 : loss : 0.036900, loss_ce: 0.015106
iteration 5719 : loss : 0.034241, loss_ce: 0.011328
iteration 5720 : loss : 0.035272, loss_ce: 0.011200
iteration 5721 : loss : 0.030864, loss_ce: 0.008629
iteration 5722 : loss : 0.039756, loss_ce: 0.006417
iteration 5723 : loss : 0.034525, loss_ce: 0.015216
iteration 5724 : loss : 0.049006, loss_ce: 0.017800
iteration 5725 : loss : 0.043523, loss_ce: 0.011029
iteration 5726 : loss : 0.034552, loss_ce: 0.009120
iteration 5727 : loss : 0.037064, loss_ce: 0.011474
iteration 5728 : loss : 0.029349, loss_ce: 0.007967
iteration 5729 : loss : 0.035270, loss_ce: 0.008111
iteration 5730 : loss : 0.034797, loss_ce: 0.017003
iteration 5731 : loss : 0.036796, loss_ce: 0.007506
iteration 5732 : loss : 0.034285, loss_ce: 0.007779
iteration 5733 : loss : 0.053786, loss_ce: 0.014543
iteration 5734 : loss : 0.041409, loss_ce: 0.007458
iteration 5735 : loss : 0.039560, loss_ce: 0.010544
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 5736 : loss : 0.077846, loss_ce: 0.009600
iteration 5737 : loss : 0.039377, loss_ce: 0.016415
iteration 5738 : loss : 0.033247, loss_ce: 0.010958
iteration 5739 : loss : 0.085086, loss_ce: 0.006857
iteration 5740 : loss : 0.033885, loss_ce: 0.013742
iteration 5741 : loss : 0.044901, loss_ce: 0.013818
iteration 5742 : loss : 0.030145, loss_ce: 0.011173
iteration 5743 : loss : 0.029906, loss_ce: 0.010512
iteration 5744 : loss : 0.034969, loss_ce: 0.007580
iteration 5745 : loss : 0.033874, loss_ce: 0.009753
iteration 5746 : loss : 0.033514, loss_ce: 0.008371
iteration 5747 : loss : 0.054627, loss_ce: 0.007012
iteration 5748 : loss : 0.034234, loss_ce: 0.012265
iteration 5749 : loss : 0.029537, loss_ce: 0.012685
iteration 5750 : loss : 0.040392, loss_ce: 0.016735
iteration 5751 : loss : 0.032008, loss_ce: 0.010469
iteration 5752 : loss : 0.023470, loss_ce: 0.007434
iteration 5753 : loss : 0.040028, loss_ce: 0.012697
iteration 5754 : loss : 0.049660, loss_ce: 0.004882
iteration 5755 : loss : 0.034666, loss_ce: 0.012300
iteration 5756 : loss : 0.042213, loss_ce: 0.010217
iteration 5757 : loss : 0.037316, loss_ce: 0.012933
iteration 5758 : loss : 0.030241, loss_ce: 0.014688
iteration 5759 : loss : 0.034730, loss_ce: 0.010278
iteration 5760 : loss : 0.046633, loss_ce: 0.009612
iteration 5761 : loss : 0.039315, loss_ce: 0.013600
iteration 5762 : loss : 0.035330, loss_ce: 0.012075
iteration 5763 : loss : 0.031649, loss_ce: 0.010100
iteration 5764 : loss : 0.031499, loss_ce: 0.013949
iteration 5765 : loss : 0.039157, loss_ce: 0.009947
iteration 5766 : loss : 0.444531, loss_ce: 0.000869
 31%|█████████▎                    | 62/200 [56:14<2:05:40, 54.64s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 5767 : loss : 0.023478, loss_ce: 0.009406
iteration 5768 : loss : 0.037346, loss_ce: 0.013839
iteration 5769 : loss : 0.036948, loss_ce: 0.014174
iteration 5770 : loss : 0.048630, loss_ce: 0.012700
iteration 5771 : loss : 0.034657, loss_ce: 0.016073
iteration 5772 : loss : 0.035559, loss_ce: 0.008202
iteration 5773 : loss : 0.032131, loss_ce: 0.009263
iteration 5774 : loss : 0.034800, loss_ce: 0.010212
iteration 5775 : loss : 0.037523, loss_ce: 0.005936
iteration 5776 : loss : 0.038811, loss_ce: 0.007496
iteration 5777 : loss : 0.034107, loss_ce: 0.010680
iteration 5778 : loss : 0.035223, loss_ce: 0.015488
iteration 5779 : loss : 0.044395, loss_ce: 0.015543
iteration 5780 : loss : 0.080663, loss_ce: 0.008305
iteration 5781 : loss : 0.037504, loss_ce: 0.005814
iteration 5782 : loss : 0.033825, loss_ce: 0.013541
iteration 5783 : loss : 0.031525, loss_ce: 0.015026
iteration 5784 : loss : 0.055582, loss_ce: 0.010867
iteration 5785 : loss : 0.064815, loss_ce: 0.009175
iteration 5786 : loss : 0.032578, loss_ce: 0.009949
iteration 5787 : loss : 0.080545, loss_ce: 0.007932
iteration 5788 : loss : 0.031831, loss_ce: 0.010894
iteration 5789 : loss : 0.037902, loss_ce: 0.010898
iteration 5790 : loss : 0.039919, loss_ce: 0.006327
iteration 5791 : loss : 0.035388, loss_ce: 0.011392
iteration 5792 : loss : 0.040374, loss_ce: 0.013215
iteration 5793 : loss : 0.033436, loss_ce: 0.016882
iteration 5794 : loss : 0.046986, loss_ce: 0.018471
iteration 5795 : loss : 0.042315, loss_ce: 0.011451
iteration 5796 : loss : 0.033138, loss_ce: 0.009755
iteration 5797 : loss : 0.033827, loss_ce: 0.015681
pred_sum 12495
gtsum tensor(13382, device='cuda:0')
iteration 5798 : loss : 0.034970, loss_ce: 0.010636
iteration 5799 : loss : 0.030440, loss_ce: 0.009153
iteration 5800 : loss : 0.030121, loss_ce: 0.010566
iteration 5801 : loss : 0.034008, loss_ce: 0.015667
iteration 5802 : loss : 0.032162, loss_ce: 0.011462
iteration 5803 : loss : 0.034480, loss_ce: 0.010890
iteration 5804 : loss : 0.031335, loss_ce: 0.009446
iteration 5805 : loss : 0.039739, loss_ce: 0.011076
iteration 5806 : loss : 0.037040, loss_ce: 0.011277
iteration 5807 : loss : 0.030911, loss_ce: 0.012342
iteration 5808 : loss : 0.034187, loss_ce: 0.012155
iteration 5809 : loss : 0.038049, loss_ce: 0.014761
iteration 5810 : loss : 0.027368, loss_ce: 0.009036
iteration 5811 : loss : 0.031651, loss_ce: 0.011124
iteration 5812 : loss : 0.037028, loss_ce: 0.011588
iteration 5813 : loss : 0.037238, loss_ce: 0.013739
iteration 5814 : loss : 0.028162, loss_ce: 0.005691
iteration 5815 : loss : 0.036172, loss_ce: 0.009508
iteration 5816 : loss : 0.031613, loss_ce: 0.012609
iteration 5817 : loss : 0.040401, loss_ce: 0.011404
iteration 5818 : loss : 0.081789, loss_ce: 0.006193
iteration 5819 : loss : 0.036928, loss_ce: 0.011047
iteration 5820 : loss : 0.028175, loss_ce: 0.007176
iteration 5821 : loss : 0.035491, loss_ce: 0.014732
iteration 5822 : loss : 0.036741, loss_ce: 0.007153
iteration 5823 : loss : 0.032454, loss_ce: 0.007056
iteration 5824 : loss : 0.025803, loss_ce: 0.009977
iteration 5825 : loss : 0.034606, loss_ce: 0.015339
iteration 5826 : loss : 0.037935, loss_ce: 0.015236
iteration 5827 : loss : 0.074102, loss_ce: 0.007436
iteration 5828 : loss : 0.030302, loss_ce: 0.006948
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 5829 : loss : 0.082964, loss_ce: 0.011067
iteration 5830 : loss : 0.032528, loss_ce: 0.016897
iteration 5831 : loss : 0.041214, loss_ce: 0.021766
iteration 5832 : loss : 0.085784, loss_ce: 0.006010
iteration 5833 : loss : 0.034048, loss_ce: 0.013305
iteration 5834 : loss : 0.029979, loss_ce: 0.007137
iteration 5835 : loss : 0.035780, loss_ce: 0.009828
iteration 5836 : loss : 0.038958, loss_ce: 0.011740
iteration 5837 : loss : 0.028403, loss_ce: 0.009332
iteration 5838 : loss : 0.026763, loss_ce: 0.007765
iteration 5839 : loss : 0.029353, loss_ce: 0.013323
iteration 5840 : loss : 0.040830, loss_ce: 0.010610
iteration 5841 : loss : 0.028217, loss_ce: 0.010938
iteration 5842 : loss : 0.032527, loss_ce: 0.012708
iteration 5843 : loss : 0.030644, loss_ce: 0.007919
iteration 5844 : loss : 0.032401, loss_ce: 0.011982
iteration 5845 : loss : 0.028472, loss_ce: 0.011601
iteration 5846 : loss : 0.033466, loss_ce: 0.010756
iteration 5847 : loss : 0.039300, loss_ce: 0.013453
iteration 5848 : loss : 0.046113, loss_ce: 0.009122
iteration 5849 : loss : 0.031876, loss_ce: 0.009841
iteration 5850 : loss : 0.032547, loss_ce: 0.011640
iteration 5851 : loss : 0.025414, loss_ce: 0.008446
iteration 5852 : loss : 0.030735, loss_ce: 0.007902
iteration 5853 : loss : 0.032426, loss_ce: 0.012087
iteration 5854 : loss : 0.086144, loss_ce: 0.002850
iteration 5855 : loss : 0.028419, loss_ce: 0.010082
iteration 5856 : loss : 0.033431, loss_ce: 0.010664
iteration 5857 : loss : 0.038083, loss_ce: 0.016306
iteration 5858 : loss : 0.037171, loss_ce: 0.012811
iteration 5859 : loss : 0.390414, loss_ce: 0.001086
 32%|█████████▍                    | 63/200 [57:08<2:04:48, 54.66s/it]pred_sum 148
gtsum tensor(141, device='cuda:0')
iteration 5860 : loss : 0.030213, loss_ce: 0.014190
iteration 5861 : loss : 0.033153, loss_ce: 0.010277
iteration 5862 : loss : 0.030829, loss_ce: 0.012011
iteration 5863 : loss : 0.035054, loss_ce: 0.014269
iteration 5864 : loss : 0.035086, loss_ce: 0.013838
iteration 5865 : loss : 0.031430, loss_ce: 0.011639
iteration 5866 : loss : 0.030347, loss_ce: 0.012613
iteration 5867 : loss : 0.035097, loss_ce: 0.015717
iteration 5868 : loss : 0.026716, loss_ce: 0.006226
iteration 5869 : loss : 0.032205, loss_ce: 0.009771
iteration 5870 : loss : 0.049581, loss_ce: 0.008774
iteration 5871 : loss : 0.024892, loss_ce: 0.007507
iteration 5872 : loss : 0.037078, loss_ce: 0.017755
iteration 5873 : loss : 0.030268, loss_ce: 0.009880
iteration 5874 : loss : 0.029087, loss_ce: 0.007384
iteration 5875 : loss : 0.078873, loss_ce: 0.009370
iteration 5876 : loss : 0.026411, loss_ce: 0.008136
iteration 5877 : loss : 0.030248, loss_ce: 0.010181
iteration 5878 : loss : 0.037379, loss_ce: 0.010198
iteration 5879 : loss : 0.028564, loss_ce: 0.004457
iteration 5880 : loss : 0.030287, loss_ce: 0.007169
iteration 5881 : loss : 0.036088, loss_ce: 0.008203
iteration 5882 : loss : 0.031770, loss_ce: 0.012242
iteration 5883 : loss : 0.028563, loss_ce: 0.007129
iteration 5884 : loss : 0.033237, loss_ce: 0.009550
iteration 5885 : loss : 0.032724, loss_ce: 0.011012
iteration 5886 : loss : 0.026123, loss_ce: 0.011889
iteration 5887 : loss : 0.032106, loss_ce: 0.013791
iteration 5888 : loss : 0.029884, loss_ce: 0.015556
iteration 5889 : loss : 0.034914, loss_ce: 0.014353
iteration 5890 : loss : 0.030258, loss_ce: 0.011789
pred_sum 40172
gtsum tensor(40010, device='cuda:0')
iteration 5891 : loss : 0.028149, loss_ce: 0.010705
iteration 5892 : loss : 0.053778, loss_ce: 0.012028
iteration 5893 : loss : 0.031130, loss_ce: 0.008069
iteration 5894 : loss : 0.031139, loss_ce: 0.011699
iteration 5895 : loss : 0.039630, loss_ce: 0.010601
iteration 5896 : loss : 0.031770, loss_ce: 0.017687
iteration 5897 : loss : 0.041294, loss_ce: 0.011079
iteration 5898 : loss : 0.036769, loss_ce: 0.012272
iteration 5899 : loss : 0.028717, loss_ce: 0.008533
iteration 5900 : loss : 0.031446, loss_ce: 0.007370
iteration 5901 : loss : 0.030445, loss_ce: 0.007555
iteration 5902 : loss : 0.029496, loss_ce: 0.013915
iteration 5903 : loss : 0.031075, loss_ce: 0.005091
iteration 5904 : loss : 0.081555, loss_ce: 0.005127
iteration 5905 : loss : 0.030692, loss_ce: 0.012160
iteration 5906 : loss : 0.056720, loss_ce: 0.011225
iteration 5907 : loss : 0.044487, loss_ce: 0.008557
iteration 5908 : loss : 0.080137, loss_ce: 0.009597
iteration 5909 : loss : 0.032492, loss_ce: 0.009683
iteration 5910 : loss : 0.036033, loss_ce: 0.012292
iteration 5911 : loss : 0.083403, loss_ce: 0.011425
iteration 5912 : loss : 0.040411, loss_ce: 0.016878
iteration 5913 : loss : 0.032079, loss_ce: 0.009003
iteration 5914 : loss : 0.030857, loss_ce: 0.008225
iteration 5915 : loss : 0.029314, loss_ce: 0.011253
iteration 5916 : loss : 0.033763, loss_ce: 0.010831
iteration 5917 : loss : 0.029456, loss_ce: 0.006614
iteration 5918 : loss : 0.082493, loss_ce: 0.009636
iteration 5919 : loss : 0.034447, loss_ce: 0.008498
iteration 5920 : loss : 0.033214, loss_ce: 0.011736
iteration 5921 : loss : 0.033920, loss_ce: 0.009796
pred_sum 0
gtsum tensor(195, device='cuda:0')
iteration 5922 : loss : 0.026225, loss_ce: 0.005923
iteration 5923 : loss : 0.029914, loss_ce: 0.009616
iteration 5924 : loss : 0.043092, loss_ce: 0.012694
iteration 5925 : loss : 0.037368, loss_ce: 0.013241
iteration 5926 : loss : 0.035268, loss_ce: 0.012724
iteration 5927 : loss : 0.084736, loss_ce: 0.007572
iteration 5928 : loss : 0.037054, loss_ce: 0.007697
iteration 5929 : loss : 0.027858, loss_ce: 0.008844
iteration 5930 : loss : 0.176013, loss_ce: 0.010541
iteration 5931 : loss : 0.029609, loss_ce: 0.005758
iteration 5932 : loss : 0.049845, loss_ce: 0.017815
iteration 5933 : loss : 0.041566, loss_ce: 0.018816
iteration 5934 : loss : 0.034809, loss_ce: 0.011670
iteration 5935 : loss : 0.045535, loss_ce: 0.010603
iteration 5936 : loss : 0.098740, loss_ce: 0.013736
iteration 5937 : loss : 0.057052, loss_ce: 0.015629
iteration 5938 : loss : 0.043943, loss_ce: 0.022755
iteration 5939 : loss : 0.037301, loss_ce: 0.014852
iteration 5940 : loss : 0.032256, loss_ce: 0.011690
iteration 5941 : loss : 0.037817, loss_ce: 0.016140
iteration 5942 : loss : 0.043546, loss_ce: 0.007700
iteration 5943 : loss : 0.038061, loss_ce: 0.014104
iteration 5944 : loss : 0.044744, loss_ce: 0.016521
iteration 5945 : loss : 0.037299, loss_ce: 0.017522
iteration 5946 : loss : 0.043632, loss_ce: 0.016282
iteration 5947 : loss : 0.044420, loss_ce: 0.019620
iteration 5948 : loss : 0.032336, loss_ce: 0.008383
iteration 5949 : loss : 0.036762, loss_ce: 0.011026
iteration 5950 : loss : 0.041657, loss_ce: 0.007015
iteration 5951 : loss : 0.029702, loss_ce: 0.004777
iteration 5952 : loss : 0.182038, loss_ce: 0.012098
 32%|█████████▌                    | 64/200 [58:03<2:03:55, 54.67s/it]pred_sum 163
gtsum tensor(182, device='cuda:0')
iteration 5953 : loss : 0.030394, loss_ce: 0.005908
iteration 5954 : loss : 0.034387, loss_ce: 0.012669
iteration 5955 : loss : 0.038423, loss_ce: 0.011203
iteration 5956 : loss : 0.035070, loss_ce: 0.014664
iteration 5957 : loss : 0.034184, loss_ce: 0.010888
iteration 5958 : loss : 0.040021, loss_ce: 0.012221
iteration 5959 : loss : 0.042036, loss_ce: 0.009887
iteration 5960 : loss : 0.034778, loss_ce: 0.008599
iteration 5961 : loss : 0.037610, loss_ce: 0.014968
iteration 5962 : loss : 0.035977, loss_ce: 0.011523
iteration 5963 : loss : 0.040258, loss_ce: 0.014030
iteration 5964 : loss : 0.030503, loss_ce: 0.009580
iteration 5965 : loss : 0.040699, loss_ce: 0.010367
iteration 5966 : loss : 0.036467, loss_ce: 0.017298
iteration 5967 : loss : 0.032403, loss_ce: 0.010936
iteration 5968 : loss : 0.036366, loss_ce: 0.004170
iteration 5969 : loss : 0.084524, loss_ce: 0.013139
iteration 5970 : loss : 0.034794, loss_ce: 0.008716
iteration 5971 : loss : 0.030746, loss_ce: 0.012513
iteration 5972 : loss : 0.033656, loss_ce: 0.014264
iteration 5973 : loss : 0.038808, loss_ce: 0.018142
iteration 5974 : loss : 0.030148, loss_ce: 0.009187
iteration 5975 : loss : 0.039909, loss_ce: 0.010218
iteration 5976 : loss : 0.030224, loss_ce: 0.009183
iteration 5977 : loss : 0.055443, loss_ce: 0.012642
iteration 5978 : loss : 0.033254, loss_ce: 0.009528
iteration 5979 : loss : 0.032782, loss_ce: 0.012105
iteration 5980 : loss : 0.045565, loss_ce: 0.005562
iteration 5981 : loss : 0.028627, loss_ce: 0.010222
iteration 5982 : loss : 0.076917, loss_ce: 0.008832
iteration 5983 : loss : 0.030537, loss_ce: 0.010831
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 5984 : loss : 0.043292, loss_ce: 0.010905
iteration 5985 : loss : 0.038273, loss_ce: 0.013527
iteration 5986 : loss : 0.036278, loss_ce: 0.015197
iteration 5987 : loss : 0.035191, loss_ce: 0.012697
iteration 5988 : loss : 0.033875, loss_ce: 0.008704
iteration 5989 : loss : 0.062789, loss_ce: 0.007354
iteration 5990 : loss : 0.040053, loss_ce: 0.009845
iteration 5991 : loss : 0.037225, loss_ce: 0.015379
iteration 5992 : loss : 0.030403, loss_ce: 0.008850
iteration 5993 : loss : 0.048499, loss_ce: 0.011928
iteration 5994 : loss : 0.080590, loss_ce: 0.005406
iteration 5995 : loss : 0.040590, loss_ce: 0.020289
iteration 5996 : loss : 0.033173, loss_ce: 0.007117
iteration 5997 : loss : 0.030823, loss_ce: 0.011144
iteration 5998 : loss : 0.030248, loss_ce: 0.014483
iteration 5999 : loss : 0.082672, loss_ce: 0.011051
iteration 6000 : loss : 0.036560, loss_ce: 0.012542
iteration 6001 : loss : 0.035595, loss_ce: 0.010660
iteration 6002 : loss : 0.068752, loss_ce: 0.009713
iteration 6003 : loss : 0.038799, loss_ce: 0.009318
iteration 6004 : loss : 0.035681, loss_ce: 0.012655
iteration 6005 : loss : 0.033661, loss_ce: 0.009714
iteration 6006 : loss : 0.035180, loss_ce: 0.011239
iteration 6007 : loss : 0.041921, loss_ce: 0.016869
iteration 6008 : loss : 0.039494, loss_ce: 0.017652
iteration 6009 : loss : 0.033220, loss_ce: 0.012068
iteration 6010 : loss : 0.044166, loss_ce: 0.012828
iteration 6011 : loss : 0.031601, loss_ce: 0.012662
iteration 6012 : loss : 0.036719, loss_ce: 0.005075
iteration 6013 : loss : 0.030032, loss_ce: 0.014506
iteration 6014 : loss : 0.037539, loss_ce: 0.010894
pred_sum 15343
gtsum tensor(14555, device='cuda:0')
iteration 6015 : loss : 0.036531, loss_ce: 0.012867
iteration 6016 : loss : 0.035885, loss_ce: 0.013591
iteration 6017 : loss : 0.036978, loss_ce: 0.012036
iteration 6018 : loss : 0.033255, loss_ce: 0.011986
iteration 6019 : loss : 0.026782, loss_ce: 0.009864
iteration 6020 : loss : 0.084621, loss_ce: 0.011520
iteration 6021 : loss : 0.036199, loss_ce: 0.013541
iteration 6022 : loss : 0.029849, loss_ce: 0.011594
iteration 6023 : loss : 0.093112, loss_ce: 0.011916
iteration 6024 : loss : 0.030172, loss_ce: 0.008057
iteration 6025 : loss : 0.042282, loss_ce: 0.007949
iteration 6026 : loss : 0.031248, loss_ce: 0.007964
iteration 6027 : loss : 0.031253, loss_ce: 0.016871
iteration 6028 : loss : 0.025892, loss_ce: 0.010056
iteration 6029 : loss : 0.031805, loss_ce: 0.010769
iteration 6030 : loss : 0.030844, loss_ce: 0.007906
iteration 6031 : loss : 0.036370, loss_ce: 0.014433
iteration 6032 : loss : 0.033273, loss_ce: 0.010999
iteration 6033 : loss : 0.029111, loss_ce: 0.011271
iteration 6034 : loss : 0.037892, loss_ce: 0.013812
iteration 6035 : loss : 0.036339, loss_ce: 0.010707
iteration 6036 : loss : 0.033739, loss_ce: 0.008493
iteration 6037 : loss : 0.035959, loss_ce: 0.011660
iteration 6038 : loss : 0.043128, loss_ce: 0.008925
iteration 6039 : loss : 0.041859, loss_ce: 0.011966
iteration 6040 : loss : 0.032253, loss_ce: 0.010414
iteration 6041 : loss : 0.033088, loss_ce: 0.014321
iteration 6042 : loss : 0.040649, loss_ce: 0.014886
iteration 6043 : loss : 0.043236, loss_ce: 0.015172
iteration 6044 : loss : 0.076333, loss_ce: 0.004627
iteration 6045 : loss : 0.187320, loss_ce: 0.010182
 32%|█████████▊                    | 65/200 [58:58<2:02:56, 54.64s/it]pred_sum 48240
gtsum tensor(46362, device='cuda:0')
iteration 6046 : loss : 0.033653, loss_ce: 0.011736
iteration 6047 : loss : 0.042621, loss_ce: 0.011784
iteration 6048 : loss : 0.039058, loss_ce: 0.015212
iteration 6049 : loss : 0.036903, loss_ce: 0.009197
iteration 6050 : loss : 0.036827, loss_ce: 0.007162
iteration 6051 : loss : 0.034241, loss_ce: 0.009436
iteration 6052 : loss : 0.074568, loss_ce: 0.004536
iteration 6053 : loss : 0.035721, loss_ce: 0.004108
iteration 6054 : loss : 0.028625, loss_ce: 0.009862
iteration 6055 : loss : 0.039210, loss_ce: 0.011211
iteration 6056 : loss : 0.033479, loss_ce: 0.009092
iteration 6057 : loss : 0.032139, loss_ce: 0.014024
iteration 6058 : loss : 0.029062, loss_ce: 0.010922
iteration 6059 : loss : 0.026157, loss_ce: 0.011038
iteration 6060 : loss : 0.034653, loss_ce: 0.012152
iteration 6061 : loss : 0.034700, loss_ce: 0.006799
iteration 6062 : loss : 0.031385, loss_ce: 0.012731
iteration 6063 : loss : 0.028177, loss_ce: 0.009181
iteration 6064 : loss : 0.031877, loss_ce: 0.008199
iteration 6065 : loss : 0.080356, loss_ce: 0.006349
iteration 6066 : loss : 0.031580, loss_ce: 0.014224
iteration 6067 : loss : 0.025792, loss_ce: 0.009516
iteration 6068 : loss : 0.083617, loss_ce: 0.009743
iteration 6069 : loss : 0.032899, loss_ce: 0.010176
iteration 6070 : loss : 0.035887, loss_ce: 0.017863
iteration 6071 : loss : 0.030003, loss_ce: 0.008883
iteration 6072 : loss : 0.028086, loss_ce: 0.013581
iteration 6073 : loss : 0.092844, loss_ce: 0.008258
iteration 6074 : loss : 0.031489, loss_ce: 0.012688
iteration 6075 : loss : 0.027097, loss_ce: 0.010862
iteration 6076 : loss : 0.033584, loss_ce: 0.011986
pred_sum 30230
gtsum tensor(28547, device='cuda:0')
iteration 6077 : loss : 0.037413, loss_ce: 0.009888
iteration 6078 : loss : 0.030977, loss_ce: 0.008777
iteration 6079 : loss : 0.028312, loss_ce: 0.009144
iteration 6080 : loss : 0.030900, loss_ce: 0.011789
iteration 6081 : loss : 0.034669, loss_ce: 0.014604
iteration 6082 : loss : 0.033784, loss_ce: 0.011617
iteration 6083 : loss : 0.086776, loss_ce: 0.006781
iteration 6084 : loss : 0.039206, loss_ce: 0.015025
iteration 6085 : loss : 0.033718, loss_ce: 0.009156
iteration 6086 : loss : 0.030868, loss_ce: 0.009847
iteration 6087 : loss : 0.031015, loss_ce: 0.015627
iteration 6088 : loss : 0.028311, loss_ce: 0.009575
iteration 6089 : loss : 0.025242, loss_ce: 0.007514
iteration 6090 : loss : 0.040296, loss_ce: 0.011620
iteration 6091 : loss : 0.025687, loss_ce: 0.006756
iteration 6092 : loss : 0.036465, loss_ce: 0.012904
iteration 6093 : loss : 0.030881, loss_ce: 0.013083
iteration 6094 : loss : 0.033015, loss_ce: 0.009317
iteration 6095 : loss : 0.030903, loss_ce: 0.004473
iteration 6096 : loss : 0.031360, loss_ce: 0.012373
iteration 6097 : loss : 0.030703, loss_ce: 0.011882
iteration 6098 : loss : 0.029802, loss_ce: 0.011324
iteration 6099 : loss : 0.028943, loss_ce: 0.009894
iteration 6100 : loss : 0.067612, loss_ce: 0.011475
iteration 6101 : loss : 0.035055, loss_ce: 0.012659
iteration 6102 : loss : 0.031608, loss_ce: 0.015800
iteration 6103 : loss : 0.034440, loss_ce: 0.009868
iteration 6104 : loss : 0.037248, loss_ce: 0.012742
iteration 6105 : loss : 0.128934, loss_ce: 0.010346
iteration 6106 : loss : 0.033642, loss_ce: 0.015467
iteration 6107 : loss : 0.036233, loss_ce: 0.015344
pred_sum 9830
gtsum tensor(11856, device='cuda:0')
iteration 6108 : loss : 0.059092, loss_ce: 0.009386
iteration 6109 : loss : 0.085331, loss_ce: 0.010607
iteration 6110 : loss : 0.082649, loss_ce: 0.008472
iteration 6111 : loss : 0.033718, loss_ce: 0.007429
iteration 6112 : loss : 0.031127, loss_ce: 0.008018
iteration 6113 : loss : 0.034689, loss_ce: 0.010282
iteration 6114 : loss : 0.035540, loss_ce: 0.006565
iteration 6115 : loss : 0.087072, loss_ce: 0.009305
iteration 6116 : loss : 0.029372, loss_ce: 0.009418
iteration 6117 : loss : 0.031558, loss_ce: 0.005328
iteration 6118 : loss : 0.036952, loss_ce: 0.012635
iteration 6119 : loss : 0.033078, loss_ce: 0.012677
iteration 6120 : loss : 0.044135, loss_ce: 0.009189
iteration 6121 : loss : 0.025337, loss_ce: 0.009126
iteration 6122 : loss : 0.023960, loss_ce: 0.009194
iteration 6123 : loss : 0.028119, loss_ce: 0.009339
iteration 6124 : loss : 0.030390, loss_ce: 0.010520
iteration 6125 : loss : 0.055478, loss_ce: 0.004889
iteration 6126 : loss : 0.033489, loss_ce: 0.013173
iteration 6127 : loss : 0.029962, loss_ce: 0.012117
iteration 6128 : loss : 0.044076, loss_ce: 0.014624
iteration 6129 : loss : 0.030863, loss_ce: 0.011617
iteration 6130 : loss : 0.036404, loss_ce: 0.009031
iteration 6131 : loss : 0.030990, loss_ce: 0.011902
iteration 6132 : loss : 0.082833, loss_ce: 0.007359
iteration 6133 : loss : 0.034760, loss_ce: 0.016108
iteration 6134 : loss : 0.033343, loss_ce: 0.010438
iteration 6135 : loss : 0.034064, loss_ce: 0.013341
iteration 6136 : loss : 0.043881, loss_ce: 0.019775
iteration 6137 : loss : 0.037589, loss_ce: 0.012240
iteration 6138 : loss : 0.361682, loss_ce: 0.003277
 33%|█████████▉                    | 66/200 [59:52<2:02:00, 54.63s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 6139 : loss : 0.029745, loss_ce: 0.010181
iteration 6140 : loss : 0.087728, loss_ce: 0.009243
iteration 6141 : loss : 0.028860, loss_ce: 0.009501
iteration 6142 : loss : 0.034290, loss_ce: 0.007800
iteration 6143 : loss : 0.037746, loss_ce: 0.013529
iteration 6144 : loss : 0.029785, loss_ce: 0.009328
iteration 6145 : loss : 0.104456, loss_ce: 0.004258
iteration 6146 : loss : 0.027914, loss_ce: 0.007620
iteration 6147 : loss : 0.042506, loss_ce: 0.012874
iteration 6148 : loss : 0.038891, loss_ce: 0.012619
iteration 6149 : loss : 0.055095, loss_ce: 0.011993
iteration 6150 : loss : 0.039494, loss_ce: 0.015768
iteration 6151 : loss : 0.043404, loss_ce: 0.015341
iteration 6152 : loss : 0.049718, loss_ce: 0.009157
iteration 6153 : loss : 0.039121, loss_ce: 0.014765
iteration 6154 : loss : 0.041670, loss_ce: 0.012055
iteration 6155 : loss : 0.033868, loss_ce: 0.012779
iteration 6156 : loss : 0.028254, loss_ce: 0.008582
iteration 6157 : loss : 0.030732, loss_ce: 0.008832
iteration 6158 : loss : 0.032067, loss_ce: 0.008000
iteration 6159 : loss : 0.038102, loss_ce: 0.011317
iteration 6160 : loss : 0.036661, loss_ce: 0.012070
iteration 6161 : loss : 0.090338, loss_ce: 0.005069
iteration 6162 : loss : 0.042723, loss_ce: 0.014120
iteration 6163 : loss : 0.028435, loss_ce: 0.007223
iteration 6164 : loss : 0.029828, loss_ce: 0.011860
iteration 6165 : loss : 0.092970, loss_ce: 0.012119
iteration 6166 : loss : 0.044255, loss_ce: 0.018153
iteration 6167 : loss : 0.031188, loss_ce: 0.010372
iteration 6168 : loss : 0.034588, loss_ce: 0.010256
iteration 6169 : loss : 0.057985, loss_ce: 0.013884
pred_sum 36906
gtsum tensor(37051, device='cuda:0')
iteration 6170 : loss : 0.045621, loss_ce: 0.007557
iteration 6171 : loss : 0.028650, loss_ce: 0.007303
iteration 6172 : loss : 0.029458, loss_ce: 0.010955
iteration 6173 : loss : 0.048890, loss_ce: 0.011303
iteration 6174 : loss : 0.035310, loss_ce: 0.010877
iteration 6175 : loss : 0.036631, loss_ce: 0.014759
iteration 6176 : loss : 0.030781, loss_ce: 0.009398
iteration 6177 : loss : 0.045051, loss_ce: 0.009650
iteration 6178 : loss : 0.047073, loss_ce: 0.014279
iteration 6179 : loss : 0.034862, loss_ce: 0.012779
iteration 6180 : loss : 0.034941, loss_ce: 0.010315
iteration 6181 : loss : 0.030316, loss_ce: 0.011518
iteration 6182 : loss : 0.040381, loss_ce: 0.015471
iteration 6183 : loss : 0.035935, loss_ce: 0.015937
iteration 6184 : loss : 0.039233, loss_ce: 0.010896
iteration 6185 : loss : 0.028823, loss_ce: 0.006178
iteration 6186 : loss : 0.032659, loss_ce: 0.010972
iteration 6187 : loss : 0.037904, loss_ce: 0.014348
iteration 6188 : loss : 0.032164, loss_ce: 0.011046
iteration 6189 : loss : 0.032829, loss_ce: 0.013851
iteration 6190 : loss : 0.036966, loss_ce: 0.017437
iteration 6191 : loss : 0.022889, loss_ce: 0.006055
iteration 6192 : loss : 0.032414, loss_ce: 0.011865
iteration 6193 : loss : 0.034025, loss_ce: 0.011400
iteration 6194 : loss : 0.032759, loss_ce: 0.012319
iteration 6195 : loss : 0.035699, loss_ce: 0.007201
iteration 6196 : loss : 0.047062, loss_ce: 0.010494
iteration 6197 : loss : 0.027366, loss_ce: 0.010578
iteration 6198 : loss : 0.034453, loss_ce: 0.018443
iteration 6199 : loss : 0.031204, loss_ce: 0.011698
iteration 6200 : loss : 0.037070, loss_ce: 0.008571
pred_sum 17151
gtsum tensor(17069, device='cuda:0')
iteration 6201 : loss : 0.074894, loss_ce: 0.010747
iteration 6202 : loss : 0.033198, loss_ce: 0.011903
iteration 6203 : loss : 0.040496, loss_ce: 0.011032
iteration 6204 : loss : 0.023319, loss_ce: 0.008400
iteration 6205 : loss : 0.024819, loss_ce: 0.006747
iteration 6206 : loss : 0.033654, loss_ce: 0.013948
iteration 6207 : loss : 0.041079, loss_ce: 0.014159
iteration 6208 : loss : 0.034665, loss_ce: 0.011960
iteration 6209 : loss : 0.037248, loss_ce: 0.010268
iteration 6210 : loss : 0.035516, loss_ce: 0.011039
iteration 6211 : loss : 0.054442, loss_ce: 0.009675
iteration 6212 : loss : 0.033544, loss_ce: 0.009466
iteration 6213 : loss : 0.041540, loss_ce: 0.010082
iteration 6214 : loss : 0.047823, loss_ce: 0.006863
iteration 6215 : loss : 0.038279, loss_ce: 0.011112
iteration 6216 : loss : 0.032156, loss_ce: 0.010977
iteration 6217 : loss : 0.028025, loss_ce: 0.009932
iteration 6218 : loss : 0.029952, loss_ce: 0.008250
iteration 6219 : loss : 0.034975, loss_ce: 0.013749
iteration 6220 : loss : 0.036652, loss_ce: 0.011580
iteration 6221 : loss : 0.048243, loss_ce: 0.013032
iteration 6222 : loss : 0.024313, loss_ce: 0.006945
iteration 6223 : loss : 0.135329, loss_ce: 0.007894
iteration 6224 : loss : 0.039577, loss_ce: 0.015003
iteration 6225 : loss : 0.033158, loss_ce: 0.013904
iteration 6226 : loss : 0.037444, loss_ce: 0.012046
iteration 6227 : loss : 0.034400, loss_ce: 0.014513
iteration 6228 : loss : 0.033540, loss_ce: 0.012546
iteration 6229 : loss : 0.076419, loss_ce: 0.009549
iteration 6230 : loss : 0.034590, loss_ce: 0.008185
iteration 6231 : loss : 0.392430, loss_ce: 0.001914
 34%|█████████▍                  | 67/200 [1:00:47<2:01:02, 54.61s/it]pred_sum 438
gtsum tensor(497, device='cuda:0')
iteration 6232 : loss : 0.028562, loss_ce: 0.010279
iteration 6233 : loss : 0.035705, loss_ce: 0.010280
iteration 6234 : loss : 0.031699, loss_ce: 0.006059
iteration 6235 : loss : 0.032969, loss_ce: 0.011481
iteration 6236 : loss : 0.037434, loss_ce: 0.015888
iteration 6237 : loss : 0.026305, loss_ce: 0.008754
iteration 6238 : loss : 0.033070, loss_ce: 0.015188
iteration 6239 : loss : 0.032614, loss_ce: 0.014893
iteration 6240 : loss : 0.033594, loss_ce: 0.011992
iteration 6241 : loss : 0.028734, loss_ce: 0.012397
iteration 6242 : loss : 0.035229, loss_ce: 0.011329
iteration 6243 : loss : 0.031842, loss_ce: 0.010119
iteration 6244 : loss : 0.040749, loss_ce: 0.011527
iteration 6245 : loss : 0.025375, loss_ce: 0.010472
iteration 6246 : loss : 0.077915, loss_ce: 0.005284
iteration 6247 : loss : 0.032130, loss_ce: 0.013750
iteration 6248 : loss : 0.028422, loss_ce: 0.009254
iteration 6249 : loss : 0.030130, loss_ce: 0.008762
iteration 6250 : loss : 0.027013, loss_ce: 0.011960
iteration 6251 : loss : 0.026798, loss_ce: 0.009717
iteration 6252 : loss : 0.085707, loss_ce: 0.005894
iteration 6253 : loss : 0.042814, loss_ce: 0.009573
iteration 6254 : loss : 0.028457, loss_ce: 0.009667
iteration 6255 : loss : 0.034889, loss_ce: 0.012873
iteration 6256 : loss : 0.025481, loss_ce: 0.009723
iteration 6257 : loss : 0.027549, loss_ce: 0.009233
iteration 6258 : loss : 0.033600, loss_ce: 0.012676
iteration 6259 : loss : 0.052601, loss_ce: 0.011742
iteration 6260 : loss : 0.078480, loss_ce: 0.007535
iteration 6261 : loss : 0.035433, loss_ce: 0.011815
iteration 6262 : loss : 0.035215, loss_ce: 0.014917
pred_sum 54062
gtsum tensor(54398, device='cuda:0')
iteration 6263 : loss : 0.033966, loss_ce: 0.011372
iteration 6264 : loss : 0.085587, loss_ce: 0.006057
iteration 6265 : loss : 0.031978, loss_ce: 0.013192
iteration 6266 : loss : 0.033806, loss_ce: 0.016831
iteration 6267 : loss : 0.035486, loss_ce: 0.012614
iteration 6268 : loss : 0.035293, loss_ce: 0.012078
iteration 6269 : loss : 0.031877, loss_ce: 0.009498
iteration 6270 : loss : 0.031676, loss_ce: 0.011419
iteration 6271 : loss : 0.028874, loss_ce: 0.007299
iteration 6272 : loss : 0.041461, loss_ce: 0.010399
iteration 6273 : loss : 0.036008, loss_ce: 0.013437
iteration 6274 : loss : 0.033738, loss_ce: 0.007694
iteration 6275 : loss : 0.078664, loss_ce: 0.004616
iteration 6276 : loss : 0.031560, loss_ce: 0.012626
iteration 6277 : loss : 0.033319, loss_ce: 0.013902
iteration 6278 : loss : 0.030697, loss_ce: 0.009168
iteration 6279 : loss : 0.059604, loss_ce: 0.010565
iteration 6280 : loss : 0.032449, loss_ce: 0.014971
iteration 6281 : loss : 0.037107, loss_ce: 0.006111
iteration 6282 : loss : 0.039496, loss_ce: 0.013017
iteration 6283 : loss : 0.027555, loss_ce: 0.009183
iteration 6284 : loss : 0.031139, loss_ce: 0.009033
iteration 6285 : loss : 0.045313, loss_ce: 0.004759
iteration 6286 : loss : 0.031289, loss_ce: 0.012667
iteration 6287 : loss : 0.082785, loss_ce: 0.008383
iteration 6288 : loss : 0.034692, loss_ce: 0.010708
iteration 6289 : loss : 0.034194, loss_ce: 0.007540
iteration 6290 : loss : 0.032214, loss_ce: 0.012535
iteration 6291 : loss : 0.028030, loss_ce: 0.007506
iteration 6292 : loss : 0.036998, loss_ce: 0.015372
iteration 6293 : loss : 0.043125, loss_ce: 0.009384
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 6294 : loss : 0.095763, loss_ce: 0.005170
iteration 6295 : loss : 0.031150, loss_ce: 0.012714
iteration 6296 : loss : 0.034806, loss_ce: 0.011898
iteration 6297 : loss : 0.042603, loss_ce: 0.012974
iteration 6298 : loss : 0.036812, loss_ce: 0.013671
iteration 6299 : loss : 0.039548, loss_ce: 0.006719
iteration 6300 : loss : 0.039936, loss_ce: 0.012065
iteration 6301 : loss : 0.033744, loss_ce: 0.013879
iteration 6302 : loss : 0.083270, loss_ce: 0.009374
iteration 6303 : loss : 0.033409, loss_ce: 0.015126
iteration 6304 : loss : 0.031002, loss_ce: 0.010883
iteration 6305 : loss : 0.031101, loss_ce: 0.011125
iteration 6306 : loss : 0.037394, loss_ce: 0.009976
iteration 6307 : loss : 0.034865, loss_ce: 0.015958
iteration 6308 : loss : 0.036649, loss_ce: 0.017238
iteration 6309 : loss : 0.025129, loss_ce: 0.006805
iteration 6310 : loss : 0.055431, loss_ce: 0.008076
iteration 6311 : loss : 0.029234, loss_ce: 0.009821
iteration 6312 : loss : 0.025465, loss_ce: 0.008708
iteration 6313 : loss : 0.087399, loss_ce: 0.010459
iteration 6314 : loss : 0.033855, loss_ce: 0.010713
iteration 6315 : loss : 0.087267, loss_ce: 0.008542
iteration 6316 : loss : 0.035153, loss_ce: 0.004196
iteration 6317 : loss : 0.037340, loss_ce: 0.016821
iteration 6318 : loss : 0.032238, loss_ce: 0.012541
iteration 6319 : loss : 0.055085, loss_ce: 0.009391
iteration 6320 : loss : 0.061355, loss_ce: 0.013114
iteration 6321 : loss : 0.036786, loss_ce: 0.011573
iteration 6322 : loss : 0.029385, loss_ce: 0.008025
iteration 6323 : loss : 0.029386, loss_ce: 0.008958
iteration 6324 : loss : 0.086405, loss_ce: 0.021313
 34%|█████████▌                  | 68/200 [1:01:41<2:00:07, 54.60s/it]pred_sum 12863
gtsum tensor(11856, device='cuda:0')
iteration 6325 : loss : 0.030900, loss_ce: 0.007365
iteration 6326 : loss : 0.089059, loss_ce: 0.011291
iteration 6327 : loss : 0.039884, loss_ce: 0.011224
iteration 6328 : loss : 0.028383, loss_ce: 0.010617
iteration 6329 : loss : 0.036543, loss_ce: 0.010510
iteration 6330 : loss : 0.033347, loss_ce: 0.009540
iteration 6331 : loss : 0.034824, loss_ce: 0.009805
iteration 6332 : loss : 0.030940, loss_ce: 0.009377
iteration 6333 : loss : 0.040403, loss_ce: 0.017120
iteration 6334 : loss : 0.034244, loss_ce: 0.012791
iteration 6335 : loss : 0.035332, loss_ce: 0.012439
iteration 6336 : loss : 0.036354, loss_ce: 0.010051
iteration 6337 : loss : 0.036561, loss_ce: 0.013225
iteration 6338 : loss : 0.034893, loss_ce: 0.009940
iteration 6339 : loss : 0.029070, loss_ce: 0.009491
iteration 6340 : loss : 0.033961, loss_ce: 0.009043
iteration 6341 : loss : 0.034265, loss_ce: 0.011879
iteration 6342 : loss : 0.083231, loss_ce: 0.008001
iteration 6343 : loss : 0.034230, loss_ce: 0.012372
iteration 6344 : loss : 0.038230, loss_ce: 0.015537
iteration 6345 : loss : 0.027351, loss_ce: 0.008222
iteration 6346 : loss : 0.027559, loss_ce: 0.010237
iteration 6347 : loss : 0.032960, loss_ce: 0.010192
iteration 6348 : loss : 0.080610, loss_ce: 0.006257
iteration 6349 : loss : 0.077325, loss_ce: 0.008601
iteration 6350 : loss : 0.046469, loss_ce: 0.013637
iteration 6351 : loss : 0.030179, loss_ce: 0.012756
iteration 6352 : loss : 0.030277, loss_ce: 0.013841
iteration 6353 : loss : 0.035510, loss_ce: 0.009560
iteration 6354 : loss : 0.028803, loss_ce: 0.012452
iteration 6355 : loss : 0.028558, loss_ce: 0.009963
pred_sum 460
gtsum tensor(455, device='cuda:0')
iteration 6356 : loss : 0.028655, loss_ce: 0.011430
iteration 6357 : loss : 0.029843, loss_ce: 0.009559
iteration 6358 : loss : 0.030553, loss_ce: 0.008153
iteration 6359 : loss : 0.027116, loss_ce: 0.011343
iteration 6360 : loss : 0.033462, loss_ce: 0.013639
iteration 6361 : loss : 0.079662, loss_ce: 0.004421
iteration 6362 : loss : 0.033128, loss_ce: 0.012718
iteration 6363 : loss : 0.034358, loss_ce: 0.013616
iteration 6364 : loss : 0.024984, loss_ce: 0.010059
iteration 6365 : loss : 0.036195, loss_ce: 0.006181
iteration 6366 : loss : 0.031308, loss_ce: 0.006818
iteration 6367 : loss : 0.030953, loss_ce: 0.013416
iteration 6368 : loss : 0.027426, loss_ce: 0.006219
iteration 6369 : loss : 0.022916, loss_ce: 0.007805
iteration 6370 : loss : 0.034151, loss_ce: 0.011009
iteration 6371 : loss : 0.027899, loss_ce: 0.010560
iteration 6372 : loss : 0.037898, loss_ce: 0.018962
iteration 6373 : loss : 0.033939, loss_ce: 0.013578
iteration 6374 : loss : 0.028312, loss_ce: 0.009912
iteration 6375 : loss : 0.027815, loss_ce: 0.010273
iteration 6376 : loss : 0.032651, loss_ce: 0.008196
iteration 6377 : loss : 0.033505, loss_ce: 0.007986
iteration 6378 : loss : 0.032861, loss_ce: 0.008423
iteration 6379 : loss : 0.041967, loss_ce: 0.011698
iteration 6380 : loss : 0.034988, loss_ce: 0.010432
iteration 6381 : loss : 0.032893, loss_ce: 0.011662
iteration 6382 : loss : 0.028622, loss_ce: 0.011959
iteration 6383 : loss : 0.032797, loss_ce: 0.008694
iteration 6384 : loss : 0.036303, loss_ce: 0.016734
iteration 6385 : loss : 0.024732, loss_ce: 0.011429
iteration 6386 : loss : 0.026723, loss_ce: 0.009825
pred_sum 20324
gtsum tensor(20239, device='cuda:0')
iteration 6387 : loss : 0.031969, loss_ce: 0.012628
iteration 6388 : loss : 0.029306, loss_ce: 0.010868
iteration 6389 : loss : 0.035409, loss_ce: 0.011060
iteration 6390 : loss : 0.078226, loss_ce: 0.004728
iteration 6391 : loss : 0.044519, loss_ce: 0.011121
iteration 6392 : loss : 0.030311, loss_ce: 0.009043
iteration 6393 : loss : 0.031443, loss_ce: 0.010256
iteration 6394 : loss : 0.086948, loss_ce: 0.007897
iteration 6395 : loss : 0.039843, loss_ce: 0.010069
iteration 6396 : loss : 0.027977, loss_ce: 0.010863
iteration 6397 : loss : 0.034218, loss_ce: 0.009311
iteration 6398 : loss : 0.027157, loss_ce: 0.010930
iteration 6399 : loss : 0.033962, loss_ce: 0.011067
iteration 6400 : loss : 0.032910, loss_ce: 0.012544
iteration 6401 : loss : 0.029702, loss_ce: 0.007089
iteration 6402 : loss : 0.023500, loss_ce: 0.005741
iteration 6403 : loss : 0.028517, loss_ce: 0.012847
iteration 6404 : loss : 0.029522, loss_ce: 0.012037
iteration 6405 : loss : 0.031171, loss_ce: 0.011434
iteration 6406 : loss : 0.034162, loss_ce: 0.016274
iteration 6407 : loss : 0.032010, loss_ce: 0.010736
iteration 6408 : loss : 0.085058, loss_ce: 0.006991
iteration 6409 : loss : 0.060914, loss_ce: 0.007367
iteration 6410 : loss : 0.032326, loss_ce: 0.012018
iteration 6411 : loss : 0.033021, loss_ce: 0.008868
iteration 6412 : loss : 0.037177, loss_ce: 0.005322
iteration 6413 : loss : 0.054286, loss_ce: 0.007902
iteration 6414 : loss : 0.058906, loss_ce: 0.015515
iteration 6415 : loss : 0.036077, loss_ce: 0.008376
iteration 6416 : loss : 0.024324, loss_ce: 0.007132
iteration 6417 : loss : 0.392307, loss_ce: 0.001838
 34%|█████████▋                  | 69/200 [1:02:36<1:59:09, 54.58s/it]pred_sum 578
gtsum tensor(586, device='cuda:0')
iteration 6418 : loss : 0.040642, loss_ce: 0.009652
iteration 6419 : loss : 0.030484, loss_ce: 0.010606
iteration 6420 : loss : 0.037363, loss_ce: 0.010156
iteration 6421 : loss : 0.030615, loss_ce: 0.009426
iteration 6422 : loss : 0.029515, loss_ce: 0.015657
iteration 6423 : loss : 0.030502, loss_ce: 0.011345
iteration 6424 : loss : 0.031004, loss_ce: 0.007742
iteration 6425 : loss : 0.033035, loss_ce: 0.011562
iteration 6426 : loss : 0.079255, loss_ce: 0.003986
iteration 6427 : loss : 0.022941, loss_ce: 0.007397
iteration 6428 : loss : 0.036824, loss_ce: 0.013721
iteration 6429 : loss : 0.032013, loss_ce: 0.007713
iteration 6430 : loss : 0.033084, loss_ce: 0.006891
iteration 6431 : loss : 0.033753, loss_ce: 0.013800
iteration 6432 : loss : 0.038229, loss_ce: 0.009476
iteration 6433 : loss : 0.034643, loss_ce: 0.008862
iteration 6434 : loss : 0.036980, loss_ce: 0.018525
iteration 6435 : loss : 0.029556, loss_ce: 0.010654
iteration 6436 : loss : 0.072976, loss_ce: 0.007945
iteration 6437 : loss : 0.030199, loss_ce: 0.009506
iteration 6438 : loss : 0.037383, loss_ce: 0.005100
iteration 6439 : loss : 0.032285, loss_ce: 0.010371
iteration 6440 : loss : 0.033810, loss_ce: 0.009418
iteration 6441 : loss : 0.035362, loss_ce: 0.014291
iteration 6442 : loss : 0.041785, loss_ce: 0.008090
iteration 6443 : loss : 0.027021, loss_ce: 0.009444
iteration 6444 : loss : 0.076654, loss_ce: 0.008184
iteration 6445 : loss : 0.033611, loss_ce: 0.010687
iteration 6446 : loss : 0.031769, loss_ce: 0.012747
iteration 6447 : loss : 0.083002, loss_ce: 0.006502
iteration 6448 : loss : 0.023598, loss_ce: 0.007596
pred_sum 106
gtsum tensor(111, device='cuda:0')
iteration 6449 : loss : 0.023605, loss_ce: 0.008620
iteration 6450 : loss : 0.032202, loss_ce: 0.011497
iteration 6451 : loss : 0.028394, loss_ce: 0.011272
iteration 6452 : loss : 0.038324, loss_ce: 0.018351
iteration 6453 : loss : 0.030928, loss_ce: 0.014075
iteration 6454 : loss : 0.081577, loss_ce: 0.006431
iteration 6455 : loss : 0.028996, loss_ce: 0.009132
iteration 6456 : loss : 0.032461, loss_ce: 0.009476
iteration 6457 : loss : 0.032138, loss_ce: 0.011021
iteration 6458 : loss : 0.035007, loss_ce: 0.010838
iteration 6459 : loss : 0.042221, loss_ce: 0.012202
iteration 6460 : loss : 0.027205, loss_ce: 0.008476
iteration 6461 : loss : 0.030676, loss_ce: 0.008835
iteration 6462 : loss : 0.032471, loss_ce: 0.008852
iteration 6463 : loss : 0.028698, loss_ce: 0.012215
iteration 6464 : loss : 0.033571, loss_ce: 0.010023
iteration 6465 : loss : 0.026165, loss_ce: 0.008930
iteration 6466 : loss : 0.027749, loss_ce: 0.007060
iteration 6467 : loss : 0.040573, loss_ce: 0.017774
iteration 6468 : loss : 0.038428, loss_ce: 0.007698
iteration 6469 : loss : 0.026599, loss_ce: 0.009739
iteration 6470 : loss : 0.082518, loss_ce: 0.014400
iteration 6471 : loss : 0.033765, loss_ce: 0.009971
iteration 6472 : loss : 0.031208, loss_ce: 0.014333
iteration 6473 : loss : 0.026938, loss_ce: 0.006499
iteration 6474 : loss : 0.032832, loss_ce: 0.009076
iteration 6475 : loss : 0.042668, loss_ce: 0.010356
iteration 6476 : loss : 0.027575, loss_ce: 0.006378
iteration 6477 : loss : 0.024498, loss_ce: 0.009354
iteration 6478 : loss : 0.027081, loss_ce: 0.006061
iteration 6479 : loss : 0.034950, loss_ce: 0.012501
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 6480 : loss : 0.028582, loss_ce: 0.009975
iteration 6481 : loss : 0.032321, loss_ce: 0.012088
iteration 6482 : loss : 0.030540, loss_ce: 0.011096
iteration 6483 : loss : 0.084590, loss_ce: 0.011157
iteration 6484 : loss : 0.039844, loss_ce: 0.010865
iteration 6485 : loss : 0.042397, loss_ce: 0.011294
iteration 6486 : loss : 0.126287, loss_ce: 0.004875
iteration 6487 : loss : 0.026046, loss_ce: 0.008327
iteration 6488 : loss : 0.029318, loss_ce: 0.010214
iteration 6489 : loss : 0.028544, loss_ce: 0.012308
iteration 6490 : loss : 0.078579, loss_ce: 0.007369
iteration 6491 : loss : 0.084174, loss_ce: 0.009123
iteration 6492 : loss : 0.033473, loss_ce: 0.012208
iteration 6493 : loss : 0.031570, loss_ce: 0.008242
iteration 6494 : loss : 0.035555, loss_ce: 0.010720
iteration 6495 : loss : 0.032732, loss_ce: 0.013888
iteration 6496 : loss : 0.084237, loss_ce: 0.005348
iteration 6497 : loss : 0.027749, loss_ce: 0.009717
iteration 6498 : loss : 0.029024, loss_ce: 0.015164
iteration 6499 : loss : 0.029447, loss_ce: 0.010581
iteration 6500 : loss : 0.030035, loss_ce: 0.014276
iteration 6501 : loss : 0.031050, loss_ce: 0.010202
iteration 6502 : loss : 0.030610, loss_ce: 0.011347
iteration 6503 : loss : 0.030177, loss_ce: 0.011148
iteration 6504 : loss : 0.029726, loss_ce: 0.012773
iteration 6505 : loss : 0.026810, loss_ce: 0.012435
iteration 6506 : loss : 0.078405, loss_ce: 0.008736
iteration 6507 : loss : 0.039293, loss_ce: 0.009655
iteration 6508 : loss : 0.025486, loss_ce: 0.010819
iteration 6509 : loss : 0.026731, loss_ce: 0.006936
iteration 6510 : loss : 0.095467, loss_ce: 0.017171
 35%|█████████▊                  | 70/200 [1:03:30<1:58:15, 54.58s/it]pred_sum 39863
gtsum tensor(40785, device='cuda:0')
iteration 6511 : loss : 0.031976, loss_ce: 0.008581
iteration 6512 : loss : 0.029768, loss_ce: 0.011909
iteration 6513 : loss : 0.032666, loss_ce: 0.009891
iteration 6514 : loss : 0.026472, loss_ce: 0.009807
iteration 6515 : loss : 0.029356, loss_ce: 0.008359
iteration 6516 : loss : 0.028407, loss_ce: 0.008270
iteration 6517 : loss : 0.026876, loss_ce: 0.005315
iteration 6518 : loss : 0.050011, loss_ce: 0.012209
iteration 6519 : loss : 0.029500, loss_ce: 0.011357
iteration 6520 : loss : 0.038529, loss_ce: 0.009075
iteration 6521 : loss : 0.030743, loss_ce: 0.010087
iteration 6522 : loss : 0.028607, loss_ce: 0.009638
iteration 6523 : loss : 0.036102, loss_ce: 0.010143
iteration 6524 : loss : 0.033837, loss_ce: 0.012648
iteration 6525 : loss : 0.034363, loss_ce: 0.010844
iteration 6526 : loss : 0.030795, loss_ce: 0.010929
iteration 6527 : loss : 0.033330, loss_ce: 0.016775
iteration 6528 : loss : 0.037306, loss_ce: 0.009663
iteration 6529 : loss : 0.030531, loss_ce: 0.009574
iteration 6530 : loss : 0.051856, loss_ce: 0.008531
iteration 6531 : loss : 0.036665, loss_ce: 0.013224
iteration 6532 : loss : 0.034705, loss_ce: 0.012757
iteration 6533 : loss : 0.029274, loss_ce: 0.006657
iteration 6534 : loss : 0.042457, loss_ce: 0.011890
iteration 6535 : loss : 0.032724, loss_ce: 0.009100
iteration 6536 : loss : 0.081533, loss_ce: 0.006819
iteration 6537 : loss : 0.028189, loss_ce: 0.009656
iteration 6538 : loss : 0.029409, loss_ce: 0.010114
iteration 6539 : loss : 0.025892, loss_ce: 0.010100
iteration 6540 : loss : 0.034167, loss_ce: 0.006051
iteration 6541 : loss : 0.031506, loss_ce: 0.006080
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 6542 : loss : 0.122311, loss_ce: 0.002000
iteration 6543 : loss : 0.030656, loss_ce: 0.010785
iteration 6544 : loss : 0.079748, loss_ce: 0.008452
iteration 6545 : loss : 0.039555, loss_ce: 0.012609
iteration 6546 : loss : 0.029443, loss_ce: 0.012903
iteration 6547 : loss : 0.027619, loss_ce: 0.011424
iteration 6548 : loss : 0.035099, loss_ce: 0.021083
iteration 6549 : loss : 0.029730, loss_ce: 0.008490
iteration 6550 : loss : 0.035959, loss_ce: 0.008778
iteration 6551 : loss : 0.034303, loss_ce: 0.012924
iteration 6552 : loss : 0.028998, loss_ce: 0.008046
iteration 6553 : loss : 0.036910, loss_ce: 0.016639
iteration 6554 : loss : 0.030280, loss_ce: 0.007722
iteration 6555 : loss : 0.028434, loss_ce: 0.014351
iteration 6556 : loss : 0.030477, loss_ce: 0.010732
iteration 6557 : loss : 0.022932, loss_ce: 0.007048
iteration 6558 : loss : 0.026781, loss_ce: 0.012473
iteration 6559 : loss : 0.079464, loss_ce: 0.008218
iteration 6560 : loss : 0.027941, loss_ce: 0.007835
iteration 6561 : loss : 0.032256, loss_ce: 0.013167
iteration 6562 : loss : 0.077539, loss_ce: 0.006763
iteration 6563 : loss : 0.122908, loss_ce: 0.005880
iteration 6564 : loss : 0.074754, loss_ce: 0.010620
iteration 6565 : loss : 0.032233, loss_ce: 0.010987
iteration 6566 : loss : 0.077351, loss_ce: 0.005399
iteration 6567 : loss : 0.076507, loss_ce: 0.008845
iteration 6568 : loss : 0.027058, loss_ce: 0.009046
iteration 6569 : loss : 0.033355, loss_ce: 0.014217
iteration 6570 : loss : 0.026613, loss_ce: 0.008867
iteration 6571 : loss : 0.030964, loss_ce: 0.014111
iteration 6572 : loss : 0.048434, loss_ce: 0.010968
pred_sum 3696
gtsum tensor(3223, device='cuda:0')
iteration 6573 : loss : 0.026143, loss_ce: 0.011040
iteration 6574 : loss : 0.031296, loss_ce: 0.013775
iteration 6575 : loss : 0.037053, loss_ce: 0.019002
iteration 6576 : loss : 0.027368, loss_ce: 0.008380
iteration 6577 : loss : 0.029674, loss_ce: 0.007565
iteration 6578 : loss : 0.031739, loss_ce: 0.008093
iteration 6579 : loss : 0.031537, loss_ce: 0.018565
iteration 6580 : loss : 0.051193, loss_ce: 0.006510
iteration 6581 : loss : 0.029820, loss_ce: 0.011570
iteration 6582 : loss : 0.025999, loss_ce: 0.009994
iteration 6583 : loss : 0.080615, loss_ce: 0.009941
iteration 6584 : loss : 0.083479, loss_ce: 0.006521
iteration 6585 : loss : 0.029955, loss_ce: 0.008402
iteration 6586 : loss : 0.029714, loss_ce: 0.007765
iteration 6587 : loss : 0.040178, loss_ce: 0.014887
iteration 6588 : loss : 0.037971, loss_ce: 0.011342
iteration 6589 : loss : 0.034648, loss_ce: 0.011971
iteration 6590 : loss : 0.028663, loss_ce: 0.009735
iteration 6591 : loss : 0.036024, loss_ce: 0.004440
iteration 6592 : loss : 0.030870, loss_ce: 0.007503
iteration 6593 : loss : 0.043638, loss_ce: 0.011026
iteration 6594 : loss : 0.033397, loss_ce: 0.009204
iteration 6595 : loss : 0.039904, loss_ce: 0.014900
iteration 6596 : loss : 0.030279, loss_ce: 0.008562
iteration 6597 : loss : 0.042226, loss_ce: 0.013923
iteration 6598 : loss : 0.047648, loss_ce: 0.009164
iteration 6599 : loss : 0.045831, loss_ce: 0.010152
iteration 6600 : loss : 0.030574, loss_ce: 0.009055
iteration 6601 : loss : 0.024385, loss_ce: 0.008527
iteration 6602 : loss : 0.036979, loss_ce: 0.012991
iteration 6603 : loss : 0.443153, loss_ce: 0.000643
 36%|█████████▉                  | 71/200 [1:04:25<1:57:17, 54.56s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 6604 : loss : 0.030561, loss_ce: 0.010181
iteration 6605 : loss : 0.031084, loss_ce: 0.010277
iteration 6606 : loss : 0.031405, loss_ce: 0.008574
iteration 6607 : loss : 0.028591, loss_ce: 0.010043
iteration 6608 : loss : 0.033818, loss_ce: 0.011858
iteration 6609 : loss : 0.032734, loss_ce: 0.014654
iteration 6610 : loss : 0.039068, loss_ce: 0.017537
iteration 6611 : loss : 0.044118, loss_ce: 0.006866
iteration 6612 : loss : 0.025516, loss_ce: 0.006216
iteration 6613 : loss : 0.080566, loss_ce: 0.008483
iteration 6614 : loss : 0.033905, loss_ce: 0.010210
iteration 6615 : loss : 0.034069, loss_ce: 0.010834
iteration 6616 : loss : 0.035046, loss_ce: 0.009974
iteration 6617 : loss : 0.026937, loss_ce: 0.009909
iteration 6618 : loss : 0.046017, loss_ce: 0.008372
iteration 6619 : loss : 0.032538, loss_ce: 0.014950
iteration 6620 : loss : 0.033253, loss_ce: 0.015990
iteration 6621 : loss : 0.031766, loss_ce: 0.012400
iteration 6622 : loss : 0.030470, loss_ce: 0.016368
iteration 6623 : loss : 0.034539, loss_ce: 0.005912
iteration 6624 : loss : 0.081376, loss_ce: 0.006655
iteration 6625 : loss : 0.028404, loss_ce: 0.010852
iteration 6626 : loss : 0.034702, loss_ce: 0.012275
iteration 6627 : loss : 0.033078, loss_ce: 0.008867
iteration 6628 : loss : 0.025637, loss_ce: 0.007112
iteration 6629 : loss : 0.034533, loss_ce: 0.009806
iteration 6630 : loss : 0.038215, loss_ce: 0.013790
iteration 6631 : loss : 0.028588, loss_ce: 0.007825
iteration 6632 : loss : 0.049020, loss_ce: 0.010552
iteration 6633 : loss : 0.026387, loss_ce: 0.009450
iteration 6634 : loss : 0.040165, loss_ce: 0.006863
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 6635 : loss : 0.030935, loss_ce: 0.010032
iteration 6636 : loss : 0.029478, loss_ce: 0.009301
iteration 6637 : loss : 0.028264, loss_ce: 0.007346
iteration 6638 : loss : 0.032064, loss_ce: 0.011658
iteration 6639 : loss : 0.043230, loss_ce: 0.009700
iteration 6640 : loss : 0.028923, loss_ce: 0.008097
iteration 6641 : loss : 0.029713, loss_ce: 0.012309
iteration 6642 : loss : 0.033462, loss_ce: 0.012413
iteration 6643 : loss : 0.036974, loss_ce: 0.014992
iteration 6644 : loss : 0.039472, loss_ce: 0.010335
iteration 6645 : loss : 0.024921, loss_ce: 0.007863
iteration 6646 : loss : 0.032967, loss_ce: 0.010074
iteration 6647 : loss : 0.027573, loss_ce: 0.007526
iteration 6648 : loss : 0.029722, loss_ce: 0.011981
iteration 6649 : loss : 0.030889, loss_ce: 0.012452
iteration 6650 : loss : 0.043063, loss_ce: 0.009277
iteration 6651 : loss : 0.051812, loss_ce: 0.013130
iteration 6652 : loss : 0.029215, loss_ce: 0.005547
iteration 6653 : loss : 0.026068, loss_ce: 0.007961
iteration 6654 : loss : 0.029435, loss_ce: 0.012377
iteration 6655 : loss : 0.031163, loss_ce: 0.006993
iteration 6656 : loss : 0.026157, loss_ce: 0.009863
iteration 6657 : loss : 0.029140, loss_ce: 0.005378
iteration 6658 : loss : 0.032111, loss_ce: 0.013943
iteration 6659 : loss : 0.028720, loss_ce: 0.006335
iteration 6660 : loss : 0.027863, loss_ce: 0.009758
iteration 6661 : loss : 0.031519, loss_ce: 0.009137
iteration 6662 : loss : 0.053509, loss_ce: 0.010664
iteration 6663 : loss : 0.083308, loss_ce: 0.007639
iteration 6664 : loss : 0.032750, loss_ce: 0.009320
iteration 6665 : loss : 0.029575, loss_ce: 0.012712
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 6666 : loss : 0.033966, loss_ce: 0.010194
iteration 6667 : loss : 0.030860, loss_ce: 0.013425
iteration 6668 : loss : 0.027067, loss_ce: 0.010918
iteration 6669 : loss : 0.031465, loss_ce: 0.010842
iteration 6670 : loss : 0.033422, loss_ce: 0.018371
iteration 6671 : loss : 0.036802, loss_ce: 0.011627
iteration 6672 : loss : 0.079421, loss_ce: 0.011334
iteration 6673 : loss : 0.082110, loss_ce: 0.010357
iteration 6674 : loss : 0.028835, loss_ce: 0.008020
iteration 6675 : loss : 0.025232, loss_ce: 0.009211
iteration 6676 : loss : 0.028560, loss_ce: 0.007733
iteration 6677 : loss : 0.030094, loss_ce: 0.014398
iteration 6678 : loss : 0.029283, loss_ce: 0.008314
iteration 6679 : loss : 0.039005, loss_ce: 0.004909
iteration 6680 : loss : 0.029780, loss_ce: 0.013514
iteration 6681 : loss : 0.035869, loss_ce: 0.011248
iteration 6682 : loss : 0.037602, loss_ce: 0.012631
iteration 6683 : loss : 0.034384, loss_ce: 0.005635
iteration 6684 : loss : 0.031954, loss_ce: 0.013188
iteration 6685 : loss : 0.040744, loss_ce: 0.006836
iteration 6686 : loss : 0.034996, loss_ce: 0.011705
iteration 6687 : loss : 0.036468, loss_ce: 0.009522
iteration 6688 : loss : 0.081506, loss_ce: 0.006805
iteration 6689 : loss : 0.031112, loss_ce: 0.011290
iteration 6690 : loss : 0.083110, loss_ce: 0.010181
iteration 6691 : loss : 0.028942, loss_ce: 0.013738
iteration 6692 : loss : 0.025624, loss_ce: 0.006665
iteration 6693 : loss : 0.079020, loss_ce: 0.008414
iteration 6694 : loss : 0.025920, loss_ce: 0.009099
iteration 6695 : loss : 0.031870, loss_ce: 0.007383
iteration 6696 : loss : 0.227410, loss_ce: 0.014618
 36%|██████████                  | 72/200 [1:05:19<1:56:19, 54.53s/it]pred_sum 826
gtsum tensor(753, device='cuda:0')
iteration 6697 : loss : 0.032510, loss_ce: 0.012614
iteration 6698 : loss : 0.032071, loss_ce: 0.009737
iteration 6699 : loss : 0.041300, loss_ce: 0.015366
iteration 6700 : loss : 0.036679, loss_ce: 0.007155
iteration 6701 : loss : 0.028876, loss_ce: 0.013868
iteration 6702 : loss : 0.039554, loss_ce: 0.009832
iteration 6703 : loss : 0.035995, loss_ce: 0.014753
iteration 6704 : loss : 0.027511, loss_ce: 0.009807
iteration 6705 : loss : 0.035687, loss_ce: 0.006697
iteration 6706 : loss : 0.038228, loss_ce: 0.010897
iteration 6707 : loss : 0.109483, loss_ce: 0.002996
iteration 6708 : loss : 0.035300, loss_ce: 0.005467
iteration 6709 : loss : 0.031379, loss_ce: 0.010677
iteration 6710 : loss : 0.051341, loss_ce: 0.024019
iteration 6711 : loss : 0.042294, loss_ce: 0.021625
iteration 6712 : loss : 0.047758, loss_ce: 0.019650
iteration 6713 : loss : 0.046073, loss_ce: 0.012792
iteration 6714 : loss : 0.043005, loss_ce: 0.018504
iteration 6715 : loss : 0.033584, loss_ce: 0.017752
iteration 6716 : loss : 0.038409, loss_ce: 0.022301
iteration 6717 : loss : 0.037644, loss_ce: 0.009606
iteration 6718 : loss : 0.031990, loss_ce: 0.011658
iteration 6719 : loss : 0.041989, loss_ce: 0.015459
iteration 6720 : loss : 0.047583, loss_ce: 0.016430
iteration 6721 : loss : 0.039624, loss_ce: 0.009292
iteration 6722 : loss : 0.036999, loss_ce: 0.011232
iteration 6723 : loss : 0.031609, loss_ce: 0.016063
iteration 6724 : loss : 0.053305, loss_ce: 0.009181
iteration 6725 : loss : 0.036991, loss_ce: 0.012951
iteration 6726 : loss : 0.041767, loss_ce: 0.022068
iteration 6727 : loss : 0.031677, loss_ce: 0.012027
pred_sum 517
gtsum tensor(497, device='cuda:0')
iteration 6728 : loss : 0.033524, loss_ce: 0.013982
iteration 6729 : loss : 0.033969, loss_ce: 0.012678
iteration 6730 : loss : 0.029180, loss_ce: 0.009043
iteration 6731 : loss : 0.043172, loss_ce: 0.016898
iteration 6732 : loss : 0.030995, loss_ce: 0.012233
iteration 6733 : loss : 0.038185, loss_ce: 0.009370
iteration 6734 : loss : 0.080543, loss_ce: 0.012697
iteration 6735 : loss : 0.032753, loss_ce: 0.007226
iteration 6736 : loss : 0.038503, loss_ce: 0.013882
iteration 6737 : loss : 0.034643, loss_ce: 0.010506
iteration 6738 : loss : 0.029403, loss_ce: 0.013967
iteration 6739 : loss : 0.038542, loss_ce: 0.009458
iteration 6740 : loss : 0.035781, loss_ce: 0.007137
iteration 6741 : loss : 0.036200, loss_ce: 0.014268
iteration 6742 : loss : 0.032540, loss_ce: 0.014653
iteration 6743 : loss : 0.027378, loss_ce: 0.008962
iteration 6744 : loss : 0.034218, loss_ce: 0.012092
iteration 6745 : loss : 0.033205, loss_ce: 0.015762
iteration 6746 : loss : 0.028110, loss_ce: 0.010073
iteration 6747 : loss : 0.075251, loss_ce: 0.006406
iteration 6748 : loss : 0.024004, loss_ce: 0.006832
iteration 6749 : loss : 0.033882, loss_ce: 0.013911
iteration 6750 : loss : 0.029443, loss_ce: 0.011798
iteration 6751 : loss : 0.033663, loss_ce: 0.006807
iteration 6752 : loss : 0.031132, loss_ce: 0.009801
iteration 6753 : loss : 0.037310, loss_ce: 0.006838
iteration 6754 : loss : 0.085788, loss_ce: 0.010300
iteration 6755 : loss : 0.027777, loss_ce: 0.008698
iteration 6756 : loss : 0.032952, loss_ce: 0.013344
iteration 6757 : loss : 0.028447, loss_ce: 0.010528
iteration 6758 : loss : 0.027312, loss_ce: 0.007744
pred_sum 5901
gtsum tensor(5839, device='cuda:0')
iteration 6759 : loss : 0.024281, loss_ce: 0.005789
iteration 6760 : loss : 0.024779, loss_ce: 0.010787
iteration 6761 : loss : 0.027457, loss_ce: 0.013653
iteration 6762 : loss : 0.029290, loss_ce: 0.012260
iteration 6763 : loss : 0.030039, loss_ce: 0.008741
iteration 6764 : loss : 0.042247, loss_ce: 0.013685
iteration 6765 : loss : 0.025225, loss_ce: 0.010628
iteration 6766 : loss : 0.032199, loss_ce: 0.006408
iteration 6767 : loss : 0.036998, loss_ce: 0.010653
iteration 6768 : loss : 0.033062, loss_ce: 0.009134
iteration 6769 : loss : 0.084755, loss_ce: 0.010564
iteration 6770 : loss : 0.033740, loss_ce: 0.011164
iteration 6771 : loss : 0.025253, loss_ce: 0.007616
iteration 6772 : loss : 0.033448, loss_ce: 0.015648
iteration 6773 : loss : 0.025413, loss_ce: 0.009723
iteration 6774 : loss : 0.035063, loss_ce: 0.009341
iteration 6775 : loss : 0.059148, loss_ce: 0.007526
iteration 6776 : loss : 0.027267, loss_ce: 0.008595
iteration 6777 : loss : 0.029676, loss_ce: 0.010584
iteration 6778 : loss : 0.035520, loss_ce: 0.010782
iteration 6779 : loss : 0.029619, loss_ce: 0.010764
iteration 6780 : loss : 0.028991, loss_ce: 0.008700
iteration 6781 : loss : 0.031779, loss_ce: 0.010030
iteration 6782 : loss : 0.030715, loss_ce: 0.008751
iteration 6783 : loss : 0.076978, loss_ce: 0.005997
iteration 6784 : loss : 0.027764, loss_ce: 0.009397
iteration 6785 : loss : 0.027614, loss_ce: 0.009991
iteration 6786 : loss : 0.032174, loss_ce: 0.015494
iteration 6787 : loss : 0.031881, loss_ce: 0.010805
iteration 6788 : loss : 0.034490, loss_ce: 0.010880
iteration 6789 : loss : 0.241458, loss_ce: 0.023286
 36%|██████████▏                 | 73/200 [1:06:14<1:55:26, 54.54s/it]pred_sum 44875
gtsum tensor(44696, device='cuda:0')
iteration 6790 : loss : 0.027211, loss_ce: 0.009803
iteration 6791 : loss : 0.026996, loss_ce: 0.010539
iteration 6792 : loss : 0.037082, loss_ce: 0.012315
iteration 6793 : loss : 0.027724, loss_ce: 0.006642
iteration 6794 : loss : 0.025290, loss_ce: 0.005299
iteration 6795 : loss : 0.033577, loss_ce: 0.010160
iteration 6796 : loss : 0.034355, loss_ce: 0.014312
iteration 6797 : loss : 0.024190, loss_ce: 0.006908
iteration 6798 : loss : 0.034466, loss_ce: 0.009837
iteration 6799 : loss : 0.026241, loss_ce: 0.007629
iteration 6800 : loss : 0.033335, loss_ce: 0.012641
iteration 6801 : loss : 0.038584, loss_ce: 0.012273
iteration 6802 : loss : 0.028889, loss_ce: 0.012592
iteration 6803 : loss : 0.029929, loss_ce: 0.010640
iteration 6804 : loss : 0.027282, loss_ce: 0.006926
iteration 6805 : loss : 0.036711, loss_ce: 0.011306
iteration 6806 : loss : 0.028456, loss_ce: 0.011083
iteration 6807 : loss : 0.030790, loss_ce: 0.010915
iteration 6808 : loss : 0.026059, loss_ce: 0.008324
iteration 6809 : loss : 0.035068, loss_ce: 0.008669
iteration 6810 : loss : 0.028276, loss_ce: 0.010839
iteration 6811 : loss : 0.023621, loss_ce: 0.009958
iteration 6812 : loss : 0.024935, loss_ce: 0.008803
iteration 6813 : loss : 0.030666, loss_ce: 0.013393
iteration 6814 : loss : 0.029848, loss_ce: 0.006127
iteration 6815 : loss : 0.033529, loss_ce: 0.009881
iteration 6816 : loss : 0.031674, loss_ce: 0.009048
iteration 6817 : loss : 0.037834, loss_ce: 0.008224
iteration 6818 : loss : 0.030024, loss_ce: 0.013218
iteration 6819 : loss : 0.025639, loss_ce: 0.007669
iteration 6820 : loss : 0.035250, loss_ce: 0.010093
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 6821 : loss : 0.032175, loss_ce: 0.006278
iteration 6822 : loss : 0.025472, loss_ce: 0.010024
iteration 6823 : loss : 0.035100, loss_ce: 0.011675
iteration 6824 : loss : 0.080405, loss_ce: 0.007341
iteration 6825 : loss : 0.027545, loss_ce: 0.013724
iteration 6826 : loss : 0.032365, loss_ce: 0.011493
iteration 6827 : loss : 0.030127, loss_ce: 0.009126
iteration 6828 : loss : 0.032342, loss_ce: 0.008276
iteration 6829 : loss : 0.029003, loss_ce: 0.008544
iteration 6830 : loss : 0.025763, loss_ce: 0.007584
iteration 6831 : loss : 0.025908, loss_ce: 0.009826
iteration 6832 : loss : 0.030626, loss_ce: 0.015075
iteration 6833 : loss : 0.027777, loss_ce: 0.008293
iteration 6834 : loss : 0.029129, loss_ce: 0.009500
iteration 6835 : loss : 0.029606, loss_ce: 0.008492
iteration 6836 : loss : 0.034100, loss_ce: 0.005899
iteration 6837 : loss : 0.023475, loss_ce: 0.007405
iteration 6838 : loss : 0.034432, loss_ce: 0.010554
iteration 6839 : loss : 0.079916, loss_ce: 0.014234
iteration 6840 : loss : 0.028939, loss_ce: 0.012738
iteration 6841 : loss : 0.027447, loss_ce: 0.008638
iteration 6842 : loss : 0.027623, loss_ce: 0.009826
iteration 6843 : loss : 0.028038, loss_ce: 0.010517
iteration 6844 : loss : 0.028270, loss_ce: 0.008669
iteration 6845 : loss : 0.086926, loss_ce: 0.006342
iteration 6846 : loss : 0.032912, loss_ce: 0.016949
iteration 6847 : loss : 0.028309, loss_ce: 0.010148
iteration 6848 : loss : 0.038906, loss_ce: 0.010963
iteration 6849 : loss : 0.034830, loss_ce: 0.006292
iteration 6850 : loss : 0.028164, loss_ce: 0.009448
iteration 6851 : loss : 0.031839, loss_ce: 0.013187
pred_sum 414
gtsum tensor(439, device='cuda:0')
iteration 6852 : loss : 0.037454, loss_ce: 0.015196
iteration 6853 : loss : 0.033689, loss_ce: 0.013713
iteration 6854 : loss : 0.027632, loss_ce: 0.011511
iteration 6855 : loss : 0.024078, loss_ce: 0.006069
iteration 6856 : loss : 0.031860, loss_ce: 0.010035
iteration 6857 : loss : 0.025063, loss_ce: 0.010396
iteration 6858 : loss : 0.030169, loss_ce: 0.008044
iteration 6859 : loss : 0.028911, loss_ce: 0.010261
iteration 6860 : loss : 0.029204, loss_ce: 0.009642
iteration 6861 : loss : 0.034412, loss_ce: 0.016453
iteration 6862 : loss : 0.027029, loss_ce: 0.010215
iteration 6863 : loss : 0.028166, loss_ce: 0.012525
iteration 6864 : loss : 0.076586, loss_ce: 0.007032
iteration 6865 : loss : 0.026961, loss_ce: 0.007994
iteration 6866 : loss : 0.036176, loss_ce: 0.008258
iteration 6867 : loss : 0.029054, loss_ce: 0.009963
iteration 6868 : loss : 0.034308, loss_ce: 0.016326
iteration 6869 : loss : 0.050235, loss_ce: 0.015210
iteration 6870 : loss : 0.032686, loss_ce: 0.013731
iteration 6871 : loss : 0.030836, loss_ce: 0.007630
iteration 6872 : loss : 0.025600, loss_ce: 0.007840
iteration 6873 : loss : 0.031016, loss_ce: 0.009149
iteration 6874 : loss : 0.030356, loss_ce: 0.009928
iteration 6875 : loss : 0.024349, loss_ce: 0.007123
iteration 6876 : loss : 0.031938, loss_ce: 0.008691
iteration 6877 : loss : 0.036801, loss_ce: 0.008696
iteration 6878 : loss : 0.030172, loss_ce: 0.008930
iteration 6879 : loss : 0.029171, loss_ce: 0.007463
iteration 6880 : loss : 0.027817, loss_ce: 0.009076
iteration 6881 : loss : 0.034713, loss_ce: 0.007824
iteration 6882 : loss : 0.138910, loss_ce: 0.017511
 37%|██████████▎                 | 74/200 [1:07:09<1:54:31, 54.53s/it]pred_sum 5083
gtsum tensor(5398, device='cuda:0')
iteration 6883 : loss : 0.027415, loss_ce: 0.011270
iteration 6884 : loss : 0.029655, loss_ce: 0.014012
iteration 6885 : loss : 0.073409, loss_ce: 0.008981
iteration 6886 : loss : 0.029500, loss_ce: 0.011062
iteration 6887 : loss : 0.029771, loss_ce: 0.012827
iteration 6888 : loss : 0.036199, loss_ce: 0.012229
iteration 6889 : loss : 0.027393, loss_ce: 0.007037
iteration 6890 : loss : 0.029974, loss_ce: 0.011003
iteration 6891 : loss : 0.033595, loss_ce: 0.009791
iteration 6892 : loss : 0.022433, loss_ce: 0.007965
iteration 6893 : loss : 0.030042, loss_ce: 0.011014
iteration 6894 : loss : 0.025322, loss_ce: 0.010367
iteration 6895 : loss : 0.023936, loss_ce: 0.006382
iteration 6896 : loss : 0.128981, loss_ce: 0.007459
iteration 6897 : loss : 0.034995, loss_ce: 0.018964
iteration 6898 : loss : 0.031292, loss_ce: 0.008151
iteration 6899 : loss : 0.029423, loss_ce: 0.005545
iteration 6900 : loss : 0.042932, loss_ce: 0.008568
iteration 6901 : loss : 0.032429, loss_ce: 0.008364
iteration 6902 : loss : 0.023959, loss_ce: 0.007455
iteration 6903 : loss : 0.042925, loss_ce: 0.008010
iteration 6904 : loss : 0.034315, loss_ce: 0.006192
iteration 6905 : loss : 0.029172, loss_ce: 0.008223
iteration 6906 : loss : 0.028613, loss_ce: 0.011829
iteration 6907 : loss : 0.033155, loss_ce: 0.013832
iteration 6908 : loss : 0.027511, loss_ce: 0.012355
iteration 6909 : loss : 0.033147, loss_ce: 0.014994
iteration 6910 : loss : 0.040150, loss_ce: 0.009629
iteration 6911 : loss : 0.034328, loss_ce: 0.007959
iteration 6912 : loss : 0.024928, loss_ce: 0.008795
iteration 6913 : loss : 0.028672, loss_ce: 0.008521
pred_sum 35086
gtsum tensor(33084, device='cuda:0')
iteration 6914 : loss : 0.044118, loss_ce: 0.013212
iteration 6915 : loss : 0.027313, loss_ce: 0.010262
iteration 6916 : loss : 0.030935, loss_ce: 0.010807
iteration 6917 : loss : 0.029084, loss_ce: 0.009504
iteration 6918 : loss : 0.037353, loss_ce: 0.008345
iteration 6919 : loss : 0.080763, loss_ce: 0.007621
iteration 6920 : loss : 0.030488, loss_ce: 0.007704
iteration 6921 : loss : 0.029989, loss_ce: 0.008188
iteration 6922 : loss : 0.077411, loss_ce: 0.011595
iteration 6923 : loss : 0.030332, loss_ce: 0.010926
iteration 6924 : loss : 0.033263, loss_ce: 0.010296
iteration 6925 : loss : 0.081692, loss_ce: 0.012043
iteration 6926 : loss : 0.031266, loss_ce: 0.011915
iteration 6927 : loss : 0.027988, loss_ce: 0.010475
iteration 6928 : loss : 0.031332, loss_ce: 0.010498
iteration 6929 : loss : 0.027535, loss_ce: 0.008091
iteration 6930 : loss : 0.029415, loss_ce: 0.010987
iteration 6931 : loss : 0.024570, loss_ce: 0.010047
iteration 6932 : loss : 0.028524, loss_ce: 0.012127
iteration 6933 : loss : 0.029174, loss_ce: 0.012870
iteration 6934 : loss : 0.029367, loss_ce: 0.010972
iteration 6935 : loss : 0.028627, loss_ce: 0.011167
iteration 6936 : loss : 0.025264, loss_ce: 0.008459
iteration 6937 : loss : 0.026610, loss_ce: 0.008439
iteration 6938 : loss : 0.136520, loss_ce: 0.005674
iteration 6939 : loss : 0.032531, loss_ce: 0.009433
iteration 6940 : loss : 0.030773, loss_ce: 0.008757
iteration 6941 : loss : 0.031534, loss_ce: 0.012404
iteration 6942 : loss : 0.026681, loss_ce: 0.010831
iteration 6943 : loss : 0.040955, loss_ce: 0.007880
iteration 6944 : loss : 0.027357, loss_ce: 0.008120
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 6945 : loss : 0.026960, loss_ce: 0.006697
iteration 6946 : loss : 0.037667, loss_ce: 0.009710
iteration 6947 : loss : 0.026784, loss_ce: 0.007537
iteration 6948 : loss : 0.027168, loss_ce: 0.007158
iteration 6949 : loss : 0.027774, loss_ce: 0.009937
iteration 6950 : loss : 0.033808, loss_ce: 0.011194
iteration 6951 : loss : 0.079881, loss_ce: 0.010410
iteration 6952 : loss : 0.032492, loss_ce: 0.012622
iteration 6953 : loss : 0.029399, loss_ce: 0.012110
iteration 6954 : loss : 0.031596, loss_ce: 0.006791
iteration 6955 : loss : 0.032373, loss_ce: 0.013295
iteration 6956 : loss : 0.037329, loss_ce: 0.008416
iteration 6957 : loss : 0.026789, loss_ce: 0.006830
iteration 6958 : loss : 0.033817, loss_ce: 0.007941
iteration 6959 : loss : 0.025896, loss_ce: 0.008496
iteration 6960 : loss : 0.033047, loss_ce: 0.016517
iteration 6961 : loss : 0.029571, loss_ce: 0.013821
iteration 6962 : loss : 0.028486, loss_ce: 0.010065
iteration 6963 : loss : 0.128145, loss_ce: 0.004722
iteration 6964 : loss : 0.077953, loss_ce: 0.008474
iteration 6965 : loss : 0.032541, loss_ce: 0.010754
iteration 6966 : loss : 0.035496, loss_ce: 0.018129
iteration 6967 : loss : 0.026206, loss_ce: 0.011514
iteration 6968 : loss : 0.027479, loss_ce: 0.010208
iteration 6969 : loss : 0.034594, loss_ce: 0.005660
iteration 6970 : loss : 0.025376, loss_ce: 0.006639
iteration 6971 : loss : 0.024204, loss_ce: 0.008879
iteration 6972 : loss : 0.031932, loss_ce: 0.014265
iteration 6973 : loss : 0.025546, loss_ce: 0.007759
iteration 6974 : loss : 0.083621, loss_ce: 0.007675
iteration 6975 : loss : 0.091879, loss_ce: 0.016230
 38%|██████████▌                 | 75/200 [1:08:03<1:53:36, 54.53s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 6976 : loss : 0.028934, loss_ce: 0.009682
iteration 6977 : loss : 0.026232, loss_ce: 0.009378
iteration 6978 : loss : 0.036730, loss_ce: 0.013345
iteration 6979 : loss : 0.028091, loss_ce: 0.009226
iteration 6980 : loss : 0.028646, loss_ce: 0.010957
iteration 6981 : loss : 0.030888, loss_ce: 0.007002
iteration 6982 : loss : 0.031310, loss_ce: 0.015072
iteration 6983 : loss : 0.031674, loss_ce: 0.010716
iteration 6984 : loss : 0.034112, loss_ce: 0.010523
iteration 6985 : loss : 0.029555, loss_ce: 0.013285
iteration 6986 : loss : 0.033035, loss_ce: 0.013080
iteration 6987 : loss : 0.027489, loss_ce: 0.008041
iteration 6988 : loss : 0.039135, loss_ce: 0.013883
iteration 6989 : loss : 0.026189, loss_ce: 0.007455
iteration 6990 : loss : 0.026828, loss_ce: 0.011554
iteration 6991 : loss : 0.027938, loss_ce: 0.010099
iteration 6992 : loss : 0.040511, loss_ce: 0.008757
iteration 6993 : loss : 0.031236, loss_ce: 0.011512
iteration 6994 : loss : 0.054944, loss_ce: 0.005525
iteration 6995 : loss : 0.028355, loss_ce: 0.013012
iteration 6996 : loss : 0.026046, loss_ce: 0.010298
iteration 6997 : loss : 0.022697, loss_ce: 0.008116
iteration 6998 : loss : 0.038668, loss_ce: 0.016700
iteration 6999 : loss : 0.028132, loss_ce: 0.009563
iteration 7000 : loss : 0.050435, loss_ce: 0.010456
iteration 7001 : loss : 0.037420, loss_ce: 0.008983
iteration 7002 : loss : 0.053242, loss_ce: 0.011430
iteration 7003 : loss : 0.079040, loss_ce: 0.011776
iteration 7004 : loss : 0.033737, loss_ce: 0.008326
iteration 7005 : loss : 0.038396, loss_ce: 0.014345
iteration 7006 : loss : 0.085724, loss_ce: 0.009169
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 7007 : loss : 0.038632, loss_ce: 0.010736
iteration 7008 : loss : 0.031324, loss_ce: 0.013720
iteration 7009 : loss : 0.037477, loss_ce: 0.015299
iteration 7010 : loss : 0.026348, loss_ce: 0.013978
iteration 7011 : loss : 0.028846, loss_ce: 0.008926
iteration 7012 : loss : 0.024635, loss_ce: 0.006675
iteration 7013 : loss : 0.039504, loss_ce: 0.011370
iteration 7014 : loss : 0.030526, loss_ce: 0.013010
iteration 7015 : loss : 0.031125, loss_ce: 0.010177
iteration 7016 : loss : 0.034599, loss_ce: 0.008833
iteration 7017 : loss : 0.031133, loss_ce: 0.015276
iteration 7018 : loss : 0.027189, loss_ce: 0.009507
iteration 7019 : loss : 0.031379, loss_ce: 0.007982
iteration 7020 : loss : 0.082529, loss_ce: 0.012633
iteration 7021 : loss : 0.038463, loss_ce: 0.014938
iteration 7022 : loss : 0.025460, loss_ce: 0.009080
iteration 7023 : loss : 0.030579, loss_ce: 0.006980
iteration 7024 : loss : 0.036547, loss_ce: 0.016900
iteration 7025 : loss : 0.028927, loss_ce: 0.008594
iteration 7026 : loss : 0.034796, loss_ce: 0.007962
iteration 7027 : loss : 0.035039, loss_ce: 0.018547
iteration 7028 : loss : 0.029557, loss_ce: 0.008732
iteration 7029 : loss : 0.045754, loss_ce: 0.013908
iteration 7030 : loss : 0.028884, loss_ce: 0.011581
iteration 7031 : loss : 0.048668, loss_ce: 0.011794
iteration 7032 : loss : 0.032943, loss_ce: 0.011588
iteration 7033 : loss : 0.031118, loss_ce: 0.008473
iteration 7034 : loss : 0.035741, loss_ce: 0.013759
iteration 7035 : loss : 0.030562, loss_ce: 0.008399
iteration 7036 : loss : 0.024517, loss_ce: 0.007320
iteration 7037 : loss : 0.082244, loss_ce: 0.008255
pred_sum 8955
gtsum tensor(9213, device='cuda:0')
iteration 7038 : loss : 0.038131, loss_ce: 0.008854
iteration 7039 : loss : 0.038105, loss_ce: 0.006668
iteration 7040 : loss : 0.034568, loss_ce: 0.011183
iteration 7041 : loss : 0.076510, loss_ce: 0.007129
iteration 7042 : loss : 0.035942, loss_ce: 0.007062
iteration 7043 : loss : 0.031437, loss_ce: 0.011232
iteration 7044 : loss : 0.028016, loss_ce: 0.008860
iteration 7045 : loss : 0.031044, loss_ce: 0.015250
iteration 7046 : loss : 0.034322, loss_ce: 0.009624
iteration 7047 : loss : 0.030433, loss_ce: 0.011480
iteration 7048 : loss : 0.037916, loss_ce: 0.010823
iteration 7049 : loss : 0.029892, loss_ce: 0.009981
iteration 7050 : loss : 0.033397, loss_ce: 0.004488
iteration 7051 : loss : 0.035079, loss_ce: 0.009343
iteration 7052 : loss : 0.030820, loss_ce: 0.013468
iteration 7053 : loss : 0.075040, loss_ce: 0.006209
iteration 7054 : loss : 0.032498, loss_ce: 0.010115
iteration 7055 : loss : 0.026784, loss_ce: 0.009998
iteration 7056 : loss : 0.066092, loss_ce: 0.011204
iteration 7057 : loss : 0.030754, loss_ce: 0.014151
iteration 7058 : loss : 0.033164, loss_ce: 0.009452
iteration 7059 : loss : 0.039417, loss_ce: 0.011215
iteration 7060 : loss : 0.037194, loss_ce: 0.007992
iteration 7061 : loss : 0.034331, loss_ce: 0.012986
iteration 7062 : loss : 0.029369, loss_ce: 0.006696
iteration 7063 : loss : 0.028415, loss_ce: 0.007405
iteration 7064 : loss : 0.030000, loss_ce: 0.011915
iteration 7065 : loss : 0.034526, loss_ce: 0.008944
iteration 7066 : loss : 0.026712, loss_ce: 0.007730
iteration 7067 : loss : 0.043343, loss_ce: 0.008513
iteration 7068 : loss : 0.332936, loss_ce: 0.003486
 38%|██████████▋                 | 76/200 [1:08:58<1:52:41, 54.53s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 7069 : loss : 0.027564, loss_ce: 0.010438
iteration 7070 : loss : 0.024623, loss_ce: 0.009441
iteration 7071 : loss : 0.033904, loss_ce: 0.007752
iteration 7072 : loss : 0.027734, loss_ce: 0.007920
iteration 7073 : loss : 0.034823, loss_ce: 0.009664
iteration 7074 : loss : 0.026147, loss_ce: 0.009559
iteration 7075 : loss : 0.037030, loss_ce: 0.012267
iteration 7076 : loss : 0.037725, loss_ce: 0.008600
iteration 7077 : loss : 0.031719, loss_ce: 0.012528
iteration 7078 : loss : 0.033037, loss_ce: 0.008546
iteration 7079 : loss : 0.041837, loss_ce: 0.015831
iteration 7080 : loss : 0.083951, loss_ce: 0.009280
iteration 7081 : loss : 0.031469, loss_ce: 0.008568
iteration 7082 : loss : 0.032105, loss_ce: 0.012186
iteration 7083 : loss : 0.031380, loss_ce: 0.009877
iteration 7084 : loss : 0.036671, loss_ce: 0.007609
iteration 7085 : loss : 0.039879, loss_ce: 0.013604
iteration 7086 : loss : 0.030969, loss_ce: 0.008847
iteration 7087 : loss : 0.027922, loss_ce: 0.008834
iteration 7088 : loss : 0.031638, loss_ce: 0.012329
iteration 7089 : loss : 0.031096, loss_ce: 0.015976
iteration 7090 : loss : 0.024913, loss_ce: 0.006130
iteration 7091 : loss : 0.050363, loss_ce: 0.012845
iteration 7092 : loss : 0.033832, loss_ce: 0.007328
iteration 7093 : loss : 0.031816, loss_ce: 0.009489
iteration 7094 : loss : 0.085653, loss_ce: 0.012825
iteration 7095 : loss : 0.037331, loss_ce: 0.006861
iteration 7096 : loss : 0.070082, loss_ce: 0.007032
iteration 7097 : loss : 0.029857, loss_ce: 0.010117
iteration 7098 : loss : 0.084198, loss_ce: 0.008676
iteration 7099 : loss : 0.036701, loss_ce: 0.005434
pred_sum 104
gtsum tensor(99, device='cuda:0')
iteration 7100 : loss : 0.038245, loss_ce: 0.011903
iteration 7101 : loss : 0.031830, loss_ce: 0.015733
iteration 7102 : loss : 0.035042, loss_ce: 0.008564
iteration 7103 : loss : 0.032649, loss_ce: 0.010070
iteration 7104 : loss : 0.034270, loss_ce: 0.014855
iteration 7105 : loss : 0.038355, loss_ce: 0.008640
iteration 7106 : loss : 0.023920, loss_ce: 0.007431
iteration 7107 : loss : 0.023593, loss_ce: 0.006475
iteration 7108 : loss : 0.031619, loss_ce: 0.012933
iteration 7109 : loss : 0.030570, loss_ce: 0.008375
iteration 7110 : loss : 0.031039, loss_ce: 0.010099
iteration 7111 : loss : 0.039510, loss_ce: 0.006398
iteration 7112 : loss : 0.032564, loss_ce: 0.013487
iteration 7113 : loss : 0.027280, loss_ce: 0.011242
iteration 7114 : loss : 0.024537, loss_ce: 0.011452
iteration 7115 : loss : 0.031795, loss_ce: 0.017105
iteration 7116 : loss : 0.031511, loss_ce: 0.015003
iteration 7117 : loss : 0.034149, loss_ce: 0.013450
iteration 7118 : loss : 0.095622, loss_ce: 0.005434
iteration 7119 : loss : 0.077824, loss_ce: 0.005909
iteration 7120 : loss : 0.031918, loss_ce: 0.005597
iteration 7121 : loss : 0.030663, loss_ce: 0.011388
iteration 7122 : loss : 0.027022, loss_ce: 0.010693
iteration 7123 : loss : 0.029686, loss_ce: 0.008167
iteration 7124 : loss : 0.026512, loss_ce: 0.007047
iteration 7125 : loss : 0.030281, loss_ce: 0.014322
iteration 7126 : loss : 0.028387, loss_ce: 0.009249
iteration 7127 : loss : 0.034763, loss_ce: 0.010675
iteration 7128 : loss : 0.030610, loss_ce: 0.008941
iteration 7129 : loss : 0.042815, loss_ce: 0.008850
iteration 7130 : loss : 0.029690, loss_ce: 0.010034
pred_sum 125
gtsum tensor(117, device='cuda:0')
iteration 7131 : loss : 0.031751, loss_ce: 0.013586
iteration 7132 : loss : 0.026158, loss_ce: 0.009129
iteration 7133 : loss : 0.030493, loss_ce: 0.009616
iteration 7134 : loss : 0.033406, loss_ce: 0.010702
iteration 7135 : loss : 0.031385, loss_ce: 0.013840
iteration 7136 : loss : 0.026842, loss_ce: 0.010918
iteration 7137 : loss : 0.025310, loss_ce: 0.011945
iteration 7138 : loss : 0.028581, loss_ce: 0.011291
iteration 7139 : loss : 0.028040, loss_ce: 0.013219
iteration 7140 : loss : 0.041676, loss_ce: 0.006057
iteration 7141 : loss : 0.038193, loss_ce: 0.013260
iteration 7142 : loss : 0.027292, loss_ce: 0.010371
iteration 7143 : loss : 0.027834, loss_ce: 0.008973
iteration 7144 : loss : 0.049066, loss_ce: 0.008815
iteration 7145 : loss : 0.027447, loss_ce: 0.012163
iteration 7146 : loss : 0.032263, loss_ce: 0.009542
iteration 7147 : loss : 0.026931, loss_ce: 0.011275
iteration 7148 : loss : 0.035065, loss_ce: 0.011774
iteration 7149 : loss : 0.032188, loss_ce: 0.010808
iteration 7150 : loss : 0.027309, loss_ce: 0.010236
iteration 7151 : loss : 0.029267, loss_ce: 0.007457
iteration 7152 : loss : 0.058565, loss_ce: 0.010013
iteration 7153 : loss : 0.046349, loss_ce: 0.011225
iteration 7154 : loss : 0.040547, loss_ce: 0.014040
iteration 7155 : loss : 0.032282, loss_ce: 0.013590
iteration 7156 : loss : 0.031271, loss_ce: 0.011202
iteration 7157 : loss : 0.028786, loss_ce: 0.013589
iteration 7158 : loss : 0.027462, loss_ce: 0.008375
iteration 7159 : loss : 0.039479, loss_ce: 0.013632
iteration 7160 : loss : 0.027337, loss_ce: 0.006124
iteration 7161 : loss : 0.057431, loss_ce: 0.015079
 38%|██████████▊                 | 77/200 [1:09:52<1:51:51, 54.57s/it]pred_sum 11402
gtsum tensor(11324, device='cuda:0')
iteration 7162 : loss : 0.032140, loss_ce: 0.010037
iteration 7163 : loss : 0.041112, loss_ce: 0.018239
iteration 7164 : loss : 0.024164, loss_ce: 0.005300
iteration 7165 : loss : 0.030372, loss_ce: 0.015864
iteration 7166 : loss : 0.057763, loss_ce: 0.009879
iteration 7167 : loss : 0.030732, loss_ce: 0.008320
iteration 7168 : loss : 0.039354, loss_ce: 0.014186
iteration 7169 : loss : 0.037052, loss_ce: 0.009022
iteration 7170 : loss : 0.028309, loss_ce: 0.009854
iteration 7171 : loss : 0.035270, loss_ce: 0.009518
iteration 7172 : loss : 0.035669, loss_ce: 0.007454
iteration 7173 : loss : 0.027291, loss_ce: 0.012972
iteration 7174 : loss : 0.038841, loss_ce: 0.013487
iteration 7175 : loss : 0.031731, loss_ce: 0.012824
iteration 7176 : loss : 0.032956, loss_ce: 0.009756
iteration 7177 : loss : 0.033385, loss_ce: 0.010584
iteration 7178 : loss : 0.029335, loss_ce: 0.009248
iteration 7179 : loss : 0.029984, loss_ce: 0.013252
iteration 7180 : loss : 0.038030, loss_ce: 0.008019
iteration 7181 : loss : 0.030726, loss_ce: 0.007553
iteration 7182 : loss : 0.036667, loss_ce: 0.004656
iteration 7183 : loss : 0.045006, loss_ce: 0.011267
iteration 7184 : loss : 0.033422, loss_ce: 0.007703
iteration 7185 : loss : 0.027727, loss_ce: 0.010028
iteration 7186 : loss : 0.079463, loss_ce: 0.006504
iteration 7187 : loss : 0.041244, loss_ce: 0.016794
iteration 7188 : loss : 0.083110, loss_ce: 0.010121
iteration 7189 : loss : 0.030370, loss_ce: 0.011609
iteration 7190 : loss : 0.029586, loss_ce: 0.008170
iteration 7191 : loss : 0.034488, loss_ce: 0.008263
iteration 7192 : loss : 0.038235, loss_ce: 0.016232
pred_sum 9147
gtsum tensor(8838, device='cuda:0')
iteration 7193 : loss : 0.035574, loss_ce: 0.009933
iteration 7194 : loss : 0.033343, loss_ce: 0.008827
iteration 7195 : loss : 0.026448, loss_ce: 0.007946
iteration 7196 : loss : 0.044219, loss_ce: 0.013332
iteration 7197 : loss : 0.033268, loss_ce: 0.008550
iteration 7198 : loss : 0.032781, loss_ce: 0.011967
iteration 7199 : loss : 0.035275, loss_ce: 0.007552
iteration 7200 : loss : 0.034968, loss_ce: 0.010613
iteration 7201 : loss : 0.028062, loss_ce: 0.013691
iteration 7202 : loss : 0.033102, loss_ce: 0.013192
iteration 7203 : loss : 0.036494, loss_ce: 0.010679
iteration 7204 : loss : 0.042365, loss_ce: 0.009197
iteration 7205 : loss : 0.030623, loss_ce: 0.008186
iteration 7206 : loss : 0.028901, loss_ce: 0.008255
iteration 7207 : loss : 0.035452, loss_ce: 0.007647
iteration 7208 : loss : 0.033844, loss_ce: 0.010749
iteration 7209 : loss : 0.029190, loss_ce: 0.010953
iteration 7210 : loss : 0.034363, loss_ce: 0.009423
iteration 7211 : loss : 0.030811, loss_ce: 0.012215
iteration 7212 : loss : 0.072968, loss_ce: 0.011766
iteration 7213 : loss : 0.031969, loss_ce: 0.010450
iteration 7214 : loss : 0.031680, loss_ce: 0.010252
iteration 7215 : loss : 0.030673, loss_ce: 0.012085
iteration 7216 : loss : 0.026449, loss_ce: 0.006468
iteration 7217 : loss : 0.026167, loss_ce: 0.010592
iteration 7218 : loss : 0.023953, loss_ce: 0.008972
iteration 7219 : loss : 0.034461, loss_ce: 0.011539
iteration 7220 : loss : 0.031781, loss_ce: 0.012563
iteration 7221 : loss : 0.024679, loss_ce: 0.010413
iteration 7222 : loss : 0.028626, loss_ce: 0.012325
iteration 7223 : loss : 0.045092, loss_ce: 0.008708
pred_sum 29321
gtsum tensor(29126, device='cuda:0')
iteration 7224 : loss : 0.038245, loss_ce: 0.008100
iteration 7225 : loss : 0.038613, loss_ce: 0.009706
iteration 7226 : loss : 0.022335, loss_ce: 0.006302
iteration 7227 : loss : 0.025295, loss_ce: 0.012470
iteration 7228 : loss : 0.027920, loss_ce: 0.008074
iteration 7229 : loss : 0.030149, loss_ce: 0.009263
iteration 7230 : loss : 0.032450, loss_ce: 0.010134
iteration 7231 : loss : 0.030326, loss_ce: 0.008193
iteration 7232 : loss : 0.031355, loss_ce: 0.011087
iteration 7233 : loss : 0.026238, loss_ce: 0.007421
iteration 7234 : loss : 0.042600, loss_ce: 0.008438
iteration 7235 : loss : 0.032905, loss_ce: 0.011362
iteration 7236 : loss : 0.079395, loss_ce: 0.009505
iteration 7237 : loss : 0.027378, loss_ce: 0.006980
iteration 7238 : loss : 0.078366, loss_ce: 0.010882
iteration 7239 : loss : 0.030083, loss_ce: 0.012218
iteration 7240 : loss : 0.079065, loss_ce: 0.006062
iteration 7241 : loss : 0.036267, loss_ce: 0.006924
iteration 7242 : loss : 0.031080, loss_ce: 0.013773
iteration 7243 : loss : 0.031983, loss_ce: 0.007633
iteration 7244 : loss : 0.031429, loss_ce: 0.011299
iteration 7245 : loss : 0.033342, loss_ce: 0.011265
iteration 7246 : loss : 0.030736, loss_ce: 0.011160
iteration 7247 : loss : 0.031900, loss_ce: 0.008803
iteration 7248 : loss : 0.036354, loss_ce: 0.012906
iteration 7249 : loss : 0.024306, loss_ce: 0.009409
iteration 7250 : loss : 0.034172, loss_ce: 0.012322
iteration 7251 : loss : 0.037554, loss_ce: 0.015330
iteration 7252 : loss : 0.028949, loss_ce: 0.011588
iteration 7253 : loss : 0.028387, loss_ce: 0.010733
iteration 7254 : loss : 0.248346, loss_ce: 0.005424
 39%|██████████▉                 | 78/200 [1:10:47<1:50:55, 54.56s/it]pred_sum 6889
gtsum tensor(6862, device='cuda:0')
iteration 7255 : loss : 0.023526, loss_ce: 0.011208
iteration 7256 : loss : 0.033350, loss_ce: 0.010715
iteration 7257 : loss : 0.025012, loss_ce: 0.008365
iteration 7258 : loss : 0.029947, loss_ce: 0.010205
iteration 7259 : loss : 0.030729, loss_ce: 0.006705
iteration 7260 : loss : 0.035439, loss_ce: 0.010604
iteration 7261 : loss : 0.031841, loss_ce: 0.017707
iteration 7262 : loss : 0.034766, loss_ce: 0.011554
iteration 7263 : loss : 0.038136, loss_ce: 0.006320
iteration 7264 : loss : 0.025915, loss_ce: 0.007216
iteration 7265 : loss : 0.022607, loss_ce: 0.010652
iteration 7266 : loss : 0.031729, loss_ce: 0.008745
iteration 7267 : loss : 0.033020, loss_ce: 0.009507
iteration 7268 : loss : 0.029893, loss_ce: 0.010290
iteration 7269 : loss : 0.032831, loss_ce: 0.007918
iteration 7270 : loss : 0.027722, loss_ce: 0.007999
iteration 7271 : loss : 0.029254, loss_ce: 0.006499
iteration 7272 : loss : 0.024095, loss_ce: 0.009117
iteration 7273 : loss : 0.028948, loss_ce: 0.010171
iteration 7274 : loss : 0.076335, loss_ce: 0.009365
iteration 7275 : loss : 0.026953, loss_ce: 0.008977
iteration 7276 : loss : 0.030458, loss_ce: 0.010656
iteration 7277 : loss : 0.032897, loss_ce: 0.014523
iteration 7278 : loss : 0.027633, loss_ce: 0.009496
iteration 7279 : loss : 0.032921, loss_ce: 0.010598
iteration 7280 : loss : 0.029861, loss_ce: 0.011507
iteration 7281 : loss : 0.031072, loss_ce: 0.012772
iteration 7282 : loss : 0.028950, loss_ce: 0.009012
iteration 7283 : loss : 0.031369, loss_ce: 0.009794
iteration 7284 : loss : 0.025524, loss_ce: 0.009409
iteration 7285 : loss : 0.028311, loss_ce: 0.009207
pred_sum 68
gtsum tensor(78, device='cuda:0')
iteration 7286 : loss : 0.029261, loss_ce: 0.011008
iteration 7287 : loss : 0.077409, loss_ce: 0.009256
iteration 7288 : loss : 0.024863, loss_ce: 0.009936
iteration 7289 : loss : 0.033492, loss_ce: 0.011515
iteration 7290 : loss : 0.030038, loss_ce: 0.008994
iteration 7291 : loss : 0.034217, loss_ce: 0.011289
iteration 7292 : loss : 0.046790, loss_ce: 0.005912
iteration 7293 : loss : 0.027080, loss_ce: 0.011519
iteration 7294 : loss : 0.026451, loss_ce: 0.009732
iteration 7295 : loss : 0.028565, loss_ce: 0.010452
iteration 7296 : loss : 0.030641, loss_ce: 0.008848
iteration 7297 : loss : 0.030553, loss_ce: 0.010698
iteration 7298 : loss : 0.036100, loss_ce: 0.007754
iteration 7299 : loss : 0.030403, loss_ce: 0.010483
iteration 7300 : loss : 0.024767, loss_ce: 0.005309
iteration 7301 : loss : 0.023986, loss_ce: 0.008341
iteration 7302 : loss : 0.033960, loss_ce: 0.012980
iteration 7303 : loss : 0.029109, loss_ce: 0.007952
iteration 7304 : loss : 0.026044, loss_ce: 0.012380
iteration 7305 : loss : 0.028985, loss_ce: 0.011552
iteration 7306 : loss : 0.033036, loss_ce: 0.007533
iteration 7307 : loss : 0.029861, loss_ce: 0.006488
iteration 7308 : loss : 0.027871, loss_ce: 0.007999
iteration 7309 : loss : 0.050220, loss_ce: 0.008008
iteration 7310 : loss : 0.038095, loss_ce: 0.011211
iteration 7311 : loss : 0.032791, loss_ce: 0.010380
iteration 7312 : loss : 0.027719, loss_ce: 0.011542
iteration 7313 : loss : 0.032085, loss_ce: 0.010020
iteration 7314 : loss : 0.024301, loss_ce: 0.006950
iteration 7315 : loss : 0.026289, loss_ce: 0.008601
iteration 7316 : loss : 0.076768, loss_ce: 0.005954
pred_sum 11104
gtsum tensor(10733, device='cuda:0')
iteration 7317 : loss : 0.028423, loss_ce: 0.013589
iteration 7318 : loss : 0.030557, loss_ce: 0.011812
iteration 7319 : loss : 0.061547, loss_ce: 0.010789
iteration 7320 : loss : 0.045423, loss_ce: 0.005107
iteration 7321 : loss : 0.026893, loss_ce: 0.006800
iteration 7322 : loss : 0.027829, loss_ce: 0.011053
iteration 7323 : loss : 0.032210, loss_ce: 0.010528
iteration 7324 : loss : 0.028231, loss_ce: 0.012677
iteration 7325 : loss : 0.023041, loss_ce: 0.007372
iteration 7326 : loss : 0.028166, loss_ce: 0.010529
iteration 7327 : loss : 0.027983, loss_ce: 0.009364
iteration 7328 : loss : 0.026455, loss_ce: 0.011841
iteration 7329 : loss : 0.026780, loss_ce: 0.011010
iteration 7330 : loss : 0.031200, loss_ce: 0.013512
iteration 7331 : loss : 0.032354, loss_ce: 0.009041
iteration 7332 : loss : 0.077238, loss_ce: 0.007533
iteration 7333 : loss : 0.028361, loss_ce: 0.012006
iteration 7334 : loss : 0.031364, loss_ce: 0.009513
iteration 7335 : loss : 0.030784, loss_ce: 0.013758
iteration 7336 : loss : 0.032678, loss_ce: 0.008322
iteration 7337 : loss : 0.031753, loss_ce: 0.009094
iteration 7338 : loss : 0.036778, loss_ce: 0.012497
iteration 7339 : loss : 0.030581, loss_ce: 0.009019
iteration 7340 : loss : 0.038817, loss_ce: 0.014595
iteration 7341 : loss : 0.034547, loss_ce: 0.012805
iteration 7342 : loss : 0.036227, loss_ce: 0.008283
iteration 7343 : loss : 0.084462, loss_ce: 0.008576
iteration 7344 : loss : 0.095780, loss_ce: 0.009216
iteration 7345 : loss : 0.077947, loss_ce: 0.008726
iteration 7346 : loss : 0.030350, loss_ce: 0.007511
iteration 7347 : loss : 0.130837, loss_ce: 0.011264
 40%|███████████                 | 79/200 [1:11:41<1:50:04, 54.58s/it]pred_sum 71
gtsum tensor(85, device='cuda:0')
iteration 7348 : loss : 0.085712, loss_ce: 0.013182
iteration 7349 : loss : 0.034268, loss_ce: 0.008766
iteration 7350 : loss : 0.031293, loss_ce: 0.014287
iteration 7351 : loss : 0.032430, loss_ce: 0.010820
iteration 7352 : loss : 0.078846, loss_ce: 0.006926
iteration 7353 : loss : 0.032418, loss_ce: 0.011080
iteration 7354 : loss : 0.032977, loss_ce: 0.008625
iteration 7355 : loss : 0.027072, loss_ce: 0.007475
iteration 7356 : loss : 0.024502, loss_ce: 0.009492
iteration 7357 : loss : 0.024747, loss_ce: 0.011020
iteration 7358 : loss : 0.030316, loss_ce: 0.009637
iteration 7359 : loss : 0.027666, loss_ce: 0.011704
iteration 7360 : loss : 0.031212, loss_ce: 0.010245
iteration 7361 : loss : 0.070074, loss_ce: 0.009815
iteration 7362 : loss : 0.027798, loss_ce: 0.009100
iteration 7363 : loss : 0.032893, loss_ce: 0.009888
iteration 7364 : loss : 0.026818, loss_ce: 0.010751
iteration 7365 : loss : 0.032279, loss_ce: 0.006930
iteration 7366 : loss : 0.029356, loss_ce: 0.008233
iteration 7367 : loss : 0.033489, loss_ce: 0.007690
iteration 7368 : loss : 0.025039, loss_ce: 0.008782
iteration 7369 : loss : 0.034056, loss_ce: 0.009063
iteration 7370 : loss : 0.031724, loss_ce: 0.011715
iteration 7371 : loss : 0.030710, loss_ce: 0.008531
iteration 7372 : loss : 0.033654, loss_ce: 0.008902
iteration 7373 : loss : 0.027511, loss_ce: 0.008023
iteration 7374 : loss : 0.028586, loss_ce: 0.008022
iteration 7375 : loss : 0.064471, loss_ce: 0.012339
iteration 7376 : loss : 0.029501, loss_ce: 0.013415
iteration 7377 : loss : 0.026499, loss_ce: 0.008613
iteration 7378 : loss : 0.031808, loss_ce: 0.018911
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 7379 : loss : 0.032729, loss_ce: 0.012094
iteration 7380 : loss : 0.029883, loss_ce: 0.008839
iteration 7381 : loss : 0.044782, loss_ce: 0.008128
iteration 7382 : loss : 0.030731, loss_ce: 0.011950
iteration 7383 : loss : 0.024675, loss_ce: 0.004687
iteration 7384 : loss : 0.028554, loss_ce: 0.009794
iteration 7385 : loss : 0.036555, loss_ce: 0.010715
iteration 7386 : loss : 0.028330, loss_ce: 0.009147
iteration 7387 : loss : 0.027439, loss_ce: 0.008963
iteration 7388 : loss : 0.023304, loss_ce: 0.006367
iteration 7389 : loss : 0.030712, loss_ce: 0.011606
iteration 7390 : loss : 0.028098, loss_ce: 0.008422
iteration 7391 : loss : 0.029975, loss_ce: 0.009638
iteration 7392 : loss : 0.030255, loss_ce: 0.011335
iteration 7393 : loss : 0.037370, loss_ce: 0.009685
iteration 7394 : loss : 0.025555, loss_ce: 0.006871
iteration 7395 : loss : 0.028156, loss_ce: 0.014925
iteration 7396 : loss : 0.080787, loss_ce: 0.006238
iteration 7397 : loss : 0.026501, loss_ce: 0.012623
iteration 7398 : loss : 0.032900, loss_ce: 0.008092
iteration 7399 : loss : 0.033447, loss_ce: 0.003938
iteration 7400 : loss : 0.031056, loss_ce: 0.011622
iteration 7401 : loss : 0.022880, loss_ce: 0.010677
iteration 7402 : loss : 0.041938, loss_ce: 0.015526
iteration 7403 : loss : 0.032719, loss_ce: 0.014980
iteration 7404 : loss : 0.027213, loss_ce: 0.008857
iteration 7405 : loss : 0.064361, loss_ce: 0.007199
iteration 7406 : loss : 0.027405, loss_ce: 0.010144
iteration 7407 : loss : 0.029007, loss_ce: 0.008684
iteration 7408 : loss : 0.026458, loss_ce: 0.010942
iteration 7409 : loss : 0.035150, loss_ce: 0.018592
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 7410 : loss : 0.032944, loss_ce: 0.014380
iteration 7411 : loss : 0.032439, loss_ce: 0.013133
iteration 7412 : loss : 0.038930, loss_ce: 0.009512
iteration 7413 : loss : 0.038619, loss_ce: 0.006346
iteration 7414 : loss : 0.037159, loss_ce: 0.012658
iteration 7415 : loss : 0.035801, loss_ce: 0.010654
iteration 7416 : loss : 0.033503, loss_ce: 0.009015
iteration 7417 : loss : 0.078449, loss_ce: 0.007606
iteration 7418 : loss : 0.128461, loss_ce: 0.005953
iteration 7419 : loss : 0.026772, loss_ce: 0.007483
iteration 7420 : loss : 0.032017, loss_ce: 0.011651
iteration 7421 : loss : 0.084647, loss_ce: 0.011656
iteration 7422 : loss : 0.027835, loss_ce: 0.008856
iteration 7423 : loss : 0.027747, loss_ce: 0.010420
iteration 7424 : loss : 0.027881, loss_ce: 0.009557
iteration 7425 : loss : 0.032024, loss_ce: 0.006468
iteration 7426 : loss : 0.027423, loss_ce: 0.008405
iteration 7427 : loss : 0.026243, loss_ce: 0.010190
iteration 7428 : loss : 0.023532, loss_ce: 0.008045
iteration 7429 : loss : 0.035142, loss_ce: 0.007113
iteration 7430 : loss : 0.028845, loss_ce: 0.007857
iteration 7431 : loss : 0.046941, loss_ce: 0.013311
iteration 7432 : loss : 0.029439, loss_ce: 0.013505
iteration 7433 : loss : 0.077615, loss_ce: 0.008239
iteration 7434 : loss : 0.029007, loss_ce: 0.006887
iteration 7435 : loss : 0.027925, loss_ce: 0.007189
iteration 7436 : loss : 0.024112, loss_ce: 0.010309
iteration 7437 : loss : 0.082321, loss_ce: 0.009301
iteration 7438 : loss : 0.027291, loss_ce: 0.010463
iteration 7439 : loss : 0.037933, loss_ce: 0.005859
iteration 7440 : loss : 0.138156, loss_ce: 0.012656
 40%|███████████▏                | 80/200 [1:12:36<1:49:09, 54.58s/it]pred_sum 30091
gtsum tensor(28864, device='cuda:0')
iteration 7441 : loss : 0.081433, loss_ce: 0.005588
iteration 7442 : loss : 0.031604, loss_ce: 0.010564
iteration 7443 : loss : 0.031003, loss_ce: 0.017354
iteration 7444 : loss : 0.035914, loss_ce: 0.009610
iteration 7445 : loss : 0.031087, loss_ce: 0.011193
iteration 7446 : loss : 0.027801, loss_ce: 0.012060
iteration 7447 : loss : 0.024507, loss_ce: 0.006448
iteration 7448 : loss : 0.027528, loss_ce: 0.010036
iteration 7449 : loss : 0.034678, loss_ce: 0.010951
iteration 7450 : loss : 0.078677, loss_ce: 0.008966
iteration 7451 : loss : 0.029098, loss_ce: 0.010778
iteration 7452 : loss : 0.027803, loss_ce: 0.006181
iteration 7453 : loss : 0.070317, loss_ce: 0.007252
iteration 7454 : loss : 0.029959, loss_ce: 0.011205
iteration 7455 : loss : 0.044704, loss_ce: 0.011096
iteration 7456 : loss : 0.026979, loss_ce: 0.013182
iteration 7457 : loss : 0.028743, loss_ce: 0.006441
iteration 7458 : loss : 0.034463, loss_ce: 0.014250
iteration 7459 : loss : 0.080390, loss_ce: 0.009582
iteration 7460 : loss : 0.039605, loss_ce: 0.012890
iteration 7461 : loss : 0.037187, loss_ce: 0.014319
iteration 7462 : loss : 0.029730, loss_ce: 0.008042
iteration 7463 : loss : 0.042991, loss_ce: 0.009418
iteration 7464 : loss : 0.029360, loss_ce: 0.010183
iteration 7465 : loss : 0.034488, loss_ce: 0.016523
iteration 7466 : loss : 0.028810, loss_ce: 0.011270
iteration 7467 : loss : 0.033774, loss_ce: 0.010379
iteration 7468 : loss : 0.028780, loss_ce: 0.011090
iteration 7469 : loss : 0.027877, loss_ce: 0.008492
iteration 7470 : loss : 0.026420, loss_ce: 0.010951
iteration 7471 : loss : 0.024107, loss_ce: 0.010152
pred_sum 2740
gtsum tensor(2525, device='cuda:0')
iteration 7472 : loss : 0.050696, loss_ce: 0.005042
iteration 7473 : loss : 0.028404, loss_ce: 0.011916
iteration 7474 : loss : 0.069489, loss_ce: 0.006548
iteration 7475 : loss : 0.028009, loss_ce: 0.011294
iteration 7476 : loss : 0.027215, loss_ce: 0.009656
iteration 7477 : loss : 0.036059, loss_ce: 0.011204
iteration 7478 : loss : 0.038117, loss_ce: 0.010482
iteration 7479 : loss : 0.035992, loss_ce: 0.011358
iteration 7480 : loss : 0.036332, loss_ce: 0.012072
iteration 7481 : loss : 0.041415, loss_ce: 0.016644
iteration 7482 : loss : 0.043050, loss_ce: 0.009756
iteration 7483 : loss : 0.043666, loss_ce: 0.010154
iteration 7484 : loss : 0.033214, loss_ce: 0.011650
iteration 7485 : loss : 0.047052, loss_ce: 0.011355
iteration 7486 : loss : 0.078146, loss_ce: 0.013906
iteration 7487 : loss : 0.034591, loss_ce: 0.012100
iteration 7488 : loss : 0.033546, loss_ce: 0.007046
iteration 7489 : loss : 0.033451, loss_ce: 0.014777
iteration 7490 : loss : 0.041292, loss_ce: 0.015832
iteration 7491 : loss : 0.050896, loss_ce: 0.017352
iteration 7492 : loss : 0.032362, loss_ce: 0.014941
iteration 7493 : loss : 0.039983, loss_ce: 0.010477
iteration 7494 : loss : 0.046629, loss_ce: 0.009818
iteration 7495 : loss : 0.032495, loss_ce: 0.011565
iteration 7496 : loss : 0.040958, loss_ce: 0.010985
iteration 7497 : loss : 0.040227, loss_ce: 0.016009
iteration 7498 : loss : 0.027655, loss_ce: 0.008881
iteration 7499 : loss : 0.032988, loss_ce: 0.012265
iteration 7500 : loss : 0.082533, loss_ce: 0.013192
iteration 7501 : loss : 0.031476, loss_ce: 0.014434
iteration 7502 : loss : 0.039092, loss_ce: 0.012833
pred_sum 259
gtsum tensor(333, device='cuda:0')
iteration 7503 : loss : 0.070462, loss_ce: 0.009495
iteration 7504 : loss : 0.098494, loss_ce: 0.006168
iteration 7505 : loss : 0.031796, loss_ce: 0.009567
iteration 7506 : loss : 0.054296, loss_ce: 0.009385
iteration 7507 : loss : 0.030160, loss_ce: 0.012828
iteration 7508 : loss : 0.034459, loss_ce: 0.009614
iteration 7509 : loss : 0.030893, loss_ce: 0.011647
iteration 7510 : loss : 0.080646, loss_ce: 0.004132
iteration 7511 : loss : 0.039321, loss_ce: 0.014550
iteration 7512 : loss : 0.030804, loss_ce: 0.010101
iteration 7513 : loss : 0.035167, loss_ce: 0.010512
iteration 7514 : loss : 0.036848, loss_ce: 0.009619
iteration 7515 : loss : 0.032940, loss_ce: 0.015876
iteration 7516 : loss : 0.037376, loss_ce: 0.011842
iteration 7517 : loss : 0.038509, loss_ce: 0.011635
iteration 7518 : loss : 0.039455, loss_ce: 0.012751
iteration 7519 : loss : 0.031608, loss_ce: 0.010741
iteration 7520 : loss : 0.035665, loss_ce: 0.006803
iteration 7521 : loss : 0.040327, loss_ce: 0.012852
iteration 7522 : loss : 0.040844, loss_ce: 0.016550
iteration 7523 : loss : 0.037316, loss_ce: 0.012616
iteration 7524 : loss : 0.031664, loss_ce: 0.011104
iteration 7525 : loss : 0.031930, loss_ce: 0.014743
iteration 7526 : loss : 0.032943, loss_ce: 0.014626
iteration 7527 : loss : 0.034458, loss_ce: 0.009888
iteration 7528 : loss : 0.033482, loss_ce: 0.011402
iteration 7529 : loss : 0.031965, loss_ce: 0.014854
iteration 7530 : loss : 0.026034, loss_ce: 0.008521
iteration 7531 : loss : 0.029349, loss_ce: 0.012392
iteration 7532 : loss : 0.027646, loss_ce: 0.010804
iteration 7533 : loss : 0.091982, loss_ce: 0.011844
 40%|███████████▎                | 81/200 [1:13:31<1:48:14, 54.58s/it]pred_sum 3851
gtsum tensor(3842, device='cuda:0')
iteration 7534 : loss : 0.029166, loss_ce: 0.012047
iteration 7535 : loss : 0.032091, loss_ce: 0.011797
iteration 7536 : loss : 0.026037, loss_ce: 0.009912
iteration 7537 : loss : 0.027135, loss_ce: 0.006833
iteration 7538 : loss : 0.033366, loss_ce: 0.014003
iteration 7539 : loss : 0.085068, loss_ce: 0.011019
iteration 7540 : loss : 0.029414, loss_ce: 0.012792
iteration 7541 : loss : 0.029891, loss_ce: 0.009831
iteration 7542 : loss : 0.029755, loss_ce: 0.013348
iteration 7543 : loss : 0.028817, loss_ce: 0.005523
iteration 7544 : loss : 0.032940, loss_ce: 0.016063
iteration 7545 : loss : 0.082837, loss_ce: 0.010766
iteration 7546 : loss : 0.036331, loss_ce: 0.015667
iteration 7547 : loss : 0.025517, loss_ce: 0.008497
iteration 7548 : loss : 0.029511, loss_ce: 0.013658
iteration 7549 : loss : 0.028982, loss_ce: 0.007648
iteration 7550 : loss : 0.029929, loss_ce: 0.014611
iteration 7551 : loss : 0.025261, loss_ce: 0.007936
iteration 7552 : loss : 0.025993, loss_ce: 0.006423
iteration 7553 : loss : 0.025507, loss_ce: 0.009956
iteration 7554 : loss : 0.031673, loss_ce: 0.014333
iteration 7555 : loss : 0.028190, loss_ce: 0.009341
iteration 7556 : loss : 0.034034, loss_ce: 0.009732
iteration 7557 : loss : 0.032538, loss_ce: 0.010388
iteration 7558 : loss : 0.038847, loss_ce: 0.010395
iteration 7559 : loss : 0.053708, loss_ce: 0.005679
iteration 7560 : loss : 0.036173, loss_ce: 0.014347
iteration 7561 : loss : 0.026901, loss_ce: 0.011876
iteration 7562 : loss : 0.052746, loss_ce: 0.011299
iteration 7563 : loss : 0.033958, loss_ce: 0.010180
iteration 7564 : loss : 0.033119, loss_ce: 0.010442
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 7565 : loss : 0.027978, loss_ce: 0.010039
iteration 7566 : loss : 0.031728, loss_ce: 0.007948
iteration 7567 : loss : 0.089195, loss_ce: 0.006565
iteration 7568 : loss : 0.034850, loss_ce: 0.007245
iteration 7569 : loss : 0.035146, loss_ce: 0.008590
iteration 7570 : loss : 0.030448, loss_ce: 0.008939
iteration 7571 : loss : 0.032024, loss_ce: 0.013417
iteration 7572 : loss : 0.039405, loss_ce: 0.010522
iteration 7573 : loss : 0.038418, loss_ce: 0.006635
iteration 7574 : loss : 0.032392, loss_ce: 0.009299
iteration 7575 : loss : 0.091393, loss_ce: 0.005660
iteration 7576 : loss : 0.033681, loss_ce: 0.012804
iteration 7577 : loss : 0.036667, loss_ce: 0.013410
iteration 7578 : loss : 0.031979, loss_ce: 0.012670
iteration 7579 : loss : 0.074956, loss_ce: 0.009694
iteration 7580 : loss : 0.023122, loss_ce: 0.009858
iteration 7581 : loss : 0.026003, loss_ce: 0.009356
iteration 7582 : loss : 0.027610, loss_ce: 0.009314
iteration 7583 : loss : 0.028451, loss_ce: 0.010286
iteration 7584 : loss : 0.025738, loss_ce: 0.011962
iteration 7585 : loss : 0.027156, loss_ce: 0.008934
iteration 7586 : loss : 0.032318, loss_ce: 0.010118
iteration 7587 : loss : 0.046352, loss_ce: 0.011195
iteration 7588 : loss : 0.033196, loss_ce: 0.011878
iteration 7589 : loss : 0.029636, loss_ce: 0.013371
iteration 7590 : loss : 0.030597, loss_ce: 0.009784
iteration 7591 : loss : 0.032613, loss_ce: 0.011928
iteration 7592 : loss : 0.027803, loss_ce: 0.011908
iteration 7593 : loss : 0.033138, loss_ce: 0.007905
iteration 7594 : loss : 0.040971, loss_ce: 0.009111
iteration 7595 : loss : 0.028390, loss_ce: 0.011035
pred_sum 9489
gtsum tensor(9338, device='cuda:0')
iteration 7596 : loss : 0.029098, loss_ce: 0.007531
iteration 7597 : loss : 0.032126, loss_ce: 0.010948
iteration 7598 : loss : 0.134034, loss_ce: 0.007204
iteration 7599 : loss : 0.030884, loss_ce: 0.007187
iteration 7600 : loss : 0.030283, loss_ce: 0.010286
iteration 7601 : loss : 0.053529, loss_ce: 0.008829
iteration 7602 : loss : 0.033925, loss_ce: 0.007631
iteration 7603 : loss : 0.082087, loss_ce: 0.011723
iteration 7604 : loss : 0.029901, loss_ce: 0.011311
iteration 7605 : loss : 0.034649, loss_ce: 0.012209
iteration 7606 : loss : 0.036832, loss_ce: 0.014660
iteration 7607 : loss : 0.083979, loss_ce: 0.012790
iteration 7608 : loss : 0.033905, loss_ce: 0.012328
iteration 7609 : loss : 0.041529, loss_ce: 0.009179
iteration 7610 : loss : 0.082652, loss_ce: 0.009390
iteration 7611 : loss : 0.029918, loss_ce: 0.013094
iteration 7612 : loss : 0.030478, loss_ce: 0.010277
iteration 7613 : loss : 0.029460, loss_ce: 0.010421
iteration 7614 : loss : 0.047985, loss_ce: 0.011568
iteration 7615 : loss : 0.033869, loss_ce: 0.010450
iteration 7616 : loss : 0.029087, loss_ce: 0.007587
iteration 7617 : loss : 0.039368, loss_ce: 0.014871
iteration 7618 : loss : 0.038363, loss_ce: 0.008597
iteration 7619 : loss : 0.031331, loss_ce: 0.008757
iteration 7620 : loss : 0.037693, loss_ce: 0.011170
iteration 7621 : loss : 0.031412, loss_ce: 0.010001
iteration 7622 : loss : 0.038946, loss_ce: 0.011210
iteration 7623 : loss : 0.048090, loss_ce: 0.010406
iteration 7624 : loss : 0.027538, loss_ce: 0.009122
iteration 7625 : loss : 0.026478, loss_ce: 0.011598
iteration 7626 : loss : 0.109799, loss_ce: 0.040281
 41%|███████████▍                | 82/200 [1:14:25<1:47:20, 54.58s/it]pred_sum 2822
gtsum tensor(4340, device='cuda:0')
iteration 7627 : loss : 0.033505, loss_ce: 0.009208
iteration 7628 : loss : 0.037384, loss_ce: 0.012926
iteration 7629 : loss : 0.033697, loss_ce: 0.011705
iteration 7630 : loss : 0.037586, loss_ce: 0.015048
iteration 7631 : loss : 0.029369, loss_ce: 0.011611
iteration 7632 : loss : 0.046590, loss_ce: 0.015996
iteration 7633 : loss : 0.034193, loss_ce: 0.016763
iteration 7634 : loss : 0.033366, loss_ce: 0.009187
iteration 7635 : loss : 0.040715, loss_ce: 0.014368
iteration 7636 : loss : 0.031325, loss_ce: 0.010830
iteration 7637 : loss : 0.026799, loss_ce: 0.007571
iteration 7638 : loss : 0.031195, loss_ce: 0.008564
iteration 7639 : loss : 0.034424, loss_ce: 0.006777
iteration 7640 : loss : 0.030850, loss_ce: 0.008879
iteration 7641 : loss : 0.029710, loss_ce: 0.009540
iteration 7642 : loss : 0.023794, loss_ce: 0.006612
iteration 7643 : loss : 0.024126, loss_ce: 0.008901
iteration 7644 : loss : 0.027520, loss_ce: 0.012855
iteration 7645 : loss : 0.031123, loss_ce: 0.014103
iteration 7646 : loss : 0.033543, loss_ce: 0.009067
iteration 7647 : loss : 0.121654, loss_ce: 0.006035
iteration 7648 : loss : 0.082642, loss_ce: 0.012814
iteration 7649 : loss : 0.036418, loss_ce: 0.013226
iteration 7650 : loss : 0.027601, loss_ce: 0.008920
iteration 7651 : loss : 0.025006, loss_ce: 0.010922
iteration 7652 : loss : 0.032651, loss_ce: 0.011922
iteration 7653 : loss : 0.079349, loss_ce: 0.008544
iteration 7654 : loss : 0.035813, loss_ce: 0.007536
iteration 7655 : loss : 0.033016, loss_ce: 0.010044
iteration 7656 : loss : 0.036614, loss_ce: 0.015186
iteration 7657 : loss : 0.028959, loss_ce: 0.010558
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 7658 : loss : 0.026387, loss_ce: 0.006490
iteration 7659 : loss : 0.025420, loss_ce: 0.010897
iteration 7660 : loss : 0.038582, loss_ce: 0.007395
iteration 7661 : loss : 0.084379, loss_ce: 0.008377
iteration 7662 : loss : 0.025885, loss_ce: 0.005841
iteration 7663 : loss : 0.035327, loss_ce: 0.013129
iteration 7664 : loss : 0.025100, loss_ce: 0.006597
iteration 7665 : loss : 0.078932, loss_ce: 0.009095
iteration 7666 : loss : 0.027772, loss_ce: 0.009055
iteration 7667 : loss : 0.035336, loss_ce: 0.011614
iteration 7668 : loss : 0.027098, loss_ce: 0.013944
iteration 7669 : loss : 0.026744, loss_ce: 0.011777
iteration 7670 : loss : 0.029756, loss_ce: 0.008468
iteration 7671 : loss : 0.030611, loss_ce: 0.013418
iteration 7672 : loss : 0.037568, loss_ce: 0.006802
iteration 7673 : loss : 0.029301, loss_ce: 0.009498
iteration 7674 : loss : 0.035378, loss_ce: 0.007148
iteration 7675 : loss : 0.027651, loss_ce: 0.013537
iteration 7676 : loss : 0.029678, loss_ce: 0.012564
iteration 7677 : loss : 0.031983, loss_ce: 0.008386
iteration 7678 : loss : 0.033833, loss_ce: 0.008238
iteration 7679 : loss : 0.025500, loss_ce: 0.006651
iteration 7680 : loss : 0.030890, loss_ce: 0.010263
iteration 7681 : loss : 0.028975, loss_ce: 0.012320
iteration 7682 : loss : 0.037040, loss_ce: 0.012492
iteration 7683 : loss : 0.079367, loss_ce: 0.006366
iteration 7684 : loss : 0.023049, loss_ce: 0.011689
iteration 7685 : loss : 0.028614, loss_ce: 0.010608
iteration 7686 : loss : 0.033011, loss_ce: 0.015823
iteration 7687 : loss : 0.028970, loss_ce: 0.009807
iteration 7688 : loss : 0.077085, loss_ce: 0.006315
pred_sum 3380
gtsum tensor(3784, device='cuda:0')
iteration 7689 : loss : 0.031377, loss_ce: 0.015451
iteration 7690 : loss : 0.032259, loss_ce: 0.011930
iteration 7691 : loss : 0.106623, loss_ce: 0.004716
iteration 7692 : loss : 0.031880, loss_ce: 0.014502
iteration 7693 : loss : 0.035751, loss_ce: 0.011875
iteration 7694 : loss : 0.029629, loss_ce: 0.011886
iteration 7695 : loss : 0.037793, loss_ce: 0.009436
iteration 7696 : loss : 0.080083, loss_ce: 0.009539
iteration 7697 : loss : 0.030975, loss_ce: 0.013341
iteration 7698 : loss : 0.055310, loss_ce: 0.008322
iteration 7699 : loss : 0.041676, loss_ce: 0.023340
iteration 7700 : loss : 0.027083, loss_ce: 0.006594
iteration 7701 : loss : 0.032405, loss_ce: 0.014325
iteration 7702 : loss : 0.035289, loss_ce: 0.013319
iteration 7703 : loss : 0.028929, loss_ce: 0.009904
iteration 7704 : loss : 0.053328, loss_ce: 0.011018
iteration 7705 : loss : 0.029123, loss_ce: 0.009600
iteration 7706 : loss : 0.032225, loss_ce: 0.010984
iteration 7707 : loss : 0.037746, loss_ce: 0.020843
iteration 7708 : loss : 0.077711, loss_ce: 0.006590
iteration 7709 : loss : 0.029266, loss_ce: 0.010484
iteration 7710 : loss : 0.033151, loss_ce: 0.007169
iteration 7711 : loss : 0.034491, loss_ce: 0.010182
iteration 7712 : loss : 0.029941, loss_ce: 0.014517
iteration 7713 : loss : 0.053309, loss_ce: 0.011202
iteration 7714 : loss : 0.036909, loss_ce: 0.008897
iteration 7715 : loss : 0.029714, loss_ce: 0.011405
iteration 7716 : loss : 0.027132, loss_ce: 0.008235
iteration 7717 : loss : 0.037388, loss_ce: 0.009399
iteration 7718 : loss : 0.027818, loss_ce: 0.006692
iteration 7719 : loss : 0.367770, loss_ce: 0.001853
 42%|███████████▌                | 83/200 [1:15:20<1:46:23, 54.56s/it]pred_sum 266
gtsum tensor(639, device='cuda:0')
iteration 7720 : loss : 0.032755, loss_ce: 0.013308
iteration 7721 : loss : 0.037278, loss_ce: 0.017997
iteration 7722 : loss : 0.037232, loss_ce: 0.012677
iteration 7723 : loss : 0.036097, loss_ce: 0.012754
iteration 7724 : loss : 0.035365, loss_ce: 0.016985
iteration 7725 : loss : 0.034180, loss_ce: 0.009955
iteration 7726 : loss : 0.028701, loss_ce: 0.012187
iteration 7727 : loss : 0.042466, loss_ce: 0.014997
iteration 7728 : loss : 0.084459, loss_ce: 0.008496
iteration 7729 : loss : 0.034942, loss_ce: 0.010563
iteration 7730 : loss : 0.085880, loss_ce: 0.011964
iteration 7731 : loss : 0.031584, loss_ce: 0.011800
iteration 7732 : loss : 0.033431, loss_ce: 0.012358
iteration 7733 : loss : 0.029342, loss_ce: 0.009011
iteration 7734 : loss : 0.045334, loss_ce: 0.015187
iteration 7735 : loss : 0.030357, loss_ce: 0.007636
iteration 7736 : loss : 0.028448, loss_ce: 0.008362
iteration 7737 : loss : 0.089810, loss_ce: 0.009421
iteration 7738 : loss : 0.034253, loss_ce: 0.012262
iteration 7739 : loss : 0.026768, loss_ce: 0.010352
iteration 7740 : loss : 0.031824, loss_ce: 0.013862
iteration 7741 : loss : 0.031764, loss_ce: 0.011981
iteration 7742 : loss : 0.036572, loss_ce: 0.014309
iteration 7743 : loss : 0.028874, loss_ce: 0.011916
iteration 7744 : loss : 0.082834, loss_ce: 0.011587
iteration 7745 : loss : 0.028334, loss_ce: 0.011725
iteration 7746 : loss : 0.029966, loss_ce: 0.008023
iteration 7747 : loss : 0.034617, loss_ce: 0.012601
iteration 7748 : loss : 0.034108, loss_ce: 0.011766
iteration 7749 : loss : 0.080159, loss_ce: 0.011800
iteration 7750 : loss : 0.079804, loss_ce: 0.010489
pred_sum 7992
gtsum tensor(7531, device='cuda:0')
iteration 7751 : loss : 0.026033, loss_ce: 0.009500
iteration 7752 : loss : 0.031386, loss_ce: 0.013133
iteration 7753 : loss : 0.027719, loss_ce: 0.011208
iteration 7754 : loss : 0.029915, loss_ce: 0.013986
iteration 7755 : loss : 0.035218, loss_ce: 0.010844
iteration 7756 : loss : 0.031920, loss_ce: 0.016405
iteration 7757 : loss : 0.059843, loss_ce: 0.009189
iteration 7758 : loss : 0.032542, loss_ce: 0.013139
iteration 7759 : loss : 0.063253, loss_ce: 0.007860
iteration 7760 : loss : 0.033313, loss_ce: 0.014542
iteration 7761 : loss : 0.092025, loss_ce: 0.008668
iteration 7762 : loss : 0.026380, loss_ce: 0.008656
iteration 7763 : loss : 0.028988, loss_ce: 0.011137
iteration 7764 : loss : 0.031248, loss_ce: 0.007034
iteration 7765 : loss : 0.038816, loss_ce: 0.007552
iteration 7766 : loss : 0.035727, loss_ce: 0.016167
iteration 7767 : loss : 0.030395, loss_ce: 0.005361
iteration 7768 : loss : 0.028474, loss_ce: 0.007669
iteration 7769 : loss : 0.033640, loss_ce: 0.009170
iteration 7770 : loss : 0.039657, loss_ce: 0.008250
iteration 7771 : loss : 0.032801, loss_ce: 0.012990
iteration 7772 : loss : 0.024436, loss_ce: 0.007833
iteration 7773 : loss : 0.031956, loss_ce: 0.012059
iteration 7774 : loss : 0.030180, loss_ce: 0.013226
iteration 7775 : loss : 0.039346, loss_ce: 0.008102
iteration 7776 : loss : 0.033763, loss_ce: 0.007432
iteration 7777 : loss : 0.033633, loss_ce: 0.011459
iteration 7778 : loss : 0.033353, loss_ce: 0.014743
iteration 7779 : loss : 0.028997, loss_ce: 0.011520
iteration 7780 : loss : 0.038440, loss_ce: 0.011895
iteration 7781 : loss : 0.025032, loss_ce: 0.006850
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 7782 : loss : 0.035099, loss_ce: 0.018005
iteration 7783 : loss : 0.029122, loss_ce: 0.012543
iteration 7784 : loss : 0.031633, loss_ce: 0.014103
iteration 7785 : loss : 0.031746, loss_ce: 0.009487
iteration 7786 : loss : 0.080063, loss_ce: 0.009017
iteration 7787 : loss : 0.028468, loss_ce: 0.006256
iteration 7788 : loss : 0.022431, loss_ce: 0.007839
iteration 7789 : loss : 0.029478, loss_ce: 0.009400
iteration 7790 : loss : 0.033262, loss_ce: 0.014235
iteration 7791 : loss : 0.031098, loss_ce: 0.012721
iteration 7792 : loss : 0.036485, loss_ce: 0.014866
iteration 7793 : loss : 0.094810, loss_ce: 0.008097
iteration 7794 : loss : 0.029270, loss_ce: 0.008228
iteration 7795 : loss : 0.027367, loss_ce: 0.013289
iteration 7796 : loss : 0.024831, loss_ce: 0.009387
iteration 7797 : loss : 0.031850, loss_ce: 0.011601
iteration 7798 : loss : 0.033773, loss_ce: 0.010501
iteration 7799 : loss : 0.080521, loss_ce: 0.006391
iteration 7800 : loss : 0.025999, loss_ce: 0.009642
iteration 7801 : loss : 0.024644, loss_ce: 0.007764
iteration 7802 : loss : 0.086961, loss_ce: 0.008321
iteration 7803 : loss : 0.030579, loss_ce: 0.009308
iteration 7804 : loss : 0.028555, loss_ce: 0.007847
iteration 7805 : loss : 0.039158, loss_ce: 0.010717
iteration 7806 : loss : 0.028675, loss_ce: 0.011424
iteration 7807 : loss : 0.029020, loss_ce: 0.007390
iteration 7808 : loss : 0.022082, loss_ce: 0.005948
iteration 7809 : loss : 0.029161, loss_ce: 0.010975
iteration 7810 : loss : 0.047150, loss_ce: 0.011627
iteration 7811 : loss : 0.025502, loss_ce: 0.007956
iteration 7812 : loss : 0.062037, loss_ce: 0.033060
 42%|███████████▊                | 84/200 [1:16:14<1:45:31, 54.58s/it]pred_sum 33897
gtsum tensor(39131, device='cuda:0')
iteration 7813 : loss : 0.029163, loss_ce: 0.011522
iteration 7814 : loss : 0.034682, loss_ce: 0.014358
iteration 7815 : loss : 0.027959, loss_ce: 0.009820
iteration 7816 : loss : 0.028152, loss_ce: 0.009756
iteration 7817 : loss : 0.031663, loss_ce: 0.010168
iteration 7818 : loss : 0.030948, loss_ce: 0.009796
iteration 7819 : loss : 0.032908, loss_ce: 0.009539
iteration 7820 : loss : 0.035164, loss_ce: 0.005349
iteration 7821 : loss : 0.082293, loss_ce: 0.011665
iteration 7822 : loss : 0.030985, loss_ce: 0.007962
iteration 7823 : loss : 0.039357, loss_ce: 0.016257
iteration 7824 : loss : 0.029171, loss_ce: 0.014742
iteration 7825 : loss : 0.034678, loss_ce: 0.013438
iteration 7826 : loss : 0.031777, loss_ce: 0.012554
iteration 7827 : loss : 0.033716, loss_ce: 0.013566
iteration 7828 : loss : 0.024744, loss_ce: 0.009893
iteration 7829 : loss : 0.040488, loss_ce: 0.011480
iteration 7830 : loss : 0.027807, loss_ce: 0.010219
iteration 7831 : loss : 0.033001, loss_ce: 0.013976
iteration 7832 : loss : 0.030958, loss_ce: 0.015084
iteration 7833 : loss : 0.031812, loss_ce: 0.011982
iteration 7834 : loss : 0.031441, loss_ce: 0.013131
iteration 7835 : loss : 0.025282, loss_ce: 0.012643
iteration 7836 : loss : 0.036288, loss_ce: 0.011040
iteration 7837 : loss : 0.027674, loss_ce: 0.011098
iteration 7838 : loss : 0.025067, loss_ce: 0.006713
iteration 7839 : loss : 0.027749, loss_ce: 0.010066
iteration 7840 : loss : 0.030187, loss_ce: 0.013810
iteration 7841 : loss : 0.034829, loss_ce: 0.008034
iteration 7842 : loss : 0.030701, loss_ce: 0.010267
iteration 7843 : loss : 0.027014, loss_ce: 0.013766
pred_sum 15246
gtsum tensor(15611, device='cuda:0')
iteration 7844 : loss : 0.025390, loss_ce: 0.008867
iteration 7845 : loss : 0.033934, loss_ce: 0.011740
iteration 7846 : loss : 0.029135, loss_ce: 0.009250
iteration 7847 : loss : 0.028821, loss_ce: 0.006542
iteration 7848 : loss : 0.065753, loss_ce: 0.010314
iteration 7849 : loss : 0.041374, loss_ce: 0.008857
iteration 7850 : loss : 0.030317, loss_ce: 0.012239
iteration 7851 : loss : 0.024881, loss_ce: 0.009676
iteration 7852 : loss : 0.041594, loss_ce: 0.013733
iteration 7853 : loss : 0.034673, loss_ce: 0.010025
iteration 7854 : loss : 0.086095, loss_ce: 0.005947
iteration 7855 : loss : 0.033465, loss_ce: 0.010165
iteration 7856 : loss : 0.033493, loss_ce: 0.009313
iteration 7857 : loss : 0.030977, loss_ce: 0.012599
iteration 7858 : loss : 0.035134, loss_ce: 0.017306
iteration 7859 : loss : 0.027342, loss_ce: 0.008011
iteration 7860 : loss : 0.030591, loss_ce: 0.009330
iteration 7861 : loss : 0.031113, loss_ce: 0.013046
iteration 7862 : loss : 0.029246, loss_ce: 0.005796
iteration 7863 : loss : 0.077036, loss_ce: 0.004861
iteration 7864 : loss : 0.070514, loss_ce: 0.004906
iteration 7865 : loss : 0.033560, loss_ce: 0.011043
iteration 7866 : loss : 0.031587, loss_ce: 0.009483
iteration 7867 : loss : 0.035338, loss_ce: 0.007377
iteration 7868 : loss : 0.030005, loss_ce: 0.008935
iteration 7869 : loss : 0.025843, loss_ce: 0.010762
iteration 7870 : loss : 0.028843, loss_ce: 0.009607
iteration 7871 : loss : 0.031140, loss_ce: 0.010050
iteration 7872 : loss : 0.080202, loss_ce: 0.004320
iteration 7873 : loss : 0.032545, loss_ce: 0.009386
iteration 7874 : loss : 0.032330, loss_ce: 0.007634
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 7875 : loss : 0.031928, loss_ce: 0.012493
iteration 7876 : loss : 0.026676, loss_ce: 0.008906
iteration 7877 : loss : 0.027302, loss_ce: 0.011835
iteration 7878 : loss : 0.029390, loss_ce: 0.009066
iteration 7879 : loss : 0.027371, loss_ce: 0.010583
iteration 7880 : loss : 0.032057, loss_ce: 0.008410
iteration 7881 : loss : 0.031470, loss_ce: 0.010892
iteration 7882 : loss : 0.027661, loss_ce: 0.004506
iteration 7883 : loss : 0.027941, loss_ce: 0.010710
iteration 7884 : loss : 0.029184, loss_ce: 0.005773
iteration 7885 : loss : 0.024751, loss_ce: 0.007233
iteration 7886 : loss : 0.029182, loss_ce: 0.012584
iteration 7887 : loss : 0.025601, loss_ce: 0.009294
iteration 7888 : loss : 0.028090, loss_ce: 0.011535
iteration 7889 : loss : 0.081414, loss_ce: 0.008975
iteration 7890 : loss : 0.027878, loss_ce: 0.009904
iteration 7891 : loss : 0.026006, loss_ce: 0.010291
iteration 7892 : loss : 0.081507, loss_ce: 0.010169
iteration 7893 : loss : 0.028813, loss_ce: 0.009781
iteration 7894 : loss : 0.046807, loss_ce: 0.006614
iteration 7895 : loss : 0.024577, loss_ce: 0.006602
iteration 7896 : loss : 0.029955, loss_ce: 0.007484
iteration 7897 : loss : 0.029419, loss_ce: 0.008346
iteration 7898 : loss : 0.026339, loss_ce: 0.009101
iteration 7899 : loss : 0.031300, loss_ce: 0.009672
iteration 7900 : loss : 0.081535, loss_ce: 0.007436
iteration 7901 : loss : 0.077260, loss_ce: 0.008011
iteration 7902 : loss : 0.039763, loss_ce: 0.009847
iteration 7903 : loss : 0.028055, loss_ce: 0.011467
iteration 7904 : loss : 0.024647, loss_ce: 0.008381
iteration 7905 : loss : 0.290959, loss_ce: 0.001893
 42%|███████████▉                | 85/200 [1:17:09<1:44:33, 54.55s/it]pred_sum 5414
gtsum tensor(5141, device='cuda:0')
iteration 7906 : loss : 0.036112, loss_ce: 0.010849
iteration 7907 : loss : 0.031451, loss_ce: 0.010612
iteration 7908 : loss : 0.025090, loss_ce: 0.004948
iteration 7909 : loss : 0.030988, loss_ce: 0.008738
iteration 7910 : loss : 0.027026, loss_ce: 0.009071
iteration 7911 : loss : 0.079335, loss_ce: 0.008728
iteration 7912 : loss : 0.034077, loss_ce: 0.009688
iteration 7913 : loss : 0.029771, loss_ce: 0.011549
iteration 7914 : loss : 0.031916, loss_ce: 0.011264
iteration 7915 : loss : 0.029751, loss_ce: 0.011218
iteration 7916 : loss : 0.031347, loss_ce: 0.006511
iteration 7917 : loss : 0.028169, loss_ce: 0.006964
iteration 7918 : loss : 0.027497, loss_ce: 0.009044
iteration 7919 : loss : 0.027797, loss_ce: 0.016303
iteration 7920 : loss : 0.029968, loss_ce: 0.008106
iteration 7921 : loss : 0.032463, loss_ce: 0.014880
iteration 7922 : loss : 0.032400, loss_ce: 0.008837
iteration 7923 : loss : 0.040727, loss_ce: 0.013856
iteration 7924 : loss : 0.026581, loss_ce: 0.009310
iteration 7925 : loss : 0.032015, loss_ce: 0.013301
iteration 7926 : loss : 0.025155, loss_ce: 0.011439
iteration 7927 : loss : 0.035505, loss_ce: 0.011077
iteration 7928 : loss : 0.034343, loss_ce: 0.010238
iteration 7929 : loss : 0.024456, loss_ce: 0.008020
iteration 7930 : loss : 0.025775, loss_ce: 0.009581
iteration 7931 : loss : 0.025625, loss_ce: 0.010810
iteration 7932 : loss : 0.025657, loss_ce: 0.008187
iteration 7933 : loss : 0.029340, loss_ce: 0.011802
iteration 7934 : loss : 0.028920, loss_ce: 0.009053
iteration 7935 : loss : 0.033682, loss_ce: 0.005908
iteration 7936 : loss : 0.022734, loss_ce: 0.007226
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 7937 : loss : 0.027914, loss_ce: 0.009963
iteration 7938 : loss : 0.025926, loss_ce: 0.007725
iteration 7939 : loss : 0.030985, loss_ce: 0.012500
iteration 7940 : loss : 0.035871, loss_ce: 0.010977
iteration 7941 : loss : 0.026254, loss_ce: 0.008750
iteration 7942 : loss : 0.030812, loss_ce: 0.009902
iteration 7943 : loss : 0.029940, loss_ce: 0.005122
iteration 7944 : loss : 0.030104, loss_ce: 0.008115
iteration 7945 : loss : 0.032954, loss_ce: 0.015373
iteration 7946 : loss : 0.030195, loss_ce: 0.008645
iteration 7947 : loss : 0.033535, loss_ce: 0.015050
iteration 7948 : loss : 0.038274, loss_ce: 0.013262
iteration 7949 : loss : 0.023858, loss_ce: 0.007136
iteration 7950 : loss : 0.029704, loss_ce: 0.008323
iteration 7951 : loss : 0.185075, loss_ce: 0.004056
iteration 7952 : loss : 0.085681, loss_ce: 0.005860
iteration 7953 : loss : 0.076342, loss_ce: 0.005467
iteration 7954 : loss : 0.028186, loss_ce: 0.008331
iteration 7955 : loss : 0.080548, loss_ce: 0.011030
iteration 7956 : loss : 0.031815, loss_ce: 0.008370
iteration 7957 : loss : 0.028799, loss_ce: 0.013087
iteration 7958 : loss : 0.026156, loss_ce: 0.009615
iteration 7959 : loss : 0.028429, loss_ce: 0.008104
iteration 7960 : loss : 0.034128, loss_ce: 0.010182
iteration 7961 : loss : 0.058574, loss_ce: 0.007574
iteration 7962 : loss : 0.034261, loss_ce: 0.009316
iteration 7963 : loss : 0.026421, loss_ce: 0.003474
iteration 7964 : loss : 0.032405, loss_ce: 0.010978
iteration 7965 : loss : 0.036410, loss_ce: 0.014191
iteration 7966 : loss : 0.029696, loss_ce: 0.009996
iteration 7967 : loss : 0.023484, loss_ce: 0.006956
pred_sum 24619
gtsum tensor(24629, device='cuda:0')
iteration 7968 : loss : 0.027675, loss_ce: 0.008928
iteration 7969 : loss : 0.029475, loss_ce: 0.013839
iteration 7970 : loss : 0.036090, loss_ce: 0.004061
iteration 7971 : loss : 0.033427, loss_ce: 0.010079
iteration 7972 : loss : 0.028467, loss_ce: 0.005828
iteration 7973 : loss : 0.022300, loss_ce: 0.006728
iteration 7974 : loss : 0.037577, loss_ce: 0.010584
iteration 7975 : loss : 0.028311, loss_ce: 0.008594
iteration 7976 : loss : 0.041161, loss_ce: 0.020410
iteration 7977 : loss : 0.033865, loss_ce: 0.016494
iteration 7978 : loss : 0.039705, loss_ce: 0.010313
iteration 7979 : loss : 0.036362, loss_ce: 0.013447
iteration 7980 : loss : 0.036379, loss_ce: 0.009942
iteration 7981 : loss : 0.029238, loss_ce: 0.013068
iteration 7982 : loss : 0.024458, loss_ce: 0.009751
iteration 7983 : loss : 0.032321, loss_ce: 0.014945
iteration 7984 : loss : 0.022013, loss_ce: 0.010146
iteration 7985 : loss : 0.027697, loss_ce: 0.008998
iteration 7986 : loss : 0.026612, loss_ce: 0.006890
iteration 7987 : loss : 0.027242, loss_ce: 0.009770
iteration 7988 : loss : 0.027789, loss_ce: 0.013112
iteration 7989 : loss : 0.027044, loss_ce: 0.008965
iteration 7990 : loss : 0.028225, loss_ce: 0.011967
iteration 7991 : loss : 0.030554, loss_ce: 0.010478
iteration 7992 : loss : 0.032998, loss_ce: 0.011210
iteration 7993 : loss : 0.028060, loss_ce: 0.008931
iteration 7994 : loss : 0.030071, loss_ce: 0.006464
iteration 7995 : loss : 0.068212, loss_ce: 0.010329
iteration 7996 : loss : 0.028053, loss_ce: 0.009637
iteration 7997 : loss : 0.030448, loss_ce: 0.010451
iteration 7998 : loss : 0.391621, loss_ce: 0.001383
 43%|████████████                | 86/200 [1:18:03<1:43:39, 54.56s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 7999 : loss : 0.026880, loss_ce: 0.013129
iteration 8000 : loss : 0.034345, loss_ce: 0.013564
iteration 8001 : loss : 0.035022, loss_ce: 0.007795
iteration 8002 : loss : 0.030234, loss_ce: 0.010918
iteration 8003 : loss : 0.041020, loss_ce: 0.009126
iteration 8004 : loss : 0.029827, loss_ce: 0.009865
iteration 8005 : loss : 0.039432, loss_ce: 0.015730
iteration 8006 : loss : 0.030326, loss_ce: 0.010137
iteration 8007 : loss : 0.024619, loss_ce: 0.006973
iteration 8008 : loss : 0.032590, loss_ce: 0.007626
iteration 8009 : loss : 0.028784, loss_ce: 0.012817
iteration 8010 : loss : 0.025010, loss_ce: 0.007214
iteration 8011 : loss : 0.031763, loss_ce: 0.007109
iteration 8012 : loss : 0.027172, loss_ce: 0.008430
iteration 8013 : loss : 0.022070, loss_ce: 0.008117
iteration 8014 : loss : 0.105525, loss_ce: 0.008683
iteration 8015 : loss : 0.027565, loss_ce: 0.008100
iteration 8016 : loss : 0.032106, loss_ce: 0.008023
iteration 8017 : loss : 0.038735, loss_ce: 0.010570
iteration 8018 : loss : 0.032075, loss_ce: 0.013289
iteration 8019 : loss : 0.029847, loss_ce: 0.010283
iteration 8020 : loss : 0.035420, loss_ce: 0.015830
iteration 8021 : loss : 0.030903, loss_ce: 0.012388
iteration 8022 : loss : 0.030729, loss_ce: 0.009565
iteration 8023 : loss : 0.081429, loss_ce: 0.007143
iteration 8024 : loss : 0.029596, loss_ce: 0.008312
iteration 8025 : loss : 0.031323, loss_ce: 0.011740
iteration 8026 : loss : 0.059403, loss_ce: 0.016855
iteration 8027 : loss : 0.074886, loss_ce: 0.009637
iteration 8028 : loss : 0.034431, loss_ce: 0.012476
iteration 8029 : loss : 0.026192, loss_ce: 0.011057
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 8030 : loss : 0.038199, loss_ce: 0.011276
iteration 8031 : loss : 0.048920, loss_ce: 0.013896
iteration 8032 : loss : 0.035458, loss_ce: 0.012705
iteration 8033 : loss : 0.038979, loss_ce: 0.014611
iteration 8034 : loss : 0.026600, loss_ce: 0.008209
iteration 8035 : loss : 0.031909, loss_ce: 0.014234
iteration 8036 : loss : 0.025692, loss_ce: 0.009645
iteration 8037 : loss : 0.031161, loss_ce: 0.009343
iteration 8038 : loss : 0.079802, loss_ce: 0.006955
iteration 8039 : loss : 0.029587, loss_ce: 0.009927
iteration 8040 : loss : 0.029891, loss_ce: 0.010113
iteration 8041 : loss : 0.029507, loss_ce: 0.009902
iteration 8042 : loss : 0.033076, loss_ce: 0.013582
iteration 8043 : loss : 0.023155, loss_ce: 0.006471
iteration 8044 : loss : 0.029897, loss_ce: 0.005951
iteration 8045 : loss : 0.034604, loss_ce: 0.010710
iteration 8046 : loss : 0.025546, loss_ce: 0.008350
iteration 8047 : loss : 0.032730, loss_ce: 0.018758
iteration 8048 : loss : 0.027781, loss_ce: 0.009750
iteration 8049 : loss : 0.078168, loss_ce: 0.009507
iteration 8050 : loss : 0.031329, loss_ce: 0.008257
iteration 8051 : loss : 0.025864, loss_ce: 0.008886
iteration 8052 : loss : 0.032936, loss_ce: 0.005026
iteration 8053 : loss : 0.028018, loss_ce: 0.005588
iteration 8054 : loss : 0.085803, loss_ce: 0.006986
iteration 8055 : loss : 0.028693, loss_ce: 0.009840
iteration 8056 : loss : 0.031515, loss_ce: 0.008778
iteration 8057 : loss : 0.033979, loss_ce: 0.010172
iteration 8058 : loss : 0.023525, loss_ce: 0.008515
iteration 8059 : loss : 0.024460, loss_ce: 0.009089
iteration 8060 : loss : 0.032505, loss_ce: 0.015395
pred_sum 34413
gtsum tensor(34051, device='cuda:0')
iteration 8061 : loss : 0.029256, loss_ce: 0.012113
iteration 8062 : loss : 0.031479, loss_ce: 0.011599
iteration 8063 : loss : 0.031283, loss_ce: 0.012890
iteration 8064 : loss : 0.026193, loss_ce: 0.009284
iteration 8065 : loss : 0.026244, loss_ce: 0.011067
iteration 8066 : loss : 0.029357, loss_ce: 0.012982
iteration 8067 : loss : 0.027111, loss_ce: 0.008203
iteration 8068 : loss : 0.031875, loss_ce: 0.006014
iteration 8069 : loss : 0.024778, loss_ce: 0.007525
iteration 8070 : loss : 0.028544, loss_ce: 0.010955
iteration 8071 : loss : 0.027994, loss_ce: 0.008259
iteration 8072 : loss : 0.033897, loss_ce: 0.011384
iteration 8073 : loss : 0.026043, loss_ce: 0.008622
iteration 8074 : loss : 0.050819, loss_ce: 0.008849
iteration 8075 : loss : 0.032522, loss_ce: 0.008664
iteration 8076 : loss : 0.032749, loss_ce: 0.005406
iteration 8077 : loss : 0.033723, loss_ce: 0.008388
iteration 8078 : loss : 0.030993, loss_ce: 0.012711
iteration 8079 : loss : 0.032479, loss_ce: 0.008355
iteration 8080 : loss : 0.034368, loss_ce: 0.011199
iteration 8081 : loss : 0.025984, loss_ce: 0.009938
iteration 8082 : loss : 0.026238, loss_ce: 0.011980
iteration 8083 : loss : 0.032371, loss_ce: 0.007105
iteration 8084 : loss : 0.030186, loss_ce: 0.009993
iteration 8085 : loss : 0.042495, loss_ce: 0.020362
iteration 8086 : loss : 0.029474, loss_ce: 0.009650
iteration 8087 : loss : 0.036947, loss_ce: 0.011769
iteration 8088 : loss : 0.037947, loss_ce: 0.011279
iteration 8089 : loss : 0.079869, loss_ce: 0.009228
iteration 8090 : loss : 0.025290, loss_ce: 0.006152
iteration 8091 : loss : 0.292496, loss_ce: 0.017179
 44%|████████████▏               | 87/200 [1:18:58<1:42:45, 54.56s/it]pred_sum 41247
gtsum tensor(42521, device='cuda:0')
iteration 8092 : loss : 0.025162, loss_ce: 0.008781
iteration 8093 : loss : 0.027829, loss_ce: 0.009393
iteration 8094 : loss : 0.027944, loss_ce: 0.009819
iteration 8095 : loss : 0.026980, loss_ce: 0.008652
iteration 8096 : loss : 0.027411, loss_ce: 0.012649
iteration 8097 : loss : 0.027615, loss_ce: 0.007822
iteration 8098 : loss : 0.031765, loss_ce: 0.010639
iteration 8099 : loss : 0.027255, loss_ce: 0.009396
iteration 8100 : loss : 0.041076, loss_ce: 0.007361
iteration 8101 : loss : 0.030758, loss_ce: 0.005535
iteration 8102 : loss : 0.036178, loss_ce: 0.012129
iteration 8103 : loss : 0.032696, loss_ce: 0.014076
iteration 8104 : loss : 0.038688, loss_ce: 0.008479
iteration 8105 : loss : 0.081375, loss_ce: 0.006186
iteration 8106 : loss : 0.081314, loss_ce: 0.013872
iteration 8107 : loss : 0.028491, loss_ce: 0.012202
iteration 8108 : loss : 0.031544, loss_ce: 0.011206
iteration 8109 : loss : 0.022733, loss_ce: 0.007237
iteration 8110 : loss : 0.039629, loss_ce: 0.007199
iteration 8111 : loss : 0.035157, loss_ce: 0.018927
iteration 8112 : loss : 0.027628, loss_ce: 0.006163
iteration 8113 : loss : 0.025298, loss_ce: 0.007301
iteration 8114 : loss : 0.025638, loss_ce: 0.004705
iteration 8115 : loss : 0.024365, loss_ce: 0.007361
iteration 8116 : loss : 0.033770, loss_ce: 0.009914
iteration 8117 : loss : 0.024310, loss_ce: 0.008936
iteration 8118 : loss : 0.030214, loss_ce: 0.011136
iteration 8119 : loss : 0.033574, loss_ce: 0.010550
iteration 8120 : loss : 0.030742, loss_ce: 0.008903
iteration 8121 : loss : 0.032167, loss_ce: 0.012208
iteration 8122 : loss : 0.028212, loss_ce: 0.012117
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 8123 : loss : 0.078028, loss_ce: 0.010391
iteration 8124 : loss : 0.025651, loss_ce: 0.009055
iteration 8125 : loss : 0.040194, loss_ce: 0.006320
iteration 8126 : loss : 0.023430, loss_ce: 0.007802
iteration 8127 : loss : 0.027488, loss_ce: 0.013138
iteration 8128 : loss : 0.028262, loss_ce: 0.011067
iteration 8129 : loss : 0.031635, loss_ce: 0.012855
iteration 8130 : loss : 0.023706, loss_ce: 0.004481
iteration 8131 : loss : 0.025276, loss_ce: 0.007609
iteration 8132 : loss : 0.029164, loss_ce: 0.011185
iteration 8133 : loss : 0.027972, loss_ce: 0.011106
iteration 8134 : loss : 0.035011, loss_ce: 0.014244
iteration 8135 : loss : 0.027649, loss_ce: 0.007572
iteration 8136 : loss : 0.026984, loss_ce: 0.008857
iteration 8137 : loss : 0.034133, loss_ce: 0.010193
iteration 8138 : loss : 0.027199, loss_ce: 0.010736
iteration 8139 : loss : 0.025195, loss_ce: 0.009585
iteration 8140 : loss : 0.028663, loss_ce: 0.006104
iteration 8141 : loss : 0.025000, loss_ce: 0.006824
iteration 8142 : loss : 0.023681, loss_ce: 0.008287
iteration 8143 : loss : 0.028044, loss_ce: 0.006671
iteration 8144 : loss : 0.029716, loss_ce: 0.010598
iteration 8145 : loss : 0.028922, loss_ce: 0.010462
iteration 8146 : loss : 0.025713, loss_ce: 0.006688
iteration 8147 : loss : 0.042122, loss_ce: 0.010936
iteration 8148 : loss : 0.030258, loss_ce: 0.014808
iteration 8149 : loss : 0.032421, loss_ce: 0.012352
iteration 8150 : loss : 0.030448, loss_ce: 0.011763
iteration 8151 : loss : 0.055994, loss_ce: 0.008068
iteration 8152 : loss : 0.033547, loss_ce: 0.010041
iteration 8153 : loss : 0.030775, loss_ce: 0.009685
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 8154 : loss : 0.126588, loss_ce: 0.003630
iteration 8155 : loss : 0.034432, loss_ce: 0.010490
iteration 8156 : loss : 0.031216, loss_ce: 0.011431
iteration 8157 : loss : 0.028091, loss_ce: 0.008723
iteration 8158 : loss : 0.036410, loss_ce: 0.015228
iteration 8159 : loss : 0.074010, loss_ce: 0.005756
iteration 8160 : loss : 0.028298, loss_ce: 0.011076
iteration 8161 : loss : 0.075940, loss_ce: 0.007211
iteration 8162 : loss : 0.028896, loss_ce: 0.009541
iteration 8163 : loss : 0.028459, loss_ce: 0.008381
iteration 8164 : loss : 0.025963, loss_ce: 0.006340
iteration 8165 : loss : 0.031858, loss_ce: 0.009655
iteration 8166 : loss : 0.030891, loss_ce: 0.010881
iteration 8167 : loss : 0.028497, loss_ce: 0.011299
iteration 8168 : loss : 0.026243, loss_ce: 0.008178
iteration 8169 : loss : 0.031994, loss_ce: 0.013419
iteration 8170 : loss : 0.025915, loss_ce: 0.009235
iteration 8171 : loss : 0.024495, loss_ce: 0.005447
iteration 8172 : loss : 0.039362, loss_ce: 0.009946
iteration 8173 : loss : 0.074342, loss_ce: 0.008023
iteration 8174 : loss : 0.030511, loss_ce: 0.006706
iteration 8175 : loss : 0.030297, loss_ce: 0.010165
iteration 8176 : loss : 0.028873, loss_ce: 0.010197
iteration 8177 : loss : 0.114407, loss_ce: 0.004924
iteration 8178 : loss : 0.028018, loss_ce: 0.014206
iteration 8179 : loss : 0.027976, loss_ce: 0.012902
iteration 8180 : loss : 0.031003, loss_ce: 0.011035
iteration 8181 : loss : 0.035043, loss_ce: 0.013667
iteration 8182 : loss : 0.031867, loss_ce: 0.012502
iteration 8183 : loss : 0.030109, loss_ce: 0.011951
iteration 8184 : loss : 0.075198, loss_ce: 0.012131
 44%|████████████▎               | 88/200 [1:19:52<1:41:50, 54.56s/it]pred_sum 49256
gtsum tensor(48370, device='cuda:0')
iteration 8185 : loss : 0.032079, loss_ce: 0.008036
iteration 8186 : loss : 0.030174, loss_ce: 0.012070
iteration 8187 : loss : 0.031149, loss_ce: 0.015121
iteration 8188 : loss : 0.029524, loss_ce: 0.009305
iteration 8189 : loss : 0.035650, loss_ce: 0.005068
iteration 8190 : loss : 0.031161, loss_ce: 0.012396
iteration 8191 : loss : 0.024451, loss_ce: 0.008752
iteration 8192 : loss : 0.030297, loss_ce: 0.011844
iteration 8193 : loss : 0.041132, loss_ce: 0.014214
iteration 8194 : loss : 0.035682, loss_ce: 0.009315
iteration 8195 : loss : 0.022525, loss_ce: 0.003263
iteration 8196 : loss : 0.024513, loss_ce: 0.008449
iteration 8197 : loss : 0.025930, loss_ce: 0.006983
iteration 8198 : loss : 0.075922, loss_ce: 0.006945
iteration 8199 : loss : 0.031306, loss_ce: 0.010439
iteration 8200 : loss : 0.079981, loss_ce: 0.007172
iteration 8201 : loss : 0.030074, loss_ce: 0.016957
iteration 8202 : loss : 0.024578, loss_ce: 0.009492
iteration 8203 : loss : 0.030102, loss_ce: 0.010167
iteration 8204 : loss : 0.024162, loss_ce: 0.007571
iteration 8205 : loss : 0.030585, loss_ce: 0.012350
iteration 8206 : loss : 0.075127, loss_ce: 0.006695
iteration 8207 : loss : 0.026064, loss_ce: 0.008382
iteration 8208 : loss : 0.022598, loss_ce: 0.009819
iteration 8209 : loss : 0.029141, loss_ce: 0.010417
iteration 8210 : loss : 0.025716, loss_ce: 0.007871
iteration 8211 : loss : 0.031048, loss_ce: 0.012790
iteration 8212 : loss : 0.023526, loss_ce: 0.008376
iteration 8213 : loss : 0.029867, loss_ce: 0.011282
iteration 8214 : loss : 0.079256, loss_ce: 0.007238
iteration 8215 : loss : 0.089252, loss_ce: 0.005039
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 8216 : loss : 0.037672, loss_ce: 0.011794
iteration 8217 : loss : 0.027507, loss_ce: 0.011455
iteration 8218 : loss : 0.030637, loss_ce: 0.011733
iteration 8219 : loss : 0.034556, loss_ce: 0.007063
iteration 8220 : loss : 0.040532, loss_ce: 0.009245
iteration 8221 : loss : 0.034525, loss_ce: 0.009836
iteration 8222 : loss : 0.076049, loss_ce: 0.007043
iteration 8223 : loss : 0.027238, loss_ce: 0.010315
iteration 8224 : loss : 0.031246, loss_ce: 0.011208
iteration 8225 : loss : 0.034548, loss_ce: 0.010979
iteration 8226 : loss : 0.030748, loss_ce: 0.009681
iteration 8227 : loss : 0.030218, loss_ce: 0.008527
iteration 8228 : loss : 0.030616, loss_ce: 0.008824
iteration 8229 : loss : 0.031679, loss_ce: 0.007281
iteration 8230 : loss : 0.028481, loss_ce: 0.006680
iteration 8231 : loss : 0.030979, loss_ce: 0.016084
iteration 8232 : loss : 0.027589, loss_ce: 0.013198
iteration 8233 : loss : 0.035286, loss_ce: 0.009920
iteration 8234 : loss : 0.029456, loss_ce: 0.012401
iteration 8235 : loss : 0.082435, loss_ce: 0.007771
iteration 8236 : loss : 0.028399, loss_ce: 0.015365
iteration 8237 : loss : 0.022312, loss_ce: 0.005894
iteration 8238 : loss : 0.028704, loss_ce: 0.007391
iteration 8239 : loss : 0.026329, loss_ce: 0.008834
iteration 8240 : loss : 0.034721, loss_ce: 0.012803
iteration 8241 : loss : 0.032847, loss_ce: 0.007972
iteration 8242 : loss : 0.026019, loss_ce: 0.007279
iteration 8243 : loss : 0.029248, loss_ce: 0.010683
iteration 8244 : loss : 0.028726, loss_ce: 0.011062
iteration 8245 : loss : 0.088034, loss_ce: 0.002927
iteration 8246 : loss : 0.026116, loss_ce: 0.009652
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 8247 : loss : 0.032098, loss_ce: 0.012781
iteration 8248 : loss : 0.031192, loss_ce: 0.009807
iteration 8249 : loss : 0.028820, loss_ce: 0.010105
iteration 8250 : loss : 0.030004, loss_ce: 0.006839
iteration 8251 : loss : 0.027287, loss_ce: 0.008565
iteration 8252 : loss : 0.027346, loss_ce: 0.007814
iteration 8253 : loss : 0.025645, loss_ce: 0.010710
iteration 8254 : loss : 0.028733, loss_ce: 0.010170
iteration 8255 : loss : 0.029442, loss_ce: 0.011744
iteration 8256 : loss : 0.018944, loss_ce: 0.004434
iteration 8257 : loss : 0.029450, loss_ce: 0.010611
iteration 8258 : loss : 0.025155, loss_ce: 0.006891
iteration 8259 : loss : 0.024670, loss_ce: 0.005341
iteration 8260 : loss : 0.028005, loss_ce: 0.012135
iteration 8261 : loss : 0.027049, loss_ce: 0.011833
iteration 8262 : loss : 0.028509, loss_ce: 0.006878
iteration 8263 : loss : 0.078313, loss_ce: 0.010687
iteration 8264 : loss : 0.034887, loss_ce: 0.006380
iteration 8265 : loss : 0.029381, loss_ce: 0.007182
iteration 8266 : loss : 0.035792, loss_ce: 0.018141
iteration 8267 : loss : 0.032598, loss_ce: 0.011851
iteration 8268 : loss : 0.032025, loss_ce: 0.010772
iteration 8269 : loss : 0.027184, loss_ce: 0.009970
iteration 8270 : loss : 0.033967, loss_ce: 0.014291
iteration 8271 : loss : 0.026132, loss_ce: 0.010649
iteration 8272 : loss : 0.030033, loss_ce: 0.012363
iteration 8273 : loss : 0.024440, loss_ce: 0.008129
iteration 8274 : loss : 0.032679, loss_ce: 0.014414
iteration 8275 : loss : 0.029351, loss_ce: 0.009288
iteration 8276 : loss : 0.026650, loss_ce: 0.011258
iteration 8277 : loss : 0.031373, loss_ce: 0.018068
 44%|████████████▍               | 89/200 [1:20:47<1:40:56, 54.56s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 8278 : loss : 0.025218, loss_ce: 0.010762
iteration 8279 : loss : 0.022903, loss_ce: 0.008535
iteration 8280 : loss : 0.029968, loss_ce: 0.010501
iteration 8281 : loss : 0.026171, loss_ce: 0.010908
iteration 8282 : loss : 0.027548, loss_ce: 0.009441
iteration 8283 : loss : 0.031395, loss_ce: 0.008909
iteration 8284 : loss : 0.080907, loss_ce: 0.009275
iteration 8285 : loss : 0.023796, loss_ce: 0.007957
iteration 8286 : loss : 0.032382, loss_ce: 0.018447
iteration 8287 : loss : 0.027509, loss_ce: 0.012200
iteration 8288 : loss : 0.027476, loss_ce: 0.008576
iteration 8289 : loss : 0.026045, loss_ce: 0.005928
iteration 8290 : loss : 0.027821, loss_ce: 0.006399
iteration 8291 : loss : 0.026934, loss_ce: 0.008725
iteration 8292 : loss : 0.027728, loss_ce: 0.009851
iteration 8293 : loss : 0.035039, loss_ce: 0.013419
iteration 8294 : loss : 0.025784, loss_ce: 0.008004
iteration 8295 : loss : 0.028505, loss_ce: 0.006380
iteration 8296 : loss : 0.031007, loss_ce: 0.005512
iteration 8297 : loss : 0.026454, loss_ce: 0.010959
iteration 8298 : loss : 0.032649, loss_ce: 0.008706
iteration 8299 : loss : 0.077738, loss_ce: 0.008155
iteration 8300 : loss : 0.032777, loss_ce: 0.007477
iteration 8301 : loss : 0.030543, loss_ce: 0.014104
iteration 8302 : loss : 0.026706, loss_ce: 0.007488
iteration 8303 : loss : 0.023434, loss_ce: 0.008802
iteration 8304 : loss : 0.073274, loss_ce: 0.005775
iteration 8305 : loss : 0.030808, loss_ce: 0.014391
iteration 8306 : loss : 0.032181, loss_ce: 0.009292
iteration 8307 : loss : 0.023590, loss_ce: 0.010785
iteration 8308 : loss : 0.054507, loss_ce: 0.007555
pred_sum 45180
gtsum tensor(44022, device='cuda:0')
iteration 8309 : loss : 0.029833, loss_ce: 0.012881
iteration 8310 : loss : 0.025241, loss_ce: 0.010543
iteration 8311 : loss : 0.023542, loss_ce: 0.008141
iteration 8312 : loss : 0.180859, loss_ce: 0.003515
iteration 8313 : loss : 0.077755, loss_ce: 0.006090
iteration 8314 : loss : 0.033080, loss_ce: 0.014045
iteration 8315 : loss : 0.028773, loss_ce: 0.010147
iteration 8316 : loss : 0.030478, loss_ce: 0.011709
iteration 8317 : loss : 0.032835, loss_ce: 0.010513
iteration 8318 : loss : 0.057262, loss_ce: 0.012336
iteration 8319 : loss : 0.024264, loss_ce: 0.008302
iteration 8320 : loss : 0.074296, loss_ce: 0.004525
iteration 8321 : loss : 0.024967, loss_ce: 0.008675
iteration 8322 : loss : 0.027765, loss_ce: 0.009106
iteration 8323 : loss : 0.036359, loss_ce: 0.011972
iteration 8324 : loss : 0.031903, loss_ce: 0.006171
iteration 8325 : loss : 0.022519, loss_ce: 0.009116
iteration 8326 : loss : 0.077974, loss_ce: 0.007223
iteration 8327 : loss : 0.030598, loss_ce: 0.012714
iteration 8328 : loss : 0.027854, loss_ce: 0.008692
iteration 8329 : loss : 0.081077, loss_ce: 0.006449
iteration 8330 : loss : 0.026972, loss_ce: 0.008481
iteration 8331 : loss : 0.026854, loss_ce: 0.007657
iteration 8332 : loss : 0.025532, loss_ce: 0.010341
iteration 8333 : loss : 0.024808, loss_ce: 0.008274
iteration 8334 : loss : 0.030082, loss_ce: 0.006975
iteration 8335 : loss : 0.022369, loss_ce: 0.005896
iteration 8336 : loss : 0.033766, loss_ce: 0.008536
iteration 8337 : loss : 0.028541, loss_ce: 0.008828
iteration 8338 : loss : 0.046438, loss_ce: 0.007667
iteration 8339 : loss : 0.028711, loss_ce: 0.014912
pred_sum 57628
gtsum tensor(56256, device='cuda:0')
iteration 8340 : loss : 0.026783, loss_ce: 0.010512
iteration 8341 : loss : 0.029415, loss_ce: 0.009555
iteration 8342 : loss : 0.079789, loss_ce: 0.008982
iteration 8343 : loss : 0.028530, loss_ce: 0.006740
iteration 8344 : loss : 0.027185, loss_ce: 0.007822
iteration 8345 : loss : 0.028712, loss_ce: 0.011681
iteration 8346 : loss : 0.037916, loss_ce: 0.011363
iteration 8347 : loss : 0.028953, loss_ce: 0.010720
iteration 8348 : loss : 0.029868, loss_ce: 0.005674
iteration 8349 : loss : 0.030567, loss_ce: 0.006661
iteration 8350 : loss : 0.028950, loss_ce: 0.009668
iteration 8351 : loss : 0.028071, loss_ce: 0.007696
iteration 8352 : loss : 0.080355, loss_ce: 0.009551
iteration 8353 : loss : 0.037840, loss_ce: 0.008717
iteration 8354 : loss : 0.027706, loss_ce: 0.008625
iteration 8355 : loss : 0.028623, loss_ce: 0.009929
iteration 8356 : loss : 0.030514, loss_ce: 0.010692
iteration 8357 : loss : 0.028113, loss_ce: 0.008673
iteration 8358 : loss : 0.030421, loss_ce: 0.016435
iteration 8359 : loss : 0.039671, loss_ce: 0.011092
iteration 8360 : loss : 0.025451, loss_ce: 0.013105
iteration 8361 : loss : 0.032469, loss_ce: 0.009800
iteration 8362 : loss : 0.029030, loss_ce: 0.010335
iteration 8363 : loss : 0.027685, loss_ce: 0.011733
iteration 8364 : loss : 0.030073, loss_ce: 0.011960
iteration 8365 : loss : 0.028155, loss_ce: 0.007579
iteration 8366 : loss : 0.026146, loss_ce: 0.010482
iteration 8367 : loss : 0.051208, loss_ce: 0.004611
iteration 8368 : loss : 0.030375, loss_ce: 0.015969
iteration 8369 : loss : 0.028436, loss_ce: 0.009289
iteration 8370 : loss : 0.133430, loss_ce: 0.020870
 45%|████████████▌               | 90/200 [1:21:42<1:40:02, 54.57s/it]pred_sum 42916
gtsum tensor(41646, device='cuda:0')
iteration 8371 : loss : 0.024562, loss_ce: 0.006125
iteration 8372 : loss : 0.032284, loss_ce: 0.014152
iteration 8373 : loss : 0.024030, loss_ce: 0.010503
iteration 8374 : loss : 0.029536, loss_ce: 0.009259
iteration 8375 : loss : 0.024820, loss_ce: 0.013573
iteration 8376 : loss : 0.030836, loss_ce: 0.011921
iteration 8377 : loss : 0.037285, loss_ce: 0.014777
iteration 8378 : loss : 0.025326, loss_ce: 0.007918
iteration 8379 : loss : 0.032586, loss_ce: 0.007380
iteration 8380 : loss : 0.026503, loss_ce: 0.008330
iteration 8381 : loss : 0.028539, loss_ce: 0.008706
iteration 8382 : loss : 0.034418, loss_ce: 0.010173
iteration 8383 : loss : 0.026723, loss_ce: 0.011198
iteration 8384 : loss : 0.080575, loss_ce: 0.007858
iteration 8385 : loss : 0.074495, loss_ce: 0.007770
iteration 8386 : loss : 0.036660, loss_ce: 0.013833
iteration 8387 : loss : 0.030620, loss_ce: 0.011155
iteration 8388 : loss : 0.030844, loss_ce: 0.009204
iteration 8389 : loss : 0.021860, loss_ce: 0.002925
iteration 8390 : loss : 0.033181, loss_ce: 0.010692
iteration 8391 : loss : 0.024754, loss_ce: 0.009796
iteration 8392 : loss : 0.027314, loss_ce: 0.009093
iteration 8393 : loss : 0.030290, loss_ce: 0.006570
iteration 8394 : loss : 0.027823, loss_ce: 0.011860
iteration 8395 : loss : 0.027768, loss_ce: 0.008758
iteration 8396 : loss : 0.029364, loss_ce: 0.009278
iteration 8397 : loss : 0.029556, loss_ce: 0.007409
iteration 8398 : loss : 0.048152, loss_ce: 0.007774
iteration 8399 : loss : 0.030733, loss_ce: 0.013197
iteration 8400 : loss : 0.025490, loss_ce: 0.006851
iteration 8401 : loss : 0.034533, loss_ce: 0.011536
pred_sum 27211
gtsum tensor(27484, device='cuda:0')
iteration 8402 : loss : 0.022991, loss_ce: 0.005688
iteration 8403 : loss : 0.025032, loss_ce: 0.007002
iteration 8404 : loss : 0.035762, loss_ce: 0.010337
iteration 8405 : loss : 0.029866, loss_ce: 0.012879
iteration 8406 : loss : 0.045537, loss_ce: 0.009363
iteration 8407 : loss : 0.028985, loss_ce: 0.010138
iteration 8408 : loss : 0.031706, loss_ce: 0.011354
iteration 8409 : loss : 0.030305, loss_ce: 0.014205
iteration 8410 : loss : 0.028304, loss_ce: 0.010059
iteration 8411 : loss : 0.033007, loss_ce: 0.013833
iteration 8412 : loss : 0.029713, loss_ce: 0.009470
iteration 8413 : loss : 0.023235, loss_ce: 0.007872
iteration 8414 : loss : 0.038779, loss_ce: 0.008767
iteration 8415 : loss : 0.021368, loss_ce: 0.004915
iteration 8416 : loss : 0.034158, loss_ce: 0.012547
iteration 8417 : loss : 0.023980, loss_ce: 0.010151
iteration 8418 : loss : 0.021364, loss_ce: 0.006001
iteration 8419 : loss : 0.033209, loss_ce: 0.006672
iteration 8420 : loss : 0.025406, loss_ce: 0.006075
iteration 8421 : loss : 0.025554, loss_ce: 0.008991
iteration 8422 : loss : 0.030762, loss_ce: 0.011944
iteration 8423 : loss : 0.034104, loss_ce: 0.012273
iteration 8424 : loss : 0.023571, loss_ce: 0.009006
iteration 8425 : loss : 0.029444, loss_ce: 0.012949
iteration 8426 : loss : 0.025277, loss_ce: 0.005838
iteration 8427 : loss : 0.031544, loss_ce: 0.009887
iteration 8428 : loss : 0.032411, loss_ce: 0.010688
iteration 8429 : loss : 0.081885, loss_ce: 0.011107
iteration 8430 : loss : 0.030715, loss_ce: 0.011194
iteration 8431 : loss : 0.025569, loss_ce: 0.007096
iteration 8432 : loss : 0.034668, loss_ce: 0.012599
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 8433 : loss : 0.028826, loss_ce: 0.011973
iteration 8434 : loss : 0.038664, loss_ce: 0.007424
iteration 8435 : loss : 0.028626, loss_ce: 0.009021
iteration 8436 : loss : 0.027357, loss_ce: 0.009908
iteration 8437 : loss : 0.035141, loss_ce: 0.008868
iteration 8438 : loss : 0.025763, loss_ce: 0.006857
iteration 8439 : loss : 0.080619, loss_ce: 0.004793
iteration 8440 : loss : 0.031753, loss_ce: 0.009298
iteration 8441 : loss : 0.027136, loss_ce: 0.010769
iteration 8442 : loss : 0.030035, loss_ce: 0.012486
iteration 8443 : loss : 0.030011, loss_ce: 0.009017
iteration 8444 : loss : 0.025253, loss_ce: 0.008708
iteration 8445 : loss : 0.029567, loss_ce: 0.013556
iteration 8446 : loss : 0.023907, loss_ce: 0.007429
iteration 8447 : loss : 0.026719, loss_ce: 0.011001
iteration 8448 : loss : 0.023430, loss_ce: 0.008852
iteration 8449 : loss : 0.029795, loss_ce: 0.007993
iteration 8450 : loss : 0.080422, loss_ce: 0.007839
iteration 8451 : loss : 0.027642, loss_ce: 0.007301
iteration 8452 : loss : 0.034912, loss_ce: 0.013877
iteration 8453 : loss : 0.035730, loss_ce: 0.012696
iteration 8454 : loss : 0.027100, loss_ce: 0.003623
iteration 8455 : loss : 0.029856, loss_ce: 0.016004
iteration 8456 : loss : 0.031480, loss_ce: 0.007527
iteration 8457 : loss : 0.028444, loss_ce: 0.011979
iteration 8458 : loss : 0.029389, loss_ce: 0.012558
iteration 8459 : loss : 0.029254, loss_ce: 0.012922
iteration 8460 : loss : 0.034301, loss_ce: 0.010132
iteration 8461 : loss : 0.088204, loss_ce: 0.005974
iteration 8462 : loss : 0.026439, loss_ce: 0.007864
iteration 8463 : loss : 0.088028, loss_ce: 0.016607
 46%|████████████▋               | 91/200 [1:22:36<1:39:09, 54.58s/it]pred_sum 17602
gtsum tensor(18193, device='cuda:0')
iteration 8464 : loss : 0.037496, loss_ce: 0.011869
iteration 8465 : loss : 0.029962, loss_ce: 0.009048
iteration 8466 : loss : 0.027166, loss_ce: 0.006775
iteration 8467 : loss : 0.027629, loss_ce: 0.010670
iteration 8468 : loss : 0.030648, loss_ce: 0.015138
iteration 8469 : loss : 0.032363, loss_ce: 0.010456
iteration 8470 : loss : 0.028819, loss_ce: 0.009429
iteration 8471 : loss : 0.024339, loss_ce: 0.006812
iteration 8472 : loss : 0.028622, loss_ce: 0.009879
iteration 8473 : loss : 0.024169, loss_ce: 0.010586
iteration 8474 : loss : 0.068066, loss_ce: 0.006693
iteration 8475 : loss : 0.024904, loss_ce: 0.012355
iteration 8476 : loss : 0.082258, loss_ce: 0.005669
iteration 8477 : loss : 0.027042, loss_ce: 0.009484
iteration 8478 : loss : 0.082659, loss_ce: 0.011600
iteration 8479 : loss : 0.024796, loss_ce: 0.009162
iteration 8480 : loss : 0.032524, loss_ce: 0.009320
iteration 8481 : loss : 0.032980, loss_ce: 0.008894
iteration 8482 : loss : 0.033745, loss_ce: 0.010581
iteration 8483 : loss : 0.029110, loss_ce: 0.012364
iteration 8484 : loss : 0.079343, loss_ce: 0.006643
iteration 8485 : loss : 0.025886, loss_ce: 0.008922
iteration 8486 : loss : 0.028368, loss_ce: 0.010235
iteration 8487 : loss : 0.029075, loss_ce: 0.007582
iteration 8488 : loss : 0.024466, loss_ce: 0.006488
iteration 8489 : loss : 0.024965, loss_ce: 0.010106
iteration 8490 : loss : 0.029021, loss_ce: 0.009281
iteration 8491 : loss : 0.027891, loss_ce: 0.011033
iteration 8492 : loss : 0.034447, loss_ce: 0.009747
iteration 8493 : loss : 0.046021, loss_ce: 0.011216
iteration 8494 : loss : 0.028626, loss_ce: 0.007596
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 8495 : loss : 0.025187, loss_ce: 0.009757
iteration 8496 : loss : 0.025429, loss_ce: 0.006971
iteration 8497 : loss : 0.076336, loss_ce: 0.005371
iteration 8498 : loss : 0.026746, loss_ce: 0.010402
iteration 8499 : loss : 0.037995, loss_ce: 0.009055
iteration 8500 : loss : 0.027160, loss_ce: 0.009665
iteration 8501 : loss : 0.030676, loss_ce: 0.008622
iteration 8502 : loss : 0.028796, loss_ce: 0.009881
iteration 8503 : loss : 0.077444, loss_ce: 0.010481
iteration 8504 : loss : 0.075922, loss_ce: 0.008092
iteration 8505 : loss : 0.028547, loss_ce: 0.010671
iteration 8506 : loss : 0.023511, loss_ce: 0.005735
iteration 8507 : loss : 0.029462, loss_ce: 0.012644
iteration 8508 : loss : 0.031693, loss_ce: 0.013275
iteration 8509 : loss : 0.027079, loss_ce: 0.012025
iteration 8510 : loss : 0.025709, loss_ce: 0.010237
iteration 8511 : loss : 0.027257, loss_ce: 0.006808
iteration 8512 : loss : 0.077783, loss_ce: 0.008116
iteration 8513 : loss : 0.023201, loss_ce: 0.006859
iteration 8514 : loss : 0.027654, loss_ce: 0.010454
iteration 8515 : loss : 0.055689, loss_ce: 0.005336
iteration 8516 : loss : 0.034341, loss_ce: 0.006358
iteration 8517 : loss : 0.038807, loss_ce: 0.007501
iteration 8518 : loss : 0.027656, loss_ce: 0.006585
iteration 8519 : loss : 0.026071, loss_ce: 0.011457
iteration 8520 : loss : 0.032135, loss_ce: 0.010766
iteration 8521 : loss : 0.032377, loss_ce: 0.011864
iteration 8522 : loss : 0.032628, loss_ce: 0.010566
iteration 8523 : loss : 0.032678, loss_ce: 0.010776
iteration 8524 : loss : 0.027380, loss_ce: 0.012449
iteration 8525 : loss : 0.134482, loss_ce: 0.002284
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 8526 : loss : 0.029704, loss_ce: 0.008789
iteration 8527 : loss : 0.027716, loss_ce: 0.009849
iteration 8528 : loss : 0.033441, loss_ce: 0.012016
iteration 8529 : loss : 0.029565, loss_ce: 0.008569
iteration 8530 : loss : 0.036909, loss_ce: 0.014123
iteration 8531 : loss : 0.080283, loss_ce: 0.012352
iteration 8532 : loss : 0.034549, loss_ce: 0.015340
iteration 8533 : loss : 0.026981, loss_ce: 0.009246
iteration 8534 : loss : 0.033744, loss_ce: 0.011819
iteration 8535 : loss : 0.028849, loss_ce: 0.013115
iteration 8536 : loss : 0.031714, loss_ce: 0.014191
iteration 8537 : loss : 0.028771, loss_ce: 0.011770
iteration 8538 : loss : 0.034205, loss_ce: 0.010896
iteration 8539 : loss : 0.077831, loss_ce: 0.008387
iteration 8540 : loss : 0.028947, loss_ce: 0.010345
iteration 8541 : loss : 0.030523, loss_ce: 0.010436
iteration 8542 : loss : 0.034133, loss_ce: 0.015627
iteration 8543 : loss : 0.035125, loss_ce: 0.011589
iteration 8544 : loss : 0.027826, loss_ce: 0.010743
iteration 8545 : loss : 0.025913, loss_ce: 0.010543
iteration 8546 : loss : 0.026200, loss_ce: 0.008577
iteration 8547 : loss : 0.028023, loss_ce: 0.012569
iteration 8548 : loss : 0.027998, loss_ce: 0.008224
iteration 8549 : loss : 0.031354, loss_ce: 0.009743
iteration 8550 : loss : 0.028466, loss_ce: 0.007812
iteration 8551 : loss : 0.031899, loss_ce: 0.008121
iteration 8552 : loss : 0.038034, loss_ce: 0.005639
iteration 8553 : loss : 0.076251, loss_ce: 0.007587
iteration 8554 : loss : 0.023500, loss_ce: 0.008565
iteration 8555 : loss : 0.026646, loss_ce: 0.009500
iteration 8556 : loss : 0.388983, loss_ce: 0.000523
 46%|████████████▉               | 92/200 [1:23:31<1:38:15, 54.59s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 8557 : loss : 0.031041, loss_ce: 0.011799
iteration 8558 : loss : 0.051575, loss_ce: 0.008697
iteration 8559 : loss : 0.030783, loss_ce: 0.009012
iteration 8560 : loss : 0.035254, loss_ce: 0.012984
iteration 8561 : loss : 0.077997, loss_ce: 0.004221
iteration 8562 : loss : 0.029814, loss_ce: 0.010690
iteration 8563 : loss : 0.029175, loss_ce: 0.006697
iteration 8564 : loss : 0.027919, loss_ce: 0.010813
iteration 8565 : loss : 0.078058, loss_ce: 0.008847
iteration 8566 : loss : 0.027296, loss_ce: 0.008679
iteration 8567 : loss : 0.024702, loss_ce: 0.009842
iteration 8568 : loss : 0.029749, loss_ce: 0.008791
iteration 8569 : loss : 0.030380, loss_ce: 0.010449
iteration 8570 : loss : 0.025976, loss_ce: 0.007236
iteration 8571 : loss : 0.025754, loss_ce: 0.008720
iteration 8572 : loss : 0.026021, loss_ce: 0.008936
iteration 8573 : loss : 0.026746, loss_ce: 0.010694
iteration 8574 : loss : 0.024106, loss_ce: 0.006353
iteration 8575 : loss : 0.021181, loss_ce: 0.004881
iteration 8576 : loss : 0.038224, loss_ce: 0.006421
iteration 8577 : loss : 0.024032, loss_ce: 0.007247
iteration 8578 : loss : 0.045337, loss_ce: 0.008073
iteration 8579 : loss : 0.029745, loss_ce: 0.012911
iteration 8580 : loss : 0.030784, loss_ce: 0.006289
iteration 8581 : loss : 0.027976, loss_ce: 0.006459
iteration 8582 : loss : 0.027291, loss_ce: 0.008344
iteration 8583 : loss : 0.027989, loss_ce: 0.009908
iteration 8584 : loss : 0.023513, loss_ce: 0.007746
iteration 8585 : loss : 0.029709, loss_ce: 0.008376
iteration 8586 : loss : 0.025642, loss_ce: 0.011054
iteration 8587 : loss : 0.024209, loss_ce: 0.011293
pred_sum 498
gtsum tensor(495, device='cuda:0')
iteration 8588 : loss : 0.023927, loss_ce: 0.006015
iteration 8589 : loss : 0.031216, loss_ce: 0.009288
iteration 8590 : loss : 0.076186, loss_ce: 0.006628
iteration 8591 : loss : 0.030650, loss_ce: 0.009608
iteration 8592 : loss : 0.031926, loss_ce: 0.010806
iteration 8593 : loss : 0.030040, loss_ce: 0.012184
iteration 8594 : loss : 0.028532, loss_ce: 0.013577
iteration 8595 : loss : 0.033512, loss_ce: 0.009273
iteration 8596 : loss : 0.023486, loss_ce: 0.006874
iteration 8597 : loss : 0.033470, loss_ce: 0.008822
iteration 8598 : loss : 0.027191, loss_ce: 0.009284
iteration 8599 : loss : 0.027137, loss_ce: 0.008658
iteration 8600 : loss : 0.026525, loss_ce: 0.004947
iteration 8601 : loss : 0.231728, loss_ce: 0.005173
iteration 8602 : loss : 0.026740, loss_ce: 0.006983
iteration 8603 : loss : 0.022923, loss_ce: 0.008236
iteration 8604 : loss : 0.025150, loss_ce: 0.007776
iteration 8605 : loss : 0.031621, loss_ce: 0.009224
iteration 8606 : loss : 0.027429, loss_ce: 0.006141
iteration 8607 : loss : 0.025022, loss_ce: 0.011639
iteration 8608 : loss : 0.024545, loss_ce: 0.009600
iteration 8609 : loss : 0.028222, loss_ce: 0.014834
iteration 8610 : loss : 0.025756, loss_ce: 0.008771
iteration 8611 : loss : 0.022145, loss_ce: 0.004315
iteration 8612 : loss : 0.023395, loss_ce: 0.008787
iteration 8613 : loss : 0.026131, loss_ce: 0.010109
iteration 8614 : loss : 0.023579, loss_ce: 0.010309
iteration 8615 : loss : 0.032226, loss_ce: 0.009391
iteration 8616 : loss : 0.025837, loss_ce: 0.011484
iteration 8617 : loss : 0.027382, loss_ce: 0.011544
iteration 8618 : loss : 0.027658, loss_ce: 0.007096
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 8619 : loss : 0.027287, loss_ce: 0.007749
iteration 8620 : loss : 0.027829, loss_ce: 0.008401
iteration 8621 : loss : 0.029920, loss_ce: 0.013060
iteration 8622 : loss : 0.027088, loss_ce: 0.007876
iteration 8623 : loss : 0.027782, loss_ce: 0.011076
iteration 8624 : loss : 0.025911, loss_ce: 0.009021
iteration 8625 : loss : 0.030486, loss_ce: 0.009178
iteration 8626 : loss : 0.030444, loss_ce: 0.013282
iteration 8627 : loss : 0.023750, loss_ce: 0.008423
iteration 8628 : loss : 0.026779, loss_ce: 0.008186
iteration 8629 : loss : 0.026029, loss_ce: 0.011875
iteration 8630 : loss : 0.029113, loss_ce: 0.009141
iteration 8631 : loss : 0.026364, loss_ce: 0.008334
iteration 8632 : loss : 0.025061, loss_ce: 0.009445
iteration 8633 : loss : 0.025872, loss_ce: 0.010322
iteration 8634 : loss : 0.038202, loss_ce: 0.009798
iteration 8635 : loss : 0.028167, loss_ce: 0.009793
iteration 8636 : loss : 0.024678, loss_ce: 0.007249
iteration 8637 : loss : 0.022524, loss_ce: 0.005589
iteration 8638 : loss : 0.026062, loss_ce: 0.009731
iteration 8639 : loss : 0.027660, loss_ce: 0.009848
iteration 8640 : loss : 0.024169, loss_ce: 0.009364
iteration 8641 : loss : 0.028459, loss_ce: 0.014956
iteration 8642 : loss : 0.037121, loss_ce: 0.009487
iteration 8643 : loss : 0.034322, loss_ce: 0.013073
iteration 8644 : loss : 0.021372, loss_ce: 0.006007
iteration 8645 : loss : 0.028592, loss_ce: 0.011876
iteration 8646 : loss : 0.025832, loss_ce: 0.012251
iteration 8647 : loss : 0.024610, loss_ce: 0.009462
iteration 8648 : loss : 0.021498, loss_ce: 0.007203
iteration 8649 : loss : 0.233655, loss_ce: 0.007688
 46%|█████████████               | 93/200 [1:24:25<1:37:17, 54.55s/it]pred_sum 144
gtsum tensor(136, device='cuda:0')
iteration 8650 : loss : 0.026498, loss_ce: 0.006794
iteration 8651 : loss : 0.027706, loss_ce: 0.013024
iteration 8652 : loss : 0.028285, loss_ce: 0.008516
iteration 8653 : loss : 0.027068, loss_ce: 0.011517
iteration 8654 : loss : 0.023990, loss_ce: 0.009851
iteration 8655 : loss : 0.027268, loss_ce: 0.013152
iteration 8656 : loss : 0.031175, loss_ce: 0.010178
iteration 8657 : loss : 0.026940, loss_ce: 0.010675
iteration 8658 : loss : 0.018151, loss_ce: 0.006009
iteration 8659 : loss : 0.025254, loss_ce: 0.007340
iteration 8660 : loss : 0.080667, loss_ce: 0.010170
iteration 8661 : loss : 0.029146, loss_ce: 0.010524
iteration 8662 : loss : 0.026419, loss_ce: 0.009999
iteration 8663 : loss : 0.037696, loss_ce: 0.008198
iteration 8664 : loss : 0.029357, loss_ce: 0.013651
iteration 8665 : loss : 0.078096, loss_ce: 0.007068
iteration 8666 : loss : 0.030867, loss_ce: 0.009850
iteration 8667 : loss : 0.025340, loss_ce: 0.010954
iteration 8668 : loss : 0.030930, loss_ce: 0.009433
iteration 8669 : loss : 0.024274, loss_ce: 0.007444
iteration 8670 : loss : 0.024428, loss_ce: 0.011120
iteration 8671 : loss : 0.026527, loss_ce: 0.010364
iteration 8672 : loss : 0.027764, loss_ce: 0.009425
iteration 8673 : loss : 0.027614, loss_ce: 0.011165
iteration 8674 : loss : 0.028317, loss_ce: 0.008637
iteration 8675 : loss : 0.079430, loss_ce: 0.008571
iteration 8676 : loss : 0.028120, loss_ce: 0.008226
iteration 8677 : loss : 0.028582, loss_ce: 0.007680
iteration 8678 : loss : 0.026827, loss_ce: 0.009061
iteration 8679 : loss : 0.028548, loss_ce: 0.010915
iteration 8680 : loss : 0.025537, loss_ce: 0.011318
pred_sum 173
gtsum tensor(170, device='cuda:0')
iteration 8681 : loss : 0.069615, loss_ce: 0.004754
iteration 8682 : loss : 0.030374, loss_ce: 0.008718
iteration 8683 : loss : 0.024380, loss_ce: 0.010735
iteration 8684 : loss : 0.027501, loss_ce: 0.009378
iteration 8685 : loss : 0.026715, loss_ce: 0.006444
iteration 8686 : loss : 0.031634, loss_ce: 0.014467
iteration 8687 : loss : 0.079587, loss_ce: 0.007105
iteration 8688 : loss : 0.025979, loss_ce: 0.011053
iteration 8689 : loss : 0.030825, loss_ce: 0.010209
iteration 8690 : loss : 0.028802, loss_ce: 0.008983
iteration 8691 : loss : 0.028614, loss_ce: 0.008200
iteration 8692 : loss : 0.027357, loss_ce: 0.008957
iteration 8693 : loss : 0.027708, loss_ce: 0.006833
iteration 8694 : loss : 0.023495, loss_ce: 0.010003
iteration 8695 : loss : 0.055676, loss_ce: 0.009120
iteration 8696 : loss : 0.023689, loss_ce: 0.010600
iteration 8697 : loss : 0.024864, loss_ce: 0.011050
iteration 8698 : loss : 0.033475, loss_ce: 0.012053
iteration 8699 : loss : 0.028613, loss_ce: 0.014458
iteration 8700 : loss : 0.079387, loss_ce: 0.004919
iteration 8701 : loss : 0.021916, loss_ce: 0.008181
iteration 8702 : loss : 0.027062, loss_ce: 0.010092
iteration 8703 : loss : 0.023754, loss_ce: 0.009531
iteration 8704 : loss : 0.023167, loss_ce: 0.009032
iteration 8705 : loss : 0.032697, loss_ce: 0.011742
iteration 8706 : loss : 0.077501, loss_ce: 0.006624
iteration 8707 : loss : 0.023112, loss_ce: 0.006424
iteration 8708 : loss : 0.027039, loss_ce: 0.010366
iteration 8709 : loss : 0.025293, loss_ce: 0.006362
iteration 8710 : loss : 0.033122, loss_ce: 0.011536
iteration 8711 : loss : 0.029297, loss_ce: 0.010844
pred_sum 35713
gtsum tensor(36282, device='cuda:0')
iteration 8712 : loss : 0.034530, loss_ce: 0.004496
iteration 8713 : loss : 0.037039, loss_ce: 0.004854
iteration 8714 : loss : 0.024167, loss_ce: 0.009278
iteration 8715 : loss : 0.025906, loss_ce: 0.009147
iteration 8716 : loss : 0.027093, loss_ce: 0.005880
iteration 8717 : loss : 0.032178, loss_ce: 0.006425
iteration 8718 : loss : 0.027014, loss_ce: 0.006717
iteration 8719 : loss : 0.028170, loss_ce: 0.009777
iteration 8720 : loss : 0.032682, loss_ce: 0.011435
iteration 8721 : loss : 0.026638, loss_ce: 0.010647
iteration 8722 : loss : 0.034626, loss_ce: 0.009462
iteration 8723 : loss : 0.023267, loss_ce: 0.004078
iteration 8724 : loss : 0.025368, loss_ce: 0.009055
iteration 8725 : loss : 0.030937, loss_ce: 0.009585
iteration 8726 : loss : 0.027639, loss_ce: 0.010390
iteration 8727 : loss : 0.024634, loss_ce: 0.009354
iteration 8728 : loss : 0.030670, loss_ce: 0.010764
iteration 8729 : loss : 0.077155, loss_ce: 0.008553
iteration 8730 : loss : 0.032310, loss_ce: 0.006782
iteration 8731 : loss : 0.027424, loss_ce: 0.010145
iteration 8732 : loss : 0.024656, loss_ce: 0.010467
iteration 8733 : loss : 0.025619, loss_ce: 0.009660
iteration 8734 : loss : 0.036935, loss_ce: 0.007915
iteration 8735 : loss : 0.028864, loss_ce: 0.010756
iteration 8736 : loss : 0.034779, loss_ce: 0.014948
iteration 8737 : loss : 0.022235, loss_ce: 0.007895
iteration 8738 : loss : 0.024304, loss_ce: 0.007292
iteration 8739 : loss : 0.025639, loss_ce: 0.005047
iteration 8740 : loss : 0.024565, loss_ce: 0.006426
iteration 8741 : loss : 0.076929, loss_ce: 0.005981
iteration 8742 : loss : 0.080480, loss_ce: 0.008854
 47%|█████████████▏              | 94/200 [1:25:20<1:36:21, 54.54s/it]pred_sum 27149
gtsum tensor(26997, device='cuda:0')
iteration 8743 : loss : 0.032635, loss_ce: 0.010384
iteration 8744 : loss : 0.080986, loss_ce: 0.006614
iteration 8745 : loss : 0.024452, loss_ce: 0.007301
iteration 8746 : loss : 0.026837, loss_ce: 0.010383
iteration 8747 : loss : 0.028567, loss_ce: 0.011189
iteration 8748 : loss : 0.077141, loss_ce: 0.004351
iteration 8749 : loss : 0.032435, loss_ce: 0.012734
iteration 8750 : loss : 0.022056, loss_ce: 0.010179
iteration 8751 : loss : 0.034822, loss_ce: 0.012553
iteration 8752 : loss : 0.024814, loss_ce: 0.010040
iteration 8753 : loss : 0.027720, loss_ce: 0.006064
iteration 8754 : loss : 0.026290, loss_ce: 0.011247
iteration 8755 : loss : 0.040147, loss_ce: 0.010633
iteration 8756 : loss : 0.022912, loss_ce: 0.005297
iteration 8757 : loss : 0.023446, loss_ce: 0.008289
iteration 8758 : loss : 0.028627, loss_ce: 0.010285
iteration 8759 : loss : 0.025056, loss_ce: 0.009025
iteration 8760 : loss : 0.073534, loss_ce: 0.008276
iteration 8761 : loss : 0.025861, loss_ce: 0.009290
iteration 8762 : loss : 0.029976, loss_ce: 0.009312
iteration 8763 : loss : 0.026182, loss_ce: 0.006674
iteration 8764 : loss : 0.078844, loss_ce: 0.010155
iteration 8765 : loss : 0.026979, loss_ce: 0.007258
iteration 8766 : loss : 0.023580, loss_ce: 0.007149
iteration 8767 : loss : 0.029570, loss_ce: 0.011799
iteration 8768 : loss : 0.025666, loss_ce: 0.009863
iteration 8769 : loss : 0.026811, loss_ce: 0.009197
iteration 8770 : loss : 0.029608, loss_ce: 0.008978
iteration 8771 : loss : 0.125505, loss_ce: 0.002974
iteration 8772 : loss : 0.028209, loss_ce: 0.008240
iteration 8773 : loss : 0.025474, loss_ce: 0.011348
pred_sum 46794
gtsum tensor(46804, device='cuda:0')
iteration 8774 : loss : 0.076400, loss_ce: 0.007528
iteration 8775 : loss : 0.022389, loss_ce: 0.007068
iteration 8776 : loss : 0.024893, loss_ce: 0.008298
iteration 8777 : loss : 0.029617, loss_ce: 0.008462
iteration 8778 : loss : 0.027981, loss_ce: 0.009679
iteration 8779 : loss : 0.031695, loss_ce: 0.005802
iteration 8780 : loss : 0.031173, loss_ce: 0.010570
iteration 8781 : loss : 0.038428, loss_ce: 0.009889
iteration 8782 : loss : 0.022398, loss_ce: 0.008068
iteration 8783 : loss : 0.078125, loss_ce: 0.008034
iteration 8784 : loss : 0.024303, loss_ce: 0.006049
iteration 8785 : loss : 0.029472, loss_ce: 0.007961
iteration 8786 : loss : 0.028563, loss_ce: 0.011346
iteration 8787 : loss : 0.048910, loss_ce: 0.014197
iteration 8788 : loss : 0.024676, loss_ce: 0.009654
iteration 8789 : loss : 0.024011, loss_ce: 0.009988
iteration 8790 : loss : 0.039817, loss_ce: 0.012511
iteration 8791 : loss : 0.039110, loss_ce: 0.011509
iteration 8792 : loss : 0.031788, loss_ce: 0.006893
iteration 8793 : loss : 0.035845, loss_ce: 0.009662
iteration 8794 : loss : 0.023707, loss_ce: 0.007672
iteration 8795 : loss : 0.027961, loss_ce: 0.014162
iteration 8796 : loss : 0.031307, loss_ce: 0.012669
iteration 8797 : loss : 0.029806, loss_ce: 0.005890
iteration 8798 : loss : 0.026610, loss_ce: 0.009901
iteration 8799 : loss : 0.026923, loss_ce: 0.006081
iteration 8800 : loss : 0.027498, loss_ce: 0.007669
iteration 8801 : loss : 0.030127, loss_ce: 0.007439
iteration 8802 : loss : 0.032736, loss_ce: 0.011153
iteration 8803 : loss : 0.030230, loss_ce: 0.015429
iteration 8804 : loss : 0.029646, loss_ce: 0.012840
pred_sum 41549
gtsum tensor(42521, device='cuda:0')
iteration 8805 : loss : 0.030035, loss_ce: 0.007716
iteration 8806 : loss : 0.026367, loss_ce: 0.007956
iteration 8807 : loss : 0.030614, loss_ce: 0.011244
iteration 8808 : loss : 0.027646, loss_ce: 0.013034
iteration 8809 : loss : 0.035238, loss_ce: 0.014345
iteration 8810 : loss : 0.035917, loss_ce: 0.014398
iteration 8811 : loss : 0.028947, loss_ce: 0.008785
iteration 8812 : loss : 0.028014, loss_ce: 0.008604
iteration 8813 : loss : 0.025226, loss_ce: 0.007179
iteration 8814 : loss : 0.025615, loss_ce: 0.011618
iteration 8815 : loss : 0.037449, loss_ce: 0.009484
iteration 8816 : loss : 0.026296, loss_ce: 0.010079
iteration 8817 : loss : 0.023283, loss_ce: 0.006916
iteration 8818 : loss : 0.025640, loss_ce: 0.007173
iteration 8819 : loss : 0.034385, loss_ce: 0.010335
iteration 8820 : loss : 0.033402, loss_ce: 0.011116
iteration 8821 : loss : 0.028622, loss_ce: 0.012820
iteration 8822 : loss : 0.024725, loss_ce: 0.008990
iteration 8823 : loss : 0.026133, loss_ce: 0.008420
iteration 8824 : loss : 0.033752, loss_ce: 0.009580
iteration 8825 : loss : 0.020989, loss_ce: 0.006443
iteration 8826 : loss : 0.025524, loss_ce: 0.008770
iteration 8827 : loss : 0.028369, loss_ce: 0.010614
iteration 8828 : loss : 0.028239, loss_ce: 0.011445
iteration 8829 : loss : 0.033732, loss_ce: 0.009745
iteration 8830 : loss : 0.022530, loss_ce: 0.006348
iteration 8831 : loss : 0.080811, loss_ce: 0.010679
iteration 8832 : loss : 0.025165, loss_ce: 0.010011
iteration 8833 : loss : 0.034047, loss_ce: 0.007529
iteration 8834 : loss : 0.075998, loss_ce: 0.006798
iteration 8835 : loss : 0.244614, loss_ce: 0.022757
 48%|█████████████▎              | 95/200 [1:26:14<1:35:25, 54.53s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 8836 : loss : 0.029191, loss_ce: 0.010967
iteration 8837 : loss : 0.028191, loss_ce: 0.011179
iteration 8838 : loss : 0.022482, loss_ce: 0.010065
iteration 8839 : loss : 0.035926, loss_ce: 0.012298
iteration 8840 : loss : 0.028951, loss_ce: 0.011164
iteration 8841 : loss : 0.024558, loss_ce: 0.006550
iteration 8842 : loss : 0.031069, loss_ce: 0.007627
iteration 8843 : loss : 0.023337, loss_ce: 0.009025
iteration 8844 : loss : 0.021972, loss_ce: 0.009231
iteration 8845 : loss : 0.084774, loss_ce: 0.006126
iteration 8846 : loss : 0.023617, loss_ce: 0.006756
iteration 8847 : loss : 0.029694, loss_ce: 0.012420
iteration 8848 : loss : 0.028357, loss_ce: 0.013111
iteration 8849 : loss : 0.026045, loss_ce: 0.005857
iteration 8850 : loss : 0.023939, loss_ce: 0.005731
iteration 8851 : loss : 0.025052, loss_ce: 0.009471
iteration 8852 : loss : 0.033021, loss_ce: 0.014247
iteration 8853 : loss : 0.029832, loss_ce: 0.011879
iteration 8854 : loss : 0.026020, loss_ce: 0.008694
iteration 8855 : loss : 0.030061, loss_ce: 0.010108
iteration 8856 : loss : 0.126814, loss_ce: 0.005711
iteration 8857 : loss : 0.022467, loss_ce: 0.008092
iteration 8858 : loss : 0.027483, loss_ce: 0.011328
iteration 8859 : loss : 0.031337, loss_ce: 0.006549
iteration 8860 : loss : 0.027573, loss_ce: 0.008416
iteration 8861 : loss : 0.025832, loss_ce: 0.008557
iteration 8862 : loss : 0.022167, loss_ce: 0.007441
iteration 8863 : loss : 0.121815, loss_ce: 0.005424
iteration 8864 : loss : 0.028575, loss_ce: 0.009553
iteration 8865 : loss : 0.028411, loss_ce: 0.008691
iteration 8866 : loss : 0.030751, loss_ce: 0.010446
pred_sum 43436
gtsum tensor(43539, device='cuda:0')
iteration 8867 : loss : 0.026115, loss_ce: 0.010087
iteration 8868 : loss : 0.024690, loss_ce: 0.005730
iteration 8869 : loss : 0.028459, loss_ce: 0.011271
iteration 8870 : loss : 0.024513, loss_ce: 0.006578
iteration 8871 : loss : 0.024988, loss_ce: 0.009188
iteration 8872 : loss : 0.029430, loss_ce: 0.010398
iteration 8873 : loss : 0.035689, loss_ce: 0.011938
iteration 8874 : loss : 0.026286, loss_ce: 0.010915
iteration 8875 : loss : 0.026364, loss_ce: 0.008650
iteration 8876 : loss : 0.027462, loss_ce: 0.012095
iteration 8877 : loss : 0.024822, loss_ce: 0.007144
iteration 8878 : loss : 0.031351, loss_ce: 0.010221
iteration 8879 : loss : 0.029632, loss_ce: 0.013539
iteration 8880 : loss : 0.081212, loss_ce: 0.005793
iteration 8881 : loss : 0.025282, loss_ce: 0.006740
iteration 8882 : loss : 0.026888, loss_ce: 0.012189
iteration 8883 : loss : 0.024080, loss_ce: 0.010131
iteration 8884 : loss : 0.027889, loss_ce: 0.012115
iteration 8885 : loss : 0.029956, loss_ce: 0.010595
iteration 8886 : loss : 0.021896, loss_ce: 0.006635
iteration 8887 : loss : 0.025156, loss_ce: 0.008817
iteration 8888 : loss : 0.033410, loss_ce: 0.012577
iteration 8889 : loss : 0.033152, loss_ce: 0.016972
iteration 8890 : loss : 0.030251, loss_ce: 0.010585
iteration 8891 : loss : 0.027360, loss_ce: 0.007876
iteration 8892 : loss : 0.023812, loss_ce: 0.005038
iteration 8893 : loss : 0.026220, loss_ce: 0.007813
iteration 8894 : loss : 0.027588, loss_ce: 0.009133
iteration 8895 : loss : 0.025644, loss_ce: 0.007737
iteration 8896 : loss : 0.030857, loss_ce: 0.010577
iteration 8897 : loss : 0.026600, loss_ce: 0.009631
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 8898 : loss : 0.024443, loss_ce: 0.005754
iteration 8899 : loss : 0.026201, loss_ce: 0.010451
iteration 8900 : loss : 0.031711, loss_ce: 0.014753
iteration 8901 : loss : 0.034818, loss_ce: 0.007023
iteration 8902 : loss : 0.027888, loss_ce: 0.010035
iteration 8903 : loss : 0.030628, loss_ce: 0.008934
iteration 8904 : loss : 0.077137, loss_ce: 0.005142
iteration 8905 : loss : 0.072020, loss_ce: 0.003557
iteration 8906 : loss : 0.028494, loss_ce: 0.007369
iteration 8907 : loss : 0.023905, loss_ce: 0.006576
iteration 8908 : loss : 0.056952, loss_ce: 0.008435
iteration 8909 : loss : 0.030378, loss_ce: 0.008128
iteration 8910 : loss : 0.022162, loss_ce: 0.008686
iteration 8911 : loss : 0.129851, loss_ce: 0.005242
iteration 8912 : loss : 0.032270, loss_ce: 0.015012
iteration 8913 : loss : 0.029923, loss_ce: 0.009404
iteration 8914 : loss : 0.028098, loss_ce: 0.009361
iteration 8915 : loss : 0.038125, loss_ce: 0.011550
iteration 8916 : loss : 0.039433, loss_ce: 0.011607
iteration 8917 : loss : 0.024684, loss_ce: 0.007277
iteration 8918 : loss : 0.031583, loss_ce: 0.011826
iteration 8919 : loss : 0.035909, loss_ce: 0.016559
iteration 8920 : loss : 0.032341, loss_ce: 0.011999
iteration 8921 : loss : 0.035741, loss_ce: 0.014296
iteration 8922 : loss : 0.037833, loss_ce: 0.008448
iteration 8923 : loss : 0.027263, loss_ce: 0.007526
iteration 8924 : loss : 0.052778, loss_ce: 0.009153
iteration 8925 : loss : 0.026246, loss_ce: 0.010583
iteration 8926 : loss : 0.040109, loss_ce: 0.011223
iteration 8927 : loss : 0.026924, loss_ce: 0.009336
iteration 8928 : loss : 0.390843, loss_ce: 0.001021
 48%|█████████████▍              | 96/200 [1:27:09<1:34:31, 54.53s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 8929 : loss : 0.030269, loss_ce: 0.012409
iteration 8930 : loss : 0.030018, loss_ce: 0.010547
iteration 8931 : loss : 0.053756, loss_ce: 0.014568
iteration 8932 : loss : 0.032890, loss_ce: 0.013069
iteration 8933 : loss : 0.030920, loss_ce: 0.010657
iteration 8934 : loss : 0.079996, loss_ce: 0.013032
iteration 8935 : loss : 0.031736, loss_ce: 0.011985
iteration 8936 : loss : 0.036149, loss_ce: 0.018853
iteration 8937 : loss : 0.029016, loss_ce: 0.009676
iteration 8938 : loss : 0.029163, loss_ce: 0.011640
iteration 8939 : loss : 0.037756, loss_ce: 0.011779
iteration 8940 : loss : 0.082140, loss_ce: 0.007550
iteration 8941 : loss : 0.030697, loss_ce: 0.006268
iteration 8942 : loss : 0.028948, loss_ce: 0.007419
iteration 8943 : loss : 0.032667, loss_ce: 0.008401
iteration 8944 : loss : 0.126972, loss_ce: 0.005087
iteration 8945 : loss : 0.027316, loss_ce: 0.008629
iteration 8946 : loss : 0.032594, loss_ce: 0.009880
iteration 8947 : loss : 0.030235, loss_ce: 0.015040
iteration 8948 : loss : 0.030010, loss_ce: 0.009738
iteration 8949 : loss : 0.032857, loss_ce: 0.008795
iteration 8950 : loss : 0.033478, loss_ce: 0.008570
iteration 8951 : loss : 0.023608, loss_ce: 0.007908
iteration 8952 : loss : 0.027362, loss_ce: 0.009751
iteration 8953 : loss : 0.058547, loss_ce: 0.006207
iteration 8954 : loss : 0.026881, loss_ce: 0.011846
iteration 8955 : loss : 0.022846, loss_ce: 0.005628
iteration 8956 : loss : 0.028479, loss_ce: 0.010342
iteration 8957 : loss : 0.077264, loss_ce: 0.008252
iteration 8958 : loss : 0.024372, loss_ce: 0.008467
iteration 8959 : loss : 0.025546, loss_ce: 0.009293
pred_sum 40617
gtsum tensor(41056, device='cuda:0')
iteration 8960 : loss : 0.025912, loss_ce: 0.009241
iteration 8961 : loss : 0.031344, loss_ce: 0.010601
iteration 8962 : loss : 0.035112, loss_ce: 0.011508
iteration 8963 : loss : 0.032076, loss_ce: 0.009717
iteration 8964 : loss : 0.022544, loss_ce: 0.004392
iteration 8965 : loss : 0.034374, loss_ce: 0.010848
iteration 8966 : loss : 0.038746, loss_ce: 0.012339
iteration 8967 : loss : 0.034840, loss_ce: 0.008961
iteration 8968 : loss : 0.033474, loss_ce: 0.010668
iteration 8969 : loss : 0.035436, loss_ce: 0.009793
iteration 8970 : loss : 0.031863, loss_ce: 0.007102
iteration 8971 : loss : 0.036040, loss_ce: 0.012356
iteration 8972 : loss : 0.025717, loss_ce: 0.005592
iteration 8973 : loss : 0.025908, loss_ce: 0.009124
iteration 8974 : loss : 0.026193, loss_ce: 0.007543
iteration 8975 : loss : 0.025397, loss_ce: 0.010355
iteration 8976 : loss : 0.032232, loss_ce: 0.007851
iteration 8977 : loss : 0.026984, loss_ce: 0.008387
iteration 8978 : loss : 0.035154, loss_ce: 0.010766
iteration 8979 : loss : 0.031082, loss_ce: 0.012826
iteration 8980 : loss : 0.026018, loss_ce: 0.008105
iteration 8981 : loss : 0.041427, loss_ce: 0.007065
iteration 8982 : loss : 0.029208, loss_ce: 0.007257
iteration 8983 : loss : 0.025834, loss_ce: 0.007962
iteration 8984 : loss : 0.033940, loss_ce: 0.006382
iteration 8985 : loss : 0.031592, loss_ce: 0.008911
iteration 8986 : loss : 0.024058, loss_ce: 0.005568
iteration 8987 : loss : 0.036292, loss_ce: 0.012027
iteration 8988 : loss : 0.034027, loss_ce: 0.013082
iteration 8989 : loss : 0.044102, loss_ce: 0.006076
iteration 8990 : loss : 0.032789, loss_ce: 0.008461
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 8991 : loss : 0.034038, loss_ce: 0.008775
iteration 8992 : loss : 0.030458, loss_ce: 0.010144
iteration 8993 : loss : 0.027731, loss_ce: 0.005381
iteration 8994 : loss : 0.035137, loss_ce: 0.007184
iteration 8995 : loss : 0.025493, loss_ce: 0.007901
iteration 8996 : loss : 0.030544, loss_ce: 0.009404
iteration 8997 : loss : 0.032032, loss_ce: 0.015513
iteration 8998 : loss : 0.028407, loss_ce: 0.007582
iteration 8999 : loss : 0.028059, loss_ce: 0.009117
iteration 9000 : loss : 0.023353, loss_ce: 0.007170
iteration 9001 : loss : 0.030766, loss_ce: 0.014473
iteration 9002 : loss : 0.029832, loss_ce: 0.012186
iteration 9003 : loss : 0.026982, loss_ce: 0.008634
iteration 9004 : loss : 0.029325, loss_ce: 0.008417
iteration 9005 : loss : 0.030068, loss_ce: 0.008562
iteration 9006 : loss : 0.032044, loss_ce: 0.009125
iteration 9007 : loss : 0.030520, loss_ce: 0.009711
iteration 9008 : loss : 0.032793, loss_ce: 0.014340
iteration 9009 : loss : 0.024423, loss_ce: 0.008027
iteration 9010 : loss : 0.027085, loss_ce: 0.011012
iteration 9011 : loss : 0.025625, loss_ce: 0.006515
iteration 9012 : loss : 0.031716, loss_ce: 0.014781
iteration 9013 : loss : 0.026281, loss_ce: 0.009330
iteration 9014 : loss : 0.023285, loss_ce: 0.011384
iteration 9015 : loss : 0.026033, loss_ce: 0.011539
iteration 9016 : loss : 0.027703, loss_ce: 0.013004
iteration 9017 : loss : 0.022486, loss_ce: 0.007433
iteration 9018 : loss : 0.022522, loss_ce: 0.010649
iteration 9019 : loss : 0.028418, loss_ce: 0.009709
iteration 9020 : loss : 0.026354, loss_ce: 0.012366
iteration 9021 : loss : 0.393258, loss_ce: 0.003133
 48%|█████████████▌              | 97/200 [1:28:03<1:33:36, 54.53s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 9022 : loss : 0.025239, loss_ce: 0.007991
iteration 9023 : loss : 0.031481, loss_ce: 0.011238
iteration 9024 : loss : 0.026392, loss_ce: 0.008985
iteration 9025 : loss : 0.027114, loss_ce: 0.013123
iteration 9026 : loss : 0.029157, loss_ce: 0.011115
iteration 9027 : loss : 0.027185, loss_ce: 0.013737
iteration 9028 : loss : 0.042701, loss_ce: 0.009380
iteration 9029 : loss : 0.026624, loss_ce: 0.006847
iteration 9030 : loss : 0.026756, loss_ce: 0.008163
iteration 9031 : loss : 0.025791, loss_ce: 0.005535
iteration 9032 : loss : 0.035199, loss_ce: 0.009966
iteration 9033 : loss : 0.027972, loss_ce: 0.012670
iteration 9034 : loss : 0.027083, loss_ce: 0.005722
iteration 9035 : loss : 0.028297, loss_ce: 0.009475
iteration 9036 : loss : 0.029722, loss_ce: 0.009637
iteration 9037 : loss : 0.032783, loss_ce: 0.007512
iteration 9038 : loss : 0.028395, loss_ce: 0.013312
iteration 9039 : loss : 0.026961, loss_ce: 0.010548
iteration 9040 : loss : 0.022836, loss_ce: 0.007200
iteration 9041 : loss : 0.032361, loss_ce: 0.010519
iteration 9042 : loss : 0.023158, loss_ce: 0.005004
iteration 9043 : loss : 0.029908, loss_ce: 0.007827
iteration 9044 : loss : 0.028552, loss_ce: 0.006729
iteration 9045 : loss : 0.031887, loss_ce: 0.010281
iteration 9046 : loss : 0.025099, loss_ce: 0.007673
iteration 9047 : loss : 0.128356, loss_ce: 0.007142
iteration 9048 : loss : 0.027845, loss_ce: 0.008980
iteration 9049 : loss : 0.028867, loss_ce: 0.008984
iteration 9050 : loss : 0.029632, loss_ce: 0.009042
iteration 9051 : loss : 0.021527, loss_ce: 0.008234
iteration 9052 : loss : 0.027710, loss_ce: 0.007847
pred_sum 21170
gtsum tensor(18599, device='cuda:0')
iteration 9053 : loss : 0.027828, loss_ce: 0.011286
iteration 9054 : loss : 0.044152, loss_ce: 0.008027
iteration 9055 : loss : 0.029600, loss_ce: 0.011330
iteration 9056 : loss : 0.039669, loss_ce: 0.013073
iteration 9057 : loss : 0.026682, loss_ce: 0.010444
iteration 9058 : loss : 0.035603, loss_ce: 0.004434
iteration 9059 : loss : 0.077746, loss_ce: 0.008028
iteration 9060 : loss : 0.032202, loss_ce: 0.015786
iteration 9061 : loss : 0.025019, loss_ce: 0.009935
iteration 9062 : loss : 0.038698, loss_ce: 0.012510
iteration 9063 : loss : 0.026974, loss_ce: 0.009791
iteration 9064 : loss : 0.028874, loss_ce: 0.008520
iteration 9065 : loss : 0.033890, loss_ce: 0.009213
iteration 9066 : loss : 0.028141, loss_ce: 0.007673
iteration 9067 : loss : 0.030367, loss_ce: 0.006806
iteration 9068 : loss : 0.024357, loss_ce: 0.006119
iteration 9069 : loss : 0.078309, loss_ce: 0.007962
iteration 9070 : loss : 0.026276, loss_ce: 0.007866
iteration 9071 : loss : 0.072635, loss_ce: 0.003572
iteration 9072 : loss : 0.079705, loss_ce: 0.006790
iteration 9073 : loss : 0.071770, loss_ce: 0.007789
iteration 9074 : loss : 0.023002, loss_ce: 0.009356
iteration 9075 : loss : 0.047118, loss_ce: 0.007766
iteration 9076 : loss : 0.080318, loss_ce: 0.008851
iteration 9077 : loss : 0.030719, loss_ce: 0.013590
iteration 9078 : loss : 0.035306, loss_ce: 0.011345
iteration 9079 : loss : 0.033067, loss_ce: 0.008268
iteration 9080 : loss : 0.026267, loss_ce: 0.012404
iteration 9081 : loss : 0.030262, loss_ce: 0.010230
iteration 9082 : loss : 0.021705, loss_ce: 0.005893
iteration 9083 : loss : 0.038431, loss_ce: 0.015523
pred_sum 177
gtsum tensor(176, device='cuda:0')
iteration 9084 : loss : 0.025608, loss_ce: 0.006833
iteration 9085 : loss : 0.029139, loss_ce: 0.013662
iteration 9086 : loss : 0.033411, loss_ce: 0.004410
iteration 9087 : loss : 0.031742, loss_ce: 0.015466
iteration 9088 : loss : 0.036700, loss_ce: 0.009370
iteration 9089 : loss : 0.029422, loss_ce: 0.010254
iteration 9090 : loss : 0.034298, loss_ce: 0.010578
iteration 9091 : loss : 0.038347, loss_ce: 0.006403
iteration 9092 : loss : 0.021814, loss_ce: 0.007581
iteration 9093 : loss : 0.030922, loss_ce: 0.006967
iteration 9094 : loss : 0.027991, loss_ce: 0.010860
iteration 9095 : loss : 0.026765, loss_ce: 0.012586
iteration 9096 : loss : 0.044147, loss_ce: 0.015800
iteration 9097 : loss : 0.026115, loss_ce: 0.008453
iteration 9098 : loss : 0.035249, loss_ce: 0.014135
iteration 9099 : loss : 0.028226, loss_ce: 0.008921
iteration 9100 : loss : 0.025189, loss_ce: 0.006446
iteration 9101 : loss : 0.033091, loss_ce: 0.006991
iteration 9102 : loss : 0.025097, loss_ce: 0.010308
iteration 9103 : loss : 0.026701, loss_ce: 0.009652
iteration 9104 : loss : 0.027784, loss_ce: 0.007313
iteration 9105 : loss : 0.025574, loss_ce: 0.011426
iteration 9106 : loss : 0.031773, loss_ce: 0.008441
iteration 9107 : loss : 0.032371, loss_ce: 0.013036
iteration 9108 : loss : 0.025901, loss_ce: 0.013185
iteration 9109 : loss : 0.079776, loss_ce: 0.007953
iteration 9110 : loss : 0.030083, loss_ce: 0.010779
iteration 9111 : loss : 0.025760, loss_ce: 0.010009
iteration 9112 : loss : 0.032014, loss_ce: 0.009901
iteration 9113 : loss : 0.024634, loss_ce: 0.008814
iteration 9114 : loss : 0.081294, loss_ce: 0.010497
 49%|█████████████▋              | 98/200 [1:28:58<1:32:39, 54.51s/it]pred_sum 28800
gtsum tensor(27619, device='cuda:0')
iteration 9115 : loss : 0.025927, loss_ce: 0.009937
iteration 9116 : loss : 0.031360, loss_ce: 0.011066
iteration 9117 : loss : 0.033763, loss_ce: 0.008329
iteration 9118 : loss : 0.028575, loss_ce: 0.010023
iteration 9119 : loss : 0.027153, loss_ce: 0.011561
iteration 9120 : loss : 0.034770, loss_ce: 0.009942
iteration 9121 : loss : 0.029712, loss_ce: 0.010044
iteration 9122 : loss : 0.028859, loss_ce: 0.013980
iteration 9123 : loss : 0.026006, loss_ce: 0.008834
iteration 9124 : loss : 0.027748, loss_ce: 0.013832
iteration 9125 : loss : 0.026128, loss_ce: 0.008681
iteration 9126 : loss : 0.030641, loss_ce: 0.011989
iteration 9127 : loss : 0.077077, loss_ce: 0.006856
iteration 9128 : loss : 0.024666, loss_ce: 0.007664
iteration 9129 : loss : 0.029078, loss_ce: 0.012945
iteration 9130 : loss : 0.027804, loss_ce: 0.013025
iteration 9131 : loss : 0.024885, loss_ce: 0.009352
iteration 9132 : loss : 0.027189, loss_ce: 0.008336
iteration 9133 : loss : 0.095384, loss_ce: 0.006448
iteration 9134 : loss : 0.077084, loss_ce: 0.005110
iteration 9135 : loss : 0.030729, loss_ce: 0.008652
iteration 9136 : loss : 0.029550, loss_ce: 0.012590
iteration 9137 : loss : 0.027292, loss_ce: 0.007959
iteration 9138 : loss : 0.024339, loss_ce: 0.009655
iteration 9139 : loss : 0.031777, loss_ce: 0.013051
iteration 9140 : loss : 0.027574, loss_ce: 0.007163
iteration 9141 : loss : 0.038623, loss_ce: 0.013511
iteration 9142 : loss : 0.029660, loss_ce: 0.006801
iteration 9143 : loss : 0.029922, loss_ce: 0.011865
iteration 9144 : loss : 0.020727, loss_ce: 0.005949
iteration 9145 : loss : 0.022412, loss_ce: 0.005966
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 9146 : loss : 0.030450, loss_ce: 0.008377
iteration 9147 : loss : 0.024525, loss_ce: 0.007454
iteration 9148 : loss : 0.024293, loss_ce: 0.009270
iteration 9149 : loss : 0.036443, loss_ce: 0.009364
iteration 9150 : loss : 0.027973, loss_ce: 0.012114
iteration 9151 : loss : 0.021549, loss_ce: 0.007118
iteration 9152 : loss : 0.033029, loss_ce: 0.007700
iteration 9153 : loss : 0.033250, loss_ce: 0.011495
iteration 9154 : loss : 0.027821, loss_ce: 0.007846
iteration 9155 : loss : 0.030962, loss_ce: 0.008066
iteration 9156 : loss : 0.025549, loss_ce: 0.010323
iteration 9157 : loss : 0.028589, loss_ce: 0.008326
iteration 9158 : loss : 0.026364, loss_ce: 0.013463
iteration 9159 : loss : 0.075203, loss_ce: 0.006152
iteration 9160 : loss : 0.030986, loss_ce: 0.012501
iteration 9161 : loss : 0.027966, loss_ce: 0.010376
iteration 9162 : loss : 0.021946, loss_ce: 0.004085
iteration 9163 : loss : 0.025672, loss_ce: 0.006481
iteration 9164 : loss : 0.022302, loss_ce: 0.009411
iteration 9165 : loss : 0.027186, loss_ce: 0.007238
iteration 9166 : loss : 0.032976, loss_ce: 0.006142
iteration 9167 : loss : 0.024973, loss_ce: 0.007968
iteration 9168 : loss : 0.027291, loss_ce: 0.007040
iteration 9169 : loss : 0.101675, loss_ce: 0.008904
iteration 9170 : loss : 0.025830, loss_ce: 0.007024
iteration 9171 : loss : 0.024623, loss_ce: 0.008986
iteration 9172 : loss : 0.023858, loss_ce: 0.009616
iteration 9173 : loss : 0.024349, loss_ce: 0.009110
iteration 9174 : loss : 0.027307, loss_ce: 0.006404
iteration 9175 : loss : 0.027735, loss_ce: 0.010536
iteration 9176 : loss : 0.032931, loss_ce: 0.011234
pred_sum 15010
gtsum tensor(14132, device='cuda:0')
iteration 9177 : loss : 0.036303, loss_ce: 0.012360
iteration 9178 : loss : 0.024178, loss_ce: 0.008241
iteration 9179 : loss : 0.032506, loss_ce: 0.013233
iteration 9180 : loss : 0.028661, loss_ce: 0.011788
iteration 9181 : loss : 0.029099, loss_ce: 0.005050
iteration 9182 : loss : 0.023281, loss_ce: 0.007305
iteration 9183 : loss : 0.035232, loss_ce: 0.011637
iteration 9184 : loss : 0.027644, loss_ce: 0.008174
iteration 9185 : loss : 0.028862, loss_ce: 0.013643
iteration 9186 : loss : 0.027561, loss_ce: 0.009912
iteration 9187 : loss : 0.025843, loss_ce: 0.008884
iteration 9188 : loss : 0.082880, loss_ce: 0.008237
iteration 9189 : loss : 0.030049, loss_ce: 0.011849
iteration 9190 : loss : 0.032428, loss_ce: 0.007764
iteration 9191 : loss : 0.032097, loss_ce: 0.009122
iteration 9192 : loss : 0.028898, loss_ce: 0.009821
iteration 9193 : loss : 0.031786, loss_ce: 0.012273
iteration 9194 : loss : 0.034438, loss_ce: 0.006775
iteration 9195 : loss : 0.026882, loss_ce: 0.009257
iteration 9196 : loss : 0.031001, loss_ce: 0.009779
iteration 9197 : loss : 0.022662, loss_ce: 0.007716
iteration 9198 : loss : 0.075595, loss_ce: 0.005449
iteration 9199 : loss : 0.032771, loss_ce: 0.012502
iteration 9200 : loss : 0.029835, loss_ce: 0.015248
iteration 9201 : loss : 0.030922, loss_ce: 0.006021
iteration 9202 : loss : 0.025281, loss_ce: 0.009675
iteration 9203 : loss : 0.027129, loss_ce: 0.007022
iteration 9204 : loss : 0.032406, loss_ce: 0.010628
iteration 9205 : loss : 0.026924, loss_ce: 0.007998
iteration 9206 : loss : 0.024111, loss_ce: 0.006637
iteration 9207 : loss : 0.189699, loss_ce: 0.021557
 50%|█████████████▊              | 99/200 [1:29:52<1:31:46, 54.52s/it]pred_sum 16220
gtsum tensor(16805, device='cuda:0')
iteration 9208 : loss : 0.038084, loss_ce: 0.009214
iteration 9209 : loss : 0.027409, loss_ce: 0.010766
iteration 9210 : loss : 0.023739, loss_ce: 0.009443
iteration 9211 : loss : 0.135647, loss_ce: 0.007355
iteration 9212 : loss : 0.028342, loss_ce: 0.011103
iteration 9213 : loss : 0.023854, loss_ce: 0.008008
iteration 9214 : loss : 0.028521, loss_ce: 0.010404
iteration 9215 : loss : 0.030966, loss_ce: 0.014239
iteration 9216 : loss : 0.026617, loss_ce: 0.012250
iteration 9217 : loss : 0.024324, loss_ce: 0.012467
iteration 9218 : loss : 0.031094, loss_ce: 0.010263
iteration 9219 : loss : 0.082898, loss_ce: 0.008906
iteration 9220 : loss : 0.027899, loss_ce: 0.010717
iteration 9221 : loss : 0.036143, loss_ce: 0.008243
iteration 9222 : loss : 0.032706, loss_ce: 0.010629
iteration 9223 : loss : 0.027555, loss_ce: 0.006752
iteration 9224 : loss : 0.024923, loss_ce: 0.009173
iteration 9225 : loss : 0.039840, loss_ce: 0.010829
iteration 9226 : loss : 0.031581, loss_ce: 0.009027
iteration 9227 : loss : 0.022700, loss_ce: 0.009667
iteration 9228 : loss : 0.024109, loss_ce: 0.007982
iteration 9229 : loss : 0.025498, loss_ce: 0.008947
iteration 9230 : loss : 0.076982, loss_ce: 0.007281
iteration 9231 : loss : 0.032959, loss_ce: 0.013329
iteration 9232 : loss : 0.028008, loss_ce: 0.010811
iteration 9233 : loss : 0.021090, loss_ce: 0.007302
iteration 9234 : loss : 0.024254, loss_ce: 0.008564
iteration 9235 : loss : 0.029603, loss_ce: 0.009450
iteration 9236 : loss : 0.027007, loss_ce: 0.010470
iteration 9237 : loss : 0.077790, loss_ce: 0.009493
iteration 9238 : loss : 0.021960, loss_ce: 0.007932
pred_sum 37260
gtsum tensor(37102, device='cuda:0')
iteration 9239 : loss : 0.077689, loss_ce: 0.006344
iteration 9240 : loss : 0.028374, loss_ce: 0.006431
iteration 9241 : loss : 0.022647, loss_ce: 0.008676
iteration 9242 : loss : 0.032491, loss_ce: 0.009328
iteration 9243 : loss : 0.025403, loss_ce: 0.008539
iteration 9244 : loss : 0.028506, loss_ce: 0.008394
iteration 9245 : loss : 0.030337, loss_ce: 0.011830
iteration 9246 : loss : 0.029883, loss_ce: 0.006766
iteration 9247 : loss : 0.021876, loss_ce: 0.011056
iteration 9248 : loss : 0.027492, loss_ce: 0.009784
iteration 9249 : loss : 0.082651, loss_ce: 0.004797
iteration 9250 : loss : 0.070289, loss_ce: 0.002689
iteration 9251 : loss : 0.022436, loss_ce: 0.007856
iteration 9252 : loss : 0.029547, loss_ce: 0.010823
iteration 9253 : loss : 0.078366, loss_ce: 0.012039
iteration 9254 : loss : 0.028503, loss_ce: 0.007724
iteration 9255 : loss : 0.022045, loss_ce: 0.007358
iteration 9256 : loss : 0.072140, loss_ce: 0.007970
iteration 9257 : loss : 0.028069, loss_ce: 0.012489
iteration 9258 : loss : 0.027362, loss_ce: 0.010233
iteration 9259 : loss : 0.032156, loss_ce: 0.013464
iteration 9260 : loss : 0.026927, loss_ce: 0.011003
iteration 9261 : loss : 0.024592, loss_ce: 0.008439
iteration 9262 : loss : 0.027433, loss_ce: 0.010220
iteration 9263 : loss : 0.028312, loss_ce: 0.009355
iteration 9264 : loss : 0.031217, loss_ce: 0.010126
iteration 9265 : loss : 0.034212, loss_ce: 0.007973
iteration 9266 : loss : 0.027035, loss_ce: 0.014098
iteration 9267 : loss : 0.028938, loss_ce: 0.009660
iteration 9268 : loss : 0.020571, loss_ce: 0.009392
iteration 9269 : loss : 0.027079, loss_ce: 0.009345
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 9270 : loss : 0.028953, loss_ce: 0.009167
iteration 9271 : loss : 0.030809, loss_ce: 0.015845
iteration 9272 : loss : 0.076062, loss_ce: 0.008081
iteration 9273 : loss : 0.018856, loss_ce: 0.005285
iteration 9274 : loss : 0.032273, loss_ce: 0.010012
iteration 9275 : loss : 0.083739, loss_ce: 0.005101
iteration 9276 : loss : 0.019787, loss_ce: 0.004968
iteration 9277 : loss : 0.030354, loss_ce: 0.007926
iteration 9278 : loss : 0.027145, loss_ce: 0.014563
iteration 9279 : loss : 0.024863, loss_ce: 0.011306
iteration 9280 : loss : 0.020897, loss_ce: 0.003938
iteration 9281 : loss : 0.026564, loss_ce: 0.009933
iteration 9282 : loss : 0.024879, loss_ce: 0.007983
iteration 9283 : loss : 0.026537, loss_ce: 0.007248
iteration 9284 : loss : 0.025091, loss_ce: 0.005255
iteration 9285 : loss : 0.043306, loss_ce: 0.005139
iteration 9286 : loss : 0.029198, loss_ce: 0.009259
iteration 9287 : loss : 0.032432, loss_ce: 0.008598
iteration 9288 : loss : 0.080628, loss_ce: 0.008488
iteration 9289 : loss : 0.031038, loss_ce: 0.009615
iteration 9290 : loss : 0.030367, loss_ce: 0.007092
iteration 9291 : loss : 0.074317, loss_ce: 0.005062
iteration 9292 : loss : 0.026657, loss_ce: 0.006956
iteration 9293 : loss : 0.027629, loss_ce: 0.010388
iteration 9294 : loss : 0.083364, loss_ce: 0.008760
iteration 9295 : loss : 0.027090, loss_ce: 0.007281
iteration 9296 : loss : 0.038834, loss_ce: 0.008817
iteration 9297 : loss : 0.030203, loss_ce: 0.010575
iteration 9298 : loss : 0.027150, loss_ce: 0.010430
iteration 9299 : loss : 0.031110, loss_ce: 0.007781
iteration 9300 : loss : 0.141522, loss_ce: 0.007695
 50%|█████████████▌             | 100/200 [1:30:47<1:30:51, 54.52s/it]pred_sum 24834
gtsum tensor(23121, device='cuda:0')
iteration 9301 : loss : 0.036545, loss_ce: 0.010070
iteration 9302 : loss : 0.043782, loss_ce: 0.008396
iteration 9303 : loss : 0.026801, loss_ce: 0.010927
iteration 9304 : loss : 0.027327, loss_ce: 0.010604
iteration 9305 : loss : 0.026052, loss_ce: 0.010201
iteration 9306 : loss : 0.029142, loss_ce: 0.011942
iteration 9307 : loss : 0.022419, loss_ce: 0.006588
iteration 9308 : loss : 0.031327, loss_ce: 0.008225
iteration 9309 : loss : 0.031173, loss_ce: 0.009407
iteration 9310 : loss : 0.024163, loss_ce: 0.007465
iteration 9311 : loss : 0.031310, loss_ce: 0.009264
iteration 9312 : loss : 0.031646, loss_ce: 0.011435
iteration 9313 : loss : 0.073279, loss_ce: 0.004616
iteration 9314 : loss : 0.035690, loss_ce: 0.010012
iteration 9315 : loss : 0.074380, loss_ce: 0.008000
iteration 9316 : loss : 0.026115, loss_ce: 0.009384
iteration 9317 : loss : 0.024975, loss_ce: 0.008428
iteration 9318 : loss : 0.033702, loss_ce: 0.015859
iteration 9319 : loss : 0.026479, loss_ce: 0.008061
iteration 9320 : loss : 0.026099, loss_ce: 0.010894
iteration 9321 : loss : 0.027200, loss_ce: 0.012417
iteration 9322 : loss : 0.023963, loss_ce: 0.006940
iteration 9323 : loss : 0.031933, loss_ce: 0.007864
iteration 9324 : loss : 0.025474, loss_ce: 0.008681
iteration 9325 : loss : 0.027852, loss_ce: 0.008261
iteration 9326 : loss : 0.023433, loss_ce: 0.009228
iteration 9327 : loss : 0.026684, loss_ce: 0.009550
iteration 9328 : loss : 0.026279, loss_ce: 0.013528
iteration 9329 : loss : 0.025804, loss_ce: 0.009331
iteration 9330 : loss : 0.025238, loss_ce: 0.007314
iteration 9331 : loss : 0.028666, loss_ce: 0.007967
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 9332 : loss : 0.032320, loss_ce: 0.006720
iteration 9333 : loss : 0.027246, loss_ce: 0.009878
iteration 9334 : loss : 0.025566, loss_ce: 0.008382
iteration 9335 : loss : 0.025386, loss_ce: 0.010967
iteration 9336 : loss : 0.025665, loss_ce: 0.007722
iteration 9337 : loss : 0.081473, loss_ce: 0.005125
iteration 9338 : loss : 0.025546, loss_ce: 0.007642
iteration 9339 : loss : 0.030274, loss_ce: 0.010964
iteration 9340 : loss : 0.085372, loss_ce: 0.008770
iteration 9341 : loss : 0.024851, loss_ce: 0.009059
iteration 9342 : loss : 0.028628, loss_ce: 0.010537
iteration 9343 : loss : 0.078384, loss_ce: 0.010495
iteration 9344 : loss : 0.024581, loss_ce: 0.005584
iteration 9345 : loss : 0.023987, loss_ce: 0.005724
iteration 9346 : loss : 0.026987, loss_ce: 0.008347
iteration 9347 : loss : 0.028593, loss_ce: 0.007897
iteration 9348 : loss : 0.026097, loss_ce: 0.010767
iteration 9349 : loss : 0.027325, loss_ce: 0.011288
iteration 9350 : loss : 0.028037, loss_ce: 0.010657
iteration 9351 : loss : 0.035080, loss_ce: 0.020157
iteration 9352 : loss : 0.027349, loss_ce: 0.011414
iteration 9353 : loss : 0.028972, loss_ce: 0.009445
iteration 9354 : loss : 0.026091, loss_ce: 0.009311
iteration 9355 : loss : 0.023823, loss_ce: 0.007713
iteration 9356 : loss : 0.029128, loss_ce: 0.010420
iteration 9357 : loss : 0.022374, loss_ce: 0.005043
iteration 9358 : loss : 0.021345, loss_ce: 0.007118
iteration 9359 : loss : 0.024387, loss_ce: 0.012068
iteration 9360 : loss : 0.025089, loss_ce: 0.008511
iteration 9361 : loss : 0.078142, loss_ce: 0.007491
iteration 9362 : loss : 0.047967, loss_ce: 0.006789
pred_sum 37493
gtsum tensor(36250, device='cuda:0')
iteration 9363 : loss : 0.032388, loss_ce: 0.009611
iteration 9364 : loss : 0.030163, loss_ce: 0.014027
iteration 9365 : loss : 0.027419, loss_ce: 0.012772
iteration 9366 : loss : 0.032104, loss_ce: 0.010197
iteration 9367 : loss : 0.034696, loss_ce: 0.007000
iteration 9368 : loss : 0.026456, loss_ce: 0.013032
iteration 9369 : loss : 0.028725, loss_ce: 0.010988
iteration 9370 : loss : 0.033303, loss_ce: 0.007937
iteration 9371 : loss : 0.029162, loss_ce: 0.005751
iteration 9372 : loss : 0.028045, loss_ce: 0.008268
iteration 9373 : loss : 0.049387, loss_ce: 0.004664
iteration 9374 : loss : 0.034658, loss_ce: 0.009927
iteration 9375 : loss : 0.028961, loss_ce: 0.008508
iteration 9376 : loss : 0.027388, loss_ce: 0.007630
iteration 9377 : loss : 0.032039, loss_ce: 0.007783
iteration 9378 : loss : 0.130193, loss_ce: 0.006030
iteration 9379 : loss : 0.029252, loss_ce: 0.011761
iteration 9380 : loss : 0.028741, loss_ce: 0.008213
iteration 9381 : loss : 0.024041, loss_ce: 0.007996
iteration 9382 : loss : 0.027278, loss_ce: 0.006678
iteration 9383 : loss : 0.026786, loss_ce: 0.005740
iteration 9384 : loss : 0.030728, loss_ce: 0.012981
iteration 9385 : loss : 0.027511, loss_ce: 0.009150
iteration 9386 : loss : 0.033770, loss_ce: 0.012083
iteration 9387 : loss : 0.029844, loss_ce: 0.009765
iteration 9388 : loss : 0.025036, loss_ce: 0.009812
iteration 9389 : loss : 0.135828, loss_ce: 0.003063
iteration 9390 : loss : 0.030428, loss_ce: 0.008315
iteration 9391 : loss : 0.024370, loss_ce: 0.011766
iteration 9392 : loss : 0.073845, loss_ce: 0.005029
iteration 9393 : loss : 0.236322, loss_ce: 0.009360
 50%|█████████████▋             | 101/200 [1:31:41<1:29:56, 54.52s/it]pred_sum 44024
gtsum tensor(43526, device='cuda:0')
iteration 9394 : loss : 0.026452, loss_ce: 0.011535
iteration 9395 : loss : 0.040982, loss_ce: 0.006996
iteration 9396 : loss : 0.031391, loss_ce: 0.011453
iteration 9397 : loss : 0.024419, loss_ce: 0.009954
iteration 9398 : loss : 0.028917, loss_ce: 0.013315
iteration 9399 : loss : 0.030747, loss_ce: 0.010051
iteration 9400 : loss : 0.030487, loss_ce: 0.007947
iteration 9401 : loss : 0.027601, loss_ce: 0.006021
iteration 9402 : loss : 0.030112, loss_ce: 0.008079
iteration 9403 : loss : 0.076055, loss_ce: 0.005922
iteration 9404 : loss : 0.026815, loss_ce: 0.012314
iteration 9405 : loss : 0.075890, loss_ce: 0.005777
iteration 9406 : loss : 0.028664, loss_ce: 0.008185
iteration 9407 : loss : 0.029727, loss_ce: 0.011517
iteration 9408 : loss : 0.027119, loss_ce: 0.009804
iteration 9409 : loss : 0.075981, loss_ce: 0.007717
iteration 9410 : loss : 0.025761, loss_ce: 0.006060
iteration 9411 : loss : 0.025175, loss_ce: 0.009812
iteration 9412 : loss : 0.023084, loss_ce: 0.009735
iteration 9413 : loss : 0.028091, loss_ce: 0.011612
iteration 9414 : loss : 0.026139, loss_ce: 0.008322
iteration 9415 : loss : 0.023072, loss_ce: 0.005340
iteration 9416 : loss : 0.030018, loss_ce: 0.014180
iteration 9417 : loss : 0.028788, loss_ce: 0.016395
iteration 9418 : loss : 0.024143, loss_ce: 0.010867
iteration 9419 : loss : 0.037280, loss_ce: 0.011411
iteration 9420 : loss : 0.030329, loss_ce: 0.007958
iteration 9421 : loss : 0.026958, loss_ce: 0.011277
iteration 9422 : loss : 0.026841, loss_ce: 0.014063
iteration 9423 : loss : 0.037401, loss_ce: 0.011219
iteration 9424 : loss : 0.025383, loss_ce: 0.011848
pred_sum 457
gtsum tensor(423, device='cuda:0')
iteration 9425 : loss : 0.023634, loss_ce: 0.009763
iteration 9426 : loss : 0.022955, loss_ce: 0.009931
iteration 9427 : loss : 0.029363, loss_ce: 0.013417
iteration 9428 : loss : 0.078419, loss_ce: 0.006755
iteration 9429 : loss : 0.025563, loss_ce: 0.004205
iteration 9430 : loss : 0.022244, loss_ce: 0.008526
iteration 9431 : loss : 0.022004, loss_ce: 0.008740
iteration 9432 : loss : 0.028133, loss_ce: 0.011498
iteration 9433 : loss : 0.024841, loss_ce: 0.009328
iteration 9434 : loss : 0.078697, loss_ce: 0.010308
iteration 9435 : loss : 0.023223, loss_ce: 0.009985
iteration 9436 : loss : 0.026151, loss_ce: 0.004046
iteration 9437 : loss : 0.056884, loss_ce: 0.006057
iteration 9438 : loss : 0.024031, loss_ce: 0.010612
iteration 9439 : loss : 0.029884, loss_ce: 0.007511
iteration 9440 : loss : 0.025099, loss_ce: 0.008578
iteration 9441 : loss : 0.028403, loss_ce: 0.009020
iteration 9442 : loss : 0.048268, loss_ce: 0.008015
iteration 9443 : loss : 0.038398, loss_ce: 0.008942
iteration 9444 : loss : 0.034743, loss_ce: 0.008176
iteration 9445 : loss : 0.057272, loss_ce: 0.010338
iteration 9446 : loss : 0.034035, loss_ce: 0.009479
iteration 9447 : loss : 0.029959, loss_ce: 0.012941
iteration 9448 : loss : 0.023599, loss_ce: 0.009686
iteration 9449 : loss : 0.027870, loss_ce: 0.006236
iteration 9450 : loss : 0.027896, loss_ce: 0.011107
iteration 9451 : loss : 0.027347, loss_ce: 0.009047
iteration 9452 : loss : 0.023021, loss_ce: 0.008570
iteration 9453 : loss : 0.030466, loss_ce: 0.006089
iteration 9454 : loss : 0.035043, loss_ce: 0.010086
iteration 9455 : loss : 0.029549, loss_ce: 0.006931
pred_sum 22443
gtsum tensor(22305, device='cuda:0')
iteration 9456 : loss : 0.076192, loss_ce: 0.005925
iteration 9457 : loss : 0.027647, loss_ce: 0.007979
iteration 9458 : loss : 0.082051, loss_ce: 0.007502
iteration 9459 : loss : 0.035313, loss_ce: 0.009274
iteration 9460 : loss : 0.077978, loss_ce: 0.006732
iteration 9461 : loss : 0.078588, loss_ce: 0.007068
iteration 9462 : loss : 0.030081, loss_ce: 0.003633
iteration 9463 : loss : 0.025877, loss_ce: 0.007335
iteration 9464 : loss : 0.030592, loss_ce: 0.011796
iteration 9465 : loss : 0.039841, loss_ce: 0.013232
iteration 9466 : loss : 0.034950, loss_ce: 0.017003
iteration 9467 : loss : 0.087696, loss_ce: 0.009397
iteration 9468 : loss : 0.023429, loss_ce: 0.007761
iteration 9469 : loss : 0.030885, loss_ce: 0.011565
iteration 9470 : loss : 0.030331, loss_ce: 0.005857
iteration 9471 : loss : 0.027271, loss_ce: 0.007719
iteration 9472 : loss : 0.024945, loss_ce: 0.007306
iteration 9473 : loss : 0.030537, loss_ce: 0.010224
iteration 9474 : loss : 0.030293, loss_ce: 0.007117
iteration 9475 : loss : 0.023058, loss_ce: 0.004887
iteration 9476 : loss : 0.032456, loss_ce: 0.014234
iteration 9477 : loss : 0.034571, loss_ce: 0.006829
iteration 9478 : loss : 0.028495, loss_ce: 0.006988
iteration 9479 : loss : 0.024357, loss_ce: 0.006810
iteration 9480 : loss : 0.031075, loss_ce: 0.009604
iteration 9481 : loss : 0.021807, loss_ce: 0.006993
iteration 9482 : loss : 0.031275, loss_ce: 0.010914
iteration 9483 : loss : 0.029748, loss_ce: 0.008874
iteration 9484 : loss : 0.029297, loss_ce: 0.013391
iteration 9485 : loss : 0.028314, loss_ce: 0.011835
iteration 9486 : loss : 0.336554, loss_ce: 0.001176
 51%|█████████████▊             | 102/200 [1:32:36<1:29:03, 54.53s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 9487 : loss : 0.076302, loss_ce: 0.009046
iteration 9488 : loss : 0.077513, loss_ce: 0.007725
iteration 9489 : loss : 0.034801, loss_ce: 0.010352
iteration 9490 : loss : 0.029083, loss_ce: 0.012364
iteration 9491 : loss : 0.035860, loss_ce: 0.009058
iteration 9492 : loss : 0.026502, loss_ce: 0.008498
iteration 9493 : loss : 0.076814, loss_ce: 0.009123
iteration 9494 : loss : 0.029268, loss_ce: 0.013393
iteration 9495 : loss : 0.024709, loss_ce: 0.005632
iteration 9496 : loss : 0.025202, loss_ce: 0.011054
iteration 9497 : loss : 0.075847, loss_ce: 0.006548
iteration 9498 : loss : 0.022936, loss_ce: 0.007659
iteration 9499 : loss : 0.028836, loss_ce: 0.006987
iteration 9500 : loss : 0.055025, loss_ce: 0.012481
iteration 9501 : loss : 0.028311, loss_ce: 0.011561
iteration 9502 : loss : 0.025511, loss_ce: 0.008365
iteration 9503 : loss : 0.021051, loss_ce: 0.005169
iteration 9504 : loss : 0.125469, loss_ce: 0.007640
iteration 9505 : loss : 0.023734, loss_ce: 0.007589
iteration 9506 : loss : 0.028646, loss_ce: 0.009556
iteration 9507 : loss : 0.026338, loss_ce: 0.007573
iteration 9508 : loss : 0.025527, loss_ce: 0.010325
iteration 9509 : loss : 0.026317, loss_ce: 0.008169
iteration 9510 : loss : 0.028908, loss_ce: 0.010714
iteration 9511 : loss : 0.029304, loss_ce: 0.013981
iteration 9512 : loss : 0.030486, loss_ce: 0.011787
iteration 9513 : loss : 0.021669, loss_ce: 0.004133
iteration 9514 : loss : 0.046493, loss_ce: 0.004476
iteration 9515 : loss : 0.024415, loss_ce: 0.006546
iteration 9516 : loss : 0.030584, loss_ce: 0.010368
iteration 9517 : loss : 0.027611, loss_ce: 0.006544
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 9518 : loss : 0.031538, loss_ce: 0.016639
iteration 9519 : loss : 0.027242, loss_ce: 0.006995
iteration 9520 : loss : 0.033687, loss_ce: 0.011261
iteration 9521 : loss : 0.089567, loss_ce: 0.011661
iteration 9522 : loss : 0.029235, loss_ce: 0.010564
iteration 9523 : loss : 0.032782, loss_ce: 0.010053
iteration 9524 : loss : 0.031119, loss_ce: 0.010707
iteration 9525 : loss : 0.030380, loss_ce: 0.008263
iteration 9526 : loss : 0.027049, loss_ce: 0.009680
iteration 9527 : loss : 0.027316, loss_ce: 0.011387
iteration 9528 : loss : 0.024987, loss_ce: 0.009085
iteration 9529 : loss : 0.038325, loss_ce: 0.019226
iteration 9530 : loss : 0.028536, loss_ce: 0.009266
iteration 9531 : loss : 0.026130, loss_ce: 0.006048
iteration 9532 : loss : 0.027450, loss_ce: 0.010011
iteration 9533 : loss : 0.025905, loss_ce: 0.007794
iteration 9534 : loss : 0.033764, loss_ce: 0.011796
iteration 9535 : loss : 0.037070, loss_ce: 0.012296
iteration 9536 : loss : 0.037250, loss_ce: 0.014000
iteration 9537 : loss : 0.030365, loss_ce: 0.009933
iteration 9538 : loss : 0.026368, loss_ce: 0.013754
iteration 9539 : loss : 0.031732, loss_ce: 0.011278
iteration 9540 : loss : 0.031791, loss_ce: 0.012476
iteration 9541 : loss : 0.026606, loss_ce: 0.011692
iteration 9542 : loss : 0.027558, loss_ce: 0.004517
iteration 9543 : loss : 0.029264, loss_ce: 0.011502
iteration 9544 : loss : 0.023255, loss_ce: 0.008970
iteration 9545 : loss : 0.028250, loss_ce: 0.006683
iteration 9546 : loss : 0.026253, loss_ce: 0.009899
iteration 9547 : loss : 0.033721, loss_ce: 0.008678
iteration 9548 : loss : 0.023432, loss_ce: 0.008487
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 9549 : loss : 0.025551, loss_ce: 0.010580
iteration 9550 : loss : 0.040264, loss_ce: 0.010762
iteration 9551 : loss : 0.025608, loss_ce: 0.009815
iteration 9552 : loss : 0.075214, loss_ce: 0.005595
iteration 9553 : loss : 0.030034, loss_ce: 0.014162
iteration 9554 : loss : 0.033958, loss_ce: 0.015555
iteration 9555 : loss : 0.024903, loss_ce: 0.008245
iteration 9556 : loss : 0.027313, loss_ce: 0.010495
iteration 9557 : loss : 0.026721, loss_ce: 0.007163
iteration 9558 : loss : 0.026840, loss_ce: 0.009877
iteration 9559 : loss : 0.027305, loss_ce: 0.008643
iteration 9560 : loss : 0.033822, loss_ce: 0.005231
iteration 9561 : loss : 0.077981, loss_ce: 0.003851
iteration 9562 : loss : 0.074745, loss_ce: 0.005109
iteration 9563 : loss : 0.033958, loss_ce: 0.006372
iteration 9564 : loss : 0.029172, loss_ce: 0.010918
iteration 9565 : loss : 0.030589, loss_ce: 0.013400
iteration 9566 : loss : 0.082113, loss_ce: 0.005666
iteration 9567 : loss : 0.025889, loss_ce: 0.010863
iteration 9568 : loss : 0.039011, loss_ce: 0.006852
iteration 9569 : loss : 0.026983, loss_ce: 0.013345
iteration 9570 : loss : 0.025822, loss_ce: 0.007037
iteration 9571 : loss : 0.039570, loss_ce: 0.010815
iteration 9572 : loss : 0.029800, loss_ce: 0.008757
iteration 9573 : loss : 0.024284, loss_ce: 0.009161
iteration 9574 : loss : 0.031366, loss_ce: 0.010178
iteration 9575 : loss : 0.028290, loss_ce: 0.010444
iteration 9576 : loss : 0.035554, loss_ce: 0.006100
iteration 9577 : loss : 0.026579, loss_ce: 0.010967
iteration 9578 : loss : 0.029707, loss_ce: 0.009265
iteration 9579 : loss : 0.233217, loss_ce: 0.006726
 52%|█████████████▉             | 103/200 [1:33:31<1:28:10, 54.54s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 9580 : loss : 0.049425, loss_ce: 0.011796
iteration 9581 : loss : 0.029423, loss_ce: 0.017420
iteration 9582 : loss : 0.034893, loss_ce: 0.010141
iteration 9583 : loss : 0.036036, loss_ce: 0.008067
iteration 9584 : loss : 0.028097, loss_ce: 0.015004
iteration 9585 : loss : 0.026092, loss_ce: 0.009146
iteration 9586 : loss : 0.029074, loss_ce: 0.010401
iteration 9587 : loss : 0.075515, loss_ce: 0.006649
iteration 9588 : loss : 0.030264, loss_ce: 0.012434
iteration 9589 : loss : 0.023680, loss_ce: 0.007132
iteration 9590 : loss : 0.032792, loss_ce: 0.016452
iteration 9591 : loss : 0.031432, loss_ce: 0.008799
iteration 9592 : loss : 0.028924, loss_ce: 0.007012
iteration 9593 : loss : 0.026092, loss_ce: 0.011608
iteration 9594 : loss : 0.024338, loss_ce: 0.007916
iteration 9595 : loss : 0.038628, loss_ce: 0.011090
iteration 9596 : loss : 0.038941, loss_ce: 0.010557
iteration 9597 : loss : 0.017876, loss_ce: 0.005408
iteration 9598 : loss : 0.046719, loss_ce: 0.006216
iteration 9599 : loss : 0.026496, loss_ce: 0.010259
iteration 9600 : loss : 0.021567, loss_ce: 0.006206
iteration 9601 : loss : 0.029274, loss_ce: 0.006412
iteration 9602 : loss : 0.032301, loss_ce: 0.010187
iteration 9603 : loss : 0.075559, loss_ce: 0.007895
iteration 9604 : loss : 0.035294, loss_ce: 0.008177
iteration 9605 : loss : 0.038530, loss_ce: 0.009609
iteration 9606 : loss : 0.028785, loss_ce: 0.007430
iteration 9607 : loss : 0.026856, loss_ce: 0.006658
iteration 9608 : loss : 0.049179, loss_ce: 0.005862
iteration 9609 : loss : 0.025909, loss_ce: 0.006250
iteration 9610 : loss : 0.038687, loss_ce: 0.012374
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 9611 : loss : 0.031721, loss_ce: 0.006463
iteration 9612 : loss : 0.023279, loss_ce: 0.008542
iteration 9613 : loss : 0.035512, loss_ce: 0.014150
iteration 9614 : loss : 0.039301, loss_ce: 0.007546
iteration 9615 : loss : 0.025789, loss_ce: 0.007189
iteration 9616 : loss : 0.036560, loss_ce: 0.009353
iteration 9617 : loss : 0.041242, loss_ce: 0.012351
iteration 9618 : loss : 0.031172, loss_ce: 0.013352
iteration 9619 : loss : 0.032659, loss_ce: 0.010301
iteration 9620 : loss : 0.029541, loss_ce: 0.008036
iteration 9621 : loss : 0.034122, loss_ce: 0.006084
iteration 9622 : loss : 0.027998, loss_ce: 0.009715
iteration 9623 : loss : 0.029491, loss_ce: 0.008024
iteration 9624 : loss : 0.026320, loss_ce: 0.006503
iteration 9625 : loss : 0.030425, loss_ce: 0.010275
iteration 9626 : loss : 0.024184, loss_ce: 0.011174
iteration 9627 : loss : 0.023570, loss_ce: 0.009946
iteration 9628 : loss : 0.026935, loss_ce: 0.012495
iteration 9629 : loss : 0.024309, loss_ce: 0.008841
iteration 9630 : loss : 0.029317, loss_ce: 0.015463
iteration 9631 : loss : 0.029072, loss_ce: 0.010219
iteration 9632 : loss : 0.031985, loss_ce: 0.014887
iteration 9633 : loss : 0.076851, loss_ce: 0.008056
iteration 9634 : loss : 0.027045, loss_ce: 0.009007
iteration 9635 : loss : 0.025664, loss_ce: 0.007744
iteration 9636 : loss : 0.027225, loss_ce: 0.006004
iteration 9637 : loss : 0.027026, loss_ce: 0.009607
iteration 9638 : loss : 0.025168, loss_ce: 0.006855
iteration 9639 : loss : 0.028277, loss_ce: 0.007144
iteration 9640 : loss : 0.029636, loss_ce: 0.008929
iteration 9641 : loss : 0.018636, loss_ce: 0.005321
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 9642 : loss : 0.034264, loss_ce: 0.010439
iteration 9643 : loss : 0.024183, loss_ce: 0.009328
iteration 9644 : loss : 0.026028, loss_ce: 0.011165
iteration 9645 : loss : 0.030500, loss_ce: 0.009052
iteration 9646 : loss : 0.025779, loss_ce: 0.008941
iteration 9647 : loss : 0.034657, loss_ce: 0.014770
iteration 9648 : loss : 0.026536, loss_ce: 0.010602
iteration 9649 : loss : 0.026019, loss_ce: 0.010778
iteration 9650 : loss : 0.030823, loss_ce: 0.010217
iteration 9651 : loss : 0.023440, loss_ce: 0.007710
iteration 9652 : loss : 0.021452, loss_ce: 0.005065
iteration 9653 : loss : 0.026526, loss_ce: 0.005268
iteration 9654 : loss : 0.020847, loss_ce: 0.005692
iteration 9655 : loss : 0.024824, loss_ce: 0.010105
iteration 9656 : loss : 0.023457, loss_ce: 0.008846
iteration 9657 : loss : 0.036124, loss_ce: 0.007978
iteration 9658 : loss : 0.022726, loss_ce: 0.009916
iteration 9659 : loss : 0.028328, loss_ce: 0.009344
iteration 9660 : loss : 0.027248, loss_ce: 0.009065
iteration 9661 : loss : 0.026130, loss_ce: 0.011582
iteration 9662 : loss : 0.079667, loss_ce: 0.012544
iteration 9663 : loss : 0.031673, loss_ce: 0.010703
iteration 9664 : loss : 0.027140, loss_ce: 0.009765
iteration 9665 : loss : 0.023084, loss_ce: 0.005832
iteration 9666 : loss : 0.026309, loss_ce: 0.009455
iteration 9667 : loss : 0.019532, loss_ce: 0.005868
iteration 9668 : loss : 0.024041, loss_ce: 0.007921
iteration 9669 : loss : 0.024472, loss_ce: 0.007052
iteration 9670 : loss : 0.027340, loss_ce: 0.007170
iteration 9671 : loss : 0.027298, loss_ce: 0.009772
iteration 9672 : loss : 0.233143, loss_ce: 0.009950
 52%|██████████████             | 104/200 [1:34:25<1:27:16, 54.54s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 9673 : loss : 0.028298, loss_ce: 0.010252
iteration 9674 : loss : 0.030891, loss_ce: 0.012811
iteration 9675 : loss : 0.028807, loss_ce: 0.013413
iteration 9676 : loss : 0.027647, loss_ce: 0.009758
iteration 9677 : loss : 0.026747, loss_ce: 0.010600
iteration 9678 : loss : 0.026304, loss_ce: 0.007940
iteration 9679 : loss : 0.025273, loss_ce: 0.006966
iteration 9680 : loss : 0.026840, loss_ce: 0.012724
iteration 9681 : loss : 0.034682, loss_ce: 0.009205
iteration 9682 : loss : 0.075492, loss_ce: 0.006103
iteration 9683 : loss : 0.028813, loss_ce: 0.007952
iteration 9684 : loss : 0.027317, loss_ce: 0.014737
iteration 9685 : loss : 0.021171, loss_ce: 0.007526
iteration 9686 : loss : 0.028162, loss_ce: 0.012515
iteration 9687 : loss : 0.033656, loss_ce: 0.009536
iteration 9688 : loss : 0.021540, loss_ce: 0.004911
iteration 9689 : loss : 0.028409, loss_ce: 0.010069
iteration 9690 : loss : 0.024129, loss_ce: 0.007723
iteration 9691 : loss : 0.079710, loss_ce: 0.005866
iteration 9692 : loss : 0.018885, loss_ce: 0.005488
iteration 9693 : loss : 0.027171, loss_ce: 0.007342
iteration 9694 : loss : 0.023781, loss_ce: 0.010250
iteration 9695 : loss : 0.077820, loss_ce: 0.007724
iteration 9696 : loss : 0.026888, loss_ce: 0.007993
iteration 9697 : loss : 0.026105, loss_ce: 0.011419
iteration 9698 : loss : 0.031646, loss_ce: 0.006480
iteration 9699 : loss : 0.024251, loss_ce: 0.007741
iteration 9700 : loss : 0.078090, loss_ce: 0.010642
iteration 9701 : loss : 0.021011, loss_ce: 0.005941
iteration 9702 : loss : 0.021490, loss_ce: 0.011204
iteration 9703 : loss : 0.026407, loss_ce: 0.010617
pred_sum 45071
gtsum tensor(45149, device='cuda:0')
iteration 9704 : loss : 0.027384, loss_ce: 0.009713
iteration 9705 : loss : 0.024705, loss_ce: 0.008997
iteration 9706 : loss : 0.025643, loss_ce: 0.007550
iteration 9707 : loss : 0.024338, loss_ce: 0.006278
iteration 9708 : loss : 0.026618, loss_ce: 0.013027
iteration 9709 : loss : 0.025817, loss_ce: 0.007984
iteration 9710 : loss : 0.031599, loss_ce: 0.009629
iteration 9711 : loss : 0.028037, loss_ce: 0.011813
iteration 9712 : loss : 0.023723, loss_ce: 0.006788
iteration 9713 : loss : 0.074461, loss_ce: 0.003630
iteration 9714 : loss : 0.075816, loss_ce: 0.006612
iteration 9715 : loss : 0.026058, loss_ce: 0.007725
iteration 9716 : loss : 0.023098, loss_ce: 0.006783
iteration 9717 : loss : 0.026074, loss_ce: 0.011062
iteration 9718 : loss : 0.027101, loss_ce: 0.008860
iteration 9719 : loss : 0.026852, loss_ce: 0.008353
iteration 9720 : loss : 0.025649, loss_ce: 0.008780
iteration 9721 : loss : 0.028166, loss_ce: 0.008681
iteration 9722 : loss : 0.027729, loss_ce: 0.006828
iteration 9723 : loss : 0.027997, loss_ce: 0.008845
iteration 9724 : loss : 0.029689, loss_ce: 0.010996
iteration 9725 : loss : 0.021806, loss_ce: 0.005281
iteration 9726 : loss : 0.029100, loss_ce: 0.012187
iteration 9727 : loss : 0.027066, loss_ce: 0.008115
iteration 9728 : loss : 0.032823, loss_ce: 0.011793
iteration 9729 : loss : 0.029859, loss_ce: 0.011777
iteration 9730 : loss : 0.024623, loss_ce: 0.007243
iteration 9731 : loss : 0.023855, loss_ce: 0.006853
iteration 9732 : loss : 0.028496, loss_ce: 0.011368
iteration 9733 : loss : 0.025051, loss_ce: 0.006901
iteration 9734 : loss : 0.021398, loss_ce: 0.006985
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 9735 : loss : 0.023042, loss_ce: 0.007837
iteration 9736 : loss : 0.028830, loss_ce: 0.009133
iteration 9737 : loss : 0.026188, loss_ce: 0.006646
iteration 9738 : loss : 0.037011, loss_ce: 0.006116
iteration 9739 : loss : 0.034995, loss_ce: 0.012280
iteration 9740 : loss : 0.027016, loss_ce: 0.008275
iteration 9741 : loss : 0.023137, loss_ce: 0.008072
iteration 9742 : loss : 0.032431, loss_ce: 0.015286
iteration 9743 : loss : 0.023957, loss_ce: 0.009931
iteration 9744 : loss : 0.024860, loss_ce: 0.005181
iteration 9745 : loss : 0.078756, loss_ce: 0.009573
iteration 9746 : loss : 0.025436, loss_ce: 0.013868
iteration 9747 : loss : 0.027863, loss_ce: 0.011421
iteration 9748 : loss : 0.025584, loss_ce: 0.005358
iteration 9749 : loss : 0.030052, loss_ce: 0.008695
iteration 9750 : loss : 0.030221, loss_ce: 0.008237
iteration 9751 : loss : 0.032014, loss_ce: 0.011634
iteration 9752 : loss : 0.031838, loss_ce: 0.007029
iteration 9753 : loss : 0.074866, loss_ce: 0.005356
iteration 9754 : loss : 0.024345, loss_ce: 0.008508
iteration 9755 : loss : 0.029890, loss_ce: 0.009833
iteration 9756 : loss : 0.029512, loss_ce: 0.007439
iteration 9757 : loss : 0.034100, loss_ce: 0.006060
iteration 9758 : loss : 0.023256, loss_ce: 0.008935
iteration 9759 : loss : 0.024105, loss_ce: 0.007263
iteration 9760 : loss : 0.075545, loss_ce: 0.007016
iteration 9761 : loss : 0.025050, loss_ce: 0.006210
iteration 9762 : loss : 0.020824, loss_ce: 0.006824
iteration 9763 : loss : 0.026873, loss_ce: 0.012580
iteration 9764 : loss : 0.020618, loss_ce: 0.004634
iteration 9765 : loss : 0.074811, loss_ce: 0.011405
 52%|██████████████▏            | 105/200 [1:35:20<1:26:19, 54.52s/it]pred_sum 8094
gtsum tensor(7769, device='cuda:0')
iteration 9766 : loss : 0.022454, loss_ce: 0.005471
iteration 9767 : loss : 0.022879, loss_ce: 0.008178
iteration 9768 : loss : 0.024707, loss_ce: 0.008177
iteration 9769 : loss : 0.026780, loss_ce: 0.010638
iteration 9770 : loss : 0.029706, loss_ce: 0.008513
iteration 9771 : loss : 0.027403, loss_ce: 0.010360
iteration 9772 : loss : 0.024428, loss_ce: 0.006899
iteration 9773 : loss : 0.022785, loss_ce: 0.008332
iteration 9774 : loss : 0.027793, loss_ce: 0.009435
iteration 9775 : loss : 0.021822, loss_ce: 0.007127
iteration 9776 : loss : 0.025617, loss_ce: 0.008675
iteration 9777 : loss : 0.028264, loss_ce: 0.013218
iteration 9778 : loss : 0.076211, loss_ce: 0.004007
iteration 9779 : loss : 0.027414, loss_ce: 0.009887
iteration 9780 : loss : 0.028112, loss_ce: 0.011038
iteration 9781 : loss : 0.026491, loss_ce: 0.006033
iteration 9782 : loss : 0.023732, loss_ce: 0.005909
iteration 9783 : loss : 0.023956, loss_ce: 0.006781
iteration 9784 : loss : 0.030111, loss_ce: 0.005897
iteration 9785 : loss : 0.024870, loss_ce: 0.009512
iteration 9786 : loss : 0.075129, loss_ce: 0.005875
iteration 9787 : loss : 0.024399, loss_ce: 0.009477
iteration 9788 : loss : 0.124873, loss_ce: 0.002982
iteration 9789 : loss : 0.026219, loss_ce: 0.009973
iteration 9790 : loss : 0.024378, loss_ce: 0.008365
iteration 9791 : loss : 0.026585, loss_ce: 0.007510
iteration 9792 : loss : 0.026750, loss_ce: 0.009109
iteration 9793 : loss : 0.025195, loss_ce: 0.006124
iteration 9794 : loss : 0.023180, loss_ce: 0.007722
iteration 9795 : loss : 0.026990, loss_ce: 0.006775
iteration 9796 : loss : 0.022152, loss_ce: 0.008732
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 9797 : loss : 0.027408, loss_ce: 0.009212
iteration 9798 : loss : 0.041831, loss_ce: 0.007305
iteration 9799 : loss : 0.021779, loss_ce: 0.007886
iteration 9800 : loss : 0.021370, loss_ce: 0.005586
iteration 9801 : loss : 0.031172, loss_ce: 0.008751
iteration 9802 : loss : 0.033024, loss_ce: 0.012966
iteration 9803 : loss : 0.025812, loss_ce: 0.009372
iteration 9804 : loss : 0.031047, loss_ce: 0.010588
iteration 9805 : loss : 0.029019, loss_ce: 0.009703
iteration 9806 : loss : 0.057844, loss_ce: 0.006603
iteration 9807 : loss : 0.022260, loss_ce: 0.006002
iteration 9808 : loss : 0.026315, loss_ce: 0.010868
iteration 9809 : loss : 0.025420, loss_ce: 0.012464
iteration 9810 : loss : 0.034394, loss_ce: 0.009680
iteration 9811 : loss : 0.026489, loss_ce: 0.009731
iteration 9812 : loss : 0.031366, loss_ce: 0.012798
iteration 9813 : loss : 0.035230, loss_ce: 0.009146
iteration 9814 : loss : 0.033787, loss_ce: 0.008773
iteration 9815 : loss : 0.024750, loss_ce: 0.009113
iteration 9816 : loss : 0.026966, loss_ce: 0.012724
iteration 9817 : loss : 0.032637, loss_ce: 0.012277
iteration 9818 : loss : 0.032282, loss_ce: 0.006744
iteration 9819 : loss : 0.027094, loss_ce: 0.012599
iteration 9820 : loss : 0.026089, loss_ce: 0.014080
iteration 9821 : loss : 0.028416, loss_ce: 0.008080
iteration 9822 : loss : 0.077144, loss_ce: 0.002961
iteration 9823 : loss : 0.024859, loss_ce: 0.010597
iteration 9824 : loss : 0.026856, loss_ce: 0.012682
iteration 9825 : loss : 0.026783, loss_ce: 0.008146
iteration 9826 : loss : 0.026976, loss_ce: 0.011732
iteration 9827 : loss : 0.024858, loss_ce: 0.006154
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 9828 : loss : 0.075923, loss_ce: 0.006321
iteration 9829 : loss : 0.053389, loss_ce: 0.009946
iteration 9830 : loss : 0.076165, loss_ce: 0.008953
iteration 9831 : loss : 0.024681, loss_ce: 0.009303
iteration 9832 : loss : 0.023348, loss_ce: 0.008571
iteration 9833 : loss : 0.028897, loss_ce: 0.008934
iteration 9834 : loss : 0.024915, loss_ce: 0.004833
iteration 9835 : loss : 0.029892, loss_ce: 0.008766
iteration 9836 : loss : 0.026565, loss_ce: 0.010024
iteration 9837 : loss : 0.023564, loss_ce: 0.009351
iteration 9838 : loss : 0.030677, loss_ce: 0.015293
iteration 9839 : loss : 0.025442, loss_ce: 0.008695
iteration 9840 : loss : 0.028685, loss_ce: 0.005789
iteration 9841 : loss : 0.031934, loss_ce: 0.016064
iteration 9842 : loss : 0.025323, loss_ce: 0.005813
iteration 9843 : loss : 0.089834, loss_ce: 0.005289
iteration 9844 : loss : 0.027723, loss_ce: 0.011131
iteration 9845 : loss : 0.026585, loss_ce: 0.010809
iteration 9846 : loss : 0.028086, loss_ce: 0.016205
iteration 9847 : loss : 0.026828, loss_ce: 0.014739
iteration 9848 : loss : 0.034475, loss_ce: 0.016592
iteration 9849 : loss : 0.029065, loss_ce: 0.008110
iteration 9850 : loss : 0.038478, loss_ce: 0.011836
iteration 9851 : loss : 0.026550, loss_ce: 0.007666
iteration 9852 : loss : 0.028970, loss_ce: 0.008386
iteration 9853 : loss : 0.023772, loss_ce: 0.009328
iteration 9854 : loss : 0.031531, loss_ce: 0.014116
iteration 9855 : loss : 0.028361, loss_ce: 0.008317
iteration 9856 : loss : 0.028560, loss_ce: 0.007192
iteration 9857 : loss : 0.033762, loss_ce: 0.010444
iteration 9858 : loss : 0.183353, loss_ce: 0.009124
 53%|██████████████▎            | 106/200 [1:36:14<1:25:24, 54.52s/it]pred_sum 4914
gtsum tensor(4820, device='cuda:0')
iteration 9859 : loss : 0.033484, loss_ce: 0.009968
iteration 9860 : loss : 0.031134, loss_ce: 0.009052
iteration 9861 : loss : 0.030963, loss_ce: 0.015818
iteration 9862 : loss : 0.031857, loss_ce: 0.012166
iteration 9863 : loss : 0.032855, loss_ce: 0.014111
iteration 9864 : loss : 0.028545, loss_ce: 0.011659
iteration 9865 : loss : 0.024401, loss_ce: 0.009373
iteration 9866 : loss : 0.023139, loss_ce: 0.007663
iteration 9867 : loss : 0.023639, loss_ce: 0.009588
iteration 9868 : loss : 0.025686, loss_ce: 0.008079
iteration 9869 : loss : 0.020217, loss_ce: 0.007112
iteration 9870 : loss : 0.028627, loss_ce: 0.011021
iteration 9871 : loss : 0.023048, loss_ce: 0.009067
iteration 9872 : loss : 0.028213, loss_ce: 0.007247
iteration 9873 : loss : 0.027546, loss_ce: 0.010937
iteration 9874 : loss : 0.026052, loss_ce: 0.010594
iteration 9875 : loss : 0.025165, loss_ce: 0.006533
iteration 9876 : loss : 0.023579, loss_ce: 0.008559
iteration 9877 : loss : 0.023633, loss_ce: 0.007881
iteration 9878 : loss : 0.023529, loss_ce: 0.008831
iteration 9879 : loss : 0.027240, loss_ce: 0.007954
iteration 9880 : loss : 0.032379, loss_ce: 0.009996
iteration 9881 : loss : 0.028009, loss_ce: 0.010078
iteration 9882 : loss : 0.022440, loss_ce: 0.008887
iteration 9883 : loss : 0.023400, loss_ce: 0.008309
iteration 9884 : loss : 0.023442, loss_ce: 0.008676
iteration 9885 : loss : 0.077391, loss_ce: 0.004148
iteration 9886 : loss : 0.024448, loss_ce: 0.008014
iteration 9887 : loss : 0.027726, loss_ce: 0.010294
iteration 9888 : loss : 0.027213, loss_ce: 0.009578
iteration 9889 : loss : 0.031166, loss_ce: 0.011231
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 9890 : loss : 0.029067, loss_ce: 0.010901
iteration 9891 : loss : 0.027030, loss_ce: 0.008860
iteration 9892 : loss : 0.030283, loss_ce: 0.008436
iteration 9893 : loss : 0.036970, loss_ce: 0.010676
iteration 9894 : loss : 0.025186, loss_ce: 0.007640
iteration 9895 : loss : 0.024399, loss_ce: 0.008330
iteration 9896 : loss : 0.018386, loss_ce: 0.006333
iteration 9897 : loss : 0.032211, loss_ce: 0.009120
iteration 9898 : loss : 0.082431, loss_ce: 0.005325
iteration 9899 : loss : 0.040914, loss_ce: 0.012953
iteration 9900 : loss : 0.021842, loss_ce: 0.007881
iteration 9901 : loss : 0.026938, loss_ce: 0.010845
iteration 9902 : loss : 0.027803, loss_ce: 0.008940
iteration 9903 : loss : 0.026516, loss_ce: 0.010325
iteration 9904 : loss : 0.025216, loss_ce: 0.012216
iteration 9905 : loss : 0.026657, loss_ce: 0.010089
iteration 9906 : loss : 0.184794, loss_ce: 0.003210
iteration 9907 : loss : 0.036252, loss_ce: 0.006817
iteration 9908 : loss : 0.126932, loss_ce: 0.005956
iteration 9909 : loss : 0.031048, loss_ce: 0.007539
iteration 9910 : loss : 0.025399, loss_ce: 0.011708
iteration 9911 : loss : 0.027925, loss_ce: 0.007511
iteration 9912 : loss : 0.025809, loss_ce: 0.009960
iteration 9913 : loss : 0.025080, loss_ce: 0.011831
iteration 9914 : loss : 0.025858, loss_ce: 0.011250
iteration 9915 : loss : 0.029884, loss_ce: 0.010998
iteration 9916 : loss : 0.023236, loss_ce: 0.008167
iteration 9917 : loss : 0.027009, loss_ce: 0.011196
iteration 9918 : loss : 0.030282, loss_ce: 0.012247
iteration 9919 : loss : 0.027376, loss_ce: 0.005557
iteration 9920 : loss : 0.028040, loss_ce: 0.010551
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 9921 : loss : 0.027788, loss_ce: 0.006884
iteration 9922 : loss : 0.026994, loss_ce: 0.009387
iteration 9923 : loss : 0.035935, loss_ce: 0.005622
iteration 9924 : loss : 0.028653, loss_ce: 0.010921
iteration 9925 : loss : 0.024047, loss_ce: 0.007739
iteration 9926 : loss : 0.077064, loss_ce: 0.005253
iteration 9927 : loss : 0.025176, loss_ce: 0.004430
iteration 9928 : loss : 0.029539, loss_ce: 0.010453
iteration 9929 : loss : 0.023581, loss_ce: 0.006137
iteration 9930 : loss : 0.022204, loss_ce: 0.010006
iteration 9931 : loss : 0.024753, loss_ce: 0.007048
iteration 9932 : loss : 0.029072, loss_ce: 0.014434
iteration 9933 : loss : 0.077541, loss_ce: 0.008400
iteration 9934 : loss : 0.023114, loss_ce: 0.005532
iteration 9935 : loss : 0.025613, loss_ce: 0.009706
iteration 9936 : loss : 0.025679, loss_ce: 0.010194
iteration 9937 : loss : 0.021185, loss_ce: 0.007040
iteration 9938 : loss : 0.030679, loss_ce: 0.012757
iteration 9939 : loss : 0.028691, loss_ce: 0.011020
iteration 9940 : loss : 0.047397, loss_ce: 0.008252
iteration 9941 : loss : 0.027106, loss_ce: 0.012633
iteration 9942 : loss : 0.032499, loss_ce: 0.011829
iteration 9943 : loss : 0.025273, loss_ce: 0.011369
iteration 9944 : loss : 0.025649, loss_ce: 0.009880
iteration 9945 : loss : 0.025040, loss_ce: 0.006219
iteration 9946 : loss : 0.027873, loss_ce: 0.006128
iteration 9947 : loss : 0.034812, loss_ce: 0.007514
iteration 9948 : loss : 0.079916, loss_ce: 0.007247
iteration 9949 : loss : 0.026134, loss_ce: 0.009796
iteration 9950 : loss : 0.029157, loss_ce: 0.006485
iteration 9951 : loss : 0.443876, loss_ce: 0.000516
 54%|██████████████▍            | 107/200 [1:37:09<1:24:29, 54.52s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 9952 : loss : 0.026009, loss_ce: 0.009090
iteration 9953 : loss : 0.027583, loss_ce: 0.009526
iteration 9954 : loss : 0.024083, loss_ce: 0.005212
iteration 9955 : loss : 0.024613, loss_ce: 0.006004
iteration 9956 : loss : 0.026946, loss_ce: 0.010080
iteration 9957 : loss : 0.028988, loss_ce: 0.015653
iteration 9958 : loss : 0.023498, loss_ce: 0.003816
iteration 9959 : loss : 0.072089, loss_ce: 0.005397
iteration 9960 : loss : 0.027724, loss_ce: 0.013461
iteration 9961 : loss : 0.032086, loss_ce: 0.007693
iteration 9962 : loss : 0.027920, loss_ce: 0.007903
iteration 9963 : loss : 0.075204, loss_ce: 0.005009
iteration 9964 : loss : 0.029012, loss_ce: 0.009566
iteration 9965 : loss : 0.053446, loss_ce: 0.008970
iteration 9966 : loss : 0.025938, loss_ce: 0.010233
iteration 9967 : loss : 0.023347, loss_ce: 0.006045
iteration 9968 : loss : 0.037353, loss_ce: 0.008498
iteration 9969 : loss : 0.024474, loss_ce: 0.009297
iteration 9970 : loss : 0.032466, loss_ce: 0.010784
iteration 9971 : loss : 0.024138, loss_ce: 0.008596
iteration 9972 : loss : 0.029535, loss_ce: 0.010178
iteration 9973 : loss : 0.024004, loss_ce: 0.009742
iteration 9974 : loss : 0.028137, loss_ce: 0.006817
iteration 9975 : loss : 0.027260, loss_ce: 0.010490
iteration 9976 : loss : 0.025547, loss_ce: 0.011715
iteration 9977 : loss : 0.030773, loss_ce: 0.009116
iteration 9978 : loss : 0.029412, loss_ce: 0.007730
iteration 9979 : loss : 0.030759, loss_ce: 0.010544
iteration 9980 : loss : 0.029399, loss_ce: 0.013412
iteration 9981 : loss : 0.031279, loss_ce: 0.010945
iteration 9982 : loss : 0.024945, loss_ce: 0.009727
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 9983 : loss : 0.030267, loss_ce: 0.010993
iteration 9984 : loss : 0.024930, loss_ce: 0.007112
iteration 9985 : loss : 0.023633, loss_ce: 0.008477
iteration 9986 : loss : 0.024417, loss_ce: 0.007248
iteration 9987 : loss : 0.025242, loss_ce: 0.008841
iteration 9988 : loss : 0.027004, loss_ce: 0.008001
iteration 9989 : loss : 0.036484, loss_ce: 0.005430
iteration 9990 : loss : 0.021970, loss_ce: 0.005842
iteration 9991 : loss : 0.029539, loss_ce: 0.009414
iteration 9992 : loss : 0.028844, loss_ce: 0.007652
iteration 9993 : loss : 0.027081, loss_ce: 0.007956
iteration 9994 : loss : 0.027036, loss_ce: 0.010887
iteration 9995 : loss : 0.026196, loss_ce: 0.011219
iteration 9996 : loss : 0.024604, loss_ce: 0.009420
iteration 9997 : loss : 0.088214, loss_ce: 0.012186
iteration 9998 : loss : 0.024729, loss_ce: 0.008237
iteration 9999 : loss : 0.024165, loss_ce: 0.004719
iteration 10000 : loss : 0.028590, loss_ce: 0.007800
iteration 10001 : loss : 0.019991, loss_ce: 0.004845
iteration 10002 : loss : 0.026445, loss_ce: 0.011544
iteration 10003 : loss : 0.034520, loss_ce: 0.009825
iteration 10004 : loss : 0.031305, loss_ce: 0.013789
iteration 10005 : loss : 0.034355, loss_ce: 0.009107
iteration 10006 : loss : 0.034313, loss_ce: 0.003235
iteration 10007 : loss : 0.039001, loss_ce: 0.009998
iteration 10008 : loss : 0.023953, loss_ce: 0.008996
iteration 10009 : loss : 0.023439, loss_ce: 0.005981
iteration 10010 : loss : 0.029100, loss_ce: 0.016482
iteration 10011 : loss : 0.030107, loss_ce: 0.009830
iteration 10012 : loss : 0.036873, loss_ce: 0.012542
iteration 10013 : loss : 0.024736, loss_ce: 0.007600
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 10014 : loss : 0.024780, loss_ce: 0.006750
iteration 10015 : loss : 0.025799, loss_ce: 0.012327
iteration 10016 : loss : 0.023522, loss_ce: 0.004639
iteration 10017 : loss : 0.034345, loss_ce: 0.008571
iteration 10018 : loss : 0.032566, loss_ce: 0.009302
iteration 10019 : loss : 0.028218, loss_ce: 0.008302
iteration 10020 : loss : 0.027843, loss_ce: 0.013156
iteration 10021 : loss : 0.077240, loss_ce: 0.007285
iteration 10022 : loss : 0.025785, loss_ce: 0.010424
iteration 10023 : loss : 0.021579, loss_ce: 0.004435
iteration 10024 : loss : 0.079576, loss_ce: 0.006094
iteration 10025 : loss : 0.029459, loss_ce: 0.008327
iteration 10026 : loss : 0.033262, loss_ce: 0.013082
iteration 10027 : loss : 0.029583, loss_ce: 0.010958
iteration 10028 : loss : 0.031885, loss_ce: 0.006320
iteration 10029 : loss : 0.026929, loss_ce: 0.009662
iteration 10030 : loss : 0.031245, loss_ce: 0.012373
iteration 10031 : loss : 0.029235, loss_ce: 0.010534
iteration 10032 : loss : 0.026889, loss_ce: 0.011136
iteration 10033 : loss : 0.023739, loss_ce: 0.005841
iteration 10034 : loss : 0.023989, loss_ce: 0.008582
iteration 10035 : loss : 0.024299, loss_ce: 0.007865
iteration 10036 : loss : 0.078370, loss_ce: 0.009018
iteration 10037 : loss : 0.051704, loss_ce: 0.006466
iteration 10038 : loss : 0.026444, loss_ce: 0.011388
iteration 10039 : loss : 0.027279, loss_ce: 0.009658
iteration 10040 : loss : 0.027063, loss_ce: 0.009765
iteration 10041 : loss : 0.026924, loss_ce: 0.008787
iteration 10042 : loss : 0.030523, loss_ce: 0.009359
iteration 10043 : loss : 0.026580, loss_ce: 0.011261
iteration 10044 : loss : 0.339118, loss_ce: 0.003159
 54%|██████████████▌            | 108/200 [1:38:03<1:23:34, 54.51s/it]pred_sum 9823
gtsum tensor(9593, device='cuda:0')
iteration 10045 : loss : 0.025253, loss_ce: 0.008984
iteration 10046 : loss : 0.029669, loss_ce: 0.006092
iteration 10047 : loss : 0.032203, loss_ce: 0.010899
iteration 10048 : loss : 0.026098, loss_ce: 0.008161
iteration 10049 : loss : 0.025478, loss_ce: 0.006674
iteration 10050 : loss : 0.029674, loss_ce: 0.011349
iteration 10051 : loss : 0.026847, loss_ce: 0.012777
iteration 10052 : loss : 0.021079, loss_ce: 0.005242
iteration 10053 : loss : 0.023112, loss_ce: 0.005949
iteration 10054 : loss : 0.022097, loss_ce: 0.009224
iteration 10055 : loss : 0.022157, loss_ce: 0.007663
iteration 10056 : loss : 0.072575, loss_ce: 0.006277
iteration 10057 : loss : 0.025770, loss_ce: 0.006673
iteration 10058 : loss : 0.026627, loss_ce: 0.006974
iteration 10059 : loss : 0.028858, loss_ce: 0.007619
iteration 10060 : loss : 0.024336, loss_ce: 0.011203
iteration 10061 : loss : 0.029324, loss_ce: 0.009569
iteration 10062 : loss : 0.072107, loss_ce: 0.006008
iteration 10063 : loss : 0.020139, loss_ce: 0.008351
iteration 10064 : loss : 0.023787, loss_ce: 0.009895
iteration 10065 : loss : 0.034269, loss_ce: 0.009539
iteration 10066 : loss : 0.021887, loss_ce: 0.005930
iteration 10067 : loss : 0.029163, loss_ce: 0.008585
iteration 10068 : loss : 0.025375, loss_ce: 0.006548
iteration 10069 : loss : 0.033320, loss_ce: 0.010477
iteration 10070 : loss : 0.077547, loss_ce: 0.009207
iteration 10071 : loss : 0.031488, loss_ce: 0.012211
iteration 10072 : loss : 0.030041, loss_ce: 0.010775
iteration 10073 : loss : 0.028832, loss_ce: 0.007749
iteration 10074 : loss : 0.027190, loss_ce: 0.011588
iteration 10075 : loss : 0.025620, loss_ce: 0.007155
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 10076 : loss : 0.027438, loss_ce: 0.009454
iteration 10077 : loss : 0.026424, loss_ce: 0.007830
iteration 10078 : loss : 0.025022, loss_ce: 0.007404
iteration 10079 : loss : 0.030107, loss_ce: 0.006753
iteration 10080 : loss : 0.032392, loss_ce: 0.013748
iteration 10081 : loss : 0.030536, loss_ce: 0.008337
iteration 10082 : loss : 0.023001, loss_ce: 0.011408
iteration 10083 : loss : 0.025457, loss_ce: 0.009706
iteration 10084 : loss : 0.025277, loss_ce: 0.006916
iteration 10085 : loss : 0.024752, loss_ce: 0.011269
iteration 10086 : loss : 0.077840, loss_ce: 0.005119
iteration 10087 : loss : 0.029633, loss_ce: 0.010208
iteration 10088 : loss : 0.030537, loss_ce: 0.013741
iteration 10089 : loss : 0.028438, loss_ce: 0.010902
iteration 10090 : loss : 0.026029, loss_ce: 0.007943
iteration 10091 : loss : 0.023349, loss_ce: 0.007787
iteration 10092 : loss : 0.020709, loss_ce: 0.007798
iteration 10093 : loss : 0.073548, loss_ce: 0.004346
iteration 10094 : loss : 0.025105, loss_ce: 0.006565
iteration 10095 : loss : 0.025512, loss_ce: 0.009023
iteration 10096 : loss : 0.024202, loss_ce: 0.007174
iteration 10097 : loss : 0.036776, loss_ce: 0.009865
iteration 10098 : loss : 0.023749, loss_ce: 0.005798
iteration 10099 : loss : 0.024884, loss_ce: 0.012906
iteration 10100 : loss : 0.030721, loss_ce: 0.011023
iteration 10101 : loss : 0.080433, loss_ce: 0.002403
iteration 10102 : loss : 0.024213, loss_ce: 0.006049
iteration 10103 : loss : 0.032150, loss_ce: 0.016645
iteration 10104 : loss : 0.028568, loss_ce: 0.006084
iteration 10105 : loss : 0.026384, loss_ce: 0.007273
iteration 10106 : loss : 0.033279, loss_ce: 0.007393
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 10107 : loss : 0.023054, loss_ce: 0.008026
iteration 10108 : loss : 0.025231, loss_ce: 0.007065
iteration 10109 : loss : 0.028609, loss_ce: 0.005564
iteration 10110 : loss : 0.024329, loss_ce: 0.008249
iteration 10111 : loss : 0.032239, loss_ce: 0.016056
iteration 10112 : loss : 0.030062, loss_ce: 0.010710
iteration 10113 : loss : 0.033146, loss_ce: 0.016651
iteration 10114 : loss : 0.028399, loss_ce: 0.011291
iteration 10115 : loss : 0.029898, loss_ce: 0.013795
iteration 10116 : loss : 0.025159, loss_ce: 0.008317
iteration 10117 : loss : 0.028691, loss_ce: 0.007760
iteration 10118 : loss : 0.023507, loss_ce: 0.006879
iteration 10119 : loss : 0.030178, loss_ce: 0.009199
iteration 10120 : loss : 0.028881, loss_ce: 0.009202
iteration 10121 : loss : 0.025859, loss_ce: 0.012987
iteration 10122 : loss : 0.031443, loss_ce: 0.008459
iteration 10123 : loss : 0.022274, loss_ce: 0.008108
iteration 10124 : loss : 0.078768, loss_ce: 0.005903
iteration 10125 : loss : 0.023526, loss_ce: 0.007727
iteration 10126 : loss : 0.036845, loss_ce: 0.008382
iteration 10127 : loss : 0.026945, loss_ce: 0.009722
iteration 10128 : loss : 0.032695, loss_ce: 0.007189
iteration 10129 : loss : 0.098991, loss_ce: 0.004028
iteration 10130 : loss : 0.022095, loss_ce: 0.005442
iteration 10131 : loss : 0.033796, loss_ce: 0.013960
iteration 10132 : loss : 0.027365, loss_ce: 0.009598
iteration 10133 : loss : 0.036025, loss_ce: 0.010069
iteration 10134 : loss : 0.045762, loss_ce: 0.009821
iteration 10135 : loss : 0.027124, loss_ce: 0.010071
iteration 10136 : loss : 0.025723, loss_ce: 0.012245
iteration 10137 : loss : 0.041112, loss_ce: 0.011112
 55%|██████████████▋            | 109/200 [1:38:58<1:22:40, 54.51s/it]pred_sum 829
gtsum tensor(123, device='cuda:0')
iteration 10138 : loss : 0.022974, loss_ce: 0.006957
iteration 10139 : loss : 0.031481, loss_ce: 0.013625
iteration 10140 : loss : 0.086613, loss_ce: 0.006734
iteration 10141 : loss : 0.025926, loss_ce: 0.011330
iteration 10142 : loss : 0.030095, loss_ce: 0.007926
iteration 10143 : loss : 0.034350, loss_ce: 0.011170
iteration 10144 : loss : 0.022606, loss_ce: 0.008256
iteration 10145 : loss : 0.026199, loss_ce: 0.011111
iteration 10146 : loss : 0.105080, loss_ce: 0.004997
iteration 10147 : loss : 0.027122, loss_ce: 0.006505
iteration 10148 : loss : 0.027514, loss_ce: 0.008859
iteration 10149 : loss : 0.084062, loss_ce: 0.010758
iteration 10150 : loss : 0.035317, loss_ce: 0.008542
iteration 10151 : loss : 0.030416, loss_ce: 0.012550
iteration 10152 : loss : 0.031776, loss_ce: 0.014834
iteration 10153 : loss : 0.029652, loss_ce: 0.009348
iteration 10154 : loss : 0.038959, loss_ce: 0.006585
iteration 10155 : loss : 0.030324, loss_ce: 0.009455
iteration 10156 : loss : 0.028652, loss_ce: 0.009532
iteration 10157 : loss : 0.044236, loss_ce: 0.006012
iteration 10158 : loss : 0.074407, loss_ce: 0.004901
iteration 10159 : loss : 0.029825, loss_ce: 0.008840
iteration 10160 : loss : 0.085407, loss_ce: 0.010590
iteration 10161 : loss : 0.031529, loss_ce: 0.009628
iteration 10162 : loss : 0.035356, loss_ce: 0.009193
iteration 10163 : loss : 0.032135, loss_ce: 0.009999
iteration 10164 : loss : 0.030427, loss_ce: 0.010490
iteration 10165 : loss : 0.028198, loss_ce: 0.008390
iteration 10166 : loss : 0.030114, loss_ce: 0.007854
iteration 10167 : loss : 0.035919, loss_ce: 0.008015
iteration 10168 : loss : 0.032132, loss_ce: 0.012109
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 10169 : loss : 0.023818, loss_ce: 0.008992
iteration 10170 : loss : 0.024601, loss_ce: 0.004135
iteration 10171 : loss : 0.028377, loss_ce: 0.008738
iteration 10172 : loss : 0.034146, loss_ce: 0.017111
iteration 10173 : loss : 0.032608, loss_ce: 0.013927
iteration 10174 : loss : 0.024582, loss_ce: 0.007136
iteration 10175 : loss : 0.030691, loss_ce: 0.008634
iteration 10176 : loss : 0.024040, loss_ce: 0.004929
iteration 10177 : loss : 0.023566, loss_ce: 0.007179
iteration 10178 : loss : 0.027172, loss_ce: 0.010951
iteration 10179 : loss : 0.027437, loss_ce: 0.013400
iteration 10180 : loss : 0.041400, loss_ce: 0.008968
iteration 10181 : loss : 0.027377, loss_ce: 0.010777
iteration 10182 : loss : 0.074731, loss_ce: 0.006002
iteration 10183 : loss : 0.024108, loss_ce: 0.005438
iteration 10184 : loss : 0.021594, loss_ce: 0.007952
iteration 10185 : loss : 0.026279, loss_ce: 0.011541
iteration 10186 : loss : 0.063727, loss_ce: 0.004933
iteration 10187 : loss : 0.028066, loss_ce: 0.009208
iteration 10188 : loss : 0.024139, loss_ce: 0.005993
iteration 10189 : loss : 0.032827, loss_ce: 0.009536
iteration 10190 : loss : 0.037706, loss_ce: 0.008658
iteration 10191 : loss : 0.028687, loss_ce: 0.009634
iteration 10192 : loss : 0.025517, loss_ce: 0.011463
iteration 10193 : loss : 0.028641, loss_ce: 0.008332
iteration 10194 : loss : 0.023493, loss_ce: 0.008318
iteration 10195 : loss : 0.027720, loss_ce: 0.009089
iteration 10196 : loss : 0.031051, loss_ce: 0.013363
iteration 10197 : loss : 0.026677, loss_ce: 0.006966
iteration 10198 : loss : 0.030091, loss_ce: 0.010776
iteration 10199 : loss : 0.023523, loss_ce: 0.009801
pred_sum 5999
gtsum tensor(6108, device='cuda:0')
iteration 10200 : loss : 0.025528, loss_ce: 0.007657
iteration 10201 : loss : 0.024232, loss_ce: 0.007207
iteration 10202 : loss : 0.028990, loss_ce: 0.012443
iteration 10203 : loss : 0.026126, loss_ce: 0.007467
iteration 10204 : loss : 0.030674, loss_ce: 0.007617
iteration 10205 : loss : 0.033335, loss_ce: 0.013064
iteration 10206 : loss : 0.025488, loss_ce: 0.008017
iteration 10207 : loss : 0.031650, loss_ce: 0.009437
iteration 10208 : loss : 0.026579, loss_ce: 0.010322
iteration 10209 : loss : 0.025507, loss_ce: 0.010036
iteration 10210 : loss : 0.027687, loss_ce: 0.008494
iteration 10211 : loss : 0.025215, loss_ce: 0.005275
iteration 10212 : loss : 0.024398, loss_ce: 0.009621
iteration 10213 : loss : 0.033098, loss_ce: 0.014388
iteration 10214 : loss : 0.028790, loss_ce: 0.017625
iteration 10215 : loss : 0.023577, loss_ce: 0.004368
iteration 10216 : loss : 0.027679, loss_ce: 0.009123
iteration 10217 : loss : 0.021690, loss_ce: 0.007053
iteration 10218 : loss : 0.029716, loss_ce: 0.009403
iteration 10219 : loss : 0.033007, loss_ce: 0.006208
iteration 10220 : loss : 0.034096, loss_ce: 0.005778
iteration 10221 : loss : 0.080892, loss_ce: 0.009078
iteration 10222 : loss : 0.029700, loss_ce: 0.006056
iteration 10223 : loss : 0.042834, loss_ce: 0.011528
iteration 10224 : loss : 0.028756, loss_ce: 0.011816
iteration 10225 : loss : 0.023760, loss_ce: 0.009265
iteration 10226 : loss : 0.029879, loss_ce: 0.008584
iteration 10227 : loss : 0.027270, loss_ce: 0.013618
iteration 10228 : loss : 0.029212, loss_ce: 0.010968
iteration 10229 : loss : 0.020019, loss_ce: 0.007392
iteration 10230 : loss : 0.232964, loss_ce: 0.009393
 55%|██████████████▊            | 110/200 [1:39:52<1:21:44, 54.49s/it]pred_sum 95
gtsum tensor(97, device='cuda:0')
iteration 10231 : loss : 0.020130, loss_ce: 0.005557
iteration 10232 : loss : 0.035958, loss_ce: 0.011164
iteration 10233 : loss : 0.026313, loss_ce: 0.010630
iteration 10234 : loss : 0.026358, loss_ce: 0.005341
iteration 10235 : loss : 0.027615, loss_ce: 0.007445
iteration 10236 : loss : 0.024109, loss_ce: 0.010936
iteration 10237 : loss : 0.030745, loss_ce: 0.011480
iteration 10238 : loss : 0.025506, loss_ce: 0.007190
iteration 10239 : loss : 0.030032, loss_ce: 0.007382
iteration 10240 : loss : 0.079924, loss_ce: 0.008646
iteration 10241 : loss : 0.029376, loss_ce: 0.010656
iteration 10242 : loss : 0.025732, loss_ce: 0.006685
iteration 10243 : loss : 0.028520, loss_ce: 0.007581
iteration 10244 : loss : 0.041305, loss_ce: 0.009724
iteration 10245 : loss : 0.025546, loss_ce: 0.006837
iteration 10246 : loss : 0.023619, loss_ce: 0.009356
iteration 10247 : loss : 0.027745, loss_ce: 0.012240
iteration 10248 : loss : 0.027704, loss_ce: 0.012325
iteration 10249 : loss : 0.026461, loss_ce: 0.004810
iteration 10250 : loss : 0.025812, loss_ce: 0.009135
iteration 10251 : loss : 0.022967, loss_ce: 0.007967
iteration 10252 : loss : 0.023703, loss_ce: 0.007644
iteration 10253 : loss : 0.036415, loss_ce: 0.007979
iteration 10254 : loss : 0.030376, loss_ce: 0.010446
iteration 10255 : loss : 0.025573, loss_ce: 0.011572
iteration 10256 : loss : 0.024706, loss_ce: 0.009139
iteration 10257 : loss : 0.026081, loss_ce: 0.005304
iteration 10258 : loss : 0.030630, loss_ce: 0.008579
iteration 10259 : loss : 0.030701, loss_ce: 0.009599
iteration 10260 : loss : 0.020300, loss_ce: 0.003524
iteration 10261 : loss : 0.022789, loss_ce: 0.008761
pred_sum 18959
gtsum tensor(18311, device='cuda:0')
iteration 10262 : loss : 0.027015, loss_ce: 0.008744
iteration 10263 : loss : 0.022066, loss_ce: 0.006839
iteration 10264 : loss : 0.027703, loss_ce: 0.009175
iteration 10265 : loss : 0.023464, loss_ce: 0.006456
iteration 10266 : loss : 0.026365, loss_ce: 0.011729
iteration 10267 : loss : 0.025452, loss_ce: 0.008278
iteration 10268 : loss : 0.025248, loss_ce: 0.010105
iteration 10269 : loss : 0.036281, loss_ce: 0.009040
iteration 10270 : loss : 0.028908, loss_ce: 0.006735
iteration 10271 : loss : 0.024348, loss_ce: 0.008108
iteration 10272 : loss : 0.027244, loss_ce: 0.007774
iteration 10273 : loss : 0.049482, loss_ce: 0.005481
iteration 10274 : loss : 0.047894, loss_ce: 0.008293
iteration 10275 : loss : 0.027507, loss_ce: 0.012542
iteration 10276 : loss : 0.023744, loss_ce: 0.005093
iteration 10277 : loss : 0.032459, loss_ce: 0.010224
iteration 10278 : loss : 0.025990, loss_ce: 0.009000
iteration 10279 : loss : 0.037460, loss_ce: 0.009771
iteration 10280 : loss : 0.025401, loss_ce: 0.005335
iteration 10281 : loss : 0.028439, loss_ce: 0.009710
iteration 10282 : loss : 0.027926, loss_ce: 0.010665
iteration 10283 : loss : 0.028474, loss_ce: 0.010640
iteration 10284 : loss : 0.030317, loss_ce: 0.011569
iteration 10285 : loss : 0.025756, loss_ce: 0.009272
iteration 10286 : loss : 0.031536, loss_ce: 0.004850
iteration 10287 : loss : 0.026506, loss_ce: 0.010969
iteration 10288 : loss : 0.025670, loss_ce: 0.010352
iteration 10289 : loss : 0.030471, loss_ce: 0.008211
iteration 10290 : loss : 0.021379, loss_ce: 0.008433
iteration 10291 : loss : 0.033525, loss_ce: 0.009158
iteration 10292 : loss : 0.031973, loss_ce: 0.013205
pred_sum 139
gtsum tensor(142, device='cuda:0')
iteration 10293 : loss : 0.027639, loss_ce: 0.007501
iteration 10294 : loss : 0.029842, loss_ce: 0.006179
iteration 10295 : loss : 0.027031, loss_ce: 0.009523
iteration 10296 : loss : 0.028395, loss_ce: 0.008475
iteration 10297 : loss : 0.035958, loss_ce: 0.010610
iteration 10298 : loss : 0.023236, loss_ce: 0.006852
iteration 10299 : loss : 0.027273, loss_ce: 0.013552
iteration 10300 : loss : 0.029752, loss_ce: 0.014284
iteration 10301 : loss : 0.032115, loss_ce: 0.011678
iteration 10302 : loss : 0.024677, loss_ce: 0.008645
iteration 10303 : loss : 0.023940, loss_ce: 0.009310
iteration 10304 : loss : 0.029065, loss_ce: 0.012644
iteration 10305 : loss : 0.031050, loss_ce: 0.013889
iteration 10306 : loss : 0.021124, loss_ce: 0.007112
iteration 10307 : loss : 0.026220, loss_ce: 0.010378
iteration 10308 : loss : 0.025084, loss_ce: 0.012784
iteration 10309 : loss : 0.031956, loss_ce: 0.015680
iteration 10310 : loss : 0.047134, loss_ce: 0.007022
iteration 10311 : loss : 0.025629, loss_ce: 0.007533
iteration 10312 : loss : 0.027684, loss_ce: 0.004580
iteration 10313 : loss : 0.031307, loss_ce: 0.012719
iteration 10314 : loss : 0.025003, loss_ce: 0.009813
iteration 10315 : loss : 0.024316, loss_ce: 0.011168
iteration 10316 : loss : 0.023867, loss_ce: 0.011168
iteration 10317 : loss : 0.030502, loss_ce: 0.008199
iteration 10318 : loss : 0.023258, loss_ce: 0.004702
iteration 10319 : loss : 0.025538, loss_ce: 0.011046
iteration 10320 : loss : 0.023348, loss_ce: 0.007261
iteration 10321 : loss : 0.129044, loss_ce: 0.006622
iteration 10322 : loss : 0.021242, loss_ce: 0.005461
iteration 10323 : loss : 0.357087, loss_ce: 0.002614
 56%|██████████████▉            | 111/200 [1:40:47<1:20:49, 54.49s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 10324 : loss : 0.029167, loss_ce: 0.005933
iteration 10325 : loss : 0.079384, loss_ce: 0.011082
iteration 10326 : loss : 0.028020, loss_ce: 0.009752
iteration 10327 : loss : 0.026467, loss_ce: 0.011251
iteration 10328 : loss : 0.028007, loss_ce: 0.011431
iteration 10329 : loss : 0.103242, loss_ce: 0.009373
iteration 10330 : loss : 0.026700, loss_ce: 0.010393
iteration 10331 : loss : 0.028742, loss_ce: 0.009384
iteration 10332 : loss : 0.034418, loss_ce: 0.012568
iteration 10333 : loss : 0.021211, loss_ce: 0.007180
iteration 10334 : loss : 0.024532, loss_ce: 0.009089
iteration 10335 : loss : 0.028889, loss_ce: 0.006425
iteration 10336 : loss : 0.026889, loss_ce: 0.010265
iteration 10337 : loss : 0.032267, loss_ce: 0.007506
iteration 10338 : loss : 0.026465, loss_ce: 0.004689
iteration 10339 : loss : 0.026554, loss_ce: 0.009532
iteration 10340 : loss : 0.031863, loss_ce: 0.010023
iteration 10341 : loss : 0.022955, loss_ce: 0.006519
iteration 10342 : loss : 0.028632, loss_ce: 0.009739
iteration 10343 : loss : 0.024265, loss_ce: 0.008502
iteration 10344 : loss : 0.029096, loss_ce: 0.011614
iteration 10345 : loss : 0.085396, loss_ce: 0.007547
iteration 10346 : loss : 0.029991, loss_ce: 0.011657
iteration 10347 : loss : 0.032194, loss_ce: 0.015774
iteration 10348 : loss : 0.030981, loss_ce: 0.011692
iteration 10349 : loss : 0.030906, loss_ce: 0.008465
iteration 10350 : loss : 0.025644, loss_ce: 0.008029
iteration 10351 : loss : 0.028927, loss_ce: 0.008598
iteration 10352 : loss : 0.025148, loss_ce: 0.010618
iteration 10353 : loss : 0.023183, loss_ce: 0.003627
iteration 10354 : loss : 0.071936, loss_ce: 0.005125
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 10355 : loss : 0.027280, loss_ce: 0.011210
iteration 10356 : loss : 0.078441, loss_ce: 0.003030
iteration 10357 : loss : 0.026803, loss_ce: 0.011107
iteration 10358 : loss : 0.027030, loss_ce: 0.008601
iteration 10359 : loss : 0.024259, loss_ce: 0.008202
iteration 10360 : loss : 0.026665, loss_ce: 0.011252
iteration 10361 : loss : 0.023528, loss_ce: 0.007096
iteration 10362 : loss : 0.033999, loss_ce: 0.013580
iteration 10363 : loss : 0.023214, loss_ce: 0.006568
iteration 10364 : loss : 0.057524, loss_ce: 0.009413
iteration 10365 : loss : 0.024782, loss_ce: 0.008356
iteration 10366 : loss : 0.034253, loss_ce: 0.006742
iteration 10367 : loss : 0.025648, loss_ce: 0.004363
iteration 10368 : loss : 0.022285, loss_ce: 0.007095
iteration 10369 : loss : 0.031394, loss_ce: 0.008247
iteration 10370 : loss : 0.031324, loss_ce: 0.010147
iteration 10371 : loss : 0.025636, loss_ce: 0.007250
iteration 10372 : loss : 0.028937, loss_ce: 0.009471
iteration 10373 : loss : 0.022092, loss_ce: 0.007684
iteration 10374 : loss : 0.021714, loss_ce: 0.006527
iteration 10375 : loss : 0.027026, loss_ce: 0.010518
iteration 10376 : loss : 0.023597, loss_ce: 0.010319
iteration 10377 : loss : 0.025013, loss_ce: 0.011890
iteration 10378 : loss : 0.026882, loss_ce: 0.010277
iteration 10379 : loss : 0.027265, loss_ce: 0.009616
iteration 10380 : loss : 0.029782, loss_ce: 0.006142
iteration 10381 : loss : 0.022154, loss_ce: 0.008467
iteration 10382 : loss : 0.031541, loss_ce: 0.009617
iteration 10383 : loss : 0.030649, loss_ce: 0.008285
iteration 10384 : loss : 0.077155, loss_ce: 0.004457
iteration 10385 : loss : 0.022829, loss_ce: 0.008302
pred_sum 27624
gtsum tensor(26339, device='cuda:0')
iteration 10386 : loss : 0.028516, loss_ce: 0.009506
iteration 10387 : loss : 0.030544, loss_ce: 0.015898
iteration 10388 : loss : 0.029496, loss_ce: 0.010965
iteration 10389 : loss : 0.024392, loss_ce: 0.005992
iteration 10390 : loss : 0.033138, loss_ce: 0.006621
iteration 10391 : loss : 0.028975, loss_ce: 0.005346
iteration 10392 : loss : 0.082687, loss_ce: 0.010065
iteration 10393 : loss : 0.025466, loss_ce: 0.009034
iteration 10394 : loss : 0.026102, loss_ce: 0.010195
iteration 10395 : loss : 0.025628, loss_ce: 0.004077
iteration 10396 : loss : 0.027653, loss_ce: 0.010536
iteration 10397 : loss : 0.023498, loss_ce: 0.010278
iteration 10398 : loss : 0.024315, loss_ce: 0.007610
iteration 10399 : loss : 0.027609, loss_ce: 0.008806
iteration 10400 : loss : 0.024577, loss_ce: 0.005647
iteration 10401 : loss : 0.026100, loss_ce: 0.009737
iteration 10402 : loss : 0.077776, loss_ce: 0.005824
iteration 10403 : loss : 0.028159, loss_ce: 0.007451
iteration 10404 : loss : 0.026549, loss_ce: 0.011057
iteration 10405 : loss : 0.050678, loss_ce: 0.008390
iteration 10406 : loss : 0.025989, loss_ce: 0.005779
iteration 10407 : loss : 0.031493, loss_ce: 0.009128
iteration 10408 : loss : 0.025019, loss_ce: 0.008110
iteration 10409 : loss : 0.039117, loss_ce: 0.013994
iteration 10410 : loss : 0.028414, loss_ce: 0.008067
iteration 10411 : loss : 0.023324, loss_ce: 0.008068
iteration 10412 : loss : 0.030155, loss_ce: 0.011947
iteration 10413 : loss : 0.027791, loss_ce: 0.006358
iteration 10414 : loss : 0.021436, loss_ce: 0.007758
iteration 10415 : loss : 0.024188, loss_ce: 0.008522
iteration 10416 : loss : 0.034084, loss_ce: 0.020735
 56%|███████████████            | 112/200 [1:41:41<1:19:56, 54.50s/it]pred_sum 47337
gtsum tensor(48230, device='cuda:0')
iteration 10417 : loss : 0.022013, loss_ce: 0.007806
iteration 10418 : loss : 0.024512, loss_ce: 0.008369
iteration 10419 : loss : 0.033662, loss_ce: 0.005588
iteration 10420 : loss : 0.076839, loss_ce: 0.004850
iteration 10421 : loss : 0.025855, loss_ce: 0.010289
iteration 10422 : loss : 0.083113, loss_ce: 0.005903
iteration 10423 : loss : 0.019693, loss_ce: 0.003891
iteration 10424 : loss : 0.026132, loss_ce: 0.008983
iteration 10425 : loss : 0.024001, loss_ce: 0.007567
iteration 10426 : loss : 0.030891, loss_ce: 0.006082
iteration 10427 : loss : 0.026685, loss_ce: 0.009495
iteration 10428 : loss : 0.026854, loss_ce: 0.008363
iteration 10429 : loss : 0.027936, loss_ce: 0.007758
iteration 10430 : loss : 0.021502, loss_ce: 0.005108
iteration 10431 : loss : 0.026510, loss_ce: 0.010294
iteration 10432 : loss : 0.025733, loss_ce: 0.006792
iteration 10433 : loss : 0.025874, loss_ce: 0.010535
iteration 10434 : loss : 0.022648, loss_ce: 0.010528
iteration 10435 : loss : 0.022296, loss_ce: 0.007569
iteration 10436 : loss : 0.023750, loss_ce: 0.007580
iteration 10437 : loss : 0.025329, loss_ce: 0.009487
iteration 10438 : loss : 0.024478, loss_ce: 0.007985
iteration 10439 : loss : 0.027729, loss_ce: 0.012257
iteration 10440 : loss : 0.042629, loss_ce: 0.005342
iteration 10441 : loss : 0.028394, loss_ce: 0.011750
iteration 10442 : loss : 0.028516, loss_ce: 0.009916
iteration 10443 : loss : 0.030088, loss_ce: 0.008201
iteration 10444 : loss : 0.028807, loss_ce: 0.009453
iteration 10445 : loss : 0.076550, loss_ce: 0.008901
iteration 10446 : loss : 0.027667, loss_ce: 0.010729
iteration 10447 : loss : 0.025006, loss_ce: 0.005398
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 10448 : loss : 0.023061, loss_ce: 0.007999
iteration 10449 : loss : 0.031927, loss_ce: 0.007039
iteration 10450 : loss : 0.034824, loss_ce: 0.008704
iteration 10451 : loss : 0.036915, loss_ce: 0.016540
iteration 10452 : loss : 0.026960, loss_ce: 0.011764
iteration 10453 : loss : 0.029889, loss_ce: 0.008041
iteration 10454 : loss : 0.030976, loss_ce: 0.015523
iteration 10455 : loss : 0.023137, loss_ce: 0.010037
iteration 10456 : loss : 0.032035, loss_ce: 0.010973
iteration 10457 : loss : 0.028018, loss_ce: 0.010350
iteration 10458 : loss : 0.028069, loss_ce: 0.010882
iteration 10459 : loss : 0.024963, loss_ce: 0.010116
iteration 10460 : loss : 0.025750, loss_ce: 0.010209
iteration 10461 : loss : 0.025421, loss_ce: 0.008328
iteration 10462 : loss : 0.027174, loss_ce: 0.007106
iteration 10463 : loss : 0.033428, loss_ce: 0.007492
iteration 10464 : loss : 0.026902, loss_ce: 0.008451
iteration 10465 : loss : 0.031082, loss_ce: 0.006702
iteration 10466 : loss : 0.027618, loss_ce: 0.008580
iteration 10467 : loss : 0.023437, loss_ce: 0.006964
iteration 10468 : loss : 0.026822, loss_ce: 0.007834
iteration 10469 : loss : 0.070694, loss_ce: 0.005435
iteration 10470 : loss : 0.052278, loss_ce: 0.013166
iteration 10471 : loss : 0.028505, loss_ce: 0.009348
iteration 10472 : loss : 0.027908, loss_ce: 0.010769
iteration 10473 : loss : 0.024629, loss_ce: 0.007349
iteration 10474 : loss : 0.027552, loss_ce: 0.011157
iteration 10475 : loss : 0.021121, loss_ce: 0.007838
iteration 10476 : loss : 0.025047, loss_ce: 0.009094
iteration 10477 : loss : 0.025299, loss_ce: 0.007812
iteration 10478 : loss : 0.028773, loss_ce: 0.007631
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 10479 : loss : 0.026955, loss_ce: 0.010530
iteration 10480 : loss : 0.081082, loss_ce: 0.006794
iteration 10481 : loss : 0.028083, loss_ce: 0.011089
iteration 10482 : loss : 0.027307, loss_ce: 0.009243
iteration 10483 : loss : 0.025476, loss_ce: 0.005443
iteration 10484 : loss : 0.075762, loss_ce: 0.007091
iteration 10485 : loss : 0.022312, loss_ce: 0.008569
iteration 10486 : loss : 0.025002, loss_ce: 0.010463
iteration 10487 : loss : 0.023683, loss_ce: 0.007574
iteration 10488 : loss : 0.026624, loss_ce: 0.005785
iteration 10489 : loss : 0.030155, loss_ce: 0.003029
iteration 10490 : loss : 0.025262, loss_ce: 0.012308
iteration 10491 : loss : 0.021521, loss_ce: 0.007492
iteration 10492 : loss : 0.021801, loss_ce: 0.007149
iteration 10493 : loss : 0.028767, loss_ce: 0.010854
iteration 10494 : loss : 0.042119, loss_ce: 0.009255
iteration 10495 : loss : 0.029701, loss_ce: 0.010999
iteration 10496 : loss : 0.033265, loss_ce: 0.013149
iteration 10497 : loss : 0.025526, loss_ce: 0.008678
iteration 10498 : loss : 0.046081, loss_ce: 0.008706
iteration 10499 : loss : 0.023786, loss_ce: 0.009424
iteration 10500 : loss : 0.026903, loss_ce: 0.006830
iteration 10501 : loss : 0.031372, loss_ce: 0.010120
iteration 10502 : loss : 0.030608, loss_ce: 0.012117
iteration 10503 : loss : 0.029205, loss_ce: 0.008005
iteration 10504 : loss : 0.026690, loss_ce: 0.010857
iteration 10505 : loss : 0.025768, loss_ce: 0.010024
iteration 10506 : loss : 0.049518, loss_ce: 0.007896
iteration 10507 : loss : 0.023326, loss_ce: 0.007037
iteration 10508 : loss : 0.026900, loss_ce: 0.005708
iteration 10509 : loss : 0.392388, loss_ce: 0.001627
 56%|███████████████▎           | 113/200 [1:42:36<1:19:02, 54.52s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 10510 : loss : 0.023415, loss_ce: 0.010053
iteration 10511 : loss : 0.031067, loss_ce: 0.010783
iteration 10512 : loss : 0.026730, loss_ce: 0.010243
iteration 10513 : loss : 0.028696, loss_ce: 0.012254
iteration 10514 : loss : 0.078937, loss_ce: 0.006665
iteration 10515 : loss : 0.032476, loss_ce: 0.010884
iteration 10516 : loss : 0.026854, loss_ce: 0.007662
iteration 10517 : loss : 0.030636, loss_ce: 0.007952
iteration 10518 : loss : 0.023312, loss_ce: 0.007523
iteration 10519 : loss : 0.025733, loss_ce: 0.008098
iteration 10520 : loss : 0.078900, loss_ce: 0.009279
iteration 10521 : loss : 0.030438, loss_ce: 0.009079
iteration 10522 : loss : 0.035500, loss_ce: 0.009350
iteration 10523 : loss : 0.023254, loss_ce: 0.008019
iteration 10524 : loss : 0.024277, loss_ce: 0.009241
iteration 10525 : loss : 0.027114, loss_ce: 0.007175
iteration 10526 : loss : 0.027721, loss_ce: 0.007313
iteration 10527 : loss : 0.078527, loss_ce: 0.007369
iteration 10528 : loss : 0.023249, loss_ce: 0.008676
iteration 10529 : loss : 0.025592, loss_ce: 0.008666
iteration 10530 : loss : 0.028786, loss_ce: 0.010991
iteration 10531 : loss : 0.026722, loss_ce: 0.009985
iteration 10532 : loss : 0.024035, loss_ce: 0.009272
iteration 10533 : loss : 0.027331, loss_ce: 0.010106
iteration 10534 : loss : 0.073391, loss_ce: 0.005581
iteration 10535 : loss : 0.026596, loss_ce: 0.011549
iteration 10536 : loss : 0.021148, loss_ce: 0.006899
iteration 10537 : loss : 0.022554, loss_ce: 0.003851
iteration 10538 : loss : 0.025447, loss_ce: 0.009234
iteration 10539 : loss : 0.080050, loss_ce: 0.008378
iteration 10540 : loss : 0.028933, loss_ce: 0.007015
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 10541 : loss : 0.028328, loss_ce: 0.008191
iteration 10542 : loss : 0.022252, loss_ce: 0.005524
iteration 10543 : loss : 0.020150, loss_ce: 0.006901
iteration 10544 : loss : 0.028151, loss_ce: 0.008124
iteration 10545 : loss : 0.022590, loss_ce: 0.007529
iteration 10546 : loss : 0.021834, loss_ce: 0.009383
iteration 10547 : loss : 0.025010, loss_ce: 0.007735
iteration 10548 : loss : 0.026287, loss_ce: 0.008872
iteration 10549 : loss : 0.026325, loss_ce: 0.012241
iteration 10550 : loss : 0.023330, loss_ce: 0.009402
iteration 10551 : loss : 0.026454, loss_ce: 0.009467
iteration 10552 : loss : 0.032117, loss_ce: 0.011356
iteration 10553 : loss : 0.026814, loss_ce: 0.008038
iteration 10554 : loss : 0.022899, loss_ce: 0.004702
iteration 10555 : loss : 0.036319, loss_ce: 0.006998
iteration 10556 : loss : 0.024323, loss_ce: 0.010378
iteration 10557 : loss : 0.021437, loss_ce: 0.008300
iteration 10558 : loss : 0.084815, loss_ce: 0.006059
iteration 10559 : loss : 0.028901, loss_ce: 0.013775
iteration 10560 : loss : 0.026961, loss_ce: 0.010106
iteration 10561 : loss : 0.028257, loss_ce: 0.011442
iteration 10562 : loss : 0.025569, loss_ce: 0.006206
iteration 10563 : loss : 0.029044, loss_ce: 0.010481
iteration 10564 : loss : 0.022946, loss_ce: 0.006472
iteration 10565 : loss : 0.029366, loss_ce: 0.010991
iteration 10566 : loss : 0.024527, loss_ce: 0.011830
iteration 10567 : loss : 0.029127, loss_ce: 0.007656
iteration 10568 : loss : 0.026964, loss_ce: 0.006843
iteration 10569 : loss : 0.029346, loss_ce: 0.010673
iteration 10570 : loss : 0.033726, loss_ce: 0.011733
iteration 10571 : loss : 0.021663, loss_ce: 0.006363
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 10572 : loss : 0.027260, loss_ce: 0.007615
iteration 10573 : loss : 0.077111, loss_ce: 0.003922
iteration 10574 : loss : 0.030471, loss_ce: 0.007840
iteration 10575 : loss : 0.026001, loss_ce: 0.008586
iteration 10576 : loss : 0.031751, loss_ce: 0.012288
iteration 10577 : loss : 0.022760, loss_ce: 0.008631
iteration 10578 : loss : 0.027952, loss_ce: 0.007690
iteration 10579 : loss : 0.025321, loss_ce: 0.011152
iteration 10580 : loss : 0.024784, loss_ce: 0.007752
iteration 10581 : loss : 0.034897, loss_ce: 0.005892
iteration 10582 : loss : 0.025468, loss_ce: 0.004721
iteration 10583 : loss : 0.029028, loss_ce: 0.012402
iteration 10584 : loss : 0.030301, loss_ce: 0.009687
iteration 10585 : loss : 0.022691, loss_ce: 0.008133
iteration 10586 : loss : 0.030237, loss_ce: 0.010423
iteration 10587 : loss : 0.031346, loss_ce: 0.011107
iteration 10588 : loss : 0.028061, loss_ce: 0.010433
iteration 10589 : loss : 0.031963, loss_ce: 0.011296
iteration 10590 : loss : 0.079482, loss_ce: 0.011141
iteration 10591 : loss : 0.029231, loss_ce: 0.010466
iteration 10592 : loss : 0.028551, loss_ce: 0.009525
iteration 10593 : loss : 0.035170, loss_ce: 0.011121
iteration 10594 : loss : 0.024120, loss_ce: 0.007977
iteration 10595 : loss : 0.030137, loss_ce: 0.006689
iteration 10596 : loss : 0.025553, loss_ce: 0.007929
iteration 10597 : loss : 0.025580, loss_ce: 0.008197
iteration 10598 : loss : 0.028313, loss_ce: 0.018314
iteration 10599 : loss : 0.027424, loss_ce: 0.006904
iteration 10600 : loss : 0.027218, loss_ce: 0.008339
iteration 10601 : loss : 0.029482, loss_ce: 0.009319
iteration 10602 : loss : 0.285405, loss_ce: 0.002472
 57%|███████████████▍           | 114/200 [1:43:30<1:18:07, 54.50s/it]pred_sum 173
gtsum tensor(173, device='cuda:0')
iteration 10603 : loss : 0.023847, loss_ce: 0.011155
iteration 10604 : loss : 0.025535, loss_ce: 0.008010
iteration 10605 : loss : 0.022789, loss_ce: 0.007581
iteration 10606 : loss : 0.025597, loss_ce: 0.011813
iteration 10607 : loss : 0.029955, loss_ce: 0.014821
iteration 10608 : loss : 0.026126, loss_ce: 0.008776
iteration 10609 : loss : 0.024536, loss_ce: 0.007891
iteration 10610 : loss : 0.022442, loss_ce: 0.011897
iteration 10611 : loss : 0.024896, loss_ce: 0.005606
iteration 10612 : loss : 0.026847, loss_ce: 0.010495
iteration 10613 : loss : 0.028344, loss_ce: 0.006673
iteration 10614 : loss : 0.023843, loss_ce: 0.007416
iteration 10615 : loss : 0.030151, loss_ce: 0.011488
iteration 10616 : loss : 0.028526, loss_ce: 0.009353
iteration 10617 : loss : 0.031645, loss_ce: 0.010342
iteration 10618 : loss : 0.077068, loss_ce: 0.008508
iteration 10619 : loss : 0.087913, loss_ce: 0.004890
iteration 10620 : loss : 0.021876, loss_ce: 0.007573
iteration 10621 : loss : 0.072970, loss_ce: 0.005068
iteration 10622 : loss : 0.024642, loss_ce: 0.008074
iteration 10623 : loss : 0.026166, loss_ce: 0.007137
iteration 10624 : loss : 0.029393, loss_ce: 0.006798
iteration 10625 : loss : 0.024350, loss_ce: 0.008958
iteration 10626 : loss : 0.029441, loss_ce: 0.013968
iteration 10627 : loss : 0.074296, loss_ce: 0.005098
iteration 10628 : loss : 0.021975, loss_ce: 0.006998
iteration 10629 : loss : 0.071085, loss_ce: 0.005521
iteration 10630 : loss : 0.030385, loss_ce: 0.008077
iteration 10631 : loss : 0.027515, loss_ce: 0.011431
iteration 10632 : loss : 0.025749, loss_ce: 0.008736
iteration 10633 : loss : 0.030881, loss_ce: 0.009561
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 10634 : loss : 0.021077, loss_ce: 0.007198
iteration 10635 : loss : 0.030435, loss_ce: 0.012789
iteration 10636 : loss : 0.022285, loss_ce: 0.006711
iteration 10637 : loss : 0.023121, loss_ce: 0.007077
iteration 10638 : loss : 0.029470, loss_ce: 0.009584
iteration 10639 : loss : 0.026207, loss_ce: 0.009102
iteration 10640 : loss : 0.029799, loss_ce: 0.012014
iteration 10641 : loss : 0.027256, loss_ce: 0.009666
iteration 10642 : loss : 0.025634, loss_ce: 0.006474
iteration 10643 : loss : 0.025735, loss_ce: 0.010641
iteration 10644 : loss : 0.026497, loss_ce: 0.009045
iteration 10645 : loss : 0.031991, loss_ce: 0.015654
iteration 10646 : loss : 0.074120, loss_ce: 0.005901
iteration 10647 : loss : 0.022460, loss_ce: 0.007581
iteration 10648 : loss : 0.024209, loss_ce: 0.008660
iteration 10649 : loss : 0.019860, loss_ce: 0.006071
iteration 10650 : loss : 0.018732, loss_ce: 0.005366
iteration 10651 : loss : 0.026023, loss_ce: 0.011471
iteration 10652 : loss : 0.025895, loss_ce: 0.008596
iteration 10653 : loss : 0.028071, loss_ce: 0.011130
iteration 10654 : loss : 0.023753, loss_ce: 0.009815
iteration 10655 : loss : 0.021588, loss_ce: 0.008042
iteration 10656 : loss : 0.038504, loss_ce: 0.007582
iteration 10657 : loss : 0.028534, loss_ce: 0.010840
iteration 10658 : loss : 0.022893, loss_ce: 0.007598
iteration 10659 : loss : 0.037611, loss_ce: 0.006607
iteration 10660 : loss : 0.086331, loss_ce: 0.006289
iteration 10661 : loss : 0.027859, loss_ce: 0.007252
iteration 10662 : loss : 0.078819, loss_ce: 0.010357
iteration 10663 : loss : 0.030321, loss_ce: 0.012638
iteration 10664 : loss : 0.031119, loss_ce: 0.009930
pred_sum 24001
gtsum tensor(23169, device='cuda:0')
iteration 10665 : loss : 0.029675, loss_ce: 0.013805
iteration 10666 : loss : 0.022696, loss_ce: 0.005434
iteration 10667 : loss : 0.022889, loss_ce: 0.007657
iteration 10668 : loss : 0.035074, loss_ce: 0.005637
iteration 10669 : loss : 0.028249, loss_ce: 0.007889
iteration 10670 : loss : 0.024896, loss_ce: 0.007953
iteration 10671 : loss : 0.023927, loss_ce: 0.008700
iteration 10672 : loss : 0.025641, loss_ce: 0.007145
iteration 10673 : loss : 0.024949, loss_ce: 0.009348
iteration 10674 : loss : 0.030746, loss_ce: 0.006464
iteration 10675 : loss : 0.027036, loss_ce: 0.011387
iteration 10676 : loss : 0.075440, loss_ce: 0.003856
iteration 10677 : loss : 0.025346, loss_ce: 0.009831
iteration 10678 : loss : 0.030619, loss_ce: 0.013121
iteration 10679 : loss : 0.027021, loss_ce: 0.007569
iteration 10680 : loss : 0.028401, loss_ce: 0.007169
iteration 10681 : loss : 0.026031, loss_ce: 0.008585
iteration 10682 : loss : 0.023282, loss_ce: 0.003983
iteration 10683 : loss : 0.033306, loss_ce: 0.009161
iteration 10684 : loss : 0.027112, loss_ce: 0.007068
iteration 10685 : loss : 0.023281, loss_ce: 0.008072
iteration 10686 : loss : 0.034666, loss_ce: 0.007222
iteration 10687 : loss : 0.028583, loss_ce: 0.014666
iteration 10688 : loss : 0.029868, loss_ce: 0.013927
iteration 10689 : loss : 0.079880, loss_ce: 0.005247
iteration 10690 : loss : 0.027870, loss_ce: 0.008371
iteration 10691 : loss : 0.028910, loss_ce: 0.014693
iteration 10692 : loss : 0.026508, loss_ce: 0.005732
iteration 10693 : loss : 0.039137, loss_ce: 0.007287
iteration 10694 : loss : 0.026162, loss_ce: 0.008465
iteration 10695 : loss : 0.253403, loss_ce: 0.001812
 57%|███████████████▌           | 115/200 [1:44:25<1:17:12, 54.50s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 10696 : loss : 0.073168, loss_ce: 0.006628
iteration 10697 : loss : 0.027647, loss_ce: 0.010593
iteration 10698 : loss : 0.022348, loss_ce: 0.007944
iteration 10699 : loss : 0.033048, loss_ce: 0.013160
iteration 10700 : loss : 0.027731, loss_ce: 0.008915
iteration 10701 : loss : 0.077900, loss_ce: 0.004936
iteration 10702 : loss : 0.073189, loss_ce: 0.006792
iteration 10703 : loss : 0.021006, loss_ce: 0.005361
iteration 10704 : loss : 0.022966, loss_ce: 0.010232
iteration 10705 : loss : 0.022905, loss_ce: 0.010788
iteration 10706 : loss : 0.033518, loss_ce: 0.008815
iteration 10707 : loss : 0.083298, loss_ce: 0.007905
iteration 10708 : loss : 0.040752, loss_ce: 0.008539
iteration 10709 : loss : 0.019840, loss_ce: 0.004492
iteration 10710 : loss : 0.079408, loss_ce: 0.005179
iteration 10711 : loss : 0.025718, loss_ce: 0.009608
iteration 10712 : loss : 0.041793, loss_ce: 0.013391
iteration 10713 : loss : 0.025236, loss_ce: 0.010408
iteration 10714 : loss : 0.024722, loss_ce: 0.009406
iteration 10715 : loss : 0.031523, loss_ce: 0.007720
iteration 10716 : loss : 0.026613, loss_ce: 0.009129
iteration 10717 : loss : 0.025884, loss_ce: 0.008560
iteration 10718 : loss : 0.027971, loss_ce: 0.008045
iteration 10719 : loss : 0.024892, loss_ce: 0.010158
iteration 10720 : loss : 0.024542, loss_ce: 0.007456
iteration 10721 : loss : 0.026366, loss_ce: 0.013837
iteration 10722 : loss : 0.024328, loss_ce: 0.011435
iteration 10723 : loss : 0.028978, loss_ce: 0.013327
iteration 10724 : loss : 0.028943, loss_ce: 0.007502
iteration 10725 : loss : 0.026626, loss_ce: 0.013066
iteration 10726 : loss : 0.035778, loss_ce: 0.005480
pred_sum 5472
gtsum tensor(5402, device='cuda:0')
iteration 10727 : loss : 0.029085, loss_ce: 0.009995
iteration 10728 : loss : 0.074926, loss_ce: 0.004828
iteration 10729 : loss : 0.025498, loss_ce: 0.008998
iteration 10730 : loss : 0.030205, loss_ce: 0.008190
iteration 10731 : loss : 0.024123, loss_ce: 0.010234
iteration 10732 : loss : 0.079197, loss_ce: 0.008711
iteration 10733 : loss : 0.021558, loss_ce: 0.006634
iteration 10734 : loss : 0.029614, loss_ce: 0.011559
iteration 10735 : loss : 0.024536, loss_ce: 0.008972
iteration 10736 : loss : 0.027062, loss_ce: 0.010235
iteration 10737 : loss : 0.026944, loss_ce: 0.007762
iteration 10738 : loss : 0.044445, loss_ce: 0.010353
iteration 10739 : loss : 0.024669, loss_ce: 0.009480
iteration 10740 : loss : 0.025963, loss_ce: 0.008934
iteration 10741 : loss : 0.023812, loss_ce: 0.008664
iteration 10742 : loss : 0.027122, loss_ce: 0.011858
iteration 10743 : loss : 0.028077, loss_ce: 0.011037
iteration 10744 : loss : 0.026828, loss_ce: 0.006786
iteration 10745 : loss : 0.024760, loss_ce: 0.010549
iteration 10746 : loss : 0.025688, loss_ce: 0.009006
iteration 10747 : loss : 0.030192, loss_ce: 0.008692
iteration 10748 : loss : 0.040903, loss_ce: 0.007198
iteration 10749 : loss : 0.029391, loss_ce: 0.007123
iteration 10750 : loss : 0.027915, loss_ce: 0.007751
iteration 10751 : loss : 0.022517, loss_ce: 0.007069
iteration 10752 : loss : 0.027589, loss_ce: 0.008191
iteration 10753 : loss : 0.027426, loss_ce: 0.012395
iteration 10754 : loss : 0.023668, loss_ce: 0.007711
iteration 10755 : loss : 0.029145, loss_ce: 0.009950
iteration 10756 : loss : 0.029082, loss_ce: 0.018254
iteration 10757 : loss : 0.030461, loss_ce: 0.005968
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 10758 : loss : 0.028302, loss_ce: 0.010920
iteration 10759 : loss : 0.024249, loss_ce: 0.008414
iteration 10760 : loss : 0.030142, loss_ce: 0.005074
iteration 10761 : loss : 0.022523, loss_ce: 0.009541
iteration 10762 : loss : 0.021326, loss_ce: 0.008294
iteration 10763 : loss : 0.024713, loss_ce: 0.007296
iteration 10764 : loss : 0.030839, loss_ce: 0.010904
iteration 10765 : loss : 0.027771, loss_ce: 0.007731
iteration 10766 : loss : 0.026575, loss_ce: 0.004959
iteration 10767 : loss : 0.027014, loss_ce: 0.010497
iteration 10768 : loss : 0.031829, loss_ce: 0.007166
iteration 10769 : loss : 0.018708, loss_ce: 0.005411
iteration 10770 : loss : 0.027343, loss_ce: 0.010312
iteration 10771 : loss : 0.029166, loss_ce: 0.007886
iteration 10772 : loss : 0.074787, loss_ce: 0.004764
iteration 10773 : loss : 0.024646, loss_ce: 0.004441
iteration 10774 : loss : 0.029775, loss_ce: 0.009030
iteration 10775 : loss : 0.084413, loss_ce: 0.007927
iteration 10776 : loss : 0.038177, loss_ce: 0.009305
iteration 10777 : loss : 0.025860, loss_ce: 0.011043
iteration 10778 : loss : 0.024916, loss_ce: 0.010181
iteration 10779 : loss : 0.024334, loss_ce: 0.012356
iteration 10780 : loss : 0.032333, loss_ce: 0.006498
iteration 10781 : loss : 0.022764, loss_ce: 0.008384
iteration 10782 : loss : 0.025137, loss_ce: 0.009391
iteration 10783 : loss : 0.074022, loss_ce: 0.007019
iteration 10784 : loss : 0.023442, loss_ce: 0.010523
iteration 10785 : loss : 0.025997, loss_ce: 0.009081
iteration 10786 : loss : 0.028009, loss_ce: 0.011613
iteration 10787 : loss : 0.024068, loss_ce: 0.005941
iteration 10788 : loss : 0.087414, loss_ce: 0.008239
 58%|███████████████▋           | 116/200 [1:45:19<1:16:18, 54.50s/it]pred_sum 26322
gtsum tensor(26842, device='cuda:0')
iteration 10789 : loss : 0.024749, loss_ce: 0.007641
iteration 10790 : loss : 0.023539, loss_ce: 0.010708
iteration 10791 : loss : 0.031627, loss_ce: 0.010194
iteration 10792 : loss : 0.024995, loss_ce: 0.009585
iteration 10793 : loss : 0.025068, loss_ce: 0.004735
iteration 10794 : loss : 0.025270, loss_ce: 0.006001
iteration 10795 : loss : 0.023226, loss_ce: 0.007024
iteration 10796 : loss : 0.023209, loss_ce: 0.008424
iteration 10797 : loss : 0.023277, loss_ce: 0.008303
iteration 10798 : loss : 0.024574, loss_ce: 0.009098
iteration 10799 : loss : 0.029545, loss_ce: 0.016656
iteration 10800 : loss : 0.027483, loss_ce: 0.008113
iteration 10801 : loss : 0.032930, loss_ce: 0.012755
iteration 10802 : loss : 0.023634, loss_ce: 0.008798
iteration 10803 : loss : 0.024386, loss_ce: 0.006069
iteration 10804 : loss : 0.025959, loss_ce: 0.010523
iteration 10805 : loss : 0.024542, loss_ce: 0.006272
iteration 10806 : loss : 0.023699, loss_ce: 0.009847
iteration 10807 : loss : 0.027993, loss_ce: 0.009452
iteration 10808 : loss : 0.024384, loss_ce: 0.008807
iteration 10809 : loss : 0.027025, loss_ce: 0.006102
iteration 10810 : loss : 0.023951, loss_ce: 0.007458
iteration 10811 : loss : 0.031508, loss_ce: 0.007756
iteration 10812 : loss : 0.029964, loss_ce: 0.010362
iteration 10813 : loss : 0.074087, loss_ce: 0.004777
iteration 10814 : loss : 0.025459, loss_ce: 0.012250
iteration 10815 : loss : 0.025402, loss_ce: 0.008226
iteration 10816 : loss : 0.024980, loss_ce: 0.008220
iteration 10817 : loss : 0.024784, loss_ce: 0.008371
iteration 10818 : loss : 0.033360, loss_ce: 0.014230
iteration 10819 : loss : 0.022080, loss_ce: 0.004334
pred_sum 692
gtsum tensor(690, device='cuda:0')
iteration 10820 : loss : 0.026903, loss_ce: 0.010922
iteration 10821 : loss : 0.026597, loss_ce: 0.009563
iteration 10822 : loss : 0.020889, loss_ce: 0.008504
iteration 10823 : loss : 0.028264, loss_ce: 0.011422
iteration 10824 : loss : 0.032140, loss_ce: 0.008020
iteration 10825 : loss : 0.026669, loss_ce: 0.008739
iteration 10826 : loss : 0.030505, loss_ce: 0.005152
iteration 10827 : loss : 0.022676, loss_ce: 0.005957
iteration 10828 : loss : 0.027357, loss_ce: 0.010351
iteration 10829 : loss : 0.020755, loss_ce: 0.005843
iteration 10830 : loss : 0.024940, loss_ce: 0.007205
iteration 10831 : loss : 0.024126, loss_ce: 0.009565
iteration 10832 : loss : 0.025724, loss_ce: 0.008622
iteration 10833 : loss : 0.076661, loss_ce: 0.004513
iteration 10834 : loss : 0.075986, loss_ce: 0.008889
iteration 10835 : loss : 0.024776, loss_ce: 0.008688
iteration 10836 : loss : 0.019899, loss_ce: 0.006922
iteration 10837 : loss : 0.023312, loss_ce: 0.008712
iteration 10838 : loss : 0.023010, loss_ce: 0.007246
iteration 10839 : loss : 0.023115, loss_ce: 0.007595
iteration 10840 : loss : 0.023673, loss_ce: 0.009449
iteration 10841 : loss : 0.022662, loss_ce: 0.009238
iteration 10842 : loss : 0.024038, loss_ce: 0.008446
iteration 10843 : loss : 0.022138, loss_ce: 0.008112
iteration 10844 : loss : 0.025302, loss_ce: 0.005951
iteration 10845 : loss : 0.053616, loss_ce: 0.005080
iteration 10846 : loss : 0.026328, loss_ce: 0.007015
iteration 10847 : loss : 0.024080, loss_ce: 0.008092
iteration 10848 : loss : 0.054725, loss_ce: 0.008305
iteration 10849 : loss : 0.027148, loss_ce: 0.008720
iteration 10850 : loss : 0.032258, loss_ce: 0.011111
pred_sum 17460
gtsum tensor(17069, device='cuda:0')
iteration 10851 : loss : 0.035623, loss_ce: 0.013499
iteration 10852 : loss : 0.032799, loss_ce: 0.011704
iteration 10853 : loss : 0.033678, loss_ce: 0.011671
iteration 10854 : loss : 0.036650, loss_ce: 0.008084
iteration 10855 : loss : 0.026956, loss_ce: 0.009697
iteration 10856 : loss : 0.037759, loss_ce: 0.015031
iteration 10857 : loss : 0.080854, loss_ce: 0.009983
iteration 10858 : loss : 0.035780, loss_ce: 0.011595
iteration 10859 : loss : 0.027309, loss_ce: 0.007542
iteration 10860 : loss : 0.027491, loss_ce: 0.007327
iteration 10861 : loss : 0.029642, loss_ce: 0.008442
iteration 10862 : loss : 0.030575, loss_ce: 0.009311
iteration 10863 : loss : 0.027957, loss_ce: 0.007487
iteration 10864 : loss : 0.029861, loss_ce: 0.010893
iteration 10865 : loss : 0.027533, loss_ce: 0.010488
iteration 10866 : loss : 0.028733, loss_ce: 0.010276
iteration 10867 : loss : 0.032245, loss_ce: 0.010078
iteration 10868 : loss : 0.030075, loss_ce: 0.009191
iteration 10869 : loss : 0.035176, loss_ce: 0.006968
iteration 10870 : loss : 0.034135, loss_ce: 0.009720
iteration 10871 : loss : 0.028661, loss_ce: 0.010506
iteration 10872 : loss : 0.032891, loss_ce: 0.009367
iteration 10873 : loss : 0.029664, loss_ce: 0.008308
iteration 10874 : loss : 0.020695, loss_ce: 0.005658
iteration 10875 : loss : 0.025924, loss_ce: 0.011399
iteration 10876 : loss : 0.079550, loss_ce: 0.008438
iteration 10877 : loss : 0.026139, loss_ce: 0.012046
iteration 10878 : loss : 0.024877, loss_ce: 0.009677
iteration 10879 : loss : 0.028146, loss_ce: 0.009069
iteration 10880 : loss : 0.027371, loss_ce: 0.008601
iteration 10881 : loss : 0.442155, loss_ce: 0.000398
 58%|███████████████▊           | 117/200 [1:46:14<1:15:22, 54.48s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 10882 : loss : 0.029504, loss_ce: 0.010499
iteration 10883 : loss : 0.027336, loss_ce: 0.007117
iteration 10884 : loss : 0.028521, loss_ce: 0.008536
iteration 10885 : loss : 0.027439, loss_ce: 0.005482
iteration 10886 : loss : 0.027134, loss_ce: 0.006897
iteration 10887 : loss : 0.042760, loss_ce: 0.011234
iteration 10888 : loss : 0.022464, loss_ce: 0.003422
iteration 10889 : loss : 0.023178, loss_ce: 0.007725
iteration 10890 : loss : 0.026476, loss_ce: 0.007991
iteration 10891 : loss : 0.023544, loss_ce: 0.006383
iteration 10892 : loss : 0.082488, loss_ce: 0.006029
iteration 10893 : loss : 0.026978, loss_ce: 0.010733
iteration 10894 : loss : 0.033321, loss_ce: 0.010963
iteration 10895 : loss : 0.028038, loss_ce: 0.007790
iteration 10896 : loss : 0.048226, loss_ce: 0.009334
iteration 10897 : loss : 0.019635, loss_ce: 0.005180
iteration 10898 : loss : 0.029785, loss_ce: 0.011514
iteration 10899 : loss : 0.024826, loss_ce: 0.011284
iteration 10900 : loss : 0.024683, loss_ce: 0.007761
iteration 10901 : loss : 0.026104, loss_ce: 0.007622
iteration 10902 : loss : 0.086308, loss_ce: 0.008047
iteration 10903 : loss : 0.029050, loss_ce: 0.011291
iteration 10904 : loss : 0.035070, loss_ce: 0.009824
iteration 10905 : loss : 0.028710, loss_ce: 0.007493
iteration 10906 : loss : 0.023014, loss_ce: 0.008214
iteration 10907 : loss : 0.024641, loss_ce: 0.005259
iteration 10908 : loss : 0.027123, loss_ce: 0.010310
iteration 10909 : loss : 0.019958, loss_ce: 0.007365
iteration 10910 : loss : 0.025936, loss_ce: 0.006564
iteration 10911 : loss : 0.024930, loss_ce: 0.009039
iteration 10912 : loss : 0.028457, loss_ce: 0.013060
pred_sum 46964
gtsum tensor(47079, device='cuda:0')
iteration 10913 : loss : 0.026511, loss_ce: 0.011615
iteration 10914 : loss : 0.025781, loss_ce: 0.009595
iteration 10915 : loss : 0.124700, loss_ce: 0.002767
iteration 10916 : loss : 0.026927, loss_ce: 0.009992
iteration 10917 : loss : 0.023247, loss_ce: 0.004659
iteration 10918 : loss : 0.023794, loss_ce: 0.006621
iteration 10919 : loss : 0.027629, loss_ce: 0.011654
iteration 10920 : loss : 0.024834, loss_ce: 0.005206
iteration 10921 : loss : 0.029052, loss_ce: 0.010440
iteration 10922 : loss : 0.039222, loss_ce: 0.006034
iteration 10923 : loss : 0.024602, loss_ce: 0.008403
iteration 10924 : loss : 0.023495, loss_ce: 0.007815
iteration 10925 : loss : 0.026000, loss_ce: 0.007061
iteration 10926 : loss : 0.026374, loss_ce: 0.007767
iteration 10927 : loss : 0.021408, loss_ce: 0.003550
iteration 10928 : loss : 0.025422, loss_ce: 0.011531
iteration 10929 : loss : 0.022808, loss_ce: 0.007528
iteration 10930 : loss : 0.030855, loss_ce: 0.012398
iteration 10931 : loss : 0.032523, loss_ce: 0.008879
iteration 10932 : loss : 0.023292, loss_ce: 0.009801
iteration 10933 : loss : 0.022831, loss_ce: 0.008524
iteration 10934 : loss : 0.022853, loss_ce: 0.006073
iteration 10935 : loss : 0.038191, loss_ce: 0.008201
iteration 10936 : loss : 0.028543, loss_ce: 0.006282
iteration 10937 : loss : 0.029423, loss_ce: 0.011075
iteration 10938 : loss : 0.025973, loss_ce: 0.009121
iteration 10939 : loss : 0.022405, loss_ce: 0.009992
iteration 10940 : loss : 0.025090, loss_ce: 0.008357
iteration 10941 : loss : 0.022081, loss_ce: 0.006811
iteration 10942 : loss : 0.026253, loss_ce: 0.007651
iteration 10943 : loss : 0.026090, loss_ce: 0.008786
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 10944 : loss : 0.026324, loss_ce: 0.009768
iteration 10945 : loss : 0.028265, loss_ce: 0.014679
iteration 10946 : loss : 0.038651, loss_ce: 0.010229
iteration 10947 : loss : 0.026278, loss_ce: 0.008619
iteration 10948 : loss : 0.030849, loss_ce: 0.003614
iteration 10949 : loss : 0.024671, loss_ce: 0.008008
iteration 10950 : loss : 0.022403, loss_ce: 0.006173
iteration 10951 : loss : 0.025437, loss_ce: 0.008028
iteration 10952 : loss : 0.026706, loss_ce: 0.009513
iteration 10953 : loss : 0.022198, loss_ce: 0.007937
iteration 10954 : loss : 0.030256, loss_ce: 0.008772
iteration 10955 : loss : 0.029677, loss_ce: 0.012383
iteration 10956 : loss : 0.022901, loss_ce: 0.006832
iteration 10957 : loss : 0.023826, loss_ce: 0.010607
iteration 10958 : loss : 0.024098, loss_ce: 0.009516
iteration 10959 : loss : 0.033779, loss_ce: 0.011022
iteration 10960 : loss : 0.028976, loss_ce: 0.010482
iteration 10961 : loss : 0.028385, loss_ce: 0.008687
iteration 10962 : loss : 0.070340, loss_ce: 0.005583
iteration 10963 : loss : 0.030086, loss_ce: 0.014140
iteration 10964 : loss : 0.028720, loss_ce: 0.009261
iteration 10965 : loss : 0.026696, loss_ce: 0.014729
iteration 10966 : loss : 0.041459, loss_ce: 0.013127
iteration 10967 : loss : 0.074738, loss_ce: 0.003498
iteration 10968 : loss : 0.028919, loss_ce: 0.014566
iteration 10969 : loss : 0.023020, loss_ce: 0.009671
iteration 10970 : loss : 0.024819, loss_ce: 0.012030
iteration 10971 : loss : 0.032547, loss_ce: 0.011794
iteration 10972 : loss : 0.027101, loss_ce: 0.006503
iteration 10973 : loss : 0.026554, loss_ce: 0.010144
iteration 10974 : loss : 0.048279, loss_ce: 0.007803
 59%|███████████████▉           | 118/200 [1:47:08<1:14:27, 54.48s/it]pred_sum 8968
gtsum tensor(9091, device='cuda:0')
iteration 10975 : loss : 0.024779, loss_ce: 0.005672
iteration 10976 : loss : 0.058591, loss_ce: 0.008886
iteration 10977 : loss : 0.025575, loss_ce: 0.005612
iteration 10978 : loss : 0.032030, loss_ce: 0.008101
iteration 10979 : loss : 0.029525, loss_ce: 0.009688
iteration 10980 : loss : 0.025446, loss_ce: 0.009505
iteration 10981 : loss : 0.032082, loss_ce: 0.010680
iteration 10982 : loss : 0.026763, loss_ce: 0.006747
iteration 10983 : loss : 0.025536, loss_ce: 0.007671
iteration 10984 : loss : 0.030123, loss_ce: 0.010263
iteration 10985 : loss : 0.028753, loss_ce: 0.008635
iteration 10986 : loss : 0.027295, loss_ce: 0.008636
iteration 10987 : loss : 0.025379, loss_ce: 0.007330
iteration 10988 : loss : 0.028593, loss_ce: 0.009690
iteration 10989 : loss : 0.024172, loss_ce: 0.009818
iteration 10990 : loss : 0.026069, loss_ce: 0.010749
iteration 10991 : loss : 0.022383, loss_ce: 0.006373
iteration 10992 : loss : 0.029606, loss_ce: 0.013331
iteration 10993 : loss : 0.025011, loss_ce: 0.006508
iteration 10994 : loss : 0.025662, loss_ce: 0.010766
iteration 10995 : loss : 0.027520, loss_ce: 0.009937
iteration 10996 : loss : 0.025292, loss_ce: 0.009969
iteration 10997 : loss : 0.026887, loss_ce: 0.011227
iteration 10998 : loss : 0.026507, loss_ce: 0.007480
iteration 10999 : loss : 0.021949, loss_ce: 0.008723
iteration 11000 : loss : 0.032030, loss_ce: 0.010123
iteration 11001 : loss : 0.022695, loss_ce: 0.007264
iteration 11002 : loss : 0.022172, loss_ce: 0.010451
iteration 11003 : loss : 0.024540, loss_ce: 0.010896
iteration 11004 : loss : 0.024865, loss_ce: 0.011048
iteration 11005 : loss : 0.023543, loss_ce: 0.007217
pred_sum 14572
gtsum tensor(14521, device='cuda:0')
iteration 11006 : loss : 0.026492, loss_ce: 0.008599
iteration 11007 : loss : 0.026173, loss_ce: 0.008007
iteration 11008 : loss : 0.074521, loss_ce: 0.005009
iteration 11009 : loss : 0.029242, loss_ce: 0.008757
iteration 11010 : loss : 0.027151, loss_ce: 0.009859
iteration 11011 : loss : 0.026871, loss_ce: 0.010779
iteration 11012 : loss : 0.024841, loss_ce: 0.012484
iteration 11013 : loss : 0.028776, loss_ce: 0.011847
iteration 11014 : loss : 0.023873, loss_ce: 0.009765
iteration 11015 : loss : 0.027440, loss_ce: 0.011725
iteration 11016 : loss : 0.027250, loss_ce: 0.006440
iteration 11017 : loss : 0.026793, loss_ce: 0.011836
iteration 11018 : loss : 0.031107, loss_ce: 0.007133
iteration 11019 : loss : 0.078284, loss_ce: 0.010132
iteration 11020 : loss : 0.025852, loss_ce: 0.006539
iteration 11021 : loss : 0.064579, loss_ce: 0.004485
iteration 11022 : loss : 0.019880, loss_ce: 0.004728
iteration 11023 : loss : 0.021558, loss_ce: 0.007699
iteration 11024 : loss : 0.022089, loss_ce: 0.008351
iteration 11025 : loss : 0.022285, loss_ce: 0.007500
iteration 11026 : loss : 0.037827, loss_ce: 0.012993
iteration 11027 : loss : 0.040819, loss_ce: 0.007314
iteration 11028 : loss : 0.025714, loss_ce: 0.007702
iteration 11029 : loss : 0.023881, loss_ce: 0.007973
iteration 11030 : loss : 0.027211, loss_ce: 0.007865
iteration 11031 : loss : 0.021828, loss_ce: 0.006530
iteration 11032 : loss : 0.027971, loss_ce: 0.012151
iteration 11033 : loss : 0.020954, loss_ce: 0.010122
iteration 11034 : loss : 0.074832, loss_ce: 0.005660
iteration 11035 : loss : 0.025378, loss_ce: 0.008921
iteration 11036 : loss : 0.025144, loss_ce: 0.007732
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 11037 : loss : 0.024035, loss_ce: 0.009074
iteration 11038 : loss : 0.026389, loss_ce: 0.006685
iteration 11039 : loss : 0.028051, loss_ce: 0.006861
iteration 11040 : loss : 0.024637, loss_ce: 0.008571
iteration 11041 : loss : 0.030208, loss_ce: 0.014713
iteration 11042 : loss : 0.028302, loss_ce: 0.012261
iteration 11043 : loss : 0.027299, loss_ce: 0.010086
iteration 11044 : loss : 0.033834, loss_ce: 0.007062
iteration 11045 : loss : 0.121972, loss_ce: 0.004781
iteration 11046 : loss : 0.028502, loss_ce: 0.008575
iteration 11047 : loss : 0.024630, loss_ce: 0.008216
iteration 11048 : loss : 0.031362, loss_ce: 0.010770
iteration 11049 : loss : 0.029407, loss_ce: 0.006464
iteration 11050 : loss : 0.027058, loss_ce: 0.005684
iteration 11051 : loss : 0.027041, loss_ce: 0.007396
iteration 11052 : loss : 0.031705, loss_ce: 0.009283
iteration 11053 : loss : 0.026383, loss_ce: 0.004944
iteration 11054 : loss : 0.024820, loss_ce: 0.008711
iteration 11055 : loss : 0.026017, loss_ce: 0.007967
iteration 11056 : loss : 0.026975, loss_ce: 0.008907
iteration 11057 : loss : 0.023140, loss_ce: 0.008005
iteration 11058 : loss : 0.029767, loss_ce: 0.009237
iteration 11059 : loss : 0.031034, loss_ce: 0.009620
iteration 11060 : loss : 0.023906, loss_ce: 0.006225
iteration 11061 : loss : 0.075017, loss_ce: 0.005081
iteration 11062 : loss : 0.076026, loss_ce: 0.006665
iteration 11063 : loss : 0.027375, loss_ce: 0.012944
iteration 11064 : loss : 0.041065, loss_ce: 0.007456
iteration 11065 : loss : 0.029579, loss_ce: 0.006380
iteration 11066 : loss : 0.026668, loss_ce: 0.010759
iteration 11067 : loss : 0.231158, loss_ce: 0.007293
 60%|████████████████           | 119/200 [1:48:02<1:13:31, 54.46s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 11068 : loss : 0.026686, loss_ce: 0.006957
iteration 11069 : loss : 0.022369, loss_ce: 0.008949
iteration 11070 : loss : 0.023394, loss_ce: 0.006431
iteration 11071 : loss : 0.027038, loss_ce: 0.008099
iteration 11072 : loss : 0.019473, loss_ce: 0.007284
iteration 11073 : loss : 0.021567, loss_ce: 0.009370
iteration 11074 : loss : 0.024451, loss_ce: 0.009050
iteration 11075 : loss : 0.022052, loss_ce: 0.005705
iteration 11076 : loss : 0.022787, loss_ce: 0.006383
iteration 11077 : loss : 0.019066, loss_ce: 0.007194
iteration 11078 : loss : 0.024818, loss_ce: 0.008349
iteration 11079 : loss : 0.026059, loss_ce: 0.009329
iteration 11080 : loss : 0.025141, loss_ce: 0.012207
iteration 11081 : loss : 0.024035, loss_ce: 0.005396
iteration 11082 : loss : 0.028727, loss_ce: 0.006031
iteration 11083 : loss : 0.077889, loss_ce: 0.008759
iteration 11084 : loss : 0.029501, loss_ce: 0.008903
iteration 11085 : loss : 0.023783, loss_ce: 0.006428
iteration 11086 : loss : 0.027077, loss_ce: 0.011058
iteration 11087 : loss : 0.071673, loss_ce: 0.004860
iteration 11088 : loss : 0.025667, loss_ce: 0.009387
iteration 11089 : loss : 0.021282, loss_ce: 0.007781
iteration 11090 : loss : 0.024330, loss_ce: 0.008465
iteration 11091 : loss : 0.027360, loss_ce: 0.010030
iteration 11092 : loss : 0.075823, loss_ce: 0.004208
iteration 11093 : loss : 0.023480, loss_ce: 0.010360
iteration 11094 : loss : 0.030899, loss_ce: 0.010692
iteration 11095 : loss : 0.024376, loss_ce: 0.012612
iteration 11096 : loss : 0.032699, loss_ce: 0.006915
iteration 11097 : loss : 0.023325, loss_ce: 0.006796
iteration 11098 : loss : 0.021784, loss_ce: 0.005627
pred_sum 51837
gtsum tensor(51172, device='cuda:0')
iteration 11099 : loss : 0.028127, loss_ce: 0.013330
iteration 11100 : loss : 0.064972, loss_ce: 0.006814
iteration 11101 : loss : 0.023123, loss_ce: 0.011181
iteration 11102 : loss : 0.024743, loss_ce: 0.009483
iteration 11103 : loss : 0.024178, loss_ce: 0.007151
iteration 11104 : loss : 0.027724, loss_ce: 0.004879
iteration 11105 : loss : 0.026055, loss_ce: 0.008927
iteration 11106 : loss : 0.028018, loss_ce: 0.008925
iteration 11107 : loss : 0.025014, loss_ce: 0.011589
iteration 11108 : loss : 0.033860, loss_ce: 0.007792
iteration 11109 : loss : 0.026117, loss_ce: 0.012349
iteration 11110 : loss : 0.023097, loss_ce: 0.006791
iteration 11111 : loss : 0.080165, loss_ce: 0.006664
iteration 11112 : loss : 0.020693, loss_ce: 0.009377
iteration 11113 : loss : 0.025774, loss_ce: 0.012127
iteration 11114 : loss : 0.038398, loss_ce: 0.007766
iteration 11115 : loss : 0.023703, loss_ce: 0.009668
iteration 11116 : loss : 0.027645, loss_ce: 0.012224
iteration 11117 : loss : 0.028820, loss_ce: 0.013101
iteration 11118 : loss : 0.023290, loss_ce: 0.010633
iteration 11119 : loss : 0.024508, loss_ce: 0.004948
iteration 11120 : loss : 0.025518, loss_ce: 0.009891
iteration 11121 : loss : 0.022708, loss_ce: 0.004976
iteration 11122 : loss : 0.024402, loss_ce: 0.009023
iteration 11123 : loss : 0.027149, loss_ce: 0.009854
iteration 11124 : loss : 0.021724, loss_ce: 0.006114
iteration 11125 : loss : 0.029717, loss_ce: 0.009088
iteration 11126 : loss : 0.027382, loss_ce: 0.008251
iteration 11127 : loss : 0.027557, loss_ce: 0.012237
iteration 11128 : loss : 0.074339, loss_ce: 0.006333
iteration 11129 : loss : 0.075884, loss_ce: 0.004063
pred_sum 488
gtsum tensor(462, device='cuda:0')
iteration 11130 : loss : 0.026817, loss_ce: 0.007592
iteration 11131 : loss : 0.025132, loss_ce: 0.011134
iteration 11132 : loss : 0.024382, loss_ce: 0.007558
iteration 11133 : loss : 0.029621, loss_ce: 0.009133
iteration 11134 : loss : 0.032096, loss_ce: 0.005522
iteration 11135 : loss : 0.022945, loss_ce: 0.009044
iteration 11136 : loss : 0.022453, loss_ce: 0.007000
iteration 11137 : loss : 0.080026, loss_ce: 0.008142
iteration 11138 : loss : 0.076850, loss_ce: 0.012191
iteration 11139 : loss : 0.033873, loss_ce: 0.012586
iteration 11140 : loss : 0.027528, loss_ce: 0.012936
iteration 11141 : loss : 0.026644, loss_ce: 0.008653
iteration 11142 : loss : 0.023842, loss_ce: 0.006714
iteration 11143 : loss : 0.028241, loss_ce: 0.006750
iteration 11144 : loss : 0.029420, loss_ce: 0.006930
iteration 11145 : loss : 0.026614, loss_ce: 0.007603
iteration 11146 : loss : 0.024533, loss_ce: 0.007343
iteration 11147 : loss : 0.029523, loss_ce: 0.008913
iteration 11148 : loss : 0.077561, loss_ce: 0.007412
iteration 11149 : loss : 0.026978, loss_ce: 0.008597
iteration 11150 : loss : 0.022819, loss_ce: 0.008171
iteration 11151 : loss : 0.076551, loss_ce: 0.005045
iteration 11152 : loss : 0.026292, loss_ce: 0.008286
iteration 11153 : loss : 0.027828, loss_ce: 0.009066
iteration 11154 : loss : 0.024371, loss_ce: 0.006772
iteration 11155 : loss : 0.026369, loss_ce: 0.009769
iteration 11156 : loss : 0.025406, loss_ce: 0.009409
iteration 11157 : loss : 0.030077, loss_ce: 0.013889
iteration 11158 : loss : 0.028945, loss_ce: 0.012116
iteration 11159 : loss : 0.028259, loss_ce: 0.007071
iteration 11160 : loss : 0.288611, loss_ce: 0.010026
 60%|████████████████▏          | 120/200 [1:48:57<1:12:34, 54.43s/it]pred_sum 175
gtsum tensor(190, device='cuda:0')
iteration 11161 : loss : 0.025005, loss_ce: 0.011087
iteration 11162 : loss : 0.025780, loss_ce: 0.003566
iteration 11163 : loss : 0.027015, loss_ce: 0.008886
iteration 11164 : loss : 0.025685, loss_ce: 0.009174
iteration 11165 : loss : 0.079447, loss_ce: 0.006582
iteration 11166 : loss : 0.025832, loss_ce: 0.009863
iteration 11167 : loss : 0.023195, loss_ce: 0.006359
iteration 11168 : loss : 0.028020, loss_ce: 0.011634
iteration 11169 : loss : 0.033151, loss_ce: 0.007295
iteration 11170 : loss : 0.022489, loss_ce: 0.007560
iteration 11171 : loss : 0.032574, loss_ce: 0.010126
iteration 11172 : loss : 0.023686, loss_ce: 0.008726
iteration 11173 : loss : 0.028113, loss_ce: 0.008396
iteration 11174 : loss : 0.020222, loss_ce: 0.006845
iteration 11175 : loss : 0.030029, loss_ce: 0.007458
iteration 11176 : loss : 0.026780, loss_ce: 0.011736
iteration 11177 : loss : 0.026030, loss_ce: 0.011751
iteration 11178 : loss : 0.028119, loss_ce: 0.006374
iteration 11179 : loss : 0.026945, loss_ce: 0.004509
iteration 11180 : loss : 0.023146, loss_ce: 0.006473
iteration 11181 : loss : 0.038161, loss_ce: 0.010043
iteration 11182 : loss : 0.025939, loss_ce: 0.009505
iteration 11183 : loss : 0.027459, loss_ce: 0.007601
iteration 11184 : loss : 0.024890, loss_ce: 0.012456
iteration 11185 : loss : 0.026317, loss_ce: 0.011050
iteration 11186 : loss : 0.026388, loss_ce: 0.012742
iteration 11187 : loss : 0.024462, loss_ce: 0.008250
iteration 11188 : loss : 0.023759, loss_ce: 0.008440
iteration 11189 : loss : 0.027771, loss_ce: 0.013722
iteration 11190 : loss : 0.024135, loss_ce: 0.005289
iteration 11191 : loss : 0.017820, loss_ce: 0.007536
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 11192 : loss : 0.022258, loss_ce: 0.007010
iteration 11193 : loss : 0.026212, loss_ce: 0.008449
iteration 11194 : loss : 0.021350, loss_ce: 0.007260
iteration 11195 : loss : 0.032283, loss_ce: 0.008852
iteration 11196 : loss : 0.022802, loss_ce: 0.010736
iteration 11197 : loss : 0.025837, loss_ce: 0.009373
iteration 11198 : loss : 0.024242, loss_ce: 0.007381
iteration 11199 : loss : 0.030211, loss_ce: 0.008665
iteration 11200 : loss : 0.073607, loss_ce: 0.004623
iteration 11201 : loss : 0.073546, loss_ce: 0.006148
iteration 11202 : loss : 0.021782, loss_ce: 0.011255
iteration 11203 : loss : 0.027538, loss_ce: 0.008808
iteration 11204 : loss : 0.028054, loss_ce: 0.008235
iteration 11205 : loss : 0.031463, loss_ce: 0.012325
iteration 11206 : loss : 0.024031, loss_ce: 0.009573
iteration 11207 : loss : 0.026574, loss_ce: 0.009642
iteration 11208 : loss : 0.022454, loss_ce: 0.008063
iteration 11209 : loss : 0.024319, loss_ce: 0.007276
iteration 11210 : loss : 0.036471, loss_ce: 0.007582
iteration 11211 : loss : 0.021779, loss_ce: 0.007580
iteration 11212 : loss : 0.028447, loss_ce: 0.013034
iteration 11213 : loss : 0.028056, loss_ce: 0.007511
iteration 11214 : loss : 0.025034, loss_ce: 0.005463
iteration 11215 : loss : 0.027658, loss_ce: 0.010467
iteration 11216 : loss : 0.018252, loss_ce: 0.005123
iteration 11217 : loss : 0.024956, loss_ce: 0.005191
iteration 11218 : loss : 0.024166, loss_ce: 0.008097
iteration 11219 : loss : 0.074549, loss_ce: 0.006610
iteration 11220 : loss : 0.025250, loss_ce: 0.009441
iteration 11221 : loss : 0.025760, loss_ce: 0.006763
iteration 11222 : loss : 0.024694, loss_ce: 0.007091
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 11223 : loss : 0.023671, loss_ce: 0.007381
iteration 11224 : loss : 0.026485, loss_ce: 0.009387
iteration 11225 : loss : 0.027726, loss_ce: 0.009506
iteration 11226 : loss : 0.024398, loss_ce: 0.006693
iteration 11227 : loss : 0.024919, loss_ce: 0.008155
iteration 11228 : loss : 0.026213, loss_ce: 0.011556
iteration 11229 : loss : 0.024457, loss_ce: 0.010550
iteration 11230 : loss : 0.027729, loss_ce: 0.013830
iteration 11231 : loss : 0.026674, loss_ce: 0.005846
iteration 11232 : loss : 0.025204, loss_ce: 0.006724
iteration 11233 : loss : 0.020924, loss_ce: 0.007464
iteration 11234 : loss : 0.019358, loss_ce: 0.006638
iteration 11235 : loss : 0.023668, loss_ce: 0.006322
iteration 11236 : loss : 0.023313, loss_ce: 0.007545
iteration 11237 : loss : 0.025007, loss_ce: 0.008489
iteration 11238 : loss : 0.028847, loss_ce: 0.009147
iteration 11239 : loss : 0.025095, loss_ce: 0.008921
iteration 11240 : loss : 0.024647, loss_ce: 0.006497
iteration 11241 : loss : 0.023115, loss_ce: 0.008906
iteration 11242 : loss : 0.031418, loss_ce: 0.006478
iteration 11243 : loss : 0.021987, loss_ce: 0.010313
iteration 11244 : loss : 0.033382, loss_ce: 0.011380
iteration 11245 : loss : 0.019638, loss_ce: 0.007540
iteration 11246 : loss : 0.019931, loss_ce: 0.005846
iteration 11247 : loss : 0.020993, loss_ce: 0.005073
iteration 11248 : loss : 0.024157, loss_ce: 0.008663
iteration 11249 : loss : 0.026903, loss_ce: 0.009161
iteration 11250 : loss : 0.022614, loss_ce: 0.006920
iteration 11251 : loss : 0.021602, loss_ce: 0.007538
iteration 11252 : loss : 0.020861, loss_ce: 0.009581
iteration 11253 : loss : 0.281997, loss_ce: 0.005953
 60%|████████████████▎          | 121/200 [1:49:51<1:11:39, 54.42s/it]pred_sum 201
gtsum tensor(197, device='cuda:0')
iteration 11254 : loss : 0.020534, loss_ce: 0.005909
iteration 11255 : loss : 0.024535, loss_ce: 0.010268
iteration 11256 : loss : 0.027569, loss_ce: 0.008673
iteration 11257 : loss : 0.071885, loss_ce: 0.004814
iteration 11258 : loss : 0.022367, loss_ce: 0.008191
iteration 11259 : loss : 0.022690, loss_ce: 0.008486
iteration 11260 : loss : 0.023257, loss_ce: 0.004289
iteration 11261 : loss : 0.025107, loss_ce: 0.007155
iteration 11262 : loss : 0.027658, loss_ce: 0.008314
iteration 11263 : loss : 0.025744, loss_ce: 0.007717
iteration 11264 : loss : 0.038097, loss_ce: 0.007440
iteration 11265 : loss : 0.024415, loss_ce: 0.008523
iteration 11266 : loss : 0.023690, loss_ce: 0.010745
iteration 11267 : loss : 0.022721, loss_ce: 0.007467
iteration 11268 : loss : 0.033090, loss_ce: 0.012954
iteration 11269 : loss : 0.035261, loss_ce: 0.007750
iteration 11270 : loss : 0.022596, loss_ce: 0.009493
iteration 11271 : loss : 0.022327, loss_ce: 0.008371
iteration 11272 : loss : 0.022627, loss_ce: 0.007885
iteration 11273 : loss : 0.022917, loss_ce: 0.006499
iteration 11274 : loss : 0.023919, loss_ce: 0.003365
iteration 11275 : loss : 0.025257, loss_ce: 0.005701
iteration 11276 : loss : 0.027431, loss_ce: 0.011891
iteration 11277 : loss : 0.023465, loss_ce: 0.006645
iteration 11278 : loss : 0.034416, loss_ce: 0.009281
iteration 11279 : loss : 0.023603, loss_ce: 0.008247
iteration 11280 : loss : 0.032871, loss_ce: 0.006999
iteration 11281 : loss : 0.026360, loss_ce: 0.010495
iteration 11282 : loss : 0.023893, loss_ce: 0.008079
iteration 11283 : loss : 0.036128, loss_ce: 0.008159
iteration 11284 : loss : 0.027397, loss_ce: 0.009013
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 11285 : loss : 0.023382, loss_ce: 0.007432
iteration 11286 : loss : 0.022311, loss_ce: 0.007839
iteration 11287 : loss : 0.026338, loss_ce: 0.008563
iteration 11288 : loss : 0.076494, loss_ce: 0.006455
iteration 11289 : loss : 0.023080, loss_ce: 0.007378
iteration 11290 : loss : 0.026239, loss_ce: 0.007983
iteration 11291 : loss : 0.025867, loss_ce: 0.010237
iteration 11292 : loss : 0.025524, loss_ce: 0.008172
iteration 11293 : loss : 0.024974, loss_ce: 0.009693
iteration 11294 : loss : 0.025018, loss_ce: 0.011729
iteration 11295 : loss : 0.029689, loss_ce: 0.009015
iteration 11296 : loss : 0.031742, loss_ce: 0.007879
iteration 11297 : loss : 0.073740, loss_ce: 0.006917
iteration 11298 : loss : 0.025653, loss_ce: 0.010511
iteration 11299 : loss : 0.027025, loss_ce: 0.005730
iteration 11300 : loss : 0.020885, loss_ce: 0.005087
iteration 11301 : loss : 0.022514, loss_ce: 0.007270
iteration 11302 : loss : 0.027350, loss_ce: 0.010965
iteration 11303 : loss : 0.027164, loss_ce: 0.008347
iteration 11304 : loss : 0.020826, loss_ce: 0.006352
iteration 11305 : loss : 0.021022, loss_ce: 0.004646
iteration 11306 : loss : 0.032054, loss_ce: 0.012828
iteration 11307 : loss : 0.021743, loss_ce: 0.007483
iteration 11308 : loss : 0.022961, loss_ce: 0.006511
iteration 11309 : loss : 0.031518, loss_ce: 0.011385
iteration 11310 : loss : 0.027916, loss_ce: 0.012852
iteration 11311 : loss : 0.027685, loss_ce: 0.011589
iteration 11312 : loss : 0.071561, loss_ce: 0.004468
iteration 11313 : loss : 0.022824, loss_ce: 0.007479
iteration 11314 : loss : 0.022898, loss_ce: 0.004288
iteration 11315 : loss : 0.025697, loss_ce: 0.007778
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 11316 : loss : 0.025034, loss_ce: 0.011406
iteration 11317 : loss : 0.031150, loss_ce: 0.014086
iteration 11318 : loss : 0.021076, loss_ce: 0.007643
iteration 11319 : loss : 0.029708, loss_ce: 0.008846
iteration 11320 : loss : 0.024620, loss_ce: 0.007112
iteration 11321 : loss : 0.026563, loss_ce: 0.011692
iteration 11322 : loss : 0.035700, loss_ce: 0.011477
iteration 11323 : loss : 0.024501, loss_ce: 0.011629
iteration 11324 : loss : 0.022737, loss_ce: 0.005452
iteration 11325 : loss : 0.024332, loss_ce: 0.009686
iteration 11326 : loss : 0.029201, loss_ce: 0.005400
iteration 11327 : loss : 0.022564, loss_ce: 0.005820
iteration 11328 : loss : 0.022980, loss_ce: 0.008855
iteration 11329 : loss : 0.026173, loss_ce: 0.009759
iteration 11330 : loss : 0.020812, loss_ce: 0.007973
iteration 11331 : loss : 0.075465, loss_ce: 0.005174
iteration 11332 : loss : 0.024976, loss_ce: 0.006942
iteration 11333 : loss : 0.075752, loss_ce: 0.009948
iteration 11334 : loss : 0.024374, loss_ce: 0.007975
iteration 11335 : loss : 0.021621, loss_ce: 0.008602
iteration 11336 : loss : 0.081199, loss_ce: 0.007331
iteration 11337 : loss : 0.022190, loss_ce: 0.007973
iteration 11338 : loss : 0.076214, loss_ce: 0.007852
iteration 11339 : loss : 0.021087, loss_ce: 0.006970
iteration 11340 : loss : 0.027375, loss_ce: 0.010926
iteration 11341 : loss : 0.023184, loss_ce: 0.008518
iteration 11342 : loss : 0.026216, loss_ce: 0.006909
iteration 11343 : loss : 0.026431, loss_ce: 0.011374
iteration 11344 : loss : 0.024113, loss_ce: 0.008789
iteration 11345 : loss : 0.023931, loss_ce: 0.007395
iteration 11346 : loss : 0.044432, loss_ce: 0.016766
 61%|████████████████▍          | 122/200 [1:50:46<1:10:44, 54.42s/it]pred_sum 18103
gtsum tensor(19227, device='cuda:0')
iteration 11347 : loss : 0.023168, loss_ce: 0.009469
iteration 11348 : loss : 0.028152, loss_ce: 0.010271
iteration 11349 : loss : 0.025425, loss_ce: 0.006059
iteration 11350 : loss : 0.026538, loss_ce: 0.008520
iteration 11351 : loss : 0.028163, loss_ce: 0.009860
iteration 11352 : loss : 0.026805, loss_ce: 0.008086
iteration 11353 : loss : 0.027109, loss_ce: 0.008760
iteration 11354 : loss : 0.026263, loss_ce: 0.008024
iteration 11355 : loss : 0.023724, loss_ce: 0.006597
iteration 11356 : loss : 0.023853, loss_ce: 0.007167
iteration 11357 : loss : 0.025699, loss_ce: 0.009489
iteration 11358 : loss : 0.039177, loss_ce: 0.006931
iteration 11359 : loss : 0.028140, loss_ce: 0.011366
iteration 11360 : loss : 0.023488, loss_ce: 0.006169
iteration 11361 : loss : 0.023467, loss_ce: 0.006645
iteration 11362 : loss : 0.024178, loss_ce: 0.011919
iteration 11363 : loss : 0.051604, loss_ce: 0.008463
iteration 11364 : loss : 0.027026, loss_ce: 0.012109
iteration 11365 : loss : 0.023848, loss_ce: 0.008214
iteration 11366 : loss : 0.039151, loss_ce: 0.005471
iteration 11367 : loss : 0.022989, loss_ce: 0.008492
iteration 11368 : loss : 0.021264, loss_ce: 0.007131
iteration 11369 : loss : 0.024187, loss_ce: 0.006864
iteration 11370 : loss : 0.076576, loss_ce: 0.008298
iteration 11371 : loss : 0.029001, loss_ce: 0.008711
iteration 11372 : loss : 0.030465, loss_ce: 0.008198
iteration 11373 : loss : 0.081613, loss_ce: 0.003583
iteration 11374 : loss : 0.028085, loss_ce: 0.009859
iteration 11375 : loss : 0.020000, loss_ce: 0.004873
iteration 11376 : loss : 0.040701, loss_ce: 0.006714
iteration 11377 : loss : 0.026549, loss_ce: 0.011386
pred_sum 26522
gtsum tensor(26316, device='cuda:0')
iteration 11378 : loss : 0.034987, loss_ce: 0.006755
iteration 11379 : loss : 0.026623, loss_ce: 0.013712
iteration 11380 : loss : 0.027499, loss_ce: 0.008991
iteration 11381 : loss : 0.025173, loss_ce: 0.008453
iteration 11382 : loss : 0.023356, loss_ce: 0.008867
iteration 11383 : loss : 0.026295, loss_ce: 0.010246
iteration 11384 : loss : 0.028402, loss_ce: 0.003907
iteration 11385 : loss : 0.025631, loss_ce: 0.004006
iteration 11386 : loss : 0.024860, loss_ce: 0.008101
iteration 11387 : loss : 0.028870, loss_ce: 0.008539
iteration 11388 : loss : 0.023622, loss_ce: 0.005897
iteration 11389 : loss : 0.027232, loss_ce: 0.005100
iteration 11390 : loss : 0.026580, loss_ce: 0.009172
iteration 11391 : loss : 0.025568, loss_ce: 0.010342
iteration 11392 : loss : 0.028177, loss_ce: 0.011449
iteration 11393 : loss : 0.025128, loss_ce: 0.008678
iteration 11394 : loss : 0.023690, loss_ce: 0.004759
iteration 11395 : loss : 0.024008, loss_ce: 0.006810
iteration 11396 : loss : 0.028031, loss_ce: 0.009203
iteration 11397 : loss : 0.023018, loss_ce: 0.008642
iteration 11398 : loss : 0.025005, loss_ce: 0.008292
iteration 11399 : loss : 0.022309, loss_ce: 0.009757
iteration 11400 : loss : 0.026113, loss_ce: 0.007941
iteration 11401 : loss : 0.025744, loss_ce: 0.011950
iteration 11402 : loss : 0.020261, loss_ce: 0.007122
iteration 11403 : loss : 0.023817, loss_ce: 0.009813
iteration 11404 : loss : 0.023856, loss_ce: 0.006475
iteration 11405 : loss : 0.026507, loss_ce: 0.010473
iteration 11406 : loss : 0.027823, loss_ce: 0.011835
iteration 11407 : loss : 0.023554, loss_ce: 0.012107
iteration 11408 : loss : 0.031954, loss_ce: 0.011766
pred_sum 44093
gtsum tensor(44479, device='cuda:0')
iteration 11409 : loss : 0.026458, loss_ce: 0.012150
iteration 11410 : loss : 0.072679, loss_ce: 0.005038
iteration 11411 : loss : 0.022223, loss_ce: 0.005378
iteration 11412 : loss : 0.021885, loss_ce: 0.009277
iteration 11413 : loss : 0.023311, loss_ce: 0.007870
iteration 11414 : loss : 0.020029, loss_ce: 0.009282
iteration 11415 : loss : 0.024870, loss_ce: 0.007243
iteration 11416 : loss : 0.022102, loss_ce: 0.005366
iteration 11417 : loss : 0.025520, loss_ce: 0.006699
iteration 11418 : loss : 0.076617, loss_ce: 0.006329
iteration 11419 : loss : 0.027518, loss_ce: 0.008204
iteration 11420 : loss : 0.028484, loss_ce: 0.008364
iteration 11421 : loss : 0.023637, loss_ce: 0.011649
iteration 11422 : loss : 0.022871, loss_ce: 0.007925
iteration 11423 : loss : 0.022884, loss_ce: 0.004724
iteration 11424 : loss : 0.017673, loss_ce: 0.005561
iteration 11425 : loss : 0.031567, loss_ce: 0.005696
iteration 11426 : loss : 0.024294, loss_ce: 0.009612
iteration 11427 : loss : 0.027761, loss_ce: 0.014115
iteration 11428 : loss : 0.076668, loss_ce: 0.006061
iteration 11429 : loss : 0.028507, loss_ce: 0.007768
iteration 11430 : loss : 0.030009, loss_ce: 0.014309
iteration 11431 : loss : 0.025705, loss_ce: 0.005717
iteration 11432 : loss : 0.077714, loss_ce: 0.002835
iteration 11433 : loss : 0.025765, loss_ce: 0.011784
iteration 11434 : loss : 0.019937, loss_ce: 0.008593
iteration 11435 : loss : 0.076445, loss_ce: 0.008648
iteration 11436 : loss : 0.026769, loss_ce: 0.008973
iteration 11437 : loss : 0.024269, loss_ce: 0.012965
iteration 11438 : loss : 0.019644, loss_ce: 0.005470
iteration 11439 : loss : 0.078889, loss_ce: 0.013557
 62%|████████████████▌          | 123/200 [1:51:40<1:09:51, 54.43s/it]pred_sum 204
gtsum tensor(200, device='cuda:0')
iteration 11440 : loss : 0.024589, loss_ce: 0.009244
iteration 11441 : loss : 0.025804, loss_ce: 0.010784
iteration 11442 : loss : 0.021864, loss_ce: 0.006546
iteration 11443 : loss : 0.028443, loss_ce: 0.008243
iteration 11444 : loss : 0.076192, loss_ce: 0.009016
iteration 11445 : loss : 0.026090, loss_ce: 0.011880
iteration 11446 : loss : 0.026336, loss_ce: 0.007525
iteration 11447 : loss : 0.073515, loss_ce: 0.004413
iteration 11448 : loss : 0.023803, loss_ce: 0.008030
iteration 11449 : loss : 0.024512, loss_ce: 0.009788
iteration 11450 : loss : 0.027394, loss_ce: 0.009402
iteration 11451 : loss : 0.032023, loss_ce: 0.007700
iteration 11452 : loss : 0.035425, loss_ce: 0.003958
iteration 11453 : loss : 0.019696, loss_ce: 0.007511
iteration 11454 : loss : 0.022119, loss_ce: 0.009821
iteration 11455 : loss : 0.023165, loss_ce: 0.009040
iteration 11456 : loss : 0.024648, loss_ce: 0.010376
iteration 11457 : loss : 0.026323, loss_ce: 0.009267
iteration 11458 : loss : 0.072818, loss_ce: 0.007433
iteration 11459 : loss : 0.022371, loss_ce: 0.007111
iteration 11460 : loss : 0.019030, loss_ce: 0.006575
iteration 11461 : loss : 0.076054, loss_ce: 0.007414
iteration 11462 : loss : 0.074612, loss_ce: 0.004785
iteration 11463 : loss : 0.023859, loss_ce: 0.007291
iteration 11464 : loss : 0.025384, loss_ce: 0.005042
iteration 11465 : loss : 0.021818, loss_ce: 0.006674
iteration 11466 : loss : 0.024170, loss_ce: 0.007587
iteration 11467 : loss : 0.021284, loss_ce: 0.003404
iteration 11468 : loss : 0.019985, loss_ce: 0.006802
iteration 11469 : loss : 0.025790, loss_ce: 0.013449
iteration 11470 : loss : 0.027963, loss_ce: 0.003590
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 11471 : loss : 0.030608, loss_ce: 0.010230
iteration 11472 : loss : 0.031824, loss_ce: 0.009921
iteration 11473 : loss : 0.021290, loss_ce: 0.003915
iteration 11474 : loss : 0.022347, loss_ce: 0.006462
iteration 11475 : loss : 0.026403, loss_ce: 0.011930
iteration 11476 : loss : 0.022659, loss_ce: 0.009972
iteration 11477 : loss : 0.032842, loss_ce: 0.010311
iteration 11478 : loss : 0.023281, loss_ce: 0.008340
iteration 11479 : loss : 0.030539, loss_ce: 0.009032
iteration 11480 : loss : 0.023299, loss_ce: 0.008820
iteration 11481 : loss : 0.023591, loss_ce: 0.008182
iteration 11482 : loss : 0.074437, loss_ce: 0.003012
iteration 11483 : loss : 0.020119, loss_ce: 0.006936
iteration 11484 : loss : 0.022337, loss_ce: 0.007370
iteration 11485 : loss : 0.083029, loss_ce: 0.006002
iteration 11486 : loss : 0.028334, loss_ce: 0.010843
iteration 11487 : loss : 0.019314, loss_ce: 0.004146
iteration 11488 : loss : 0.022156, loss_ce: 0.009062
iteration 11489 : loss : 0.025689, loss_ce: 0.008272
iteration 11490 : loss : 0.024072, loss_ce: 0.013403
iteration 11491 : loss : 0.023134, loss_ce: 0.006571
iteration 11492 : loss : 0.025362, loss_ce: 0.009481
iteration 11493 : loss : 0.024320, loss_ce: 0.010121
iteration 11494 : loss : 0.031235, loss_ce: 0.010280
iteration 11495 : loss : 0.025955, loss_ce: 0.007434
iteration 11496 : loss : 0.027391, loss_ce: 0.009748
iteration 11497 : loss : 0.028286, loss_ce: 0.013008
iteration 11498 : loss : 0.026924, loss_ce: 0.009649
iteration 11499 : loss : 0.020967, loss_ce: 0.005081
iteration 11500 : loss : 0.021122, loss_ce: 0.006513
iteration 11501 : loss : 0.017980, loss_ce: 0.005268
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 11502 : loss : 0.026583, loss_ce: 0.008118
iteration 11503 : loss : 0.026690, loss_ce: 0.011203
iteration 11504 : loss : 0.030730, loss_ce: 0.011008
iteration 11505 : loss : 0.023706, loss_ce: 0.006185
iteration 11506 : loss : 0.029950, loss_ce: 0.006849
iteration 11507 : loss : 0.025360, loss_ce: 0.005892
iteration 11508 : loss : 0.021679, loss_ce: 0.005818
iteration 11509 : loss : 0.081378, loss_ce: 0.006002
iteration 11510 : loss : 0.021958, loss_ce: 0.007337
iteration 11511 : loss : 0.024770, loss_ce: 0.012583
iteration 11512 : loss : 0.026951, loss_ce: 0.009429
iteration 11513 : loss : 0.026594, loss_ce: 0.005508
iteration 11514 : loss : 0.025258, loss_ce: 0.009683
iteration 11515 : loss : 0.027683, loss_ce: 0.013155
iteration 11516 : loss : 0.039051, loss_ce: 0.007628
iteration 11517 : loss : 0.028946, loss_ce: 0.008952
iteration 11518 : loss : 0.030491, loss_ce: 0.010689
iteration 11519 : loss : 0.023806, loss_ce: 0.008073
iteration 11520 : loss : 0.028162, loss_ce: 0.008684
iteration 11521 : loss : 0.026605, loss_ce: 0.008873
iteration 11522 : loss : 0.028012, loss_ce: 0.010678
iteration 11523 : loss : 0.032524, loss_ce: 0.011275
iteration 11524 : loss : 0.019883, loss_ce: 0.006324
iteration 11525 : loss : 0.022728, loss_ce: 0.009001
iteration 11526 : loss : 0.024200, loss_ce: 0.009811
iteration 11527 : loss : 0.025884, loss_ce: 0.010329
iteration 11528 : loss : 0.033600, loss_ce: 0.008140
iteration 11529 : loss : 0.024587, loss_ce: 0.009677
iteration 11530 : loss : 0.027349, loss_ce: 0.009269
iteration 11531 : loss : 0.028007, loss_ce: 0.008862
iteration 11532 : loss : 0.131143, loss_ce: 0.009913
 62%|████████████████▋          | 124/200 [1:52:34<1:08:56, 54.43s/it]pred_sum 1572
gtsum tensor(1534, device='cuda:0')
iteration 11533 : loss : 0.037043, loss_ce: 0.005430
iteration 11534 : loss : 0.026020, loss_ce: 0.010336
iteration 11535 : loss : 0.026343, loss_ce: 0.009889
iteration 11536 : loss : 0.026893, loss_ce: 0.009270
iteration 11537 : loss : 0.024909, loss_ce: 0.007362
iteration 11538 : loss : 0.020521, loss_ce: 0.004780
iteration 11539 : loss : 0.027463, loss_ce: 0.009977
iteration 11540 : loss : 0.024226, loss_ce: 0.010695
iteration 11541 : loss : 0.021537, loss_ce: 0.007669
iteration 11542 : loss : 0.073756, loss_ce: 0.002834
iteration 11543 : loss : 0.023030, loss_ce: 0.008258
iteration 11544 : loss : 0.028993, loss_ce: 0.009833
iteration 11545 : loss : 0.030324, loss_ce: 0.009437
iteration 11546 : loss : 0.021048, loss_ce: 0.006610
iteration 11547 : loss : 0.023380, loss_ce: 0.008714
iteration 11548 : loss : 0.026572, loss_ce: 0.010526
iteration 11549 : loss : 0.026251, loss_ce: 0.008617
iteration 11550 : loss : 0.023616, loss_ce: 0.006340
iteration 11551 : loss : 0.020214, loss_ce: 0.009116
iteration 11552 : loss : 0.024740, loss_ce: 0.005959
iteration 11553 : loss : 0.022595, loss_ce: 0.011206
iteration 11554 : loss : 0.027384, loss_ce: 0.007545
iteration 11555 : loss : 0.023005, loss_ce: 0.008268
iteration 11556 : loss : 0.028875, loss_ce: 0.008621
iteration 11557 : loss : 0.023627, loss_ce: 0.007569
iteration 11558 : loss : 0.020083, loss_ce: 0.010251
iteration 11559 : loss : 0.020942, loss_ce: 0.006998
iteration 11560 : loss : 0.025006, loss_ce: 0.007271
iteration 11561 : loss : 0.077525, loss_ce: 0.007015
iteration 11562 : loss : 0.021522, loss_ce: 0.010405
iteration 11563 : loss : 0.022967, loss_ce: 0.004175
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 11564 : loss : 0.025228, loss_ce: 0.007333
iteration 11565 : loss : 0.027564, loss_ce: 0.009089
iteration 11566 : loss : 0.028534, loss_ce: 0.011189
iteration 11567 : loss : 0.027035, loss_ce: 0.012469
iteration 11568 : loss : 0.020651, loss_ce: 0.007158
iteration 11569 : loss : 0.024127, loss_ce: 0.010237
iteration 11570 : loss : 0.021999, loss_ce: 0.007227
iteration 11571 : loss : 0.026489, loss_ce: 0.010514
iteration 11572 : loss : 0.028909, loss_ce: 0.007104
iteration 11573 : loss : 0.025895, loss_ce: 0.005006
iteration 11574 : loss : 0.025618, loss_ce: 0.010018
iteration 11575 : loss : 0.024892, loss_ce: 0.007258
iteration 11576 : loss : 0.021740, loss_ce: 0.005457
iteration 11577 : loss : 0.024925, loss_ce: 0.009325
iteration 11578 : loss : 0.077900, loss_ce: 0.010562
iteration 11579 : loss : 0.020355, loss_ce: 0.007609
iteration 11580 : loss : 0.023700, loss_ce: 0.009179
iteration 11581 : loss : 0.020764, loss_ce: 0.008939
iteration 11582 : loss : 0.029961, loss_ce: 0.006657
iteration 11583 : loss : 0.030416, loss_ce: 0.009424
iteration 11584 : loss : 0.074522, loss_ce: 0.006325
iteration 11585 : loss : 0.232766, loss_ce: 0.004093
iteration 11586 : loss : 0.021524, loss_ce: 0.007190
iteration 11587 : loss : 0.077482, loss_ce: 0.005926
iteration 11588 : loss : 0.026567, loss_ce: 0.006826
iteration 11589 : loss : 0.020095, loss_ce: 0.007252
iteration 11590 : loss : 0.027209, loss_ce: 0.007197
iteration 11591 : loss : 0.026242, loss_ce: 0.009381
iteration 11592 : loss : 0.023782, loss_ce: 0.008364
iteration 11593 : loss : 0.026351, loss_ce: 0.011346
iteration 11594 : loss : 0.035088, loss_ce: 0.007237
pred_sum 32278
gtsum tensor(31882, device='cuda:0')
iteration 11595 : loss : 0.026136, loss_ce: 0.010427
iteration 11596 : loss : 0.025343, loss_ce: 0.009260
iteration 11597 : loss : 0.024447, loss_ce: 0.007898
iteration 11598 : loss : 0.023674, loss_ce: 0.011490
iteration 11599 : loss : 0.021718, loss_ce: 0.008487
iteration 11600 : loss : 0.024928, loss_ce: 0.006985
iteration 11601 : loss : 0.025385, loss_ce: 0.010424
iteration 11602 : loss : 0.020876, loss_ce: 0.006007
iteration 11603 : loss : 0.023125, loss_ce: 0.005241
iteration 11604 : loss : 0.023847, loss_ce: 0.008740
iteration 11605 : loss : 0.026732, loss_ce: 0.010559
iteration 11606 : loss : 0.076900, loss_ce: 0.006342
iteration 11607 : loss : 0.028987, loss_ce: 0.009700
iteration 11608 : loss : 0.022356, loss_ce: 0.008084
iteration 11609 : loss : 0.025884, loss_ce: 0.006752
iteration 11610 : loss : 0.021080, loss_ce: 0.005669
iteration 11611 : loss : 0.024193, loss_ce: 0.009439
iteration 11612 : loss : 0.024591, loss_ce: 0.008509
iteration 11613 : loss : 0.022233, loss_ce: 0.009082
iteration 11614 : loss : 0.021482, loss_ce: 0.006938
iteration 11615 : loss : 0.023874, loss_ce: 0.009640
iteration 11616 : loss : 0.021271, loss_ce: 0.006844
iteration 11617 : loss : 0.024847, loss_ce: 0.008499
iteration 11618 : loss : 0.073862, loss_ce: 0.003648
iteration 11619 : loss : 0.022053, loss_ce: 0.006096
iteration 11620 : loss : 0.022408, loss_ce: 0.004723
iteration 11621 : loss : 0.024460, loss_ce: 0.010630
iteration 11622 : loss : 0.024869, loss_ce: 0.006943
iteration 11623 : loss : 0.031578, loss_ce: 0.013277
iteration 11624 : loss : 0.024074, loss_ce: 0.011238
iteration 11625 : loss : 0.235563, loss_ce: 0.010783
 62%|████████████████▉          | 125/200 [1:53:29<1:08:04, 54.45s/it]pred_sum 517
gtsum tensor(418, device='cuda:0')
iteration 11626 : loss : 0.025906, loss_ce: 0.005136
iteration 11627 : loss : 0.030235, loss_ce: 0.015120
iteration 11628 : loss : 0.073205, loss_ce: 0.005764
iteration 11629 : loss : 0.023050, loss_ce: 0.007830
iteration 11630 : loss : 0.023531, loss_ce: 0.008879
iteration 11631 : loss : 0.020238, loss_ce: 0.007506
iteration 11632 : loss : 0.027511, loss_ce: 0.014776
iteration 11633 : loss : 0.022562, loss_ce: 0.005447
iteration 11634 : loss : 0.024632, loss_ce: 0.008380
iteration 11635 : loss : 0.022625, loss_ce: 0.011305
iteration 11636 : loss : 0.021829, loss_ce: 0.007277
iteration 11637 : loss : 0.020833, loss_ce: 0.006540
iteration 11638 : loss : 0.025032, loss_ce: 0.010691
iteration 11639 : loss : 0.026462, loss_ce: 0.008100
iteration 11640 : loss : 0.020374, loss_ce: 0.005641
iteration 11641 : loss : 0.020690, loss_ce: 0.008567
iteration 11642 : loss : 0.021606, loss_ce: 0.005892
iteration 11643 : loss : 0.024988, loss_ce: 0.009737
iteration 11644 : loss : 0.023467, loss_ce: 0.008707
iteration 11645 : loss : 0.023248, loss_ce: 0.007827
iteration 11646 : loss : 0.023486, loss_ce: 0.012422
iteration 11647 : loss : 0.028277, loss_ce: 0.008335
iteration 11648 : loss : 0.055496, loss_ce: 0.005876
iteration 11649 : loss : 0.023572, loss_ce: 0.008795
iteration 11650 : loss : 0.022360, loss_ce: 0.009254
iteration 11651 : loss : 0.029557, loss_ce: 0.014020
iteration 11652 : loss : 0.020314, loss_ce: 0.006488
iteration 11653 : loss : 0.031669, loss_ce: 0.010763
iteration 11654 : loss : 0.083541, loss_ce: 0.012180
iteration 11655 : loss : 0.033160, loss_ce: 0.013182
iteration 11656 : loss : 0.025560, loss_ce: 0.011873
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 11657 : loss : 0.026528, loss_ce: 0.007238
iteration 11658 : loss : 0.029713, loss_ce: 0.008110
iteration 11659 : loss : 0.026812, loss_ce: 0.009872
iteration 11660 : loss : 0.078492, loss_ce: 0.007319
iteration 11661 : loss : 0.029150, loss_ce: 0.010148
iteration 11662 : loss : 0.023712, loss_ce: 0.008083
iteration 11663 : loss : 0.030694, loss_ce: 0.014118
iteration 11664 : loss : 0.027050, loss_ce: 0.008131
iteration 11665 : loss : 0.027124, loss_ce: 0.008829
iteration 11666 : loss : 0.035415, loss_ce: 0.012524
iteration 11667 : loss : 0.080007, loss_ce: 0.010111
iteration 11668 : loss : 0.029119, loss_ce: 0.010897
iteration 11669 : loss : 0.025959, loss_ce: 0.009985
iteration 11670 : loss : 0.028335, loss_ce: 0.012648
iteration 11671 : loss : 0.029201, loss_ce: 0.005893
iteration 11672 : loss : 0.024016, loss_ce: 0.010671
iteration 11673 : loss : 0.026407, loss_ce: 0.013310
iteration 11674 : loss : 0.029020, loss_ce: 0.011090
iteration 11675 : loss : 0.027143, loss_ce: 0.012590
iteration 11676 : loss : 0.024239, loss_ce: 0.006948
iteration 11677 : loss : 0.024667, loss_ce: 0.009987
iteration 11678 : loss : 0.023762, loss_ce: 0.009519
iteration 11679 : loss : 0.024362, loss_ce: 0.010141
iteration 11680 : loss : 0.031343, loss_ce: 0.006355
iteration 11681 : loss : 0.024480, loss_ce: 0.007813
iteration 11682 : loss : 0.029274, loss_ce: 0.005426
iteration 11683 : loss : 0.022720, loss_ce: 0.007418
iteration 11684 : loss : 0.030487, loss_ce: 0.006990
iteration 11685 : loss : 0.042012, loss_ce: 0.006347
iteration 11686 : loss : 0.023323, loss_ce: 0.009190
iteration 11687 : loss : 0.027599, loss_ce: 0.007792
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 11688 : loss : 0.024931, loss_ce: 0.008544
iteration 11689 : loss : 0.032091, loss_ce: 0.014671
iteration 11690 : loss : 0.024405, loss_ce: 0.005878
iteration 11691 : loss : 0.021848, loss_ce: 0.007483
iteration 11692 : loss : 0.029836, loss_ce: 0.009612
iteration 11693 : loss : 0.028227, loss_ce: 0.010070
iteration 11694 : loss : 0.025595, loss_ce: 0.007433
iteration 11695 : loss : 0.023433, loss_ce: 0.006690
iteration 11696 : loss : 0.021782, loss_ce: 0.006433
iteration 11697 : loss : 0.035762, loss_ce: 0.007937
iteration 11698 : loss : 0.020661, loss_ce: 0.006289
iteration 11699 : loss : 0.026154, loss_ce: 0.007835
iteration 11700 : loss : 0.025124, loss_ce: 0.007105
iteration 11701 : loss : 0.024121, loss_ce: 0.005336
iteration 11702 : loss : 0.030308, loss_ce: 0.011239
iteration 11703 : loss : 0.074224, loss_ce: 0.007201
iteration 11704 : loss : 0.077449, loss_ce: 0.006391
iteration 11705 : loss : 0.030794, loss_ce: 0.010279
iteration 11706 : loss : 0.078961, loss_ce: 0.007191
iteration 11707 : loss : 0.028760, loss_ce: 0.008388
iteration 11708 : loss : 0.026110, loss_ce: 0.010631
iteration 11709 : loss : 0.024997, loss_ce: 0.008950
iteration 11710 : loss : 0.023615, loss_ce: 0.008798
iteration 11711 : loss : 0.026205, loss_ce: 0.010794
iteration 11712 : loss : 0.026819, loss_ce: 0.004893
iteration 11713 : loss : 0.075598, loss_ce: 0.006526
iteration 11714 : loss : 0.025641, loss_ce: 0.007921
iteration 11715 : loss : 0.024286, loss_ce: 0.008388
iteration 11716 : loss : 0.026146, loss_ce: 0.010640
iteration 11717 : loss : 0.023091, loss_ce: 0.010858
iteration 11718 : loss : 0.031150, loss_ce: 0.020959
 63%|█████████████████          | 126/200 [1:54:23<1:07:09, 54.45s/it]pred_sum 33127
gtsum tensor(33237, device='cuda:0')
iteration 11719 : loss : 0.025911, loss_ce: 0.007486
iteration 11720 : loss : 0.021987, loss_ce: 0.009927
iteration 11721 : loss : 0.025328, loss_ce: 0.009427
iteration 11722 : loss : 0.020439, loss_ce: 0.005383
iteration 11723 : loss : 0.028881, loss_ce: 0.012332
iteration 11724 : loss : 0.022700, loss_ce: 0.008000
iteration 11725 : loss : 0.025432, loss_ce: 0.007024
iteration 11726 : loss : 0.023767, loss_ce: 0.009475
iteration 11727 : loss : 0.024739, loss_ce: 0.007684
iteration 11728 : loss : 0.022888, loss_ce: 0.006713
iteration 11729 : loss : 0.023383, loss_ce: 0.007144
iteration 11730 : loss : 0.025496, loss_ce: 0.006328
iteration 11731 : loss : 0.025257, loss_ce: 0.007524
iteration 11732 : loss : 0.025799, loss_ce: 0.008985
iteration 11733 : loss : 0.036531, loss_ce: 0.010964
iteration 11734 : loss : 0.022638, loss_ce: 0.008948
iteration 11735 : loss : 0.026137, loss_ce: 0.008386
iteration 11736 : loss : 0.030450, loss_ce: 0.006888
iteration 11737 : loss : 0.021760, loss_ce: 0.006663
iteration 11738 : loss : 0.031114, loss_ce: 0.007145
iteration 11739 : loss : 0.079183, loss_ce: 0.006828
iteration 11740 : loss : 0.022638, loss_ce: 0.005039
iteration 11741 : loss : 0.024508, loss_ce: 0.008364
iteration 11742 : loss : 0.032597, loss_ce: 0.007575
iteration 11743 : loss : 0.029041, loss_ce: 0.012400
iteration 11744 : loss : 0.025301, loss_ce: 0.010603
iteration 11745 : loss : 0.025794, loss_ce: 0.007618
iteration 11746 : loss : 0.020650, loss_ce: 0.007035
iteration 11747 : loss : 0.027966, loss_ce: 0.008543
iteration 11748 : loss : 0.025317, loss_ce: 0.007431
iteration 11749 : loss : 0.021229, loss_ce: 0.008781
pred_sum 74
gtsum tensor(182, device='cuda:0')
iteration 11750 : loss : 0.023181, loss_ce: 0.007648
iteration 11751 : loss : 0.021309, loss_ce: 0.008756
iteration 11752 : loss : 0.021563, loss_ce: 0.005186
iteration 11753 : loss : 0.030186, loss_ce: 0.007370
iteration 11754 : loss : 0.029937, loss_ce: 0.008355
iteration 11755 : loss : 0.031026, loss_ce: 0.012832
iteration 11756 : loss : 0.027081, loss_ce: 0.009640
iteration 11757 : loss : 0.021730, loss_ce: 0.006019
iteration 11758 : loss : 0.022593, loss_ce: 0.010071
iteration 11759 : loss : 0.023674, loss_ce: 0.007311
iteration 11760 : loss : 0.025242, loss_ce: 0.005253
iteration 11761 : loss : 0.075663, loss_ce: 0.004719
iteration 11762 : loss : 0.021062, loss_ce: 0.007190
iteration 11763 : loss : 0.030584, loss_ce: 0.008354
iteration 11764 : loss : 0.025581, loss_ce: 0.008234
iteration 11765 : loss : 0.022758, loss_ce: 0.009590
iteration 11766 : loss : 0.023169, loss_ce: 0.009598
iteration 11767 : loss : 0.025265, loss_ce: 0.010914
iteration 11768 : loss : 0.025335, loss_ce: 0.012510
iteration 11769 : loss : 0.024060, loss_ce: 0.011831
iteration 11770 : loss : 0.025705, loss_ce: 0.009356
iteration 11771 : loss : 0.026528, loss_ce: 0.013368
iteration 11772 : loss : 0.024784, loss_ce: 0.009826
iteration 11773 : loss : 0.023150, loss_ce: 0.008195
iteration 11774 : loss : 0.024700, loss_ce: 0.008877
iteration 11775 : loss : 0.024940, loss_ce: 0.012958
iteration 11776 : loss : 0.034077, loss_ce: 0.008363
iteration 11777 : loss : 0.017355, loss_ce: 0.004450
iteration 11778 : loss : 0.026292, loss_ce: 0.005294
iteration 11779 : loss : 0.023143, loss_ce: 0.007503
iteration 11780 : loss : 0.075704, loss_ce: 0.006931
pred_sum 9751
gtsum tensor(9267, device='cuda:0')
iteration 11781 : loss : 0.020251, loss_ce: 0.004454
iteration 11782 : loss : 0.026434, loss_ce: 0.013000
iteration 11783 : loss : 0.026404, loss_ce: 0.012095
iteration 11784 : loss : 0.026424, loss_ce: 0.013353
iteration 11785 : loss : 0.074547, loss_ce: 0.005438
iteration 11786 : loss : 0.024918, loss_ce: 0.006258
iteration 11787 : loss : 0.075763, loss_ce: 0.004254
iteration 11788 : loss : 0.072974, loss_ce: 0.003082
iteration 11789 : loss : 0.024190, loss_ce: 0.008691
iteration 11790 : loss : 0.075759, loss_ce: 0.008649
iteration 11791 : loss : 0.076215, loss_ce: 0.004267
iteration 11792 : loss : 0.025811, loss_ce: 0.009784
iteration 11793 : loss : 0.074093, loss_ce: 0.005254
iteration 11794 : loss : 0.024013, loss_ce: 0.010111
iteration 11795 : loss : 0.042750, loss_ce: 0.007602
iteration 11796 : loss : 0.027735, loss_ce: 0.013859
iteration 11797 : loss : 0.027653, loss_ce: 0.005044
iteration 11798 : loss : 0.026202, loss_ce: 0.009648
iteration 11799 : loss : 0.027832, loss_ce: 0.011087
iteration 11800 : loss : 0.026698, loss_ce: 0.010084
iteration 11801 : loss : 0.027356, loss_ce: 0.005868
iteration 11802 : loss : 0.027662, loss_ce: 0.011285
iteration 11803 : loss : 0.023293, loss_ce: 0.006370
iteration 11804 : loss : 0.028252, loss_ce: 0.010599
iteration 11805 : loss : 0.038057, loss_ce: 0.006189
iteration 11806 : loss : 0.024698, loss_ce: 0.009787
iteration 11807 : loss : 0.025942, loss_ce: 0.011612
iteration 11808 : loss : 0.027608, loss_ce: 0.006569
iteration 11809 : loss : 0.028309, loss_ce: 0.008459
iteration 11810 : loss : 0.024384, loss_ce: 0.008707
iteration 11811 : loss : 0.171450, loss_ce: 0.006877
 64%|█████████████████▏         | 127/200 [1:55:18<1:06:14, 54.45s/it]pred_sum 13633
gtsum tensor(13476, device='cuda:0')
iteration 11812 : loss : 0.031132, loss_ce: 0.006052
iteration 11813 : loss : 0.039351, loss_ce: 0.012007
iteration 11814 : loss : 0.121940, loss_ce: 0.006862
iteration 11815 : loss : 0.035095, loss_ce: 0.011023
iteration 11816 : loss : 0.029028, loss_ce: 0.011193
iteration 11817 : loss : 0.023311, loss_ce: 0.010923
iteration 11818 : loss : 0.032502, loss_ce: 0.010018
iteration 11819 : loss : 0.026030, loss_ce: 0.009562
iteration 11820 : loss : 0.026681, loss_ce: 0.008977
iteration 11821 : loss : 0.030821, loss_ce: 0.008972
iteration 11822 : loss : 0.025663, loss_ce: 0.010182
iteration 11823 : loss : 0.025917, loss_ce: 0.008062
iteration 11824 : loss : 0.029390, loss_ce: 0.009905
iteration 11825 : loss : 0.025964, loss_ce: 0.008653
iteration 11826 : loss : 0.026449, loss_ce: 0.009395
iteration 11827 : loss : 0.027190, loss_ce: 0.011682
iteration 11828 : loss : 0.031189, loss_ce: 0.011237
iteration 11829 : loss : 0.024992, loss_ce: 0.007319
iteration 11830 : loss : 0.028622, loss_ce: 0.008291
iteration 11831 : loss : 0.024697, loss_ce: 0.008777
iteration 11832 : loss : 0.026279, loss_ce: 0.011381
iteration 11833 : loss : 0.024445, loss_ce: 0.006549
iteration 11834 : loss : 0.035122, loss_ce: 0.012862
iteration 11835 : loss : 0.028819, loss_ce: 0.009714
iteration 11836 : loss : 0.074249, loss_ce: 0.005662
iteration 11837 : loss : 0.025738, loss_ce: 0.013305
iteration 11838 : loss : 0.026134, loss_ce: 0.008018
iteration 11839 : loss : 0.027932, loss_ce: 0.010577
iteration 11840 : loss : 0.024426, loss_ce: 0.006975
iteration 11841 : loss : 0.022585, loss_ce: 0.008078
iteration 11842 : loss : 0.023352, loss_ce: 0.007592
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 11843 : loss : 0.034030, loss_ce: 0.003505
iteration 11844 : loss : 0.026912, loss_ce: 0.006028
iteration 11845 : loss : 0.022837, loss_ce: 0.009606
iteration 11846 : loss : 0.025213, loss_ce: 0.006639
iteration 11847 : loss : 0.035609, loss_ce: 0.010217
iteration 11848 : loss : 0.025915, loss_ce: 0.005165
iteration 11849 : loss : 0.025416, loss_ce: 0.007369
iteration 11850 : loss : 0.028324, loss_ce: 0.008552
iteration 11851 : loss : 0.023262, loss_ce: 0.007636
iteration 11852 : loss : 0.027368, loss_ce: 0.007628
iteration 11853 : loss : 0.020826, loss_ce: 0.006288
iteration 11854 : loss : 0.024711, loss_ce: 0.008845
iteration 11855 : loss : 0.023955, loss_ce: 0.008893
iteration 11856 : loss : 0.026684, loss_ce: 0.008657
iteration 11857 : loss : 0.024394, loss_ce: 0.008064
iteration 11858 : loss : 0.027039, loss_ce: 0.009476
iteration 11859 : loss : 0.027776, loss_ce: 0.005045
iteration 11860 : loss : 0.025169, loss_ce: 0.007969
iteration 11861 : loss : 0.022866, loss_ce: 0.009749
iteration 11862 : loss : 0.026501, loss_ce: 0.010685
iteration 11863 : loss : 0.025913, loss_ce: 0.011889
iteration 11864 : loss : 0.075532, loss_ce: 0.008557
iteration 11865 : loss : 0.028246, loss_ce: 0.011209
iteration 11866 : loss : 0.021943, loss_ce: 0.007654
iteration 11867 : loss : 0.028554, loss_ce: 0.008482
iteration 11868 : loss : 0.020468, loss_ce: 0.007527
iteration 11869 : loss : 0.021496, loss_ce: 0.008137
iteration 11870 : loss : 0.075929, loss_ce: 0.007208
iteration 11871 : loss : 0.023975, loss_ce: 0.009781
iteration 11872 : loss : 0.019518, loss_ce: 0.006729
iteration 11873 : loss : 0.024753, loss_ce: 0.005365
pred_sum 26538
gtsum tensor(26842, device='cuda:0')
iteration 11874 : loss : 0.036012, loss_ce: 0.007787
iteration 11875 : loss : 0.072358, loss_ce: 0.005600
iteration 11876 : loss : 0.024836, loss_ce: 0.007903
iteration 11877 : loss : 0.024659, loss_ce: 0.009077
iteration 11878 : loss : 0.027047, loss_ce: 0.008504
iteration 11879 : loss : 0.030234, loss_ce: 0.005891
iteration 11880 : loss : 0.078130, loss_ce: 0.013463
iteration 11881 : loss : 0.022664, loss_ce: 0.005044
iteration 11882 : loss : 0.020519, loss_ce: 0.005807
iteration 11883 : loss : 0.024576, loss_ce: 0.011207
iteration 11884 : loss : 0.022809, loss_ce: 0.005923
iteration 11885 : loss : 0.021536, loss_ce: 0.008276
iteration 11886 : loss : 0.021865, loss_ce: 0.009632
iteration 11887 : loss : 0.076520, loss_ce: 0.006959
iteration 11888 : loss : 0.028571, loss_ce: 0.007840
iteration 11889 : loss : 0.026420, loss_ce: 0.012460
iteration 11890 : loss : 0.029446, loss_ce: 0.012742
iteration 11891 : loss : 0.034827, loss_ce: 0.007133
iteration 11892 : loss : 0.024525, loss_ce: 0.006407
iteration 11893 : loss : 0.025136, loss_ce: 0.008876
iteration 11894 : loss : 0.031351, loss_ce: 0.008223
iteration 11895 : loss : 0.026960, loss_ce: 0.011458
iteration 11896 : loss : 0.023720, loss_ce: 0.007920
iteration 11897 : loss : 0.027603, loss_ce: 0.010732
iteration 11898 : loss : 0.031681, loss_ce: 0.010991
iteration 11899 : loss : 0.022445, loss_ce: 0.009331
iteration 11900 : loss : 0.025393, loss_ce: 0.012446
iteration 11901 : loss : 0.026448, loss_ce: 0.010363
iteration 11902 : loss : 0.027992, loss_ce: 0.009526
iteration 11903 : loss : 0.022717, loss_ce: 0.009524
iteration 11904 : loss : 0.134432, loss_ce: 0.011262
 64%|█████████████████▎         | 128/200 [1:56:12<1:05:20, 54.45s/it]pred_sum 13139
gtsum tensor(13078, device='cuda:0')
iteration 11905 : loss : 0.073643, loss_ce: 0.006367
iteration 11906 : loss : 0.031496, loss_ce: 0.012559
iteration 11907 : loss : 0.022696, loss_ce: 0.009070
iteration 11908 : loss : 0.027065, loss_ce: 0.012583
iteration 11909 : loss : 0.024845, loss_ce: 0.008933
iteration 11910 : loss : 0.020025, loss_ce: 0.004724
iteration 11911 : loss : 0.081033, loss_ce: 0.005327
iteration 11912 : loss : 0.033317, loss_ce: 0.007533
iteration 11913 : loss : 0.024902, loss_ce: 0.006567
iteration 11914 : loss : 0.021388, loss_ce: 0.005902
iteration 11915 : loss : 0.027225, loss_ce: 0.009637
iteration 11916 : loss : 0.024163, loss_ce: 0.007136
iteration 11917 : loss : 0.028832, loss_ce: 0.011570
iteration 11918 : loss : 0.024422, loss_ce: 0.011718
iteration 11919 : loss : 0.024226, loss_ce: 0.009348
iteration 11920 : loss : 0.024100, loss_ce: 0.008382
iteration 11921 : loss : 0.025566, loss_ce: 0.005422
iteration 11922 : loss : 0.075656, loss_ce: 0.012001
iteration 11923 : loss : 0.022478, loss_ce: 0.007329
iteration 11924 : loss : 0.044206, loss_ce: 0.006065
iteration 11925 : loss : 0.025055, loss_ce: 0.009580
iteration 11926 : loss : 0.022978, loss_ce: 0.006297
iteration 11927 : loss : 0.025500, loss_ce: 0.007575
iteration 11928 : loss : 0.023237, loss_ce: 0.006561
iteration 11929 : loss : 0.027324, loss_ce: 0.009448
iteration 11930 : loss : 0.024305, loss_ce: 0.011383
iteration 11931 : loss : 0.026784, loss_ce: 0.006745
iteration 11932 : loss : 0.025970, loss_ce: 0.007234
iteration 11933 : loss : 0.025841, loss_ce: 0.006507
iteration 11934 : loss : 0.024539, loss_ce: 0.009099
iteration 11935 : loss : 0.022078, loss_ce: 0.005734
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 11936 : loss : 0.022994, loss_ce: 0.010215
iteration 11937 : loss : 0.023537, loss_ce: 0.007901
iteration 11938 : loss : 0.025547, loss_ce: 0.009695
iteration 11939 : loss : 0.023191, loss_ce: 0.009248
iteration 11940 : loss : 0.024235, loss_ce: 0.010115
iteration 11941 : loss : 0.063057, loss_ce: 0.009565
iteration 11942 : loss : 0.026402, loss_ce: 0.013867
iteration 11943 : loss : 0.026934, loss_ce: 0.010101
iteration 11944 : loss : 0.077279, loss_ce: 0.007165
iteration 11945 : loss : 0.026825, loss_ce: 0.009563
iteration 11946 : loss : 0.027769, loss_ce: 0.007578
iteration 11947 : loss : 0.027013, loss_ce: 0.013921
iteration 11948 : loss : 0.025175, loss_ce: 0.010646
iteration 11949 : loss : 0.023920, loss_ce: 0.009616
iteration 11950 : loss : 0.021184, loss_ce: 0.006411
iteration 11951 : loss : 0.027637, loss_ce: 0.009866
iteration 11952 : loss : 0.019935, loss_ce: 0.007357
iteration 11953 : loss : 0.027669, loss_ce: 0.012385
iteration 11954 : loss : 0.025742, loss_ce: 0.009606
iteration 11955 : loss : 0.026204, loss_ce: 0.005970
iteration 11956 : loss : 0.027354, loss_ce: 0.007780
iteration 11957 : loss : 0.081090, loss_ce: 0.006817
iteration 11958 : loss : 0.027847, loss_ce: 0.006931
iteration 11959 : loss : 0.021058, loss_ce: 0.008225
iteration 11960 : loss : 0.020321, loss_ce: 0.007057
iteration 11961 : loss : 0.022082, loss_ce: 0.010305
iteration 11962 : loss : 0.027165, loss_ce: 0.007325
iteration 11963 : loss : 0.024357, loss_ce: 0.009902
iteration 11964 : loss : 0.035322, loss_ce: 0.008809
iteration 11965 : loss : 0.082499, loss_ce: 0.003257
iteration 11966 : loss : 0.046287, loss_ce: 0.006666
pred_sum 6236
gtsum tensor(5840, device='cuda:0')
iteration 11967 : loss : 0.029250, loss_ce: 0.007892
iteration 11968 : loss : 0.028403, loss_ce: 0.006058
iteration 11969 : loss : 0.023214, loss_ce: 0.008428
iteration 11970 : loss : 0.022785, loss_ce: 0.008112
iteration 11971 : loss : 0.026922, loss_ce: 0.009380
iteration 11972 : loss : 0.022022, loss_ce: 0.008681
iteration 11973 : loss : 0.028155, loss_ce: 0.010836
iteration 11974 : loss : 0.021442, loss_ce: 0.007133
iteration 11975 : loss : 0.080841, loss_ce: 0.005413
iteration 11976 : loss : 0.021526, loss_ce: 0.006543
iteration 11977 : loss : 0.020426, loss_ce: 0.005392
iteration 11978 : loss : 0.026527, loss_ce: 0.009943
iteration 11979 : loss : 0.024799, loss_ce: 0.006092
iteration 11980 : loss : 0.025882, loss_ce: 0.008984
iteration 11981 : loss : 0.021933, loss_ce: 0.008032
iteration 11982 : loss : 0.027859, loss_ce: 0.011059
iteration 11983 : loss : 0.023287, loss_ce: 0.009666
iteration 11984 : loss : 0.027586, loss_ce: 0.007685
iteration 11985 : loss : 0.023796, loss_ce: 0.006929
iteration 11986 : loss : 0.026598, loss_ce: 0.010030
iteration 11987 : loss : 0.025604, loss_ce: 0.012765
iteration 11988 : loss : 0.022678, loss_ce: 0.007734
iteration 11989 : loss : 0.028778, loss_ce: 0.007973
iteration 11990 : loss : 0.025642, loss_ce: 0.006371
iteration 11991 : loss : 0.023165, loss_ce: 0.006872
iteration 11992 : loss : 0.023932, loss_ce: 0.010369
iteration 11993 : loss : 0.028284, loss_ce: 0.008052
iteration 11994 : loss : 0.020406, loss_ce: 0.006070
iteration 11995 : loss : 0.029751, loss_ce: 0.011812
iteration 11996 : loss : 0.021331, loss_ce: 0.006017
iteration 11997 : loss : 0.041908, loss_ce: 0.015631
 64%|█████████████████▍         | 129/200 [1:57:07<1:04:27, 54.47s/it]pred_sum 10544
gtsum tensor(11431, device='cuda:0')
iteration 11998 : loss : 0.021620, loss_ce: 0.006537
iteration 11999 : loss : 0.023417, loss_ce: 0.009038
iteration 12000 : loss : 0.023361, loss_ce: 0.006258
iteration 12001 : loss : 0.021734, loss_ce: 0.008482
iteration 12002 : loss : 0.023970, loss_ce: 0.007318
iteration 12003 : loss : 0.023537, loss_ce: 0.009975
iteration 12004 : loss : 0.032022, loss_ce: 0.005352
iteration 12005 : loss : 0.021778, loss_ce: 0.004559
iteration 12006 : loss : 0.026350, loss_ce: 0.011284
iteration 12007 : loss : 0.025206, loss_ce: 0.012107
iteration 12008 : loss : 0.029314, loss_ce: 0.006355
iteration 12009 : loss : 0.027681, loss_ce: 0.006775
iteration 12010 : loss : 0.023400, loss_ce: 0.008678
iteration 12011 : loss : 0.022268, loss_ce: 0.007515
iteration 12012 : loss : 0.022616, loss_ce: 0.009054
iteration 12013 : loss : 0.029979, loss_ce: 0.012045
iteration 12014 : loss : 0.024424, loss_ce: 0.008799
iteration 12015 : loss : 0.025264, loss_ce: 0.008772
iteration 12016 : loss : 0.019943, loss_ce: 0.009472
iteration 12017 : loss : 0.026823, loss_ce: 0.009057
iteration 12018 : loss : 0.074437, loss_ce: 0.005088
iteration 12019 : loss : 0.020606, loss_ce: 0.007357
iteration 12020 : loss : 0.025800, loss_ce: 0.007512
iteration 12021 : loss : 0.025254, loss_ce: 0.008635
iteration 12022 : loss : 0.075506, loss_ce: 0.007552
iteration 12023 : loss : 0.023299, loss_ce: 0.008995
iteration 12024 : loss : 0.022619, loss_ce: 0.006249
iteration 12025 : loss : 0.022956, loss_ce: 0.007920
iteration 12026 : loss : 0.023370, loss_ce: 0.009455
iteration 12027 : loss : 0.025434, loss_ce: 0.009733
iteration 12028 : loss : 0.025298, loss_ce: 0.010566
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 12029 : loss : 0.022084, loss_ce: 0.009140
iteration 12030 : loss : 0.031997, loss_ce: 0.007200
iteration 12031 : loss : 0.021724, loss_ce: 0.005873
iteration 12032 : loss : 0.025573, loss_ce: 0.010675
iteration 12033 : loss : 0.072426, loss_ce: 0.003732
iteration 12034 : loss : 0.020358, loss_ce: 0.007996
iteration 12035 : loss : 0.024971, loss_ce: 0.009449
iteration 12036 : loss : 0.026355, loss_ce: 0.008993
iteration 12037 : loss : 0.028182, loss_ce: 0.009315
iteration 12038 : loss : 0.024352, loss_ce: 0.006128
iteration 12039 : loss : 0.033365, loss_ce: 0.005919
iteration 12040 : loss : 0.021765, loss_ce: 0.006111
iteration 12041 : loss : 0.030316, loss_ce: 0.006161
iteration 12042 : loss : 0.026322, loss_ce: 0.005701
iteration 12043 : loss : 0.025010, loss_ce: 0.011765
iteration 12044 : loss : 0.023992, loss_ce: 0.010610
iteration 12045 : loss : 0.025217, loss_ce: 0.007412
iteration 12046 : loss : 0.024832, loss_ce: 0.008533
iteration 12047 : loss : 0.021804, loss_ce: 0.008258
iteration 12048 : loss : 0.024954, loss_ce: 0.010757
iteration 12049 : loss : 0.025622, loss_ce: 0.007774
iteration 12050 : loss : 0.026419, loss_ce: 0.009593
iteration 12051 : loss : 0.036678, loss_ce: 0.009306
iteration 12052 : loss : 0.022736, loss_ce: 0.011008
iteration 12053 : loss : 0.023058, loss_ce: 0.006485
iteration 12054 : loss : 0.023989, loss_ce: 0.010411
iteration 12055 : loss : 0.024242, loss_ce: 0.011576
iteration 12056 : loss : 0.024974, loss_ce: 0.007930
iteration 12057 : loss : 0.023819, loss_ce: 0.010770
iteration 12058 : loss : 0.023668, loss_ce: 0.008438
iteration 12059 : loss : 0.024138, loss_ce: 0.008552
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 12060 : loss : 0.027118, loss_ce: 0.009621
iteration 12061 : loss : 0.026065, loss_ce: 0.005599
iteration 12062 : loss : 0.074832, loss_ce: 0.005743
iteration 12063 : loss : 0.021914, loss_ce: 0.009689
iteration 12064 : loss : 0.022960, loss_ce: 0.007749
iteration 12065 : loss : 0.022450, loss_ce: 0.009159
iteration 12066 : loss : 0.025403, loss_ce: 0.004802
iteration 12067 : loss : 0.073745, loss_ce: 0.005673
iteration 12068 : loss : 0.021285, loss_ce: 0.006322
iteration 12069 : loss : 0.024054, loss_ce: 0.009890
iteration 12070 : loss : 0.023931, loss_ce: 0.006650
iteration 12071 : loss : 0.026749, loss_ce: 0.011711
iteration 12072 : loss : 0.022422, loss_ce: 0.006080
iteration 12073 : loss : 0.022057, loss_ce: 0.007289
iteration 12074 : loss : 0.018925, loss_ce: 0.007081
iteration 12075 : loss : 0.028078, loss_ce: 0.004642
iteration 12076 : loss : 0.030606, loss_ce: 0.010687
iteration 12077 : loss : 0.024373, loss_ce: 0.006485
iteration 12078 : loss : 0.023626, loss_ce: 0.007529
iteration 12079 : loss : 0.073830, loss_ce: 0.005497
iteration 12080 : loss : 0.022993, loss_ce: 0.008329
iteration 12081 : loss : 0.033893, loss_ce: 0.009909
iteration 12082 : loss : 0.074388, loss_ce: 0.006794
iteration 12083 : loss : 0.021632, loss_ce: 0.008082
iteration 12084 : loss : 0.025731, loss_ce: 0.007848
iteration 12085 : loss : 0.022070, loss_ce: 0.007940
iteration 12086 : loss : 0.032865, loss_ce: 0.014564
iteration 12087 : loss : 0.025775, loss_ce: 0.007946
iteration 12088 : loss : 0.039832, loss_ce: 0.010719
iteration 12089 : loss : 0.022372, loss_ce: 0.006357
iteration 12090 : loss : 0.284328, loss_ce: 0.005108
 65%|█████████████████▌         | 130/200 [1:58:01<1:03:33, 54.48s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 12091 : loss : 0.020435, loss_ce: 0.003769
iteration 12092 : loss : 0.020731, loss_ce: 0.005327
iteration 12093 : loss : 0.026621, loss_ce: 0.011588
iteration 12094 : loss : 0.021730, loss_ce: 0.008436
iteration 12095 : loss : 0.024970, loss_ce: 0.005067
iteration 12096 : loss : 0.076654, loss_ce: 0.008485
iteration 12097 : loss : 0.023541, loss_ce: 0.008036
iteration 12098 : loss : 0.021699, loss_ce: 0.007505
iteration 12099 : loss : 0.023416, loss_ce: 0.007023
iteration 12100 : loss : 0.022640, loss_ce: 0.007584
iteration 12101 : loss : 0.019279, loss_ce: 0.006520
iteration 12102 : loss : 0.024963, loss_ce: 0.007311
iteration 12103 : loss : 0.027984, loss_ce: 0.004340
iteration 12104 : loss : 0.022537, loss_ce: 0.008209
iteration 12105 : loss : 0.025179, loss_ce: 0.007864
iteration 12106 : loss : 0.024006, loss_ce: 0.008020
iteration 12107 : loss : 0.025591, loss_ce: 0.011985
iteration 12108 : loss : 0.029368, loss_ce: 0.007920
iteration 12109 : loss : 0.020560, loss_ce: 0.007176
iteration 12110 : loss : 0.024458, loss_ce: 0.007830
iteration 12111 : loss : 0.024655, loss_ce: 0.010487
iteration 12112 : loss : 0.046892, loss_ce: 0.008449
iteration 12113 : loss : 0.026205, loss_ce: 0.008987
iteration 12114 : loss : 0.028725, loss_ce: 0.008097
iteration 12115 : loss : 0.070355, loss_ce: 0.006306
iteration 12116 : loss : 0.019460, loss_ce: 0.007350
iteration 12117 : loss : 0.020405, loss_ce: 0.007651
iteration 12118 : loss : 0.021236, loss_ce: 0.005053
iteration 12119 : loss : 0.027950, loss_ce: 0.012756
iteration 12120 : loss : 0.028170, loss_ce: 0.009725
iteration 12121 : loss : 0.075698, loss_ce: 0.005720
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 12122 : loss : 0.027791, loss_ce: 0.010731
iteration 12123 : loss : 0.075780, loss_ce: 0.008599
iteration 12124 : loss : 0.023306, loss_ce: 0.008742
iteration 12125 : loss : 0.022580, loss_ce: 0.007539
iteration 12126 : loss : 0.024052, loss_ce: 0.009498
iteration 12127 : loss : 0.025681, loss_ce: 0.005178
iteration 12128 : loss : 0.034877, loss_ce: 0.007925
iteration 12129 : loss : 0.030838, loss_ce: 0.014277
iteration 12130 : loss : 0.022801, loss_ce: 0.007999
iteration 12131 : loss : 0.032114, loss_ce: 0.009886
iteration 12132 : loss : 0.025882, loss_ce: 0.010550
iteration 12133 : loss : 0.025299, loss_ce: 0.007479
iteration 12134 : loss : 0.023452, loss_ce: 0.005261
iteration 12135 : loss : 0.027477, loss_ce: 0.006625
iteration 12136 : loss : 0.026278, loss_ce: 0.007697
iteration 12137 : loss : 0.023750, loss_ce: 0.008498
iteration 12138 : loss : 0.032360, loss_ce: 0.009501
iteration 12139 : loss : 0.024661, loss_ce: 0.007167
iteration 12140 : loss : 0.076283, loss_ce: 0.004246
iteration 12141 : loss : 0.082261, loss_ce: 0.004932
iteration 12142 : loss : 0.026567, loss_ce: 0.010160
iteration 12143 : loss : 0.028921, loss_ce: 0.008990
iteration 12144 : loss : 0.025853, loss_ce: 0.008688
iteration 12145 : loss : 0.027464, loss_ce: 0.008775
iteration 12146 : loss : 0.025584, loss_ce: 0.011770
iteration 12147 : loss : 0.024580, loss_ce: 0.008330
iteration 12148 : loss : 0.032224, loss_ce: 0.010366
iteration 12149 : loss : 0.024690, loss_ce: 0.010257
iteration 12150 : loss : 0.024140, loss_ce: 0.012478
iteration 12151 : loss : 0.027064, loss_ce: 0.011196
iteration 12152 : loss : 0.023720, loss_ce: 0.008670
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 12153 : loss : 0.025076, loss_ce: 0.009055
iteration 12154 : loss : 0.027998, loss_ce: 0.013652
iteration 12155 : loss : 0.024820, loss_ce: 0.008281
iteration 12156 : loss : 0.022455, loss_ce: 0.007580
iteration 12157 : loss : 0.030517, loss_ce: 0.005918
iteration 12158 : loss : 0.023075, loss_ce: 0.006950
iteration 12159 : loss : 0.026802, loss_ce: 0.008762
iteration 12160 : loss : 0.023103, loss_ce: 0.009554
iteration 12161 : loss : 0.043654, loss_ce: 0.012953
iteration 12162 : loss : 0.078850, loss_ce: 0.008369
iteration 12163 : loss : 0.024483, loss_ce: 0.006704
iteration 12164 : loss : 0.023239, loss_ce: 0.006412
iteration 12165 : loss : 0.023441, loss_ce: 0.008635
iteration 12166 : loss : 0.025364, loss_ce: 0.010726
iteration 12167 : loss : 0.022408, loss_ce: 0.008699
iteration 12168 : loss : 0.032834, loss_ce: 0.009204
iteration 12169 : loss : 0.025442, loss_ce: 0.009309
iteration 12170 : loss : 0.078500, loss_ce: 0.003561
iteration 12171 : loss : 0.022834, loss_ce: 0.007652
iteration 12172 : loss : 0.026389, loss_ce: 0.007272
iteration 12173 : loss : 0.025086, loss_ce: 0.002966
iteration 12174 : loss : 0.025106, loss_ce: 0.009637
iteration 12175 : loss : 0.026098, loss_ce: 0.010405
iteration 12176 : loss : 0.026798, loss_ce: 0.011197
iteration 12177 : loss : 0.030420, loss_ce: 0.008261
iteration 12178 : loss : 0.034440, loss_ce: 0.005154
iteration 12179 : loss : 0.024305, loss_ce: 0.007623
iteration 12180 : loss : 0.076248, loss_ce: 0.009727
iteration 12181 : loss : 0.026234, loss_ce: 0.009083
iteration 12182 : loss : 0.018018, loss_ce: 0.007058
iteration 12183 : loss : 0.388303, loss_ce: 0.000545
 66%|█████████████████▋         | 131/200 [1:58:56<1:02:39, 54.49s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 12184 : loss : 0.025709, loss_ce: 0.009364
iteration 12185 : loss : 0.038598, loss_ce: 0.010253
iteration 12186 : loss : 0.023697, loss_ce: 0.008040
iteration 12187 : loss : 0.018979, loss_ce: 0.005821
iteration 12188 : loss : 0.022854, loss_ce: 0.006217
iteration 12189 : loss : 0.025938, loss_ce: 0.007104
iteration 12190 : loss : 0.030458, loss_ce: 0.006399
iteration 12191 : loss : 0.018890, loss_ce: 0.004753
iteration 12192 : loss : 0.026372, loss_ce: 0.011076
iteration 12193 : loss : 0.075813, loss_ce: 0.008836
iteration 12194 : loss : 0.024731, loss_ce: 0.008060
iteration 12195 : loss : 0.022406, loss_ce: 0.006101
iteration 12196 : loss : 0.025271, loss_ce: 0.008648
iteration 12197 : loss : 0.022414, loss_ce: 0.009995
iteration 12198 : loss : 0.023241, loss_ce: 0.010013
iteration 12199 : loss : 0.023217, loss_ce: 0.008840
iteration 12200 : loss : 0.033397, loss_ce: 0.006452
iteration 12201 : loss : 0.039819, loss_ce: 0.004659
iteration 12202 : loss : 0.023702, loss_ce: 0.008747
iteration 12203 : loss : 0.032606, loss_ce: 0.006459
iteration 12204 : loss : 0.022794, loss_ce: 0.006767
iteration 12205 : loss : 0.025920, loss_ce: 0.008240
iteration 12206 : loss : 0.028499, loss_ce: 0.012540
iteration 12207 : loss : 0.023225, loss_ce: 0.006560
iteration 12208 : loss : 0.028926, loss_ce: 0.009824
iteration 12209 : loss : 0.026528, loss_ce: 0.012592
iteration 12210 : loss : 0.028072, loss_ce: 0.008419
iteration 12211 : loss : 0.025003, loss_ce: 0.004589
iteration 12212 : loss : 0.024390, loss_ce: 0.012110
iteration 12213 : loss : 0.026975, loss_ce: 0.010827
iteration 12214 : loss : 0.073145, loss_ce: 0.007037
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 12215 : loss : 0.019763, loss_ce: 0.005853
iteration 12216 : loss : 0.018624, loss_ce: 0.004956
iteration 12217 : loss : 0.025217, loss_ce: 0.005550
iteration 12218 : loss : 0.027196, loss_ce: 0.012453
iteration 12219 : loss : 0.025461, loss_ce: 0.009317
iteration 12220 : loss : 0.022425, loss_ce: 0.010164
iteration 12221 : loss : 0.029683, loss_ce: 0.008811
iteration 12222 : loss : 0.022155, loss_ce: 0.009976
iteration 12223 : loss : 0.021414, loss_ce: 0.007459
iteration 12224 : loss : 0.027754, loss_ce: 0.007436
iteration 12225 : loss : 0.026187, loss_ce: 0.010996
iteration 12226 : loss : 0.025672, loss_ce: 0.006094
iteration 12227 : loss : 0.077623, loss_ce: 0.003984
iteration 12228 : loss : 0.022075, loss_ce: 0.005881
iteration 12229 : loss : 0.022783, loss_ce: 0.011018
iteration 12230 : loss : 0.031807, loss_ce: 0.010229
iteration 12231 : loss : 0.020631, loss_ce: 0.005612
iteration 12232 : loss : 0.027551, loss_ce: 0.005205
iteration 12233 : loss : 0.019898, loss_ce: 0.008248
iteration 12234 : loss : 0.027134, loss_ce: 0.005819
iteration 12235 : loss : 0.020465, loss_ce: 0.009114
iteration 12236 : loss : 0.022887, loss_ce: 0.007382
iteration 12237 : loss : 0.027991, loss_ce: 0.010890
iteration 12238 : loss : 0.022375, loss_ce: 0.007768
iteration 12239 : loss : 0.022739, loss_ce: 0.007744
iteration 12240 : loss : 0.028826, loss_ce: 0.009889
iteration 12241 : loss : 0.030260, loss_ce: 0.009381
iteration 12242 : loss : 0.023482, loss_ce: 0.006229
iteration 12243 : loss : 0.023912, loss_ce: 0.011577
iteration 12244 : loss : 0.023727, loss_ce: 0.010147
iteration 12245 : loss : 0.022987, loss_ce: 0.007379
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 12246 : loss : 0.024065, loss_ce: 0.010712
iteration 12247 : loss : 0.069742, loss_ce: 0.003653
iteration 12248 : loss : 0.027941, loss_ce: 0.014312
iteration 12249 : loss : 0.029858, loss_ce: 0.006629
iteration 12250 : loss : 0.019687, loss_ce: 0.005945
iteration 12251 : loss : 0.075311, loss_ce: 0.007823
iteration 12252 : loss : 0.025410, loss_ce: 0.009479
iteration 12253 : loss : 0.022964, loss_ce: 0.007391
iteration 12254 : loss : 0.023025, loss_ce: 0.008126
iteration 12255 : loss : 0.025381, loss_ce: 0.005442
iteration 12256 : loss : 0.022993, loss_ce: 0.009800
iteration 12257 : loss : 0.022664, loss_ce: 0.010340
iteration 12258 : loss : 0.026668, loss_ce: 0.009748
iteration 12259 : loss : 0.024180, loss_ce: 0.012391
iteration 12260 : loss : 0.078275, loss_ce: 0.006751
iteration 12261 : loss : 0.039471, loss_ce: 0.004389
iteration 12262 : loss : 0.072867, loss_ce: 0.005009
iteration 12263 : loss : 0.037613, loss_ce: 0.008622
iteration 12264 : loss : 0.024177, loss_ce: 0.006109
iteration 12265 : loss : 0.026054, loss_ce: 0.007610
iteration 12266 : loss : 0.027023, loss_ce: 0.012026
iteration 12267 : loss : 0.023967, loss_ce: 0.006348
iteration 12268 : loss : 0.026800, loss_ce: 0.009657
iteration 12269 : loss : 0.021926, loss_ce: 0.006697
iteration 12270 : loss : 0.027966, loss_ce: 0.010270
iteration 12271 : loss : 0.028645, loss_ce: 0.010094
iteration 12272 : loss : 0.022631, loss_ce: 0.009584
iteration 12273 : loss : 0.034282, loss_ce: 0.008000
iteration 12274 : loss : 0.022558, loss_ce: 0.006427
iteration 12275 : loss : 0.048586, loss_ce: 0.005585
iteration 12276 : loss : 0.184464, loss_ce: 0.006161
 66%|█████████████████▊         | 132/200 [1:59:50<1:01:45, 54.49s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 12277 : loss : 0.026963, loss_ce: 0.007724
iteration 12278 : loss : 0.021690, loss_ce: 0.007192
iteration 12279 : loss : 0.035293, loss_ce: 0.005756
iteration 12280 : loss : 0.022535, loss_ce: 0.008647
iteration 12281 : loss : 0.076706, loss_ce: 0.004562
iteration 12282 : loss : 0.026735, loss_ce: 0.009318
iteration 12283 : loss : 0.028131, loss_ce: 0.007362
iteration 12284 : loss : 0.025110, loss_ce: 0.008525
iteration 12285 : loss : 0.021147, loss_ce: 0.006564
iteration 12286 : loss : 0.025394, loss_ce: 0.006966
iteration 12287 : loss : 0.026572, loss_ce: 0.009175
iteration 12288 : loss : 0.026933, loss_ce: 0.008646
iteration 12289 : loss : 0.074417, loss_ce: 0.007860
iteration 12290 : loss : 0.022593, loss_ce: 0.009013
iteration 12291 : loss : 0.027832, loss_ce: 0.012369
iteration 12292 : loss : 0.022245, loss_ce: 0.008036
iteration 12293 : loss : 0.025000, loss_ce: 0.007518
iteration 12294 : loss : 0.023313, loss_ce: 0.009277
iteration 12295 : loss : 0.023919, loss_ce: 0.005205
iteration 12296 : loss : 0.019878, loss_ce: 0.008260
iteration 12297 : loss : 0.079581, loss_ce: 0.009125
iteration 12298 : loss : 0.016888, loss_ce: 0.004361
iteration 12299 : loss : 0.072112, loss_ce: 0.005592
iteration 12300 : loss : 0.021731, loss_ce: 0.007628
iteration 12301 : loss : 0.025318, loss_ce: 0.005260
iteration 12302 : loss : 0.039209, loss_ce: 0.009282
iteration 12303 : loss : 0.026065, loss_ce: 0.008168
iteration 12304 : loss : 0.025980, loss_ce: 0.007177
iteration 12305 : loss : 0.027525, loss_ce: 0.008379
iteration 12306 : loss : 0.023493, loss_ce: 0.011219
iteration 12307 : loss : 0.024074, loss_ce: 0.010453
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 12308 : loss : 0.024190, loss_ce: 0.006825
iteration 12309 : loss : 0.040530, loss_ce: 0.006131
iteration 12310 : loss : 0.026758, loss_ce: 0.005827
iteration 12311 : loss : 0.020372, loss_ce: 0.006481
iteration 12312 : loss : 0.023168, loss_ce: 0.006689
iteration 12313 : loss : 0.030165, loss_ce: 0.007763
iteration 12314 : loss : 0.022735, loss_ce: 0.009186
iteration 12315 : loss : 0.075907, loss_ce: 0.006955
iteration 12316 : loss : 0.032498, loss_ce: 0.012478
iteration 12317 : loss : 0.024670, loss_ce: 0.009026
iteration 12318 : loss : 0.022496, loss_ce: 0.005933
iteration 12319 : loss : 0.030832, loss_ce: 0.007761
iteration 12320 : loss : 0.021827, loss_ce: 0.006487
iteration 12321 : loss : 0.033958, loss_ce: 0.006795
iteration 12322 : loss : 0.024288, loss_ce: 0.010845
iteration 12323 : loss : 0.023545, loss_ce: 0.010871
iteration 12324 : loss : 0.023401, loss_ce: 0.009240
iteration 12325 : loss : 0.029418, loss_ce: 0.006395
iteration 12326 : loss : 0.026487, loss_ce: 0.006895
iteration 12327 : loss : 0.025033, loss_ce: 0.006583
iteration 12328 : loss : 0.025597, loss_ce: 0.009044
iteration 12329 : loss : 0.026049, loss_ce: 0.006912
iteration 12330 : loss : 0.027211, loss_ce: 0.011394
iteration 12331 : loss : 0.026614, loss_ce: 0.007591
iteration 12332 : loss : 0.021779, loss_ce: 0.005310
iteration 12333 : loss : 0.027658, loss_ce: 0.007759
iteration 12334 : loss : 0.021352, loss_ce: 0.007603
iteration 12335 : loss : 0.022423, loss_ce: 0.007117
iteration 12336 : loss : 0.019759, loss_ce: 0.008114
iteration 12337 : loss : 0.023352, loss_ce: 0.007978
iteration 12338 : loss : 0.021962, loss_ce: 0.009517
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 12339 : loss : 0.022575, loss_ce: 0.008075
iteration 12340 : loss : 0.024600, loss_ce: 0.009015
iteration 12341 : loss : 0.024998, loss_ce: 0.010724
iteration 12342 : loss : 0.023752, loss_ce: 0.009519
iteration 12343 : loss : 0.023705, loss_ce: 0.010526
iteration 12344 : loss : 0.021652, loss_ce: 0.004966
iteration 12345 : loss : 0.021344, loss_ce: 0.008295
iteration 12346 : loss : 0.021947, loss_ce: 0.007320
iteration 12347 : loss : 0.026235, loss_ce: 0.010385
iteration 12348 : loss : 0.023722, loss_ce: 0.008814
iteration 12349 : loss : 0.030733, loss_ce: 0.007697
iteration 12350 : loss : 0.024036, loss_ce: 0.006074
iteration 12351 : loss : 0.025459, loss_ce: 0.004409
iteration 12352 : loss : 0.023036, loss_ce: 0.010877
iteration 12353 : loss : 0.078517, loss_ce: 0.005067
iteration 12354 : loss : 0.019819, loss_ce: 0.006372
iteration 12355 : loss : 0.022892, loss_ce: 0.008811
iteration 12356 : loss : 0.023229, loss_ce: 0.010156
iteration 12357 : loss : 0.026256, loss_ce: 0.007983
iteration 12358 : loss : 0.062447, loss_ce: 0.007257
iteration 12359 : loss : 0.028487, loss_ce: 0.012071
iteration 12360 : loss : 0.024999, loss_ce: 0.012888
iteration 12361 : loss : 0.024429, loss_ce: 0.006624
iteration 12362 : loss : 0.029398, loss_ce: 0.009547
iteration 12363 : loss : 0.029614, loss_ce: 0.012423
iteration 12364 : loss : 0.024048, loss_ce: 0.009093
iteration 12365 : loss : 0.026677, loss_ce: 0.008352
iteration 12366 : loss : 0.027513, loss_ce: 0.009706
iteration 12367 : loss : 0.022155, loss_ce: 0.010417
iteration 12368 : loss : 0.021634, loss_ce: 0.007554
iteration 12369 : loss : 0.137328, loss_ce: 0.009887
 66%|█████████████████▉         | 133/200 [2:00:45<1:00:51, 54.50s/it]pred_sum 34692
gtsum tensor(34881, device='cuda:0')
iteration 12370 : loss : 0.024322, loss_ce: 0.005847
iteration 12371 : loss : 0.023846, loss_ce: 0.007928
iteration 12372 : loss : 0.020115, loss_ce: 0.007579
iteration 12373 : loss : 0.024370, loss_ce: 0.010048
iteration 12374 : loss : 0.075819, loss_ce: 0.006722
iteration 12375 : loss : 0.020151, loss_ce: 0.006314
iteration 12376 : loss : 0.021668, loss_ce: 0.011194
iteration 12377 : loss : 0.023181, loss_ce: 0.007979
iteration 12378 : loss : 0.030236, loss_ce: 0.009562
iteration 12379 : loss : 0.019040, loss_ce: 0.006150
iteration 12380 : loss : 0.076055, loss_ce: 0.006555
iteration 12381 : loss : 0.026171, loss_ce: 0.006677
iteration 12382 : loss : 0.024732, loss_ce: 0.008899
iteration 12383 : loss : 0.017630, loss_ce: 0.003758
iteration 12384 : loss : 0.027586, loss_ce: 0.012600
iteration 12385 : loss : 0.024977, loss_ce: 0.009909
iteration 12386 : loss : 0.025664, loss_ce: 0.011562
iteration 12387 : loss : 0.018282, loss_ce: 0.005401
iteration 12388 : loss : 0.022271, loss_ce: 0.007465
iteration 12389 : loss : 0.022940, loss_ce: 0.006027
iteration 12390 : loss : 0.020833, loss_ce: 0.007028
iteration 12391 : loss : 0.022469, loss_ce: 0.010564
iteration 12392 : loss : 0.018789, loss_ce: 0.004867
iteration 12393 : loss : 0.076386, loss_ce: 0.010043
iteration 12394 : loss : 0.023086, loss_ce: 0.005441
iteration 12395 : loss : 0.024760, loss_ce: 0.007189
iteration 12396 : loss : 0.022978, loss_ce: 0.005308
iteration 12397 : loss : 0.024886, loss_ce: 0.007187
iteration 12398 : loss : 0.024666, loss_ce: 0.011661
iteration 12399 : loss : 0.028727, loss_ce: 0.007118
iteration 12400 : loss : 0.025579, loss_ce: 0.004766
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 12401 : loss : 0.023579, loss_ce: 0.007666
iteration 12402 : loss : 0.021622, loss_ce: 0.005991
iteration 12403 : loss : 0.023396, loss_ce: 0.010726
iteration 12404 : loss : 0.022210, loss_ce: 0.004386
iteration 12405 : loss : 0.025441, loss_ce: 0.007120
iteration 12406 : loss : 0.025061, loss_ce: 0.006685
iteration 12407 : loss : 0.018948, loss_ce: 0.005354
iteration 12408 : loss : 0.026071, loss_ce: 0.007726
iteration 12409 : loss : 0.026406, loss_ce: 0.005452
iteration 12410 : loss : 0.022018, loss_ce: 0.006589
iteration 12411 : loss : 0.023809, loss_ce: 0.006799
iteration 12412 : loss : 0.078362, loss_ce: 0.005097
iteration 12413 : loss : 0.026402, loss_ce: 0.009014
iteration 12414 : loss : 0.124896, loss_ce: 0.004565
iteration 12415 : loss : 0.029873, loss_ce: 0.007829
iteration 12416 : loss : 0.028734, loss_ce: 0.007710
iteration 12417 : loss : 0.022887, loss_ce: 0.006625
iteration 12418 : loss : 0.028635, loss_ce: 0.013550
iteration 12419 : loss : 0.028428, loss_ce: 0.004996
iteration 12420 : loss : 0.025828, loss_ce: 0.011820
iteration 12421 : loss : 0.027797, loss_ce: 0.008152
iteration 12422 : loss : 0.029458, loss_ce: 0.004515
iteration 12423 : loss : 0.023958, loss_ce: 0.011441
iteration 12424 : loss : 0.021102, loss_ce: 0.009006
iteration 12425 : loss : 0.021956, loss_ce: 0.006738
iteration 12426 : loss : 0.027981, loss_ce: 0.005260
iteration 12427 : loss : 0.024732, loss_ce: 0.008514
iteration 12428 : loss : 0.038290, loss_ce: 0.006395
iteration 12429 : loss : 0.025380, loss_ce: 0.012398
iteration 12430 : loss : 0.025732, loss_ce: 0.012608
iteration 12431 : loss : 0.021917, loss_ce: 0.009910
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 12432 : loss : 0.020957, loss_ce: 0.008768
iteration 12433 : loss : 0.027608, loss_ce: 0.007398
iteration 12434 : loss : 0.020920, loss_ce: 0.008102
iteration 12435 : loss : 0.127307, loss_ce: 0.001933
iteration 12436 : loss : 0.024030, loss_ce: 0.012229
iteration 12437 : loss : 0.026016, loss_ce: 0.003745
iteration 12438 : loss : 0.027737, loss_ce: 0.009487
iteration 12439 : loss : 0.026785, loss_ce: 0.011388
iteration 12440 : loss : 0.025671, loss_ce: 0.005864
iteration 12441 : loss : 0.022108, loss_ce: 0.009604
iteration 12442 : loss : 0.025921, loss_ce: 0.012771
iteration 12443 : loss : 0.021846, loss_ce: 0.008135
iteration 12444 : loss : 0.024734, loss_ce: 0.009447
iteration 12445 : loss : 0.021102, loss_ce: 0.005201
iteration 12446 : loss : 0.026936, loss_ce: 0.011720
iteration 12447 : loss : 0.024636, loss_ce: 0.009533
iteration 12448 : loss : 0.024258, loss_ce: 0.009671
iteration 12449 : loss : 0.026310, loss_ce: 0.009639
iteration 12450 : loss : 0.022208, loss_ce: 0.008297
iteration 12451 : loss : 0.074471, loss_ce: 0.007212
iteration 12452 : loss : 0.076208, loss_ce: 0.006957
iteration 12453 : loss : 0.023053, loss_ce: 0.007748
iteration 12454 : loss : 0.026705, loss_ce: 0.014808
iteration 12455 : loss : 0.027225, loss_ce: 0.010403
iteration 12456 : loss : 0.020137, loss_ce: 0.006272
iteration 12457 : loss : 0.020768, loss_ce: 0.009571
iteration 12458 : loss : 0.020678, loss_ce: 0.006832
iteration 12459 : loss : 0.025419, loss_ce: 0.010783
iteration 12460 : loss : 0.020921, loss_ce: 0.008813
iteration 12461 : loss : 0.026207, loss_ce: 0.010497
iteration 12462 : loss : 0.129412, loss_ce: 0.012334
 67%|███████████████████▍         | 134/200 [2:01:39<59:58, 54.53s/it]pred_sum 33821
gtsum tensor(32247, device='cuda:0')
iteration 12463 : loss : 0.021169, loss_ce: 0.007617
iteration 12464 : loss : 0.019240, loss_ce: 0.005695
iteration 12465 : loss : 0.023107, loss_ce: 0.009271
iteration 12466 : loss : 0.023082, loss_ce: 0.011762
iteration 12467 : loss : 0.028589, loss_ce: 0.007723
iteration 12468 : loss : 0.040988, loss_ce: 0.006842
iteration 12469 : loss : 0.025319, loss_ce: 0.010086
iteration 12470 : loss : 0.024045, loss_ce: 0.005548
iteration 12471 : loss : 0.074451, loss_ce: 0.004546
iteration 12472 : loss : 0.025627, loss_ce: 0.009526
iteration 12473 : loss : 0.023866, loss_ce: 0.008960
iteration 12474 : loss : 0.020857, loss_ce: 0.010051
iteration 12475 : loss : 0.022179, loss_ce: 0.010691
iteration 12476 : loss : 0.023416, loss_ce: 0.004105
iteration 12477 : loss : 0.026399, loss_ce: 0.010706
iteration 12478 : loss : 0.023553, loss_ce: 0.009501
iteration 12479 : loss : 0.022163, loss_ce: 0.008917
iteration 12480 : loss : 0.021020, loss_ce: 0.006667
iteration 12481 : loss : 0.019102, loss_ce: 0.005956
iteration 12482 : loss : 0.021777, loss_ce: 0.007094
iteration 12483 : loss : 0.020285, loss_ce: 0.008981
iteration 12484 : loss : 0.026297, loss_ce: 0.007906
iteration 12485 : loss : 0.027241, loss_ce: 0.010317
iteration 12486 : loss : 0.024817, loss_ce: 0.008409
iteration 12487 : loss : 0.022516, loss_ce: 0.007150
iteration 12488 : loss : 0.024297, loss_ce: 0.007350
iteration 12489 : loss : 0.024987, loss_ce: 0.008150
iteration 12490 : loss : 0.022849, loss_ce: 0.008736
iteration 12491 : loss : 0.076826, loss_ce: 0.008095
iteration 12492 : loss : 0.024847, loss_ce: 0.007643
iteration 12493 : loss : 0.022789, loss_ce: 0.008589
pred_sum 2631
gtsum tensor(2631, device='cuda:0')
iteration 12494 : loss : 0.020017, loss_ce: 0.007237
iteration 12495 : loss : 0.020571, loss_ce: 0.008648
iteration 12496 : loss : 0.020080, loss_ce: 0.009676
iteration 12497 : loss : 0.019690, loss_ce: 0.007186
iteration 12498 : loss : 0.026062, loss_ce: 0.008603
iteration 12499 : loss : 0.020864, loss_ce: 0.006197
iteration 12500 : loss : 0.024028, loss_ce: 0.006703
iteration 12501 : loss : 0.023292, loss_ce: 0.007972
iteration 12502 : loss : 0.026720, loss_ce: 0.005650
iteration 12503 : loss : 0.026106, loss_ce: 0.007260
iteration 12504 : loss : 0.074968, loss_ce: 0.006911
iteration 12505 : loss : 0.027399, loss_ce: 0.010569
iteration 12506 : loss : 0.021442, loss_ce: 0.008949
iteration 12507 : loss : 0.073851, loss_ce: 0.006150
iteration 12508 : loss : 0.023686, loss_ce: 0.008232
iteration 12509 : loss : 0.023197, loss_ce: 0.009358
iteration 12510 : loss : 0.027971, loss_ce: 0.006413
iteration 12511 : loss : 0.017089, loss_ce: 0.004975
iteration 12512 : loss : 0.025079, loss_ce: 0.008806
iteration 12513 : loss : 0.025556, loss_ce: 0.008408
iteration 12514 : loss : 0.031964, loss_ce: 0.007716
iteration 12515 : loss : 0.023709, loss_ce: 0.008549
iteration 12516 : loss : 0.021750, loss_ce: 0.007767
iteration 12517 : loss : 0.025975, loss_ce: 0.007154
iteration 12518 : loss : 0.076709, loss_ce: 0.008534
iteration 12519 : loss : 0.025126, loss_ce: 0.008706
iteration 12520 : loss : 0.038481, loss_ce: 0.010785
iteration 12521 : loss : 0.026359, loss_ce: 0.006661
iteration 12522 : loss : 0.033805, loss_ce: 0.007790
iteration 12523 : loss : 0.024747, loss_ce: 0.008606
iteration 12524 : loss : 0.022683, loss_ce: 0.005851
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 12525 : loss : 0.031800, loss_ce: 0.010196
iteration 12526 : loss : 0.024884, loss_ce: 0.006303
iteration 12527 : loss : 0.033041, loss_ce: 0.005921
iteration 12528 : loss : 0.024177, loss_ce: 0.006514
iteration 12529 : loss : 0.025734, loss_ce: 0.011737
iteration 12530 : loss : 0.080350, loss_ce: 0.009153
iteration 12531 : loss : 0.025760, loss_ce: 0.008185
iteration 12532 : loss : 0.023247, loss_ce: 0.010743
iteration 12533 : loss : 0.075507, loss_ce: 0.005392
iteration 12534 : loss : 0.020960, loss_ce: 0.005524
iteration 12535 : loss : 0.021620, loss_ce: 0.005252
iteration 12536 : loss : 0.022764, loss_ce: 0.007870
iteration 12537 : loss : 0.021599, loss_ce: 0.008512
iteration 12538 : loss : 0.028201, loss_ce: 0.009901
iteration 12539 : loss : 0.022520, loss_ce: 0.005767
iteration 12540 : loss : 0.026682, loss_ce: 0.005694
iteration 12541 : loss : 0.022820, loss_ce: 0.008885
iteration 12542 : loss : 0.021776, loss_ce: 0.008335
iteration 12543 : loss : 0.029367, loss_ce: 0.007072
iteration 12544 : loss : 0.020417, loss_ce: 0.007698
iteration 12545 : loss : 0.027265, loss_ce: 0.010203
iteration 12546 : loss : 0.034315, loss_ce: 0.010300
iteration 12547 : loss : 0.025525, loss_ce: 0.005357
iteration 12548 : loss : 0.026503, loss_ce: 0.010094
iteration 12549 : loss : 0.026369, loss_ce: 0.009655
iteration 12550 : loss : 0.024448, loss_ce: 0.007463
iteration 12551 : loss : 0.023035, loss_ce: 0.010433
iteration 12552 : loss : 0.020137, loss_ce: 0.006670
iteration 12553 : loss : 0.077764, loss_ce: 0.008347
iteration 12554 : loss : 0.026342, loss_ce: 0.009301
iteration 12555 : loss : 0.090379, loss_ce: 0.016790
 68%|███████████████████▌         | 135/200 [2:02:34<59:03, 54.52s/it]pred_sum 22371
gtsum tensor(22801, device='cuda:0')
iteration 12556 : loss : 0.030598, loss_ce: 0.009449
iteration 12557 : loss : 0.026484, loss_ce: 0.012809
iteration 12558 : loss : 0.024625, loss_ce: 0.006365
iteration 12559 : loss : 0.023523, loss_ce: 0.011727
iteration 12560 : loss : 0.026387, loss_ce: 0.010226
iteration 12561 : loss : 0.027451, loss_ce: 0.012030
iteration 12562 : loss : 0.022904, loss_ce: 0.008710
iteration 12563 : loss : 0.025749, loss_ce: 0.008414
iteration 12564 : loss : 0.074854, loss_ce: 0.008465
iteration 12565 : loss : 0.028104, loss_ce: 0.010490
iteration 12566 : loss : 0.028919, loss_ce: 0.011400
iteration 12567 : loss : 0.026288, loss_ce: 0.007349
iteration 12568 : loss : 0.020721, loss_ce: 0.007427
iteration 12569 : loss : 0.022442, loss_ce: 0.006850
iteration 12570 : loss : 0.027832, loss_ce: 0.005687
iteration 12571 : loss : 0.023689, loss_ce: 0.005084
iteration 12572 : loss : 0.024507, loss_ce: 0.008838
iteration 12573 : loss : 0.025796, loss_ce: 0.007802
iteration 12574 : loss : 0.020011, loss_ce: 0.008179
iteration 12575 : loss : 0.023285, loss_ce: 0.008836
iteration 12576 : loss : 0.025303, loss_ce: 0.009833
iteration 12577 : loss : 0.029508, loss_ce: 0.005651
iteration 12578 : loss : 0.022277, loss_ce: 0.007493
iteration 12579 : loss : 0.023233, loss_ce: 0.010081
iteration 12580 : loss : 0.039022, loss_ce: 0.005965
iteration 12581 : loss : 0.020889, loss_ce: 0.008708
iteration 12582 : loss : 0.021132, loss_ce: 0.008744
iteration 12583 : loss : 0.074323, loss_ce: 0.007412
iteration 12584 : loss : 0.074391, loss_ce: 0.003411
iteration 12585 : loss : 0.021519, loss_ce: 0.010657
iteration 12586 : loss : 0.019613, loss_ce: 0.008093
pred_sum 2237
gtsum tensor(2134, device='cuda:0')
iteration 12587 : loss : 0.021914, loss_ce: 0.005420
iteration 12588 : loss : 0.021051, loss_ce: 0.007622
iteration 12589 : loss : 0.023848, loss_ce: 0.007539
iteration 12590 : loss : 0.023340, loss_ce: 0.010115
iteration 12591 : loss : 0.073836, loss_ce: 0.005824
iteration 12592 : loss : 0.025537, loss_ce: 0.006459
iteration 12593 : loss : 0.025543, loss_ce: 0.010219
iteration 12594 : loss : 0.024239, loss_ce: 0.007950
iteration 12595 : loss : 0.024126, loss_ce: 0.009087
iteration 12596 : loss : 0.020418, loss_ce: 0.004785
iteration 12597 : loss : 0.021591, loss_ce: 0.007876
iteration 12598 : loss : 0.021807, loss_ce: 0.010147
iteration 12599 : loss : 0.022635, loss_ce: 0.007026
iteration 12600 : loss : 0.021906, loss_ce: 0.009724
iteration 12601 : loss : 0.026597, loss_ce: 0.005587
iteration 12602 : loss : 0.023490, loss_ce: 0.007641
iteration 12603 : loss : 0.024943, loss_ce: 0.006184
iteration 12604 : loss : 0.022595, loss_ce: 0.006173
iteration 12605 : loss : 0.026157, loss_ce: 0.005144
iteration 12606 : loss : 0.023559, loss_ce: 0.008139
iteration 12607 : loss : 0.020775, loss_ce: 0.006888
iteration 12608 : loss : 0.019297, loss_ce: 0.005228
iteration 12609 : loss : 0.024606, loss_ce: 0.011581
iteration 12610 : loss : 0.020406, loss_ce: 0.005828
iteration 12611 : loss : 0.033232, loss_ce: 0.007936
iteration 12612 : loss : 0.025521, loss_ce: 0.005487
iteration 12613 : loss : 0.027302, loss_ce: 0.007063
iteration 12614 : loss : 0.021930, loss_ce: 0.009809
iteration 12615 : loss : 0.017786, loss_ce: 0.003340
iteration 12616 : loss : 0.025374, loss_ce: 0.009267
iteration 12617 : loss : 0.075332, loss_ce: 0.006589
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 12618 : loss : 0.077154, loss_ce: 0.004448
iteration 12619 : loss : 0.023440, loss_ce: 0.007788
iteration 12620 : loss : 0.025759, loss_ce: 0.009953
iteration 12621 : loss : 0.033375, loss_ce: 0.007578
iteration 12622 : loss : 0.021679, loss_ce: 0.008727
iteration 12623 : loss : 0.023056, loss_ce: 0.007706
iteration 12624 : loss : 0.035094, loss_ce: 0.005202
iteration 12625 : loss : 0.018957, loss_ce: 0.007680
iteration 12626 : loss : 0.022873, loss_ce: 0.009263
iteration 12627 : loss : 0.023685, loss_ce: 0.009687
iteration 12628 : loss : 0.025449, loss_ce: 0.005885
iteration 12629 : loss : 0.020307, loss_ce: 0.006111
iteration 12630 : loss : 0.027000, loss_ce: 0.014153
iteration 12631 : loss : 0.026512, loss_ce: 0.008918
iteration 12632 : loss : 0.024319, loss_ce: 0.012319
iteration 12633 : loss : 0.031280, loss_ce: 0.005053
iteration 12634 : loss : 0.020616, loss_ce: 0.008304
iteration 12635 : loss : 0.022949, loss_ce: 0.007451
iteration 12636 : loss : 0.027441, loss_ce: 0.009792
iteration 12637 : loss : 0.025596, loss_ce: 0.008989
iteration 12638 : loss : 0.022064, loss_ce: 0.009906
iteration 12639 : loss : 0.023723, loss_ce: 0.008097
iteration 12640 : loss : 0.024449, loss_ce: 0.007169
iteration 12641 : loss : 0.019520, loss_ce: 0.005494
iteration 12642 : loss : 0.025443, loss_ce: 0.010470
iteration 12643 : loss : 0.044099, loss_ce: 0.008548
iteration 12644 : loss : 0.022066, loss_ce: 0.008299
iteration 12645 : loss : 0.021843, loss_ce: 0.003922
iteration 12646 : loss : 0.024631, loss_ce: 0.011512
iteration 12647 : loss : 0.021599, loss_ce: 0.002752
iteration 12648 : loss : 0.392154, loss_ce: 0.002509
 68%|███████████████████▋         | 136/200 [2:03:28<58:08, 54.51s/it]pred_sum 179
gtsum tensor(193, device='cuda:0')
iteration 12649 : loss : 0.020990, loss_ce: 0.005683
iteration 12650 : loss : 0.022543, loss_ce: 0.008434
iteration 12651 : loss : 0.021823, loss_ce: 0.008351
iteration 12652 : loss : 0.025466, loss_ce: 0.008176
iteration 12653 : loss : 0.025383, loss_ce: 0.011147
iteration 12654 : loss : 0.021313, loss_ce: 0.006729
iteration 12655 : loss : 0.033966, loss_ce: 0.007390
iteration 12656 : loss : 0.017886, loss_ce: 0.005705
iteration 12657 : loss : 0.022520, loss_ce: 0.009977
iteration 12658 : loss : 0.023653, loss_ce: 0.006097
iteration 12659 : loss : 0.024912, loss_ce: 0.009944
iteration 12660 : loss : 0.022791, loss_ce: 0.006510
iteration 12661 : loss : 0.026553, loss_ce: 0.009706
iteration 12662 : loss : 0.021025, loss_ce: 0.008684
iteration 12663 : loss : 0.025803, loss_ce: 0.014009
iteration 12664 : loss : 0.021821, loss_ce: 0.007522
iteration 12665 : loss : 0.024618, loss_ce: 0.006600
iteration 12666 : loss : 0.028607, loss_ce: 0.007183
iteration 12667 : loss : 0.024201, loss_ce: 0.007075
iteration 12668 : loss : 0.030860, loss_ce: 0.006177
iteration 12669 : loss : 0.021202, loss_ce: 0.006532
iteration 12670 : loss : 0.023196, loss_ce: 0.007815
iteration 12671 : loss : 0.020217, loss_ce: 0.004628
iteration 12672 : loss : 0.027650, loss_ce: 0.008347
iteration 12673 : loss : 0.027626, loss_ce: 0.012502
iteration 12674 : loss : 0.024389, loss_ce: 0.005892
iteration 12675 : loss : 0.024181, loss_ce: 0.007853
iteration 12676 : loss : 0.026902, loss_ce: 0.011455
iteration 12677 : loss : 0.021934, loss_ce: 0.005416
iteration 12678 : loss : 0.023923, loss_ce: 0.009118
iteration 12679 : loss : 0.023517, loss_ce: 0.007903
pred_sum 19366
gtsum tensor(18599, device='cuda:0')
iteration 12680 : loss : 0.024303, loss_ce: 0.009955
iteration 12681 : loss : 0.021380, loss_ce: 0.006822
iteration 12682 : loss : 0.027407, loss_ce: 0.010530
iteration 12683 : loss : 0.024633, loss_ce: 0.011080
iteration 12684 : loss : 0.026793, loss_ce: 0.007183
iteration 12685 : loss : 0.024962, loss_ce: 0.009593
iteration 12686 : loss : 0.024702, loss_ce: 0.007304
iteration 12687 : loss : 0.022580, loss_ce: 0.008581
iteration 12688 : loss : 0.027530, loss_ce: 0.011461
iteration 12689 : loss : 0.022246, loss_ce: 0.007225
iteration 12690 : loss : 0.021975, loss_ce: 0.005782
iteration 12691 : loss : 0.021844, loss_ce: 0.007134
iteration 12692 : loss : 0.027106, loss_ce: 0.006894
iteration 12693 : loss : 0.029125, loss_ce: 0.008402
iteration 12694 : loss : 0.022576, loss_ce: 0.005798
iteration 12695 : loss : 0.023213, loss_ce: 0.004668
iteration 12696 : loss : 0.024180, loss_ce: 0.008040
iteration 12697 : loss : 0.023993, loss_ce: 0.009253
iteration 12698 : loss : 0.026133, loss_ce: 0.008128
iteration 12699 : loss : 0.024266, loss_ce: 0.006768
iteration 12700 : loss : 0.023672, loss_ce: 0.008495
iteration 12701 : loss : 0.021996, loss_ce: 0.008537
iteration 12702 : loss : 0.019593, loss_ce: 0.007636
iteration 12703 : loss : 0.027735, loss_ce: 0.012253
iteration 12704 : loss : 0.021358, loss_ce: 0.005179
iteration 12705 : loss : 0.030678, loss_ce: 0.006672
iteration 12706 : loss : 0.024024, loss_ce: 0.007154
iteration 12707 : loss : 0.025041, loss_ce: 0.008726
iteration 12708 : loss : 0.021986, loss_ce: 0.007413
iteration 12709 : loss : 0.131204, loss_ce: 0.006293
iteration 12710 : loss : 0.028935, loss_ce: 0.006907
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 12711 : loss : 0.025508, loss_ce: 0.007021
iteration 12712 : loss : 0.025740, loss_ce: 0.011541
iteration 12713 : loss : 0.026203, loss_ce: 0.012439
iteration 12714 : loss : 0.023566, loss_ce: 0.011310
iteration 12715 : loss : 0.019904, loss_ce: 0.004660
iteration 12716 : loss : 0.022622, loss_ce: 0.007461
iteration 12717 : loss : 0.026016, loss_ce: 0.011847
iteration 12718 : loss : 0.023615, loss_ce: 0.008972
iteration 12719 : loss : 0.022677, loss_ce: 0.008431
iteration 12720 : loss : 0.025423, loss_ce: 0.009811
iteration 12721 : loss : 0.019138, loss_ce: 0.005774
iteration 12722 : loss : 0.074737, loss_ce: 0.004668
iteration 12723 : loss : 0.020945, loss_ce: 0.005042
iteration 12724 : loss : 0.018347, loss_ce: 0.006918
iteration 12725 : loss : 0.075987, loss_ce: 0.005153
iteration 12726 : loss : 0.022273, loss_ce: 0.005868
iteration 12727 : loss : 0.075444, loss_ce: 0.007870
iteration 12728 : loss : 0.073613, loss_ce: 0.004993
iteration 12729 : loss : 0.023496, loss_ce: 0.008727
iteration 12730 : loss : 0.081715, loss_ce: 0.004672
iteration 12731 : loss : 0.076265, loss_ce: 0.008548
iteration 12732 : loss : 0.023305, loss_ce: 0.010181
iteration 12733 : loss : 0.024685, loss_ce: 0.007873
iteration 12734 : loss : 0.021374, loss_ce: 0.007007
iteration 12735 : loss : 0.073569, loss_ce: 0.005735
iteration 12736 : loss : 0.021994, loss_ce: 0.008336
iteration 12737 : loss : 0.021766, loss_ce: 0.006335
iteration 12738 : loss : 0.026049, loss_ce: 0.013485
iteration 12739 : loss : 0.023593, loss_ce: 0.010267
iteration 12740 : loss : 0.023380, loss_ce: 0.007095
iteration 12741 : loss : 0.144860, loss_ce: 0.034608
 68%|███████████████████▊         | 137/200 [2:04:23<57:16, 54.55s/it]pred_sum 33548
gtsum tensor(33367, device='cuda:0')
iteration 12742 : loss : 0.026951, loss_ce: 0.006286
iteration 12743 : loss : 0.027329, loss_ce: 0.009556
iteration 12744 : loss : 0.078872, loss_ce: 0.005808
iteration 12745 : loss : 0.022907, loss_ce: 0.006581
iteration 12746 : loss : 0.019269, loss_ce: 0.005240
iteration 12747 : loss : 0.082435, loss_ce: 0.007426
iteration 12748 : loss : 0.022822, loss_ce: 0.010736
iteration 12749 : loss : 0.071846, loss_ce: 0.007257
iteration 12750 : loss : 0.023161, loss_ce: 0.005902
iteration 12751 : loss : 0.018252, loss_ce: 0.006675
iteration 12752 : loss : 0.078386, loss_ce: 0.004799
iteration 12753 : loss : 0.022693, loss_ce: 0.008008
iteration 12754 : loss : 0.022060, loss_ce: 0.005903
iteration 12755 : loss : 0.025671, loss_ce: 0.008909
iteration 12756 : loss : 0.025330, loss_ce: 0.009116
iteration 12757 : loss : 0.026717, loss_ce: 0.010370
iteration 12758 : loss : 0.033958, loss_ce: 0.008711
iteration 12759 : loss : 0.023204, loss_ce: 0.006210
iteration 12760 : loss : 0.023455, loss_ce: 0.010834
iteration 12761 : loss : 0.020612, loss_ce: 0.008616
iteration 12762 : loss : 0.024201, loss_ce: 0.011365
iteration 12763 : loss : 0.025036, loss_ce: 0.008185
iteration 12764 : loss : 0.026090, loss_ce: 0.008277
iteration 12765 : loss : 0.022724, loss_ce: 0.006849
iteration 12766 : loss : 0.020853, loss_ce: 0.007072
iteration 12767 : loss : 0.023893, loss_ce: 0.007678
iteration 12768 : loss : 0.077285, loss_ce: 0.007668
iteration 12769 : loss : 0.079257, loss_ce: 0.006142
iteration 12770 : loss : 0.022123, loss_ce: 0.008500
iteration 12771 : loss : 0.025859, loss_ce: 0.012162
iteration 12772 : loss : 0.019546, loss_ce: 0.007983
pred_sum 13889
gtsum tensor(14212, device='cuda:0')
iteration 12773 : loss : 0.022759, loss_ce: 0.008515
iteration 12774 : loss : 0.023073, loss_ce: 0.006678
iteration 12775 : loss : 0.020461, loss_ce: 0.008506
iteration 12776 : loss : 0.027207, loss_ce: 0.011070
iteration 12777 : loss : 0.025049, loss_ce: 0.009387
iteration 12778 : loss : 0.025983, loss_ce: 0.010193
iteration 12779 : loss : 0.077865, loss_ce: 0.005098
iteration 12780 : loss : 0.073495, loss_ce: 0.006392
iteration 12781 : loss : 0.021312, loss_ce: 0.008992
iteration 12782 : loss : 0.020997, loss_ce: 0.006965
iteration 12783 : loss : 0.019172, loss_ce: 0.006189
iteration 12784 : loss : 0.022641, loss_ce: 0.008989
iteration 12785 : loss : 0.027722, loss_ce: 0.010529
iteration 12786 : loss : 0.023435, loss_ce: 0.009051
iteration 12787 : loss : 0.021138, loss_ce: 0.006338
iteration 12788 : loss : 0.021206, loss_ce: 0.005777
iteration 12789 : loss : 0.022256, loss_ce: 0.007143
iteration 12790 : loss : 0.027840, loss_ce: 0.010762
iteration 12791 : loss : 0.024501, loss_ce: 0.008146
iteration 12792 : loss : 0.024682, loss_ce: 0.007155
iteration 12793 : loss : 0.053998, loss_ce: 0.007813
iteration 12794 : loss : 0.026970, loss_ce: 0.009690
iteration 12795 : loss : 0.025610, loss_ce: 0.008292
iteration 12796 : loss : 0.024214, loss_ce: 0.005108
iteration 12797 : loss : 0.025368, loss_ce: 0.008739
iteration 12798 : loss : 0.024756, loss_ce: 0.010608
iteration 12799 : loss : 0.026575, loss_ce: 0.009224
iteration 12800 : loss : 0.024727, loss_ce: 0.007050
iteration 12801 : loss : 0.024465, loss_ce: 0.009724
iteration 12802 : loss : 0.025377, loss_ce: 0.006739
iteration 12803 : loss : 0.029157, loss_ce: 0.009812
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 12804 : loss : 0.031838, loss_ce: 0.010969
iteration 12805 : loss : 0.042819, loss_ce: 0.007070
iteration 12806 : loss : 0.030082, loss_ce: 0.010946
iteration 12807 : loss : 0.080084, loss_ce: 0.006650
iteration 12808 : loss : 0.029095, loss_ce: 0.012088
iteration 12809 : loss : 0.034632, loss_ce: 0.006390
iteration 12810 : loss : 0.034132, loss_ce: 0.011203
iteration 12811 : loss : 0.027980, loss_ce: 0.006039
iteration 12812 : loss : 0.023452, loss_ce: 0.012777
iteration 12813 : loss : 0.027286, loss_ce: 0.010242
iteration 12814 : loss : 0.076733, loss_ce: 0.009606
iteration 12815 : loss : 0.024364, loss_ce: 0.007225
iteration 12816 : loss : 0.026611, loss_ce: 0.012029
iteration 12817 : loss : 0.024732, loss_ce: 0.007312
iteration 12818 : loss : 0.031529, loss_ce: 0.009689
iteration 12819 : loss : 0.024713, loss_ce: 0.009330
iteration 12820 : loss : 0.033584, loss_ce: 0.012237
iteration 12821 : loss : 0.020231, loss_ce: 0.008162
iteration 12822 : loss : 0.025894, loss_ce: 0.007501
iteration 12823 : loss : 0.026303, loss_ce: 0.007338
iteration 12824 : loss : 0.032270, loss_ce: 0.008718
iteration 12825 : loss : 0.020857, loss_ce: 0.007079
iteration 12826 : loss : 0.026015, loss_ce: 0.006272
iteration 12827 : loss : 0.028815, loss_ce: 0.009841
iteration 12828 : loss : 0.036492, loss_ce: 0.007730
iteration 12829 : loss : 0.021491, loss_ce: 0.009966
iteration 12830 : loss : 0.027671, loss_ce: 0.012812
iteration 12831 : loss : 0.021609, loss_ce: 0.007555
iteration 12832 : loss : 0.027747, loss_ce: 0.008996
iteration 12833 : loss : 0.023920, loss_ce: 0.008553
iteration 12834 : loss : 0.136347, loss_ce: 0.014724
 69%|████████████████████         | 138/200 [2:05:18<56:30, 54.69s/it]pred_sum 3856
gtsum tensor(4577, device='cuda:0')
iteration 12835 : loss : 0.073981, loss_ce: 0.006475
iteration 12836 : loss : 0.029722, loss_ce: 0.009028
iteration 12837 : loss : 0.025178, loss_ce: 0.006587
iteration 12838 : loss : 0.020766, loss_ce: 0.007294
iteration 12839 : loss : 0.025422, loss_ce: 0.008031
iteration 12840 : loss : 0.027377, loss_ce: 0.010555
iteration 12841 : loss : 0.021533, loss_ce: 0.008770
iteration 12842 : loss : 0.026978, loss_ce: 0.007357
iteration 12843 : loss : 0.025808, loss_ce: 0.009331
iteration 12844 : loss : 0.025452, loss_ce: 0.010439
iteration 12845 : loss : 0.021724, loss_ce: 0.007678
iteration 12846 : loss : 0.021936, loss_ce: 0.009927
iteration 12847 : loss : 0.044380, loss_ce: 0.007772
iteration 12848 : loss : 0.072181, loss_ce: 0.005043
iteration 12849 : loss : 0.023929, loss_ce: 0.007414
iteration 12850 : loss : 0.022045, loss_ce: 0.004313
iteration 12851 : loss : 0.027750, loss_ce: 0.010770
iteration 12852 : loss : 0.024927, loss_ce: 0.012238
iteration 12853 : loss : 0.031514, loss_ce: 0.005789
iteration 12854 : loss : 0.019002, loss_ce: 0.008568
iteration 12855 : loss : 0.022124, loss_ce: 0.006061
iteration 12856 : loss : 0.020712, loss_ce: 0.007152
iteration 12857 : loss : 0.074702, loss_ce: 0.006848
iteration 12858 : loss : 0.022456, loss_ce: 0.009179
iteration 12859 : loss : 0.026588, loss_ce: 0.006671
iteration 12860 : loss : 0.028357, loss_ce: 0.005728
iteration 12861 : loss : 0.021138, loss_ce: 0.007191
iteration 12862 : loss : 0.022180, loss_ce: 0.008076
iteration 12863 : loss : 0.080190, loss_ce: 0.011500
iteration 12864 : loss : 0.023232, loss_ce: 0.007184
iteration 12865 : loss : 0.019674, loss_ce: 0.009643
pred_sum 40836
gtsum tensor(40545, device='cuda:0')
iteration 12866 : loss : 0.033361, loss_ce: 0.011653
iteration 12867 : loss : 0.085384, loss_ce: 0.007452
iteration 12868 : loss : 0.073322, loss_ce: 0.007011
iteration 12869 : loss : 0.028635, loss_ce: 0.007109
iteration 12870 : loss : 0.024741, loss_ce: 0.009113
iteration 12871 : loss : 0.075183, loss_ce: 0.005740
iteration 12872 : loss : 0.023654, loss_ce: 0.007646
iteration 12873 : loss : 0.022456, loss_ce: 0.008365
iteration 12874 : loss : 0.022721, loss_ce: 0.008257
iteration 12875 : loss : 0.070755, loss_ce: 0.005762
iteration 12876 : loss : 0.024088, loss_ce: 0.005249
iteration 12877 : loss : 0.026391, loss_ce: 0.008523
iteration 12878 : loss : 0.026144, loss_ce: 0.008867
iteration 12879 : loss : 0.021309, loss_ce: 0.006812
iteration 12880 : loss : 0.019503, loss_ce: 0.007704
iteration 12881 : loss : 0.025091, loss_ce: 0.009801
iteration 12882 : loss : 0.023764, loss_ce: 0.008603
iteration 12883 : loss : 0.077072, loss_ce: 0.006546
iteration 12884 : loss : 0.020982, loss_ce: 0.006164
iteration 12885 : loss : 0.024548, loss_ce: 0.007984
iteration 12886 : loss : 0.023313, loss_ce: 0.008120
iteration 12887 : loss : 0.027880, loss_ce: 0.009389
iteration 12888 : loss : 0.023922, loss_ce: 0.006313
iteration 12889 : loss : 0.026155, loss_ce: 0.010531
iteration 12890 : loss : 0.025178, loss_ce: 0.009171
iteration 12891 : loss : 0.026185, loss_ce: 0.006815
iteration 12892 : loss : 0.022199, loss_ce: 0.008108
iteration 12893 : loss : 0.023057, loss_ce: 0.008812
iteration 12894 : loss : 0.025354, loss_ce: 0.010348
iteration 12895 : loss : 0.025386, loss_ce: 0.008127
iteration 12896 : loss : 0.024869, loss_ce: 0.007549
pred_sum 8409
gtsum tensor(8347, device='cuda:0')
iteration 12897 : loss : 0.028651, loss_ce: 0.009943
iteration 12898 : loss : 0.022828, loss_ce: 0.012005
iteration 12899 : loss : 0.025219, loss_ce: 0.011874
iteration 12900 : loss : 0.025773, loss_ce: 0.008008
iteration 12901 : loss : 0.028350, loss_ce: 0.012004
iteration 12902 : loss : 0.021812, loss_ce: 0.005673
iteration 12903 : loss : 0.025431, loss_ce: 0.009326
iteration 12904 : loss : 0.045678, loss_ce: 0.008399
iteration 12905 : loss : 0.026865, loss_ce: 0.012039
iteration 12906 : loss : 0.023996, loss_ce: 0.007920
iteration 12907 : loss : 0.027971, loss_ce: 0.008983
iteration 12908 : loss : 0.037044, loss_ce: 0.010017
iteration 12909 : loss : 0.027461, loss_ce: 0.010085
iteration 12910 : loss : 0.021504, loss_ce: 0.007028
iteration 12911 : loss : 0.019536, loss_ce: 0.005385
iteration 12912 : loss : 0.024924, loss_ce: 0.008434
iteration 12913 : loss : 0.023652, loss_ce: 0.006844
iteration 12914 : loss : 0.030175, loss_ce: 0.011309
iteration 12915 : loss : 0.027814, loss_ce: 0.008669
iteration 12916 : loss : 0.025821, loss_ce: 0.011373
iteration 12917 : loss : 0.023316, loss_ce: 0.008657
iteration 12918 : loss : 0.020500, loss_ce: 0.006629
iteration 12919 : loss : 0.020273, loss_ce: 0.006291
iteration 12920 : loss : 0.023495, loss_ce: 0.010177
iteration 12921 : loss : 0.028097, loss_ce: 0.010351
iteration 12922 : loss : 0.024887, loss_ce: 0.009348
iteration 12923 : loss : 0.020940, loss_ce: 0.004322
iteration 12924 : loss : 0.037218, loss_ce: 0.007807
iteration 12925 : loss : 0.024107, loss_ce: 0.006942
iteration 12926 : loss : 0.019641, loss_ce: 0.005816
iteration 12927 : loss : 0.058769, loss_ce: 0.011274
 70%|████████████████████▏        | 139/200 [2:06:13<55:39, 54.74s/it]pred_sum 35327
gtsum tensor(36581, device='cuda:0')
iteration 12928 : loss : 0.019815, loss_ce: 0.007435
iteration 12929 : loss : 0.026466, loss_ce: 0.011498
iteration 12930 : loss : 0.029273, loss_ce: 0.004570
iteration 12931 : loss : 0.022068, loss_ce: 0.007680
iteration 12932 : loss : 0.023398, loss_ce: 0.009218
iteration 12933 : loss : 0.023600, loss_ce: 0.008809
iteration 12934 : loss : 0.029441, loss_ce: 0.013854
iteration 12935 : loss : 0.022696, loss_ce: 0.009669
iteration 12936 : loss : 0.026079, loss_ce: 0.011794
iteration 12937 : loss : 0.027075, loss_ce: 0.008578
iteration 12938 : loss : 0.024847, loss_ce: 0.009004
iteration 12939 : loss : 0.025509, loss_ce: 0.008854
iteration 12940 : loss : 0.034266, loss_ce: 0.010802
iteration 12941 : loss : 0.041793, loss_ce: 0.013286
iteration 12942 : loss : 0.023953, loss_ce: 0.011577
iteration 12943 : loss : 0.027095, loss_ce: 0.009231
iteration 12944 : loss : 0.025366, loss_ce: 0.009609
iteration 12945 : loss : 0.022801, loss_ce: 0.006850
iteration 12946 : loss : 0.025707, loss_ce: 0.008723
iteration 12947 : loss : 0.022691, loss_ce: 0.006074
iteration 12948 : loss : 0.023932, loss_ce: 0.006785
iteration 12949 : loss : 0.021825, loss_ce: 0.006707
iteration 12950 : loss : 0.024111, loss_ce: 0.008215
iteration 12951 : loss : 0.021109, loss_ce: 0.006764
iteration 12952 : loss : 0.025606, loss_ce: 0.005980
iteration 12953 : loss : 0.019421, loss_ce: 0.007529
iteration 12954 : loss : 0.026176, loss_ce: 0.012994
iteration 12955 : loss : 0.076188, loss_ce: 0.007677
iteration 12956 : loss : 0.028313, loss_ce: 0.013012
iteration 12957 : loss : 0.025504, loss_ce: 0.012231
iteration 12958 : loss : 0.075406, loss_ce: 0.008128
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 12959 : loss : 0.028696, loss_ce: 0.009287
iteration 12960 : loss : 0.024286, loss_ce: 0.008416
iteration 12961 : loss : 0.020883, loss_ce: 0.006014
iteration 12962 : loss : 0.029072, loss_ce: 0.012551
iteration 12963 : loss : 0.076655, loss_ce: 0.009453
iteration 12964 : loss : 0.023579, loss_ce: 0.005910
iteration 12965 : loss : 0.029227, loss_ce: 0.007692
iteration 12966 : loss : 0.024575, loss_ce: 0.007836
iteration 12967 : loss : 0.030788, loss_ce: 0.008869
iteration 12968 : loss : 0.021645, loss_ce: 0.006642
iteration 12969 : loss : 0.023722, loss_ce: 0.008584
iteration 12970 : loss : 0.022630, loss_ce: 0.005663
iteration 12971 : loss : 0.025535, loss_ce: 0.006082
iteration 12972 : loss : 0.023346, loss_ce: 0.005918
iteration 12973 : loss : 0.028095, loss_ce: 0.009100
iteration 12974 : loss : 0.029755, loss_ce: 0.003805
iteration 12975 : loss : 0.023586, loss_ce: 0.009897
iteration 12976 : loss : 0.028263, loss_ce: 0.009401
iteration 12977 : loss : 0.022511, loss_ce: 0.008332
iteration 12978 : loss : 0.037303, loss_ce: 0.007579
iteration 12979 : loss : 0.022345, loss_ce: 0.008608
iteration 12980 : loss : 0.023400, loss_ce: 0.007775
iteration 12981 : loss : 0.028128, loss_ce: 0.009176
iteration 12982 : loss : 0.076204, loss_ce: 0.003789
iteration 12983 : loss : 0.022691, loss_ce: 0.007775
iteration 12984 : loss : 0.024940, loss_ce: 0.009601
iteration 12985 : loss : 0.026566, loss_ce: 0.011813
iteration 12986 : loss : 0.043892, loss_ce: 0.006589
iteration 12987 : loss : 0.023024, loss_ce: 0.009067
iteration 12988 : loss : 0.073345, loss_ce: 0.005060
iteration 12989 : loss : 0.026419, loss_ce: 0.009046
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 12990 : loss : 0.023292, loss_ce: 0.007600
iteration 12991 : loss : 0.022574, loss_ce: 0.007888
iteration 12992 : loss : 0.030922, loss_ce: 0.009441
iteration 12993 : loss : 0.027582, loss_ce: 0.009499
iteration 12994 : loss : 0.026404, loss_ce: 0.005449
iteration 12995 : loss : 0.026752, loss_ce: 0.010286
iteration 12996 : loss : 0.029856, loss_ce: 0.005689
iteration 12997 : loss : 0.023526, loss_ce: 0.010855
iteration 12998 : loss : 0.021538, loss_ce: 0.007225
iteration 12999 : loss : 0.028540, loss_ce: 0.007705
iteration 13000 : loss : 0.023443, loss_ce: 0.010647
iteration 13001 : loss : 0.026814, loss_ce: 0.011230
iteration 13002 : loss : 0.043119, loss_ce: 0.009277
iteration 13003 : loss : 0.076347, loss_ce: 0.007617
iteration 13004 : loss : 0.021255, loss_ce: 0.006072
iteration 13005 : loss : 0.025477, loss_ce: 0.009602
iteration 13006 : loss : 0.022298, loss_ce: 0.005043
iteration 13007 : loss : 0.024193, loss_ce: 0.009450
iteration 13008 : loss : 0.025718, loss_ce: 0.008520
iteration 13009 : loss : 0.025781, loss_ce: 0.008766
iteration 13010 : loss : 0.024077, loss_ce: 0.009874
iteration 13011 : loss : 0.027035, loss_ce: 0.012094
iteration 13012 : loss : 0.026152, loss_ce: 0.004705
iteration 13013 : loss : 0.023815, loss_ce: 0.009741
iteration 13014 : loss : 0.027265, loss_ce: 0.009793
iteration 13015 : loss : 0.021719, loss_ce: 0.006264
iteration 13016 : loss : 0.029405, loss_ce: 0.009636
iteration 13017 : loss : 0.034218, loss_ce: 0.010512
iteration 13018 : loss : 0.023328, loss_ce: 0.005203
iteration 13019 : loss : 0.022924, loss_ce: 0.006442
iteration 13020 : loss : 0.140577, loss_ce: 0.013710
 70%|████████████████████▎        | 140/200 [2:07:07<54:40, 54.67s/it]pred_sum 36793
gtsum tensor(37029, device='cuda:0')
iteration 13021 : loss : 0.022231, loss_ce: 0.006552
iteration 13022 : loss : 0.025555, loss_ce: 0.010428
iteration 13023 : loss : 0.025934, loss_ce: 0.013953
iteration 13024 : loss : 0.021244, loss_ce: 0.003914
iteration 13025 : loss : 0.027656, loss_ce: 0.006498
iteration 13026 : loss : 0.023600, loss_ce: 0.007405
iteration 13027 : loss : 0.032792, loss_ce: 0.007727
iteration 13028 : loss : 0.020815, loss_ce: 0.009091
iteration 13029 : loss : 0.042242, loss_ce: 0.012246
iteration 13030 : loss : 0.022980, loss_ce: 0.005571
iteration 13031 : loss : 0.021321, loss_ce: 0.008610
iteration 13032 : loss : 0.030627, loss_ce: 0.011697
iteration 13033 : loss : 0.025670, loss_ce: 0.008150
iteration 13034 : loss : 0.026708, loss_ce: 0.008089
iteration 13035 : loss : 0.027665, loss_ce: 0.012597
iteration 13036 : loss : 0.022645, loss_ce: 0.005303
iteration 13037 : loss : 0.023761, loss_ce: 0.009993
iteration 13038 : loss : 0.024948, loss_ce: 0.006185
iteration 13039 : loss : 0.019639, loss_ce: 0.008291
iteration 13040 : loss : 0.024715, loss_ce: 0.007583
iteration 13041 : loss : 0.018711, loss_ce: 0.002544
iteration 13042 : loss : 0.025652, loss_ce: 0.011679
iteration 13043 : loss : 0.023129, loss_ce: 0.009437
iteration 13044 : loss : 0.025704, loss_ce: 0.008807
iteration 13045 : loss : 0.023900, loss_ce: 0.008833
iteration 13046 : loss : 0.019004, loss_ce: 0.006731
iteration 13047 : loss : 0.023050, loss_ce: 0.007194
iteration 13048 : loss : 0.022467, loss_ce: 0.009015
iteration 13049 : loss : 0.026939, loss_ce: 0.007994
iteration 13050 : loss : 0.023732, loss_ce: 0.010631
iteration 13051 : loss : 0.023753, loss_ce: 0.008688
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 13052 : loss : 0.025517, loss_ce: 0.007422
iteration 13053 : loss : 0.022364, loss_ce: 0.005527
iteration 13054 : loss : 0.026754, loss_ce: 0.007805
iteration 13055 : loss : 0.023870, loss_ce: 0.007419
iteration 13056 : loss : 0.023267, loss_ce: 0.007210
iteration 13057 : loss : 0.020500, loss_ce: 0.009171
iteration 13058 : loss : 0.028253, loss_ce: 0.010578
iteration 13059 : loss : 0.075538, loss_ce: 0.007166
iteration 13060 : loss : 0.027460, loss_ce: 0.008685
iteration 13061 : loss : 0.021746, loss_ce: 0.009087
iteration 13062 : loss : 0.025171, loss_ce: 0.009595
iteration 13063 : loss : 0.024549, loss_ce: 0.005048
iteration 13064 : loss : 0.022955, loss_ce: 0.007585
iteration 13065 : loss : 0.030742, loss_ce: 0.007738
iteration 13066 : loss : 0.023762, loss_ce: 0.007503
iteration 13067 : loss : 0.024563, loss_ce: 0.009926
iteration 13068 : loss : 0.021239, loss_ce: 0.009092
iteration 13069 : loss : 0.022926, loss_ce: 0.007186
iteration 13070 : loss : 0.028769, loss_ce: 0.009485
iteration 13071 : loss : 0.019580, loss_ce: 0.007907
iteration 13072 : loss : 0.073860, loss_ce: 0.006118
iteration 13073 : loss : 0.020726, loss_ce: 0.007328
iteration 13074 : loss : 0.022273, loss_ce: 0.006237
iteration 13075 : loss : 0.019569, loss_ce: 0.005425
iteration 13076 : loss : 0.024590, loss_ce: 0.007985
iteration 13077 : loss : 0.023584, loss_ce: 0.005615
iteration 13078 : loss : 0.027812, loss_ce: 0.010775
iteration 13079 : loss : 0.026557, loss_ce: 0.007238
iteration 13080 : loss : 0.023765, loss_ce: 0.006835
iteration 13081 : loss : 0.021248, loss_ce: 0.007999
iteration 13082 : loss : 0.023130, loss_ce: 0.009713
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 13083 : loss : 0.025360, loss_ce: 0.010044
iteration 13084 : loss : 0.023458, loss_ce: 0.008129
iteration 13085 : loss : 0.033566, loss_ce: 0.009716
iteration 13086 : loss : 0.024038, loss_ce: 0.008031
iteration 13087 : loss : 0.025243, loss_ce: 0.008078
iteration 13088 : loss : 0.022389, loss_ce: 0.008046
iteration 13089 : loss : 0.024563, loss_ce: 0.007386
iteration 13090 : loss : 0.027471, loss_ce: 0.009116
iteration 13091 : loss : 0.026110, loss_ce: 0.007992
iteration 13092 : loss : 0.023377, loss_ce: 0.007484
iteration 13093 : loss : 0.024074, loss_ce: 0.009057
iteration 13094 : loss : 0.025761, loss_ce: 0.012556
iteration 13095 : loss : 0.076181, loss_ce: 0.006958
iteration 13096 : loss : 0.022272, loss_ce: 0.007869
iteration 13097 : loss : 0.027482, loss_ce: 0.005759
iteration 13098 : loss : 0.020169, loss_ce: 0.005602
iteration 13099 : loss : 0.020393, loss_ce: 0.005313
iteration 13100 : loss : 0.022013, loss_ce: 0.006498
iteration 13101 : loss : 0.022695, loss_ce: 0.008758
iteration 13102 : loss : 0.074144, loss_ce: 0.007562
iteration 13103 : loss : 0.074246, loss_ce: 0.005688
iteration 13104 : loss : 0.022641, loss_ce: 0.009851
iteration 13105 : loss : 0.023122, loss_ce: 0.007801
iteration 13106 : loss : 0.020255, loss_ce: 0.006530
iteration 13107 : loss : 0.084716, loss_ce: 0.007302
iteration 13108 : loss : 0.025881, loss_ce: 0.008158
iteration 13109 : loss : 0.025378, loss_ce: 0.005625
iteration 13110 : loss : 0.074843, loss_ce: 0.011732
iteration 13111 : loss : 0.022238, loss_ce: 0.010224
iteration 13112 : loss : 0.022576, loss_ce: 0.010241
iteration 13113 : loss : 0.232760, loss_ce: 0.005519
 70%|████████████████████▍        | 141/200 [2:08:02<53:42, 54.62s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 13114 : loss : 0.020175, loss_ce: 0.007488
iteration 13115 : loss : 0.028620, loss_ce: 0.011121
iteration 13116 : loss : 0.022543, loss_ce: 0.007788
iteration 13117 : loss : 0.022603, loss_ce: 0.005666
iteration 13118 : loss : 0.023232, loss_ce: 0.009641
iteration 13119 : loss : 0.024954, loss_ce: 0.007088
iteration 13120 : loss : 0.023387, loss_ce: 0.008617
iteration 13121 : loss : 0.020316, loss_ce: 0.004938
iteration 13122 : loss : 0.026607, loss_ce: 0.005277
iteration 13123 : loss : 0.023948, loss_ce: 0.006733
iteration 13124 : loss : 0.021135, loss_ce: 0.007447
iteration 13125 : loss : 0.074383, loss_ce: 0.006464
iteration 13126 : loss : 0.024689, loss_ce: 0.008273
iteration 13127 : loss : 0.024125, loss_ce: 0.008674
iteration 13128 : loss : 0.074248, loss_ce: 0.006323
iteration 13129 : loss : 0.023094, loss_ce: 0.008236
iteration 13130 : loss : 0.077004, loss_ce: 0.009847
iteration 13131 : loss : 0.026820, loss_ce: 0.009709
iteration 13132 : loss : 0.017646, loss_ce: 0.003088
iteration 13133 : loss : 0.024921, loss_ce: 0.006516
iteration 13134 : loss : 0.020030, loss_ce: 0.007571
iteration 13135 : loss : 0.023837, loss_ce: 0.008587
iteration 13136 : loss : 0.041117, loss_ce: 0.010099
iteration 13137 : loss : 0.027287, loss_ce: 0.009689
iteration 13138 : loss : 0.026513, loss_ce: 0.009863
iteration 13139 : loss : 0.026296, loss_ce: 0.008898
iteration 13140 : loss : 0.019825, loss_ce: 0.006158
iteration 13141 : loss : 0.023483, loss_ce: 0.006824
iteration 13142 : loss : 0.022883, loss_ce: 0.006513
iteration 13143 : loss : 0.024303, loss_ce: 0.004791
iteration 13144 : loss : 0.030826, loss_ce: 0.007796
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 13145 : loss : 0.022469, loss_ce: 0.007299
iteration 13146 : loss : 0.020651, loss_ce: 0.009502
iteration 13147 : loss : 0.019818, loss_ce: 0.008092
iteration 13148 : loss : 0.025232, loss_ce: 0.008693
iteration 13149 : loss : 0.028741, loss_ce: 0.006137
iteration 13150 : loss : 0.020260, loss_ce: 0.007999
iteration 13151 : loss : 0.024750, loss_ce: 0.012936
iteration 13152 : loss : 0.027878, loss_ce: 0.009489
iteration 13153 : loss : 0.020968, loss_ce: 0.007944
iteration 13154 : loss : 0.022493, loss_ce: 0.008656
iteration 13155 : loss : 0.024611, loss_ce: 0.007392
iteration 13156 : loss : 0.023295, loss_ce: 0.005245
iteration 13157 : loss : 0.019086, loss_ce: 0.006101
iteration 13158 : loss : 0.028733, loss_ce: 0.009016
iteration 13159 : loss : 0.022431, loss_ce: 0.008386
iteration 13160 : loss : 0.026690, loss_ce: 0.007561
iteration 13161 : loss : 0.022016, loss_ce: 0.009400
iteration 13162 : loss : 0.025695, loss_ce: 0.007861
iteration 13163 : loss : 0.028981, loss_ce: 0.006347
iteration 13164 : loss : 0.022488, loss_ce: 0.010814
iteration 13165 : loss : 0.023541, loss_ce: 0.008025
iteration 13166 : loss : 0.024343, loss_ce: 0.006694
iteration 13167 : loss : 0.025275, loss_ce: 0.008212
iteration 13168 : loss : 0.023517, loss_ce: 0.012004
iteration 13169 : loss : 0.046497, loss_ce: 0.009820
iteration 13170 : loss : 0.075355, loss_ce: 0.006217
iteration 13171 : loss : 0.021888, loss_ce: 0.005059
iteration 13172 : loss : 0.021333, loss_ce: 0.007120
iteration 13173 : loss : 0.085265, loss_ce: 0.006419
iteration 13174 : loss : 0.030241, loss_ce: 0.011951
iteration 13175 : loss : 0.028309, loss_ce: 0.010668
pred_sum 197
gtsum tensor(198, device='cuda:0')
iteration 13176 : loss : 0.026380, loss_ce: 0.012975
iteration 13177 : loss : 0.028413, loss_ce: 0.008801
iteration 13178 : loss : 0.031379, loss_ce: 0.013500
iteration 13179 : loss : 0.033793, loss_ce: 0.014731
iteration 13180 : loss : 0.091959, loss_ce: 0.010295
iteration 13181 : loss : 0.030156, loss_ce: 0.011808
iteration 13182 : loss : 0.029343, loss_ce: 0.006229
iteration 13183 : loss : 0.025818, loss_ce: 0.006622
iteration 13184 : loss : 0.025555, loss_ce: 0.009690
iteration 13185 : loss : 0.025965, loss_ce: 0.009787
iteration 13186 : loss : 0.029263, loss_ce: 0.011280
iteration 13187 : loss : 0.021136, loss_ce: 0.005447
iteration 13188 : loss : 0.029724, loss_ce: 0.009660
iteration 13189 : loss : 0.023378, loss_ce: 0.008804
iteration 13190 : loss : 0.023393, loss_ce: 0.008237
iteration 13191 : loss : 0.020052, loss_ce: 0.006290
iteration 13192 : loss : 0.034666, loss_ce: 0.009988
iteration 13193 : loss : 0.025906, loss_ce: 0.008019
iteration 13194 : loss : 0.025786, loss_ce: 0.010456
iteration 13195 : loss : 0.029449, loss_ce: 0.010092
iteration 13196 : loss : 0.029826, loss_ce: 0.009336
iteration 13197 : loss : 0.033665, loss_ce: 0.005968
iteration 13198 : loss : 0.023569, loss_ce: 0.006895
iteration 13199 : loss : 0.027219, loss_ce: 0.010754
iteration 13200 : loss : 0.025301, loss_ce: 0.009067
iteration 13201 : loss : 0.079102, loss_ce: 0.004756
iteration 13202 : loss : 0.025823, loss_ce: 0.008602
iteration 13203 : loss : 0.023763, loss_ce: 0.008914
iteration 13204 : loss : 0.027402, loss_ce: 0.006370
iteration 13205 : loss : 0.023730, loss_ce: 0.005232
iteration 13206 : loss : 0.036776, loss_ce: 0.029009
 71%|████████████████████▌        | 142/200 [2:08:57<52:46, 54.60s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 13207 : loss : 0.027765, loss_ce: 0.014678
iteration 13208 : loss : 0.025663, loss_ce: 0.010942
iteration 13209 : loss : 0.042511, loss_ce: 0.009356
iteration 13210 : loss : 0.074047, loss_ce: 0.010243
iteration 13211 : loss : 0.022529, loss_ce: 0.009672
iteration 13212 : loss : 0.045412, loss_ce: 0.010768
iteration 13213 : loss : 0.026913, loss_ce: 0.008734
iteration 13214 : loss : 0.024831, loss_ce: 0.006982
iteration 13215 : loss : 0.024403, loss_ce: 0.007320
iteration 13216 : loss : 0.076461, loss_ce: 0.005865
iteration 13217 : loss : 0.023128, loss_ce: 0.007062
iteration 13218 : loss : 0.028566, loss_ce: 0.008813
iteration 13219 : loss : 0.020301, loss_ce: 0.003858
iteration 13220 : loss : 0.025894, loss_ce: 0.010787
iteration 13221 : loss : 0.022059, loss_ce: 0.006335
iteration 13222 : loss : 0.028204, loss_ce: 0.008901
iteration 13223 : loss : 0.028004, loss_ce: 0.012217
iteration 13224 : loss : 0.030549, loss_ce: 0.006122
iteration 13225 : loss : 0.026346, loss_ce: 0.005975
iteration 13226 : loss : 0.025273, loss_ce: 0.009844
iteration 13227 : loss : 0.023179, loss_ce: 0.005534
iteration 13228 : loss : 0.075898, loss_ce: 0.008304
iteration 13229 : loss : 0.023184, loss_ce: 0.008894
iteration 13230 : loss : 0.077594, loss_ce: 0.008214
iteration 13231 : loss : 0.025227, loss_ce: 0.009822
iteration 13232 : loss : 0.030151, loss_ce: 0.010499
iteration 13233 : loss : 0.025064, loss_ce: 0.008441
iteration 13234 : loss : 0.023564, loss_ce: 0.004222
iteration 13235 : loss : 0.024638, loss_ce: 0.012215
iteration 13236 : loss : 0.029582, loss_ce: 0.010341
iteration 13237 : loss : 0.023418, loss_ce: 0.006012
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 13238 : loss : 0.029319, loss_ce: 0.010838
iteration 13239 : loss : 0.025041, loss_ce: 0.012195
iteration 13240 : loss : 0.023973, loss_ce: 0.009746
iteration 13241 : loss : 0.034694, loss_ce: 0.004777
iteration 13242 : loss : 0.024341, loss_ce: 0.006361
iteration 13243 : loss : 0.024136, loss_ce: 0.008478
iteration 13244 : loss : 0.039105, loss_ce: 0.011751
iteration 13245 : loss : 0.025593, loss_ce: 0.007534
iteration 13246 : loss : 0.024096, loss_ce: 0.009325
iteration 13247 : loss : 0.021942, loss_ce: 0.007117
iteration 13248 : loss : 0.075500, loss_ce: 0.009755
iteration 13249 : loss : 0.086626, loss_ce: 0.007396
iteration 13250 : loss : 0.021915, loss_ce: 0.007622
iteration 13251 : loss : 0.023721, loss_ce: 0.007609
iteration 13252 : loss : 0.023848, loss_ce: 0.004845
iteration 13253 : loss : 0.022954, loss_ce: 0.006677
iteration 13254 : loss : 0.022228, loss_ce: 0.009680
iteration 13255 : loss : 0.023809, loss_ce: 0.005305
iteration 13256 : loss : 0.025702, loss_ce: 0.008167
iteration 13257 : loss : 0.022978, loss_ce: 0.006739
iteration 13258 : loss : 0.023838, loss_ce: 0.008241
iteration 13259 : loss : 0.022911, loss_ce: 0.009490
iteration 13260 : loss : 0.021686, loss_ce: 0.006925
iteration 13261 : loss : 0.021764, loss_ce: 0.007743
iteration 13262 : loss : 0.024759, loss_ce: 0.005127
iteration 13263 : loss : 0.024614, loss_ce: 0.006518
iteration 13264 : loss : 0.020102, loss_ce: 0.006341
iteration 13265 : loss : 0.024242, loss_ce: 0.008030
iteration 13266 : loss : 0.033353, loss_ce: 0.005412
iteration 13267 : loss : 0.028122, loss_ce: 0.010838
iteration 13268 : loss : 0.025831, loss_ce: 0.006226
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 13269 : loss : 0.077283, loss_ce: 0.004985
iteration 13270 : loss : 0.078143, loss_ce: 0.006718
iteration 13271 : loss : 0.020903, loss_ce: 0.006244
iteration 13272 : loss : 0.023013, loss_ce: 0.007473
iteration 13273 : loss : 0.019570, loss_ce: 0.008674
iteration 13274 : loss : 0.024831, loss_ce: 0.008919
iteration 13275 : loss : 0.035458, loss_ce: 0.010410
iteration 13276 : loss : 0.024055, loss_ce: 0.010598
iteration 13277 : loss : 0.029287, loss_ce: 0.005689
iteration 13278 : loss : 0.021926, loss_ce: 0.007969
iteration 13279 : loss : 0.023562, loss_ce: 0.008565
iteration 13280 : loss : 0.023908, loss_ce: 0.005424
iteration 13281 : loss : 0.023749, loss_ce: 0.009128
iteration 13282 : loss : 0.025880, loss_ce: 0.006976
iteration 13283 : loss : 0.022693, loss_ce: 0.009419
iteration 13284 : loss : 0.023104, loss_ce: 0.009203
iteration 13285 : loss : 0.026171, loss_ce: 0.009159
iteration 13286 : loss : 0.019282, loss_ce: 0.004967
iteration 13287 : loss : 0.022190, loss_ce: 0.008357
iteration 13288 : loss : 0.023264, loss_ce: 0.009996
iteration 13289 : loss : 0.024497, loss_ce: 0.009233
iteration 13290 : loss : 0.035592, loss_ce: 0.008264
iteration 13291 : loss : 0.026355, loss_ce: 0.008449
iteration 13292 : loss : 0.024373, loss_ce: 0.008195
iteration 13293 : loss : 0.041677, loss_ce: 0.009984
iteration 13294 : loss : 0.027755, loss_ce: 0.009306
iteration 13295 : loss : 0.026389, loss_ce: 0.010442
iteration 13296 : loss : 0.020358, loss_ce: 0.007212
iteration 13297 : loss : 0.022287, loss_ce: 0.007661
iteration 13298 : loss : 0.019471, loss_ce: 0.007347
iteration 13299 : loss : 0.337007, loss_ce: 0.004330
 72%|████████████████████▋        | 143/200 [2:09:51<51:51, 54.59s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 13300 : loss : 0.029240, loss_ce: 0.008599
iteration 13301 : loss : 0.025285, loss_ce: 0.008959
iteration 13302 : loss : 0.025314, loss_ce: 0.007066
iteration 13303 : loss : 0.023268, loss_ce: 0.007693
iteration 13304 : loss : 0.026238, loss_ce: 0.011726
iteration 13305 : loss : 0.024092, loss_ce: 0.006167
iteration 13306 : loss : 0.024214, loss_ce: 0.007507
iteration 13307 : loss : 0.020758, loss_ce: 0.008920
iteration 13308 : loss : 0.022784, loss_ce: 0.007270
iteration 13309 : loss : 0.028591, loss_ce: 0.007209
iteration 13310 : loss : 0.021937, loss_ce: 0.010342
iteration 13311 : loss : 0.020730, loss_ce: 0.006714
iteration 13312 : loss : 0.022713, loss_ce: 0.008297
iteration 13313 : loss : 0.039388, loss_ce: 0.005771
iteration 13314 : loss : 0.026044, loss_ce: 0.007237
iteration 13315 : loss : 0.022135, loss_ce: 0.007001
iteration 13316 : loss : 0.026191, loss_ce: 0.006093
iteration 13317 : loss : 0.026069, loss_ce: 0.012560
iteration 13318 : loss : 0.022970, loss_ce: 0.007445
iteration 13319 : loss : 0.023186, loss_ce: 0.008041
iteration 13320 : loss : 0.024927, loss_ce: 0.012230
iteration 13321 : loss : 0.026282, loss_ce: 0.008309
iteration 13322 : loss : 0.018288, loss_ce: 0.005690
iteration 13323 : loss : 0.028839, loss_ce: 0.007294
iteration 13324 : loss : 0.026222, loss_ce: 0.006490
iteration 13325 : loss : 0.021412, loss_ce: 0.009038
iteration 13326 : loss : 0.021968, loss_ce: 0.010053
iteration 13327 : loss : 0.031359, loss_ce: 0.012015
iteration 13328 : loss : 0.024815, loss_ce: 0.007723
iteration 13329 : loss : 0.020363, loss_ce: 0.008124
iteration 13330 : loss : 0.025079, loss_ce: 0.011319
pred_sum 28809
gtsum tensor(27789, device='cuda:0')
iteration 13331 : loss : 0.022829, loss_ce: 0.009652
iteration 13332 : loss : 0.029877, loss_ce: 0.006257
iteration 13333 : loss : 0.024321, loss_ce: 0.011800
iteration 13334 : loss : 0.022610, loss_ce: 0.007626
iteration 13335 : loss : 0.026754, loss_ce: 0.006287
iteration 13336 : loss : 0.022900, loss_ce: 0.004029
iteration 13337 : loss : 0.031521, loss_ce: 0.007348
iteration 13338 : loss : 0.025757, loss_ce: 0.008216
iteration 13339 : loss : 0.027417, loss_ce: 0.003062
iteration 13340 : loss : 0.029025, loss_ce: 0.012055
iteration 13341 : loss : 0.023712, loss_ce: 0.009036
iteration 13342 : loss : 0.023804, loss_ce: 0.006132
iteration 13343 : loss : 0.026171, loss_ce: 0.006247
iteration 13344 : loss : 0.023599, loss_ce: 0.008018
iteration 13345 : loss : 0.022313, loss_ce: 0.008196
iteration 13346 : loss : 0.078195, loss_ce: 0.008885
iteration 13347 : loss : 0.020757, loss_ce: 0.008401
iteration 13348 : loss : 0.023582, loss_ce: 0.009772
iteration 13349 : loss : 0.023700, loss_ce: 0.007873
iteration 13350 : loss : 0.036714, loss_ce: 0.008263
iteration 13351 : loss : 0.022152, loss_ce: 0.006386
iteration 13352 : loss : 0.028220, loss_ce: 0.008983
iteration 13353 : loss : 0.077989, loss_ce: 0.003797
iteration 13354 : loss : 0.019732, loss_ce: 0.004371
iteration 13355 : loss : 0.022854, loss_ce: 0.009521
iteration 13356 : loss : 0.024725, loss_ce: 0.012765
iteration 13357 : loss : 0.029668, loss_ce: 0.008422
iteration 13358 : loss : 0.025024, loss_ce: 0.006616
iteration 13359 : loss : 0.021069, loss_ce: 0.008906
iteration 13360 : loss : 0.024536, loss_ce: 0.010465
iteration 13361 : loss : 0.028875, loss_ce: 0.013171
pred_sum 19065
gtsum tensor(19399, device='cuda:0')
iteration 13362 : loss : 0.022919, loss_ce: 0.007507
iteration 13363 : loss : 0.024584, loss_ce: 0.006451
iteration 13364 : loss : 0.024899, loss_ce: 0.011549
iteration 13365 : loss : 0.074391, loss_ce: 0.004274
iteration 13366 : loss : 0.023856, loss_ce: 0.008104
iteration 13367 : loss : 0.024338, loss_ce: 0.012556
iteration 13368 : loss : 0.022292, loss_ce: 0.007847
iteration 13369 : loss : 0.022798, loss_ce: 0.009387
iteration 13370 : loss : 0.020909, loss_ce: 0.009791
iteration 13371 : loss : 0.023458, loss_ce: 0.006895
iteration 13372 : loss : 0.073309, loss_ce: 0.006399
iteration 13373 : loss : 0.021933, loss_ce: 0.007818
iteration 13374 : loss : 0.024288, loss_ce: 0.010805
iteration 13375 : loss : 0.022449, loss_ce: 0.010201
iteration 13376 : loss : 0.024021, loss_ce: 0.004278
iteration 13377 : loss : 0.022394, loss_ce: 0.006401
iteration 13378 : loss : 0.031026, loss_ce: 0.005267
iteration 13379 : loss : 0.023280, loss_ce: 0.005847
iteration 13380 : loss : 0.027053, loss_ce: 0.008360
iteration 13381 : loss : 0.022973, loss_ce: 0.009495
iteration 13382 : loss : 0.023133, loss_ce: 0.004311
iteration 13383 : loss : 0.046033, loss_ce: 0.011046
iteration 13384 : loss : 0.028688, loss_ce: 0.008666
iteration 13385 : loss : 0.021111, loss_ce: 0.008172
iteration 13386 : loss : 0.028348, loss_ce: 0.012252
iteration 13387 : loss : 0.025583, loss_ce: 0.006469
iteration 13388 : loss : 0.019913, loss_ce: 0.005334
iteration 13389 : loss : 0.074336, loss_ce: 0.004740
iteration 13390 : loss : 0.024525, loss_ce: 0.008579
iteration 13391 : loss : 0.177858, loss_ce: 0.004932
iteration 13392 : loss : 0.230039, loss_ce: 0.003055
 72%|████████████████████▉        | 144/200 [2:10:46<50:56, 54.58s/it]pred_sum 8057
gtsum tensor(7596, device='cuda:0')
iteration 13393 : loss : 0.017377, loss_ce: 0.005563
iteration 13394 : loss : 0.029342, loss_ce: 0.007942
iteration 13395 : loss : 0.024200, loss_ce: 0.006893
iteration 13396 : loss : 0.024805, loss_ce: 0.006182
iteration 13397 : loss : 0.027814, loss_ce: 0.009513
iteration 13398 : loss : 0.020425, loss_ce: 0.007824
iteration 13399 : loss : 0.026245, loss_ce: 0.009560
iteration 13400 : loss : 0.024337, loss_ce: 0.005581
iteration 13401 : loss : 0.018954, loss_ce: 0.006733
iteration 13402 : loss : 0.021980, loss_ce: 0.008917
iteration 13403 : loss : 0.026438, loss_ce: 0.007041
iteration 13404 : loss : 0.074080, loss_ce: 0.006461
iteration 13405 : loss : 0.025194, loss_ce: 0.008095
iteration 13406 : loss : 0.021606, loss_ce: 0.006536
iteration 13407 : loss : 0.021280, loss_ce: 0.006849
iteration 13408 : loss : 0.023934, loss_ce: 0.005892
iteration 13409 : loss : 0.021318, loss_ce: 0.009042
iteration 13410 : loss : 0.027829, loss_ce: 0.011367
iteration 13411 : loss : 0.028425, loss_ce: 0.006035
iteration 13412 : loss : 0.020953, loss_ce: 0.007732
iteration 13413 : loss : 0.020046, loss_ce: 0.009131
iteration 13414 : loss : 0.022058, loss_ce: 0.007316
iteration 13415 : loss : 0.021236, loss_ce: 0.006662
iteration 13416 : loss : 0.025374, loss_ce: 0.012055
iteration 13417 : loss : 0.061530, loss_ce: 0.007829
iteration 13418 : loss : 0.021539, loss_ce: 0.004998
iteration 13419 : loss : 0.023189, loss_ce: 0.009184
iteration 13420 : loss : 0.020891, loss_ce: 0.007674
iteration 13421 : loss : 0.075259, loss_ce: 0.005722
iteration 13422 : loss : 0.022576, loss_ce: 0.005171
iteration 13423 : loss : 0.023043, loss_ce: 0.007510
pred_sum 179
gtsum tensor(174, device='cuda:0')
iteration 13424 : loss : 0.026405, loss_ce: 0.013463
iteration 13425 : loss : 0.018037, loss_ce: 0.003058
iteration 13426 : loss : 0.023061, loss_ce: 0.008374
iteration 13427 : loss : 0.024465, loss_ce: 0.011095
iteration 13428 : loss : 0.025405, loss_ce: 0.008317
iteration 13429 : loss : 0.025120, loss_ce: 0.010046
iteration 13430 : loss : 0.028656, loss_ce: 0.008723
iteration 13431 : loss : 0.080993, loss_ce: 0.010243
iteration 13432 : loss : 0.022285, loss_ce: 0.004333
iteration 13433 : loss : 0.023206, loss_ce: 0.007575
iteration 13434 : loss : 0.025336, loss_ce: 0.007101
iteration 13435 : loss : 0.025324, loss_ce: 0.010585
iteration 13436 : loss : 0.020691, loss_ce: 0.004315
iteration 13437 : loss : 0.023405, loss_ce: 0.007101
iteration 13438 : loss : 0.020074, loss_ce: 0.006221
iteration 13439 : loss : 0.021651, loss_ce: 0.006010
iteration 13440 : loss : 0.022345, loss_ce: 0.010390
iteration 13441 : loss : 0.026493, loss_ce: 0.009249
iteration 13442 : loss : 0.028399, loss_ce: 0.005828
iteration 13443 : loss : 0.024692, loss_ce: 0.009462
iteration 13444 : loss : 0.026230, loss_ce: 0.010362
iteration 13445 : loss : 0.024867, loss_ce: 0.011370
iteration 13446 : loss : 0.023855, loss_ce: 0.009807
iteration 13447 : loss : 0.022124, loss_ce: 0.009763
iteration 13448 : loss : 0.022886, loss_ce: 0.007749
iteration 13449 : loss : 0.026878, loss_ce: 0.014337
iteration 13450 : loss : 0.024261, loss_ce: 0.009528
iteration 13451 : loss : 0.038253, loss_ce: 0.007268
iteration 13452 : loss : 0.082053, loss_ce: 0.005181
iteration 13453 : loss : 0.026080, loss_ce: 0.008407
iteration 13454 : loss : 0.024021, loss_ce: 0.010480
pred_sum 398
gtsum tensor(403, device='cuda:0')
iteration 13455 : loss : 0.028137, loss_ce: 0.013073
iteration 13456 : loss : 0.127268, loss_ce: 0.005298
iteration 13457 : loss : 0.024024, loss_ce: 0.007681
iteration 13458 : loss : 0.044004, loss_ce: 0.008362
iteration 13459 : loss : 0.021939, loss_ce: 0.009560
iteration 13460 : loss : 0.025614, loss_ce: 0.011480
iteration 13461 : loss : 0.024937, loss_ce: 0.011207
iteration 13462 : loss : 0.023925, loss_ce: 0.007907
iteration 13463 : loss : 0.025976, loss_ce: 0.011974
iteration 13464 : loss : 0.019926, loss_ce: 0.005225
iteration 13465 : loss : 0.076058, loss_ce: 0.006582
iteration 13466 : loss : 0.020498, loss_ce: 0.007302
iteration 13467 : loss : 0.026316, loss_ce: 0.005745
iteration 13468 : loss : 0.023840, loss_ce: 0.006910
iteration 13469 : loss : 0.022147, loss_ce: 0.006248
iteration 13470 : loss : 0.026924, loss_ce: 0.009300
iteration 13471 : loss : 0.028441, loss_ce: 0.008167
iteration 13472 : loss : 0.036560, loss_ce: 0.007233
iteration 13473 : loss : 0.025936, loss_ce: 0.007696
iteration 13474 : loss : 0.023844, loss_ce: 0.010342
iteration 13475 : loss : 0.023120, loss_ce: 0.002983
iteration 13476 : loss : 0.021043, loss_ce: 0.008776
iteration 13477 : loss : 0.025115, loss_ce: 0.012586
iteration 13478 : loss : 0.085829, loss_ce: 0.006202
iteration 13479 : loss : 0.021613, loss_ce: 0.006462
iteration 13480 : loss : 0.075332, loss_ce: 0.009210
iteration 13481 : loss : 0.025046, loss_ce: 0.006843
iteration 13482 : loss : 0.025772, loss_ce: 0.004122
iteration 13483 : loss : 0.024433, loss_ce: 0.007108
iteration 13484 : loss : 0.019873, loss_ce: 0.008160
iteration 13485 : loss : 0.287124, loss_ce: 0.004807
 72%|█████████████████████        | 145/200 [2:11:40<50:01, 54.56s/it]pred_sum 214
gtsum tensor(205, device='cuda:0')
iteration 13486 : loss : 0.024127, loss_ce: 0.009400
iteration 13487 : loss : 0.021894, loss_ce: 0.008430
iteration 13488 : loss : 0.024799, loss_ce: 0.011578
iteration 13489 : loss : 0.023237, loss_ce: 0.009235
iteration 13490 : loss : 0.033219, loss_ce: 0.009911
iteration 13491 : loss : 0.029533, loss_ce: 0.009210
iteration 13492 : loss : 0.026438, loss_ce: 0.010111
iteration 13493 : loss : 0.022594, loss_ce: 0.007939
iteration 13494 : loss : 0.018969, loss_ce: 0.004895
iteration 13495 : loss : 0.024043, loss_ce: 0.010011
iteration 13496 : loss : 0.022184, loss_ce: 0.008429
iteration 13497 : loss : 0.027735, loss_ce: 0.007419
iteration 13498 : loss : 0.025694, loss_ce: 0.009452
iteration 13499 : loss : 0.023265, loss_ce: 0.008322
iteration 13500 : loss : 0.029659, loss_ce: 0.007872
iteration 13501 : loss : 0.027428, loss_ce: 0.006669
iteration 13502 : loss : 0.024848, loss_ce: 0.010767
iteration 13503 : loss : 0.021412, loss_ce: 0.007907
iteration 13504 : loss : 0.024173, loss_ce: 0.007862
iteration 13505 : loss : 0.021465, loss_ce: 0.006065
iteration 13506 : loss : 0.021674, loss_ce: 0.004260
iteration 13507 : loss : 0.019511, loss_ce: 0.005957
iteration 13508 : loss : 0.023634, loss_ce: 0.008749
iteration 13509 : loss : 0.025705, loss_ce: 0.007582
iteration 13510 : loss : 0.076134, loss_ce: 0.005151
iteration 13511 : loss : 0.022987, loss_ce: 0.008435
iteration 13512 : loss : 0.074828, loss_ce: 0.006343
iteration 13513 : loss : 0.023847, loss_ce: 0.005165
iteration 13514 : loss : 0.025469, loss_ce: 0.009109
iteration 13515 : loss : 0.023008, loss_ce: 0.009257
iteration 13516 : loss : 0.024708, loss_ce: 0.006222
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 13517 : loss : 0.019021, loss_ce: 0.008113
iteration 13518 : loss : 0.024459, loss_ce: 0.010729
iteration 13519 : loss : 0.026108, loss_ce: 0.008666
iteration 13520 : loss : 0.021578, loss_ce: 0.007724
iteration 13521 : loss : 0.024143, loss_ce: 0.009500
iteration 13522 : loss : 0.024499, loss_ce: 0.004949
iteration 13523 : loss : 0.024543, loss_ce: 0.008896
iteration 13524 : loss : 0.024267, loss_ce: 0.008198
iteration 13525 : loss : 0.041913, loss_ce: 0.006028
iteration 13526 : loss : 0.022546, loss_ce: 0.011122
iteration 13527 : loss : 0.021045, loss_ce: 0.005761
iteration 13528 : loss : 0.022235, loss_ce: 0.008820
iteration 13529 : loss : 0.023282, loss_ce: 0.007114
iteration 13530 : loss : 0.029534, loss_ce: 0.008481
iteration 13531 : loss : 0.026209, loss_ce: 0.007327
iteration 13532 : loss : 0.026064, loss_ce: 0.006048
iteration 13533 : loss : 0.022840, loss_ce: 0.011304
iteration 13534 : loss : 0.023681, loss_ce: 0.009046
iteration 13535 : loss : 0.024340, loss_ce: 0.009775
iteration 13536 : loss : 0.027589, loss_ce: 0.009122
iteration 13537 : loss : 0.031355, loss_ce: 0.007007
iteration 13538 : loss : 0.022699, loss_ce: 0.006706
iteration 13539 : loss : 0.020592, loss_ce: 0.006548
iteration 13540 : loss : 0.023969, loss_ce: 0.007232
iteration 13541 : loss : 0.024339, loss_ce: 0.007370
iteration 13542 : loss : 0.019741, loss_ce: 0.008284
iteration 13543 : loss : 0.022711, loss_ce: 0.008838
iteration 13544 : loss : 0.025511, loss_ce: 0.006674
iteration 13545 : loss : 0.026016, loss_ce: 0.011524
iteration 13546 : loss : 0.025670, loss_ce: 0.007045
iteration 13547 : loss : 0.076257, loss_ce: 0.006550
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 13548 : loss : 0.021638, loss_ce: 0.007494
iteration 13549 : loss : 0.022753, loss_ce: 0.009407
iteration 13550 : loss : 0.026814, loss_ce: 0.004385
iteration 13551 : loss : 0.028674, loss_ce: 0.008900
iteration 13552 : loss : 0.026432, loss_ce: 0.011055
iteration 13553 : loss : 0.023886, loss_ce: 0.009449
iteration 13554 : loss : 0.020018, loss_ce: 0.006433
iteration 13555 : loss : 0.025308, loss_ce: 0.008871
iteration 13556 : loss : 0.027041, loss_ce: 0.006449
iteration 13557 : loss : 0.019016, loss_ce: 0.006140
iteration 13558 : loss : 0.078469, loss_ce: 0.007357
iteration 13559 : loss : 0.021358, loss_ce: 0.009981
iteration 13560 : loss : 0.021530, loss_ce: 0.008042
iteration 13561 : loss : 0.026223, loss_ce: 0.006218
iteration 13562 : loss : 0.025502, loss_ce: 0.005673
iteration 13563 : loss : 0.023171, loss_ce: 0.007416
iteration 13564 : loss : 0.030619, loss_ce: 0.004904
iteration 13565 : loss : 0.019816, loss_ce: 0.007580
iteration 13566 : loss : 0.022674, loss_ce: 0.008575
iteration 13567 : loss : 0.022251, loss_ce: 0.007020
iteration 13568 : loss : 0.079313, loss_ce: 0.004588
iteration 13569 : loss : 0.025135, loss_ce: 0.011236
iteration 13570 : loss : 0.025237, loss_ce: 0.007800
iteration 13571 : loss : 0.023089, loss_ce: 0.007542
iteration 13572 : loss : 0.021543, loss_ce: 0.005097
iteration 13573 : loss : 0.019318, loss_ce: 0.007073
iteration 13574 : loss : 0.030737, loss_ce: 0.010823
iteration 13575 : loss : 0.021557, loss_ce: 0.009056
iteration 13576 : loss : 0.025594, loss_ce: 0.008414
iteration 13577 : loss : 0.079279, loss_ce: 0.001932
iteration 13578 : loss : 0.143398, loss_ce: 0.006184
 73%|█████████████████████▏       | 146/200 [2:12:35<49:05, 54.55s/it]pred_sum 9839
gtsum tensor(10212, device='cuda:0')
iteration 13579 : loss : 0.024889, loss_ce: 0.007197
iteration 13580 : loss : 0.022527, loss_ce: 0.007414
iteration 13581 : loss : 0.022287, loss_ce: 0.007109
iteration 13582 : loss : 0.022227, loss_ce: 0.005649
iteration 13583 : loss : 0.021559, loss_ce: 0.006251
iteration 13584 : loss : 0.072428, loss_ce: 0.003838
iteration 13585 : loss : 0.025268, loss_ce: 0.009043
iteration 13586 : loss : 0.071600, loss_ce: 0.005720
iteration 13587 : loss : 0.027952, loss_ce: 0.009968
iteration 13588 : loss : 0.024931, loss_ce: 0.007465
iteration 13589 : loss : 0.025627, loss_ce: 0.006879
iteration 13590 : loss : 0.021544, loss_ce: 0.007166
iteration 13591 : loss : 0.022673, loss_ce: 0.007159
iteration 13592 : loss : 0.021499, loss_ce: 0.005005
iteration 13593 : loss : 0.024197, loss_ce: 0.010326
iteration 13594 : loss : 0.022774, loss_ce: 0.009193
iteration 13595 : loss : 0.023902, loss_ce: 0.006807
iteration 13596 : loss : 0.042641, loss_ce: 0.009345
iteration 13597 : loss : 0.025467, loss_ce: 0.009968
iteration 13598 : loss : 0.026425, loss_ce: 0.008002
iteration 13599 : loss : 0.018076, loss_ce: 0.004657
iteration 13600 : loss : 0.022155, loss_ce: 0.004341
iteration 13601 : loss : 0.018537, loss_ce: 0.004447
iteration 13602 : loss : 0.021600, loss_ce: 0.009724
iteration 13603 : loss : 0.024329, loss_ce: 0.006990
iteration 13604 : loss : 0.018706, loss_ce: 0.006073
iteration 13605 : loss : 0.020490, loss_ce: 0.006932
iteration 13606 : loss : 0.024026, loss_ce: 0.008600
iteration 13607 : loss : 0.023703, loss_ce: 0.010451
iteration 13608 : loss : 0.023194, loss_ce: 0.011791
iteration 13609 : loss : 0.027672, loss_ce: 0.006206
pred_sum 747
gtsum tensor(750, device='cuda:0')
iteration 13610 : loss : 0.024159, loss_ce: 0.009215
iteration 13611 : loss : 0.023234, loss_ce: 0.009122
iteration 13612 : loss : 0.023863, loss_ce: 0.007044
iteration 13613 : loss : 0.023267, loss_ce: 0.008642
iteration 13614 : loss : 0.019460, loss_ce: 0.004913
iteration 13615 : loss : 0.026110, loss_ce: 0.009084
iteration 13616 : loss : 0.022162, loss_ce: 0.009195
iteration 13617 : loss : 0.034322, loss_ce: 0.007211
iteration 13618 : loss : 0.023074, loss_ce: 0.007737
iteration 13619 : loss : 0.026679, loss_ce: 0.011105
iteration 13620 : loss : 0.048386, loss_ce: 0.006359
iteration 13621 : loss : 0.025745, loss_ce: 0.012199
iteration 13622 : loss : 0.020657, loss_ce: 0.005110
iteration 13623 : loss : 0.023877, loss_ce: 0.011413
iteration 13624 : loss : 0.024141, loss_ce: 0.007074
iteration 13625 : loss : 0.024507, loss_ce: 0.006120
iteration 13626 : loss : 0.023023, loss_ce: 0.007751
iteration 13627 : loss : 0.025143, loss_ce: 0.008627
iteration 13628 : loss : 0.080117, loss_ce: 0.006751
iteration 13629 : loss : 0.033090, loss_ce: 0.009963
iteration 13630 : loss : 0.022854, loss_ce: 0.007730
iteration 13631 : loss : 0.023868, loss_ce: 0.009417
iteration 13632 : loss : 0.078069, loss_ce: 0.007998
iteration 13633 : loss : 0.024499, loss_ce: 0.010672
iteration 13634 : loss : 0.028530, loss_ce: 0.006554
iteration 13635 : loss : 0.027057, loss_ce: 0.007129
iteration 13636 : loss : 0.030973, loss_ce: 0.007760
iteration 13637 : loss : 0.025745, loss_ce: 0.005747
iteration 13638 : loss : 0.077179, loss_ce: 0.007921
iteration 13639 : loss : 0.024420, loss_ce: 0.010863
iteration 13640 : loss : 0.023601, loss_ce: 0.008799
pred_sum 29823
gtsum tensor(29740, device='cuda:0')
iteration 13641 : loss : 0.026624, loss_ce: 0.010303
iteration 13642 : loss : 0.026112, loss_ce: 0.011325
iteration 13643 : loss : 0.078000, loss_ce: 0.008694
iteration 13644 : loss : 0.024494, loss_ce: 0.005589
iteration 13645 : loss : 0.018450, loss_ce: 0.007026
iteration 13646 : loss : 0.022068, loss_ce: 0.009586
iteration 13647 : loss : 0.021475, loss_ce: 0.006839
iteration 13648 : loss : 0.026205, loss_ce: 0.010723
iteration 13649 : loss : 0.027116, loss_ce: 0.009955
iteration 13650 : loss : 0.023201, loss_ce: 0.008786
iteration 13651 : loss : 0.022303, loss_ce: 0.005770
iteration 13652 : loss : 0.023768, loss_ce: 0.009304
iteration 13653 : loss : 0.024889, loss_ce: 0.009852
iteration 13654 : loss : 0.023283, loss_ce: 0.005519
iteration 13655 : loss : 0.020895, loss_ce: 0.008467
iteration 13656 : loss : 0.021651, loss_ce: 0.008796
iteration 13657 : loss : 0.021341, loss_ce: 0.005020
iteration 13658 : loss : 0.075439, loss_ce: 0.006194
iteration 13659 : loss : 0.074429, loss_ce: 0.005441
iteration 13660 : loss : 0.027872, loss_ce: 0.010937
iteration 13661 : loss : 0.020873, loss_ce: 0.007133
iteration 13662 : loss : 0.078211, loss_ce: 0.008211
iteration 13663 : loss : 0.023383, loss_ce: 0.011181
iteration 13664 : loss : 0.023209, loss_ce: 0.010509
iteration 13665 : loss : 0.031988, loss_ce: 0.008078
iteration 13666 : loss : 0.023793, loss_ce: 0.011449
iteration 13667 : loss : 0.022775, loss_ce: 0.008023
iteration 13668 : loss : 0.025435, loss_ce: 0.010731
iteration 13669 : loss : 0.022510, loss_ce: 0.006863
iteration 13670 : loss : 0.020143, loss_ce: 0.008596
iteration 13671 : loss : 0.239372, loss_ce: 0.008990
 74%|█████████████████████▎       | 147/200 [2:13:29<48:10, 54.53s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 13672 : loss : 0.026490, loss_ce: 0.006484
iteration 13673 : loss : 0.024706, loss_ce: 0.005821
iteration 13674 : loss : 0.025055, loss_ce: 0.009488
iteration 13675 : loss : 0.025697, loss_ce: 0.008630
iteration 13676 : loss : 0.018958, loss_ce: 0.006613
iteration 13677 : loss : 0.020617, loss_ce: 0.006700
iteration 13678 : loss : 0.024532, loss_ce: 0.006937
iteration 13679 : loss : 0.021167, loss_ce: 0.009138
iteration 13680 : loss : 0.021795, loss_ce: 0.009206
iteration 13681 : loss : 0.075860, loss_ce: 0.006021
iteration 13682 : loss : 0.025341, loss_ce: 0.010726
iteration 13683 : loss : 0.021827, loss_ce: 0.004477
iteration 13684 : loss : 0.073061, loss_ce: 0.005036
iteration 13685 : loss : 0.026871, loss_ce: 0.006789
iteration 13686 : loss : 0.022620, loss_ce: 0.007576
iteration 13687 : loss : 0.024389, loss_ce: 0.008994
iteration 13688 : loss : 0.020016, loss_ce: 0.008102
iteration 13689 : loss : 0.021004, loss_ce: 0.007905
iteration 13690 : loss : 0.024789, loss_ce: 0.006177
iteration 13691 : loss : 0.016294, loss_ce: 0.006386
iteration 13692 : loss : 0.021876, loss_ce: 0.006643
iteration 13693 : loss : 0.025419, loss_ce: 0.009709
iteration 13694 : loss : 0.026864, loss_ce: 0.012715
iteration 13695 : loss : 0.021328, loss_ce: 0.008280
iteration 13696 : loss : 0.024440, loss_ce: 0.010974
iteration 13697 : loss : 0.021895, loss_ce: 0.008329
iteration 13698 : loss : 0.019427, loss_ce: 0.006531
iteration 13699 : loss : 0.023406, loss_ce: 0.007300
iteration 13700 : loss : 0.020521, loss_ce: 0.007685
iteration 13701 : loss : 0.080238, loss_ce: 0.010798
iteration 13702 : loss : 0.020853, loss_ce: 0.008883
pred_sum 342
gtsum tensor(416, device='cuda:0')
iteration 13703 : loss : 0.022382, loss_ce: 0.006734
iteration 13704 : loss : 0.026111, loss_ce: 0.005831
iteration 13705 : loss : 0.024921, loss_ce: 0.014447
iteration 13706 : loss : 0.024946, loss_ce: 0.009610
iteration 13707 : loss : 0.025709, loss_ce: 0.010712
iteration 13708 : loss : 0.024124, loss_ce: 0.010466
iteration 13709 : loss : 0.021099, loss_ce: 0.005010
iteration 13710 : loss : 0.024848, loss_ce: 0.009495
iteration 13711 : loss : 0.060466, loss_ce: 0.012100
iteration 13712 : loss : 0.025580, loss_ce: 0.011737
iteration 13713 : loss : 0.024782, loss_ce: 0.011078
iteration 13714 : loss : 0.031356, loss_ce: 0.006810
iteration 13715 : loss : 0.020594, loss_ce: 0.006282
iteration 13716 : loss : 0.122260, loss_ce: 0.004395
iteration 13717 : loss : 0.024426, loss_ce: 0.006037
iteration 13718 : loss : 0.072261, loss_ce: 0.004029
iteration 13719 : loss : 0.126244, loss_ce: 0.003392
iteration 13720 : loss : 0.022630, loss_ce: 0.008717
iteration 13721 : loss : 0.023801, loss_ce: 0.008847
iteration 13722 : loss : 0.040614, loss_ce: 0.007939
iteration 13723 : loss : 0.029759, loss_ce: 0.013099
iteration 13724 : loss : 0.028251, loss_ce: 0.006837
iteration 13725 : loss : 0.023941, loss_ce: 0.011933
iteration 13726 : loss : 0.025159, loss_ce: 0.005325
iteration 13727 : loss : 0.023029, loss_ce: 0.007726
iteration 13728 : loss : 0.024205, loss_ce: 0.008445
iteration 13729 : loss : 0.024859, loss_ce: 0.009829
iteration 13730 : loss : 0.025087, loss_ce: 0.009803
iteration 13731 : loss : 0.051882, loss_ce: 0.006390
iteration 13732 : loss : 0.019856, loss_ce: 0.005235
iteration 13733 : loss : 0.022934, loss_ce: 0.006731
pred_sum 451
gtsum tensor(434, device='cuda:0')
iteration 13734 : loss : 0.026081, loss_ce: 0.008200
iteration 13735 : loss : 0.023981, loss_ce: 0.006678
iteration 13736 : loss : 0.021820, loss_ce: 0.007394
iteration 13737 : loss : 0.026113, loss_ce: 0.008584
iteration 13738 : loss : 0.024052, loss_ce: 0.008753
iteration 13739 : loss : 0.079228, loss_ce: 0.007624
iteration 13740 : loss : 0.025674, loss_ce: 0.008632
iteration 13741 : loss : 0.024389, loss_ce: 0.007791
iteration 13742 : loss : 0.024490, loss_ce: 0.009101
iteration 13743 : loss : 0.029083, loss_ce: 0.007155
iteration 13744 : loss : 0.023858, loss_ce: 0.008283
iteration 13745 : loss : 0.025629, loss_ce: 0.013215
iteration 13746 : loss : 0.021871, loss_ce: 0.007489
iteration 13747 : loss : 0.033796, loss_ce: 0.012584
iteration 13748 : loss : 0.024372, loss_ce: 0.007934
iteration 13749 : loss : 0.024910, loss_ce: 0.009006
iteration 13750 : loss : 0.024187, loss_ce: 0.008823
iteration 13751 : loss : 0.025377, loss_ce: 0.005712
iteration 13752 : loss : 0.073155, loss_ce: 0.003903
iteration 13753 : loss : 0.030061, loss_ce: 0.007338
iteration 13754 : loss : 0.027226, loss_ce: 0.013890
iteration 13755 : loss : 0.028594, loss_ce: 0.012863
iteration 13756 : loss : 0.029317, loss_ce: 0.002934
iteration 13757 : loss : 0.022010, loss_ce: 0.005059
iteration 13758 : loss : 0.024752, loss_ce: 0.009057
iteration 13759 : loss : 0.026882, loss_ce: 0.008387
iteration 13760 : loss : 0.072740, loss_ce: 0.002958
iteration 13761 : loss : 0.024778, loss_ce: 0.008542
iteration 13762 : loss : 0.023093, loss_ce: 0.005926
iteration 13763 : loss : 0.123632, loss_ce: 0.005669
iteration 13764 : loss : 0.189919, loss_ce: 0.018339
 74%|█████████████████████▍       | 148/200 [2:14:24<47:15, 54.53s/it]pred_sum 48922
gtsum tensor(48172, device='cuda:0')
iteration 13765 : loss : 0.026396, loss_ce: 0.008859
iteration 13766 : loss : 0.020195, loss_ce: 0.006312
iteration 13767 : loss : 0.029740, loss_ce: 0.013450
iteration 13768 : loss : 0.075312, loss_ce: 0.004373
iteration 13769 : loss : 0.024224, loss_ce: 0.010573
iteration 13770 : loss : 0.024283, loss_ce: 0.009010
iteration 13771 : loss : 0.025550, loss_ce: 0.010529
iteration 13772 : loss : 0.074870, loss_ce: 0.007246
iteration 13773 : loss : 0.022426, loss_ce: 0.004661
iteration 13774 : loss : 0.030818, loss_ce: 0.009015
iteration 13775 : loss : 0.022990, loss_ce: 0.007413
iteration 13776 : loss : 0.025360, loss_ce: 0.008880
iteration 13777 : loss : 0.023284, loss_ce: 0.006148
iteration 13778 : loss : 0.023852, loss_ce: 0.009882
iteration 13779 : loss : 0.020804, loss_ce: 0.005541
iteration 13780 : loss : 0.038591, loss_ce: 0.008670
iteration 13781 : loss : 0.023117, loss_ce: 0.009279
iteration 13782 : loss : 0.026370, loss_ce: 0.008546
iteration 13783 : loss : 0.022204, loss_ce: 0.007294
iteration 13784 : loss : 0.027684, loss_ce: 0.012164
iteration 13785 : loss : 0.023560, loss_ce: 0.005306
iteration 13786 : loss : 0.024398, loss_ce: 0.005698
iteration 13787 : loss : 0.025978, loss_ce: 0.011366
iteration 13788 : loss : 0.021631, loss_ce: 0.005020
iteration 13789 : loss : 0.027266, loss_ce: 0.006217
iteration 13790 : loss : 0.022882, loss_ce: 0.004683
iteration 13791 : loss : 0.027969, loss_ce: 0.009777
iteration 13792 : loss : 0.024125, loss_ce: 0.009882
iteration 13793 : loss : 0.023016, loss_ce: 0.008718
iteration 13794 : loss : 0.025578, loss_ce: 0.008717
iteration 13795 : loss : 0.021153, loss_ce: 0.009080
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 13796 : loss : 0.028213, loss_ce: 0.010306
iteration 13797 : loss : 0.022793, loss_ce: 0.009377
iteration 13798 : loss : 0.023638, loss_ce: 0.005363
iteration 13799 : loss : 0.025306, loss_ce: 0.010282
iteration 13800 : loss : 0.022113, loss_ce: 0.005983
iteration 13801 : loss : 0.026399, loss_ce: 0.009192
iteration 13802 : loss : 0.021518, loss_ce: 0.008026
iteration 13803 : loss : 0.018121, loss_ce: 0.005143
iteration 13804 : loss : 0.029963, loss_ce: 0.008720
iteration 13805 : loss : 0.024858, loss_ce: 0.009458
iteration 13806 : loss : 0.036401, loss_ce: 0.004160
iteration 13807 : loss : 0.028254, loss_ce: 0.005341
iteration 13808 : loss : 0.019848, loss_ce: 0.007242
iteration 13809 : loss : 0.023277, loss_ce: 0.008419
iteration 13810 : loss : 0.027219, loss_ce: 0.008168
iteration 13811 : loss : 0.020854, loss_ce: 0.005355
iteration 13812 : loss : 0.020968, loss_ce: 0.006939
iteration 13813 : loss : 0.022531, loss_ce: 0.008156
iteration 13814 : loss : 0.021091, loss_ce: 0.008247
iteration 13815 : loss : 0.025643, loss_ce: 0.007091
iteration 13816 : loss : 0.026701, loss_ce: 0.010680
iteration 13817 : loss : 0.021874, loss_ce: 0.007245
iteration 13818 : loss : 0.028050, loss_ce: 0.012040
iteration 13819 : loss : 0.026850, loss_ce: 0.007921
iteration 13820 : loss : 0.022785, loss_ce: 0.007705
iteration 13821 : loss : 0.022134, loss_ce: 0.005653
iteration 13822 : loss : 0.024188, loss_ce: 0.010514
iteration 13823 : loss : 0.024133, loss_ce: 0.008732
iteration 13824 : loss : 0.023957, loss_ce: 0.009518
iteration 13825 : loss : 0.021682, loss_ce: 0.008773
iteration 13826 : loss : 0.076248, loss_ce: 0.008202
pred_sum 35461
gtsum tensor(34699, device='cuda:0')
iteration 13827 : loss : 0.030803, loss_ce: 0.009846
iteration 13828 : loss : 0.025107, loss_ce: 0.008992
iteration 13829 : loss : 0.025393, loss_ce: 0.012929
iteration 13830 : loss : 0.027491, loss_ce: 0.008143
iteration 13831 : loss : 0.022273, loss_ce: 0.011353
iteration 13832 : loss : 0.028546, loss_ce: 0.008149
iteration 13833 : loss : 0.018876, loss_ce: 0.004709
iteration 13834 : loss : 0.024596, loss_ce: 0.010331
iteration 13835 : loss : 0.022882, loss_ce: 0.010013
iteration 13836 : loss : 0.020212, loss_ce: 0.008958
iteration 13837 : loss : 0.025461, loss_ce: 0.006269
iteration 13838 : loss : 0.020117, loss_ce: 0.007844
iteration 13839 : loss : 0.022481, loss_ce: 0.006377
iteration 13840 : loss : 0.019311, loss_ce: 0.005178
iteration 13841 : loss : 0.021726, loss_ce: 0.007404
iteration 13842 : loss : 0.021138, loss_ce: 0.005341
iteration 13843 : loss : 0.025684, loss_ce: 0.009041
iteration 13844 : loss : 0.025953, loss_ce: 0.008901
iteration 13845 : loss : 0.022858, loss_ce: 0.003828
iteration 13846 : loss : 0.025921, loss_ce: 0.008241
iteration 13847 : loss : 0.028264, loss_ce: 0.008024
iteration 13848 : loss : 0.075357, loss_ce: 0.008198
iteration 13849 : loss : 0.020118, loss_ce: 0.006608
iteration 13850 : loss : 0.074264, loss_ce: 0.006473
iteration 13851 : loss : 0.027297, loss_ce: 0.009663
iteration 13852 : loss : 0.022414, loss_ce: 0.008228
iteration 13853 : loss : 0.023032, loss_ce: 0.006416
iteration 13854 : loss : 0.030164, loss_ce: 0.007475
iteration 13855 : loss : 0.022106, loss_ce: 0.006038
iteration 13856 : loss : 0.020548, loss_ce: 0.008168
iteration 13857 : loss : 0.394844, loss_ce: 0.001180
 74%|█████████████████████▌       | 149/200 [2:15:18<46:20, 54.52s/it]pred_sum 122
gtsum tensor(106, device='cuda:0')
iteration 13858 : loss : 0.072517, loss_ce: 0.007718
iteration 13859 : loss : 0.020045, loss_ce: 0.006279
iteration 13860 : loss : 0.034569, loss_ce: 0.010033
iteration 13861 : loss : 0.024826, loss_ce: 0.013133
iteration 13862 : loss : 0.025006, loss_ce: 0.009240
iteration 13863 : loss : 0.022864, loss_ce: 0.009327
iteration 13864 : loss : 0.106267, loss_ce: 0.004141
iteration 13865 : loss : 0.035825, loss_ce: 0.007659
iteration 13866 : loss : 0.021525, loss_ce: 0.006528
iteration 13867 : loss : 0.022536, loss_ce: 0.010120
iteration 13868 : loss : 0.022737, loss_ce: 0.006717
iteration 13869 : loss : 0.076671, loss_ce: 0.006671
iteration 13870 : loss : 0.029058, loss_ce: 0.005698
iteration 13871 : loss : 0.023491, loss_ce: 0.005841
iteration 13872 : loss : 0.024478, loss_ce: 0.006007
iteration 13873 : loss : 0.078773, loss_ce: 0.002926
iteration 13874 : loss : 0.026284, loss_ce: 0.007724
iteration 13875 : loss : 0.026011, loss_ce: 0.010194
iteration 13876 : loss : 0.018993, loss_ce: 0.007186
iteration 13877 : loss : 0.068023, loss_ce: 0.007018
iteration 13878 : loss : 0.029330, loss_ce: 0.007979
iteration 13879 : loss : 0.028334, loss_ce: 0.011281
iteration 13880 : loss : 0.027764, loss_ce: 0.009427
iteration 13881 : loss : 0.027253, loss_ce: 0.010154
iteration 13882 : loss : 0.031001, loss_ce: 0.012059
iteration 13883 : loss : 0.019163, loss_ce: 0.005259
iteration 13884 : loss : 0.024342, loss_ce: 0.010499
iteration 13885 : loss : 0.022375, loss_ce: 0.008777
iteration 13886 : loss : 0.027666, loss_ce: 0.006830
iteration 13887 : loss : 0.022477, loss_ce: 0.009210
iteration 13888 : loss : 0.072604, loss_ce: 0.007019
pred_sum 7079
gtsum tensor(7130, device='cuda:0')
iteration 13889 : loss : 0.024801, loss_ce: 0.009312
iteration 13890 : loss : 0.023470, loss_ce: 0.007378
iteration 13891 : loss : 0.025846, loss_ce: 0.005496
iteration 13892 : loss : 0.027340, loss_ce: 0.012606
iteration 13893 : loss : 0.125738, loss_ce: 0.004514
iteration 13894 : loss : 0.084438, loss_ce: 0.004748
iteration 13895 : loss : 0.021915, loss_ce: 0.006075
iteration 13896 : loss : 0.027475, loss_ce: 0.012913
iteration 13897 : loss : 0.023371, loss_ce: 0.007834
iteration 13898 : loss : 0.036832, loss_ce: 0.007684
iteration 13899 : loss : 0.026278, loss_ce: 0.012133
iteration 13900 : loss : 0.022446, loss_ce: 0.009626
iteration 13901 : loss : 0.078967, loss_ce: 0.006057
iteration 13902 : loss : 0.020010, loss_ce: 0.007716
iteration 13903 : loss : 0.031121, loss_ce: 0.015282
iteration 13904 : loss : 0.024655, loss_ce: 0.008244
iteration 13905 : loss : 0.023455, loss_ce: 0.008650
iteration 13906 : loss : 0.022964, loss_ce: 0.010358
iteration 13907 : loss : 0.029789, loss_ce: 0.006878
iteration 13908 : loss : 0.074941, loss_ce: 0.006375
iteration 13909 : loss : 0.024521, loss_ce: 0.009344
iteration 13910 : loss : 0.021336, loss_ce: 0.006674
iteration 13911 : loss : 0.020433, loss_ce: 0.005386
iteration 13912 : loss : 0.077460, loss_ce: 0.003112
iteration 13913 : loss : 0.026450, loss_ce: 0.011055
iteration 13914 : loss : 0.025001, loss_ce: 0.008970
iteration 13915 : loss : 0.026435, loss_ce: 0.010111
iteration 13916 : loss : 0.074804, loss_ce: 0.006669
iteration 13917 : loss : 0.025849, loss_ce: 0.008470
iteration 13918 : loss : 0.074267, loss_ce: 0.005485
iteration 13919 : loss : 0.029760, loss_ce: 0.008939
pred_sum 3240
gtsum tensor(3196, device='cuda:0')
iteration 13920 : loss : 0.035388, loss_ce: 0.010236
iteration 13921 : loss : 0.023700, loss_ce: 0.005311
iteration 13922 : loss : 0.048301, loss_ce: 0.006965
iteration 13923 : loss : 0.023369, loss_ce: 0.010401
iteration 13924 : loss : 0.025621, loss_ce: 0.013042
iteration 13925 : loss : 0.021458, loss_ce: 0.008402
iteration 13926 : loss : 0.024615, loss_ce: 0.006771
iteration 13927 : loss : 0.024281, loss_ce: 0.010513
iteration 13928 : loss : 0.028330, loss_ce: 0.010995
iteration 13929 : loss : 0.021619, loss_ce: 0.008747
iteration 13930 : loss : 0.024129, loss_ce: 0.008576
iteration 13931 : loss : 0.020283, loss_ce: 0.006970
iteration 13932 : loss : 0.022111, loss_ce: 0.006338
iteration 13933 : loss : 0.017862, loss_ce: 0.003642
iteration 13934 : loss : 0.024042, loss_ce: 0.007623
iteration 13935 : loss : 0.021915, loss_ce: 0.007000
iteration 13936 : loss : 0.074844, loss_ce: 0.009090
iteration 13937 : loss : 0.026734, loss_ce: 0.007356
iteration 13938 : loss : 0.028215, loss_ce: 0.012636
iteration 13939 : loss : 0.025609, loss_ce: 0.008260
iteration 13940 : loss : 0.029263, loss_ce: 0.006335
iteration 13941 : loss : 0.021674, loss_ce: 0.006695
iteration 13942 : loss : 0.023112, loss_ce: 0.005303
iteration 13943 : loss : 0.027403, loss_ce: 0.011044
iteration 13944 : loss : 0.023475, loss_ce: 0.008594
iteration 13945 : loss : 0.023313, loss_ce: 0.007283
iteration 13946 : loss : 0.022021, loss_ce: 0.007618
iteration 13947 : loss : 0.020964, loss_ce: 0.007615
iteration 13948 : loss : 0.022973, loss_ce: 0.006472
iteration 13949 : loss : 0.020437, loss_ce: 0.006908
iteration 13950 : loss : 0.337903, loss_ce: 0.002499
pred_sum 0
gtsum tensor(0, device='cuda:0')
save model to ../model/TU_Synapse224/TU_pretrain_R50-ViT-B_16_skip3_epo200_bs24_224/epoch_149.pth
 75%|█████████████████████▊       | 150/200 [2:16:14<45:38, 54.77s/it]iteration 13951 : loss : 0.024991, loss_ce: 0.009002
iteration 13952 : loss : 0.024828, loss_ce: 0.008541
iteration 13953 : loss : 0.023788, loss_ce: 0.005673
iteration 13954 : loss : 0.023876, loss_ce: 0.007200
iteration 13955 : loss : 0.023855, loss_ce: 0.006909
iteration 13956 : loss : 0.022366, loss_ce: 0.010121
iteration 13957 : loss : 0.025660, loss_ce: 0.005013
iteration 13958 : loss : 0.020223, loss_ce: 0.004877
iteration 13959 : loss : 0.018627, loss_ce: 0.008566
iteration 13960 : loss : 0.026198, loss_ce: 0.010655
iteration 13961 : loss : 0.022965, loss_ce: 0.008183
iteration 13962 : loss : 0.022480, loss_ce: 0.006752
iteration 13963 : loss : 0.025887, loss_ce: 0.007910
iteration 13964 : loss : 0.018014, loss_ce: 0.006253
iteration 13965 : loss : 0.018874, loss_ce: 0.007899
iteration 13966 : loss : 0.020986, loss_ce: 0.006581
iteration 13967 : loss : 0.018331, loss_ce: 0.006175
iteration 13968 : loss : 0.022268, loss_ce: 0.005332
iteration 13969 : loss : 0.022454, loss_ce: 0.009851
iteration 13970 : loss : 0.022637, loss_ce: 0.008095
iteration 13971 : loss : 0.023022, loss_ce: 0.006795
iteration 13972 : loss : 0.073797, loss_ce: 0.004581
iteration 13973 : loss : 0.072250, loss_ce: 0.006871
iteration 13974 : loss : 0.022472, loss_ce: 0.008603
iteration 13975 : loss : 0.059583, loss_ce: 0.009984
iteration 13976 : loss : 0.022615, loss_ce: 0.011133
iteration 13977 : loss : 0.022660, loss_ce: 0.007266
iteration 13978 : loss : 0.025934, loss_ce: 0.013443
iteration 13979 : loss : 0.022149, loss_ce: 0.010793
iteration 13980 : loss : 0.027550, loss_ce: 0.009355
iteration 13981 : loss : 0.024479, loss_ce: 0.010058
pred_sum 3698
gtsum tensor(3916, device='cuda:0')
iteration 13982 : loss : 0.026096, loss_ce: 0.011655
iteration 13983 : loss : 0.024660, loss_ce: 0.006598
iteration 13984 : loss : 0.025367, loss_ce: 0.007533
iteration 13985 : loss : 0.029628, loss_ce: 0.007205
iteration 13986 : loss : 0.026025, loss_ce: 0.008790
iteration 13987 : loss : 0.072313, loss_ce: 0.006446
iteration 13988 : loss : 0.020841, loss_ce: 0.008964
iteration 13989 : loss : 0.024983, loss_ce: 0.007421
iteration 13990 : loss : 0.025155, loss_ce: 0.008255
iteration 13991 : loss : 0.022675, loss_ce: 0.007502
iteration 13992 : loss : 0.020496, loss_ce: 0.009295
iteration 13993 : loss : 0.027792, loss_ce: 0.008690
iteration 13994 : loss : 0.022940, loss_ce: 0.006120
iteration 13995 : loss : 0.025207, loss_ce: 0.008938
iteration 13996 : loss : 0.074481, loss_ce: 0.005112
iteration 13997 : loss : 0.026925, loss_ce: 0.008695
iteration 13998 : loss : 0.073914, loss_ce: 0.005848
iteration 13999 : loss : 0.020174, loss_ce: 0.007484
iteration 14000 : loss : 0.024690, loss_ce: 0.008761
iteration 14001 : loss : 0.019460, loss_ce: 0.005272
iteration 14002 : loss : 0.026018, loss_ce: 0.012399
iteration 14003 : loss : 0.029272, loss_ce: 0.008846
iteration 14004 : loss : 0.020554, loss_ce: 0.010081
iteration 14005 : loss : 0.026899, loss_ce: 0.007556
iteration 14006 : loss : 0.022851, loss_ce: 0.006296
iteration 14007 : loss : 0.020483, loss_ce: 0.009020
iteration 14008 : loss : 0.018955, loss_ce: 0.008972
iteration 14009 : loss : 0.023863, loss_ce: 0.005683
iteration 14010 : loss : 0.024447, loss_ce: 0.011248
iteration 14011 : loss : 0.024390, loss_ce: 0.008645
iteration 14012 : loss : 0.025990, loss_ce: 0.012313
pred_sum 54831
gtsum tensor(54525, device='cuda:0')
iteration 14013 : loss : 0.025345, loss_ce: 0.008216
iteration 14014 : loss : 0.073303, loss_ce: 0.003895
iteration 14015 : loss : 0.024546, loss_ce: 0.011447
iteration 14016 : loss : 0.024789, loss_ce: 0.006280
iteration 14017 : loss : 0.019442, loss_ce: 0.005616
iteration 14018 : loss : 0.027821, loss_ce: 0.006734
iteration 14019 : loss : 0.021504, loss_ce: 0.005741
iteration 14020 : loss : 0.022372, loss_ce: 0.007347
iteration 14021 : loss : 0.020268, loss_ce: 0.006334
iteration 14022 : loss : 0.033993, loss_ce: 0.007541
iteration 14023 : loss : 0.021635, loss_ce: 0.007726
iteration 14024 : loss : 0.022999, loss_ce: 0.009449
iteration 14025 : loss : 0.021352, loss_ce: 0.006047
iteration 14026 : loss : 0.023043, loss_ce: 0.007630
iteration 14027 : loss : 0.025356, loss_ce: 0.007030
iteration 14028 : loss : 0.023535, loss_ce: 0.008826
iteration 14029 : loss : 0.021657, loss_ce: 0.007986
iteration 14030 : loss : 0.028645, loss_ce: 0.011429
iteration 14031 : loss : 0.023526, loss_ce: 0.009553
iteration 14032 : loss : 0.028888, loss_ce: 0.007330
iteration 14033 : loss : 0.022854, loss_ce: 0.005217
iteration 14034 : loss : 0.024143, loss_ce: 0.007851
iteration 14035 : loss : 0.019335, loss_ce: 0.005571
iteration 14036 : loss : 0.026558, loss_ce: 0.009891
iteration 14037 : loss : 0.026915, loss_ce: 0.007735
iteration 14038 : loss : 0.022527, loss_ce: 0.009556
iteration 14039 : loss : 0.022224, loss_ce: 0.003525
iteration 14040 : loss : 0.025687, loss_ce: 0.007457
iteration 14041 : loss : 0.028736, loss_ce: 0.007486
iteration 14042 : loss : 0.022681, loss_ce: 0.006197
iteration 14043 : loss : 0.332520, loss_ce: 0.005412
 76%|█████████████████████▉       | 151/200 [2:17:08<44:39, 54.69s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 14044 : loss : 0.024032, loss_ce: 0.010231
iteration 14045 : loss : 0.025281, loss_ce: 0.010527
iteration 14046 : loss : 0.073395, loss_ce: 0.003264
iteration 14047 : loss : 0.023661, loss_ce: 0.009729
iteration 14048 : loss : 0.021663, loss_ce: 0.009871
iteration 14049 : loss : 0.023700, loss_ce: 0.008900
iteration 14050 : loss : 0.020887, loss_ce: 0.008434
iteration 14051 : loss : 0.022635, loss_ce: 0.008569
iteration 14052 : loss : 0.022214, loss_ce: 0.008528
iteration 14053 : loss : 0.019473, loss_ce: 0.005148
iteration 14054 : loss : 0.020987, loss_ce: 0.010324
iteration 14055 : loss : 0.021725, loss_ce: 0.008369
iteration 14056 : loss : 0.022176, loss_ce: 0.007102
iteration 14057 : loss : 0.074247, loss_ce: 0.008429
iteration 14058 : loss : 0.025842, loss_ce: 0.006239
iteration 14059 : loss : 0.024929, loss_ce: 0.011228
iteration 14060 : loss : 0.020781, loss_ce: 0.004436
iteration 14061 : loss : 0.022341, loss_ce: 0.009486
iteration 14062 : loss : 0.020679, loss_ce: 0.005801
iteration 14063 : loss : 0.022117, loss_ce: 0.006541
iteration 14064 : loss : 0.024957, loss_ce: 0.006466
iteration 14065 : loss : 0.027211, loss_ce: 0.008334
iteration 14066 : loss : 0.023510, loss_ce: 0.006603
iteration 14067 : loss : 0.027073, loss_ce: 0.009386
iteration 14068 : loss : 0.024759, loss_ce: 0.007995
iteration 14069 : loss : 0.021300, loss_ce: 0.006345
iteration 14070 : loss : 0.026858, loss_ce: 0.007910
iteration 14071 : loss : 0.021621, loss_ce: 0.010015
iteration 14072 : loss : 0.021756, loss_ce: 0.006544
iteration 14073 : loss : 0.074503, loss_ce: 0.009795
iteration 14074 : loss : 0.023792, loss_ce: 0.006415
pred_sum 27176
gtsum tensor(27032, device='cuda:0')
iteration 14075 : loss : 0.024242, loss_ce: 0.004886
iteration 14076 : loss : 0.021021, loss_ce: 0.007336
iteration 14077 : loss : 0.075008, loss_ce: 0.004655
iteration 14078 : loss : 0.033435, loss_ce: 0.010551
iteration 14079 : loss : 0.023004, loss_ce: 0.006336
iteration 14080 : loss : 0.024591, loss_ce: 0.008953
iteration 14081 : loss : 0.025452, loss_ce: 0.012374
iteration 14082 : loss : 0.024131, loss_ce: 0.009746
iteration 14083 : loss : 0.021983, loss_ce: 0.006472
iteration 14084 : loss : 0.023249, loss_ce: 0.008657
iteration 14085 : loss : 0.074263, loss_ce: 0.005094
iteration 14086 : loss : 0.022473, loss_ce: 0.006179
iteration 14087 : loss : 0.019836, loss_ce: 0.009806
iteration 14088 : loss : 0.036769, loss_ce: 0.008957
iteration 14089 : loss : 0.024150, loss_ce: 0.005962
iteration 14090 : loss : 0.025060, loss_ce: 0.006572
iteration 14091 : loss : 0.018572, loss_ce: 0.006939
iteration 14092 : loss : 0.022985, loss_ce: 0.007390
iteration 14093 : loss : 0.033827, loss_ce: 0.008948
iteration 14094 : loss : 0.023412, loss_ce: 0.010102
iteration 14095 : loss : 0.023993, loss_ce: 0.005949
iteration 14096 : loss : 0.027921, loss_ce: 0.007587
iteration 14097 : loss : 0.182633, loss_ce: 0.001773
iteration 14098 : loss : 0.019698, loss_ce: 0.007795
iteration 14099 : loss : 0.073310, loss_ce: 0.004690
iteration 14100 : loss : 0.024907, loss_ce: 0.008092
iteration 14101 : loss : 0.020604, loss_ce: 0.006524
iteration 14102 : loss : 0.027152, loss_ce: 0.006287
iteration 14103 : loss : 0.030503, loss_ce: 0.010690
iteration 14104 : loss : 0.020574, loss_ce: 0.005520
iteration 14105 : loss : 0.029406, loss_ce: 0.009090
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 14106 : loss : 0.019570, loss_ce: 0.006195
iteration 14107 : loss : 0.025879, loss_ce: 0.009235
iteration 14108 : loss : 0.027498, loss_ce: 0.008621
iteration 14109 : loss : 0.024673, loss_ce: 0.008786
iteration 14110 : loss : 0.025351, loss_ce: 0.007967
iteration 14111 : loss : 0.023677, loss_ce: 0.009152
iteration 14112 : loss : 0.021362, loss_ce: 0.007853
iteration 14113 : loss : 0.025324, loss_ce: 0.010156
iteration 14114 : loss : 0.021555, loss_ce: 0.006051
iteration 14115 : loss : 0.022568, loss_ce: 0.011356
iteration 14116 : loss : 0.027235, loss_ce: 0.005734
iteration 14117 : loss : 0.074940, loss_ce: 0.006709
iteration 14118 : loss : 0.021763, loss_ce: 0.007410
iteration 14119 : loss : 0.022800, loss_ce: 0.007548
iteration 14120 : loss : 0.022359, loss_ce: 0.006528
iteration 14121 : loss : 0.022427, loss_ce: 0.011352
iteration 14122 : loss : 0.021857, loss_ce: 0.005736
iteration 14123 : loss : 0.023929, loss_ce: 0.009776
iteration 14124 : loss : 0.025631, loss_ce: 0.006330
iteration 14125 : loss : 0.027042, loss_ce: 0.006167
iteration 14126 : loss : 0.025147, loss_ce: 0.010330
iteration 14127 : loss : 0.024912, loss_ce: 0.008473
iteration 14128 : loss : 0.028337, loss_ce: 0.005579
iteration 14129 : loss : 0.024076, loss_ce: 0.008947
iteration 14130 : loss : 0.027910, loss_ce: 0.007469
iteration 14131 : loss : 0.017862, loss_ce: 0.004589
iteration 14132 : loss : 0.020653, loss_ce: 0.007894
iteration 14133 : loss : 0.025865, loss_ce: 0.010090
iteration 14134 : loss : 0.024039, loss_ce: 0.011330
iteration 14135 : loss : 0.021973, loss_ce: 0.009013
iteration 14136 : loss : 0.026594, loss_ce: 0.009286
 76%|██████████████████████       | 152/200 [2:18:03<43:42, 54.64s/it]pred_sum 102
gtsum tensor(94, device='cuda:0')
iteration 14137 : loss : 0.073442, loss_ce: 0.007765
iteration 14138 : loss : 0.019624, loss_ce: 0.004833
iteration 14139 : loss : 0.026084, loss_ce: 0.004552
iteration 14140 : loss : 0.022687, loss_ce: 0.009870
iteration 14141 : loss : 0.025209, loss_ce: 0.008798
iteration 14142 : loss : 0.026037, loss_ce: 0.006862
iteration 14143 : loss : 0.078360, loss_ce: 0.005557
iteration 14144 : loss : 0.022023, loss_ce: 0.006750
iteration 14145 : loss : 0.022248, loss_ce: 0.008371
iteration 14146 : loss : 0.029830, loss_ce: 0.008065
iteration 14147 : loss : 0.025397, loss_ce: 0.008214
iteration 14148 : loss : 0.026019, loss_ce: 0.009064
iteration 14149 : loss : 0.026758, loss_ce: 0.010988
iteration 14150 : loss : 0.024689, loss_ce: 0.013069
iteration 14151 : loss : 0.021025, loss_ce: 0.004931
iteration 14152 : loss : 0.022623, loss_ce: 0.008297
iteration 14153 : loss : 0.021605, loss_ce: 0.008233
iteration 14154 : loss : 0.023427, loss_ce: 0.009920
iteration 14155 : loss : 0.024936, loss_ce: 0.009027
iteration 14156 : loss : 0.021019, loss_ce: 0.006336
iteration 14157 : loss : 0.021200, loss_ce: 0.006638
iteration 14158 : loss : 0.025162, loss_ce: 0.013077
iteration 14159 : loss : 0.074687, loss_ce: 0.005386
iteration 14160 : loss : 0.023521, loss_ce: 0.012637
iteration 14161 : loss : 0.020144, loss_ce: 0.008385
iteration 14162 : loss : 0.028322, loss_ce: 0.005825
iteration 14163 : loss : 0.020977, loss_ce: 0.005710
iteration 14164 : loss : 0.022325, loss_ce: 0.008520
iteration 14165 : loss : 0.023378, loss_ce: 0.011770
iteration 14166 : loss : 0.024342, loss_ce: 0.005830
iteration 14167 : loss : 0.023049, loss_ce: 0.008127
pred_sum 6277
gtsum tensor(6680, device='cuda:0')
iteration 14168 : loss : 0.025838, loss_ce: 0.006020
iteration 14169 : loss : 0.026156, loss_ce: 0.010696
iteration 14170 : loss : 0.022837, loss_ce: 0.006916
iteration 14171 : loss : 0.025041, loss_ce: 0.011604
iteration 14172 : loss : 0.038777, loss_ce: 0.008660
iteration 14173 : loss : 0.021981, loss_ce: 0.006794
iteration 14174 : loss : 0.073670, loss_ce: 0.005227
iteration 14175 : loss : 0.022667, loss_ce: 0.007190
iteration 14176 : loss : 0.024700, loss_ce: 0.009158
iteration 14177 : loss : 0.023679, loss_ce: 0.009309
iteration 14178 : loss : 0.025187, loss_ce: 0.009884
iteration 14179 : loss : 0.075320, loss_ce: 0.005767
iteration 14180 : loss : 0.019857, loss_ce: 0.008254
iteration 14181 : loss : 0.022557, loss_ce: 0.007934
iteration 14182 : loss : 0.077385, loss_ce: 0.004201
iteration 14183 : loss : 0.023543, loss_ce: 0.006423
iteration 14184 : loss : 0.021409, loss_ce: 0.006546
iteration 14185 : loss : 0.049784, loss_ce: 0.008765
iteration 14186 : loss : 0.020417, loss_ce: 0.008289
iteration 14187 : loss : 0.026850, loss_ce: 0.009427
iteration 14188 : loss : 0.026506, loss_ce: 0.010391
iteration 14189 : loss : 0.070663, loss_ce: 0.004649
iteration 14190 : loss : 0.091232, loss_ce: 0.008987
iteration 14191 : loss : 0.073247, loss_ce: 0.004888
iteration 14192 : loss : 0.025178, loss_ce: 0.010759
iteration 14193 : loss : 0.026263, loss_ce: 0.007834
iteration 14194 : loss : 0.021334, loss_ce: 0.006014
iteration 14195 : loss : 0.019529, loss_ce: 0.006200
iteration 14196 : loss : 0.021974, loss_ce: 0.006352
iteration 14197 : loss : 0.022192, loss_ce: 0.008396
iteration 14198 : loss : 0.022034, loss_ce: 0.005573
pred_sum 12306
gtsum tensor(12507, device='cuda:0')
iteration 14199 : loss : 0.022536, loss_ce: 0.008854
iteration 14200 : loss : 0.022585, loss_ce: 0.005619
iteration 14201 : loss : 0.022550, loss_ce: 0.006953
iteration 14202 : loss : 0.023894, loss_ce: 0.009262
iteration 14203 : loss : 0.029367, loss_ce: 0.005949
iteration 14204 : loss : 0.023687, loss_ce: 0.008073
iteration 14205 : loss : 0.024912, loss_ce: 0.008173
iteration 14206 : loss : 0.021003, loss_ce: 0.009811
iteration 14207 : loss : 0.025256, loss_ce: 0.012049
iteration 14208 : loss : 0.074311, loss_ce: 0.005270
iteration 14209 : loss : 0.024667, loss_ce: 0.011722
iteration 14210 : loss : 0.022662, loss_ce: 0.009218
iteration 14211 : loss : 0.078332, loss_ce: 0.003976
iteration 14212 : loss : 0.024064, loss_ce: 0.007705
iteration 14213 : loss : 0.023564, loss_ce: 0.007825
iteration 14214 : loss : 0.021509, loss_ce: 0.009224
iteration 14215 : loss : 0.077171, loss_ce: 0.007787
iteration 14216 : loss : 0.020390, loss_ce: 0.007915
iteration 14217 : loss : 0.024304, loss_ce: 0.008926
iteration 14218 : loss : 0.031885, loss_ce: 0.009051
iteration 14219 : loss : 0.023445, loss_ce: 0.005448
iteration 14220 : loss : 0.023190, loss_ce: 0.007479
iteration 14221 : loss : 0.030100, loss_ce: 0.006384
iteration 14222 : loss : 0.023063, loss_ce: 0.006611
iteration 14223 : loss : 0.034021, loss_ce: 0.007660
iteration 14224 : loss : 0.023506, loss_ce: 0.011137
iteration 14225 : loss : 0.026200, loss_ce: 0.008778
iteration 14226 : loss : 0.023980, loss_ce: 0.006080
iteration 14227 : loss : 0.024318, loss_ce: 0.009365
iteration 14228 : loss : 0.018138, loss_ce: 0.004965
iteration 14229 : loss : 0.231645, loss_ce: 0.006338
 76%|██████████████████████▏      | 153/200 [2:18:57<42:45, 54.59s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 14230 : loss : 0.024760, loss_ce: 0.005919
iteration 14231 : loss : 0.023307, loss_ce: 0.006283
iteration 14232 : loss : 0.023812, loss_ce: 0.007174
iteration 14233 : loss : 0.021161, loss_ce: 0.009491
iteration 14234 : loss : 0.028757, loss_ce: 0.008745
iteration 14235 : loss : 0.023740, loss_ce: 0.009354
iteration 14236 : loss : 0.022996, loss_ce: 0.005157
iteration 14237 : loss : 0.021262, loss_ce: 0.006666
iteration 14238 : loss : 0.023755, loss_ce: 0.009530
iteration 14239 : loss : 0.021901, loss_ce: 0.007533
iteration 14240 : loss : 0.020394, loss_ce: 0.009068
iteration 14241 : loss : 0.022018, loss_ce: 0.007648
iteration 14242 : loss : 0.022806, loss_ce: 0.006427
iteration 14243 : loss : 0.025650, loss_ce: 0.008783
iteration 14244 : loss : 0.022976, loss_ce: 0.009514
iteration 14245 : loss : 0.025985, loss_ce: 0.009856
iteration 14246 : loss : 0.026354, loss_ce: 0.005474
iteration 14247 : loss : 0.022484, loss_ce: 0.005405
iteration 14248 : loss : 0.019023, loss_ce: 0.006103
iteration 14249 : loss : 0.024523, loss_ce: 0.012073
iteration 14250 : loss : 0.022201, loss_ce: 0.009640
iteration 14251 : loss : 0.026089, loss_ce: 0.007957
iteration 14252 : loss : 0.023707, loss_ce: 0.013442
iteration 14253 : loss : 0.022552, loss_ce: 0.009709
iteration 14254 : loss : 0.025787, loss_ce: 0.006698
iteration 14255 : loss : 0.025920, loss_ce: 0.007753
iteration 14256 : loss : 0.024505, loss_ce: 0.008501
iteration 14257 : loss : 0.019672, loss_ce: 0.009153
iteration 14258 : loss : 0.079019, loss_ce: 0.005196
iteration 14259 : loss : 0.024064, loss_ce: 0.006272
iteration 14260 : loss : 0.018242, loss_ce: 0.006383
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 14261 : loss : 0.025401, loss_ce: 0.010030
iteration 14262 : loss : 0.022717, loss_ce: 0.006634
iteration 14263 : loss : 0.022017, loss_ce: 0.009538
iteration 14264 : loss : 0.030066, loss_ce: 0.009312
iteration 14265 : loss : 0.026469, loss_ce: 0.006729
iteration 14266 : loss : 0.029101, loss_ce: 0.007602
iteration 14267 : loss : 0.025168, loss_ce: 0.005480
iteration 14268 : loss : 0.027072, loss_ce: 0.007935
iteration 14269 : loss : 0.024841, loss_ce: 0.006043
iteration 14270 : loss : 0.018248, loss_ce: 0.007393
iteration 14271 : loss : 0.021366, loss_ce: 0.008296
iteration 14272 : loss : 0.024802, loss_ce: 0.004598
iteration 14273 : loss : 0.020509, loss_ce: 0.006789
iteration 14274 : loss : 0.019998, loss_ce: 0.005343
iteration 14275 : loss : 0.022861, loss_ce: 0.009787
iteration 14276 : loss : 0.020596, loss_ce: 0.006945
iteration 14277 : loss : 0.018589, loss_ce: 0.004897
iteration 14278 : loss : 0.024987, loss_ce: 0.004464
iteration 14279 : loss : 0.023862, loss_ce: 0.010459
iteration 14280 : loss : 0.023550, loss_ce: 0.009345
iteration 14281 : loss : 0.024119, loss_ce: 0.007402
iteration 14282 : loss : 0.025903, loss_ce: 0.013280
iteration 14283 : loss : 0.026605, loss_ce: 0.012230
iteration 14284 : loss : 0.024261, loss_ce: 0.005363
iteration 14285 : loss : 0.027933, loss_ce: 0.015452
iteration 14286 : loss : 0.020087, loss_ce: 0.005798
iteration 14287 : loss : 0.023648, loss_ce: 0.008520
iteration 14288 : loss : 0.018803, loss_ce: 0.006558
iteration 14289 : loss : 0.021453, loss_ce: 0.009904
iteration 14290 : loss : 0.018172, loss_ce: 0.007659
iteration 14291 : loss : 0.027012, loss_ce: 0.007252
pred_sum 722
gtsum tensor(657, device='cuda:0')
iteration 14292 : loss : 0.075121, loss_ce: 0.005221
iteration 14293 : loss : 0.020998, loss_ce: 0.007123
iteration 14294 : loss : 0.023949, loss_ce: 0.005554
iteration 14295 : loss : 0.022575, loss_ce: 0.008989
iteration 14296 : loss : 0.072763, loss_ce: 0.004516
iteration 14297 : loss : 0.024431, loss_ce: 0.010070
iteration 14298 : loss : 0.034646, loss_ce: 0.005076
iteration 14299 : loss : 0.022698, loss_ce: 0.006792
iteration 14300 : loss : 0.017258, loss_ce: 0.005326
iteration 14301 : loss : 0.025249, loss_ce: 0.009730
iteration 14302 : loss : 0.021673, loss_ce: 0.006633
iteration 14303 : loss : 0.021331, loss_ce: 0.005235
iteration 14304 : loss : 0.076569, loss_ce: 0.005098
iteration 14305 : loss : 0.029881, loss_ce: 0.005466
iteration 14306 : loss : 0.020540, loss_ce: 0.006383
iteration 14307 : loss : 0.022215, loss_ce: 0.010840
iteration 14308 : loss : 0.022029, loss_ce: 0.009752
iteration 14309 : loss : 0.022213, loss_ce: 0.007333
iteration 14310 : loss : 0.023098, loss_ce: 0.007782
iteration 14311 : loss : 0.021588, loss_ce: 0.006574
iteration 14312 : loss : 0.023052, loss_ce: 0.010739
iteration 14313 : loss : 0.026346, loss_ce: 0.010882
iteration 14314 : loss : 0.026419, loss_ce: 0.009684
iteration 14315 : loss : 0.024126, loss_ce: 0.007463
iteration 14316 : loss : 0.023657, loss_ce: 0.009804
iteration 14317 : loss : 0.020804, loss_ce: 0.009797
iteration 14318 : loss : 0.134862, loss_ce: 0.004364
iteration 14319 : loss : 0.021335, loss_ce: 0.005886
iteration 14320 : loss : 0.022037, loss_ce: 0.006504
iteration 14321 : loss : 0.023847, loss_ce: 0.008437
iteration 14322 : loss : 0.037463, loss_ce: 0.024983
 77%|██████████████████████▎      | 154/200 [2:19:51<41:48, 54.54s/it]pred_sum 44665
gtsum tensor(43981, device='cuda:0')
iteration 14323 : loss : 0.022581, loss_ce: 0.006763
iteration 14324 : loss : 0.025230, loss_ce: 0.009855
iteration 14325 : loss : 0.076881, loss_ce: 0.008077
iteration 14326 : loss : 0.022399, loss_ce: 0.007071
iteration 14327 : loss : 0.026171, loss_ce: 0.011690
iteration 14328 : loss : 0.082050, loss_ce: 0.007018
iteration 14329 : loss : 0.022013, loss_ce: 0.005300
iteration 14330 : loss : 0.029082, loss_ce: 0.004580
iteration 14331 : loss : 0.020553, loss_ce: 0.007203
iteration 14332 : loss : 0.024586, loss_ce: 0.010395
iteration 14333 : loss : 0.021452, loss_ce: 0.008051
iteration 14334 : loss : 0.019039, loss_ce: 0.008520
iteration 14335 : loss : 0.024870, loss_ce: 0.005457
iteration 14336 : loss : 0.023964, loss_ce: 0.009094
iteration 14337 : loss : 0.021334, loss_ce: 0.007551
iteration 14338 : loss : 0.022215, loss_ce: 0.007934
iteration 14339 : loss : 0.022249, loss_ce: 0.006813
iteration 14340 : loss : 0.026123, loss_ce: 0.011776
iteration 14341 : loss : 0.021951, loss_ce: 0.007610
iteration 14342 : loss : 0.021356, loss_ce: 0.007888
iteration 14343 : loss : 0.020741, loss_ce: 0.004870
iteration 14344 : loss : 0.073471, loss_ce: 0.004682
iteration 14345 : loss : 0.020997, loss_ce: 0.004550
iteration 14346 : loss : 0.076142, loss_ce: 0.007583
iteration 14347 : loss : 0.030169, loss_ce: 0.007817
iteration 14348 : loss : 0.024318, loss_ce: 0.007226
iteration 14349 : loss : 0.023490, loss_ce: 0.008333
iteration 14350 : loss : 0.021599, loss_ce: 0.008208
iteration 14351 : loss : 0.024175, loss_ce: 0.007108
iteration 14352 : loss : 0.020847, loss_ce: 0.005401
iteration 14353 : loss : 0.029247, loss_ce: 0.008160
pred_sum 31568
gtsum tensor(31126, device='cuda:0')
iteration 14354 : loss : 0.028389, loss_ce: 0.007000
iteration 14355 : loss : 0.027353, loss_ce: 0.008603
iteration 14356 : loss : 0.022891, loss_ce: 0.009366
iteration 14357 : loss : 0.076090, loss_ce: 0.008191
iteration 14358 : loss : 0.026760, loss_ce: 0.009491
iteration 14359 : loss : 0.026046, loss_ce: 0.005399
iteration 14360 : loss : 0.022128, loss_ce: 0.004657
iteration 14361 : loss : 0.026648, loss_ce: 0.011788
iteration 14362 : loss : 0.026749, loss_ce: 0.004568
iteration 14363 : loss : 0.073210, loss_ce: 0.005739
iteration 14364 : loss : 0.017319, loss_ce: 0.004851
iteration 14365 : loss : 0.023940, loss_ce: 0.004620
iteration 14366 : loss : 0.070637, loss_ce: 0.005357
iteration 14367 : loss : 0.022927, loss_ce: 0.008424
iteration 14368 : loss : 0.020997, loss_ce: 0.007211
iteration 14369 : loss : 0.022757, loss_ce: 0.010122
iteration 14370 : loss : 0.018049, loss_ce: 0.006949
iteration 14371 : loss : 0.022291, loss_ce: 0.006203
iteration 14372 : loss : 0.019820, loss_ce: 0.008187
iteration 14373 : loss : 0.018954, loss_ce: 0.005348
iteration 14374 : loss : 0.022504, loss_ce: 0.004624
iteration 14375 : loss : 0.020148, loss_ce: 0.008088
iteration 14376 : loss : 0.023399, loss_ce: 0.008870
iteration 14377 : loss : 0.020781, loss_ce: 0.008657
iteration 14378 : loss : 0.022755, loss_ce: 0.008222
iteration 14379 : loss : 0.075435, loss_ce: 0.009192
iteration 14380 : loss : 0.075159, loss_ce: 0.008171
iteration 14381 : loss : 0.025169, loss_ce: 0.010142
iteration 14382 : loss : 0.023843, loss_ce: 0.011182
iteration 14383 : loss : 0.026859, loss_ce: 0.009516
iteration 14384 : loss : 0.023689, loss_ce: 0.010078
pred_sum 47810
gtsum tensor(45877, device='cuda:0')
iteration 14385 : loss : 0.030961, loss_ce: 0.008750
iteration 14386 : loss : 0.025624, loss_ce: 0.005426
iteration 14387 : loss : 0.076679, loss_ce: 0.006354
iteration 14388 : loss : 0.022562, loss_ce: 0.012506
iteration 14389 : loss : 0.021788, loss_ce: 0.007851
iteration 14390 : loss : 0.028160, loss_ce: 0.010695
iteration 14391 : loss : 0.069740, loss_ce: 0.003702
iteration 14392 : loss : 0.021691, loss_ce: 0.008266
iteration 14393 : loss : 0.020444, loss_ce: 0.008908
iteration 14394 : loss : 0.022094, loss_ce: 0.006332
iteration 14395 : loss : 0.023404, loss_ce: 0.003814
iteration 14396 : loss : 0.021811, loss_ce: 0.007611
iteration 14397 : loss : 0.029026, loss_ce: 0.012830
iteration 14398 : loss : 0.076831, loss_ce: 0.006961
iteration 14399 : loss : 0.023441, loss_ce: 0.005401
iteration 14400 : loss : 0.024106, loss_ce: 0.010842
iteration 14401 : loss : 0.024011, loss_ce: 0.011293
iteration 14402 : loss : 0.024564, loss_ce: 0.009762
iteration 14403 : loss : 0.071756, loss_ce: 0.005015
iteration 14404 : loss : 0.024892, loss_ce: 0.010824
iteration 14405 : loss : 0.021898, loss_ce: 0.008054
iteration 14406 : loss : 0.022902, loss_ce: 0.010055
iteration 14407 : loss : 0.026910, loss_ce: 0.007800
iteration 14408 : loss : 0.022454, loss_ce: 0.010124
iteration 14409 : loss : 0.025039, loss_ce: 0.009164
iteration 14410 : loss : 0.022244, loss_ce: 0.004439
iteration 14411 : loss : 0.028551, loss_ce: 0.012157
iteration 14412 : loss : 0.022761, loss_ce: 0.006827
iteration 14413 : loss : 0.022705, loss_ce: 0.009359
iteration 14414 : loss : 0.018029, loss_ce: 0.003514
iteration 14415 : loss : 0.332523, loss_ce: 0.001164
 78%|██████████████████████▍      | 155/200 [2:20:46<40:54, 54.54s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 14416 : loss : 0.020612, loss_ce: 0.006367
iteration 14417 : loss : 0.027176, loss_ce: 0.005622
iteration 14418 : loss : 0.028157, loss_ce: 0.004763
iteration 14419 : loss : 0.021052, loss_ce: 0.007951
iteration 14420 : loss : 0.025287, loss_ce: 0.008336
iteration 14421 : loss : 0.020193, loss_ce: 0.006751
iteration 14422 : loss : 0.025361, loss_ce: 0.007584
iteration 14423 : loss : 0.022693, loss_ce: 0.005673
iteration 14424 : loss : 0.022962, loss_ce: 0.008757
iteration 14425 : loss : 0.021680, loss_ce: 0.007826
iteration 14426 : loss : 0.025734, loss_ce: 0.008216
iteration 14427 : loss : 0.025812, loss_ce: 0.014188
iteration 14428 : loss : 0.020665, loss_ce: 0.008325
iteration 14429 : loss : 0.022173, loss_ce: 0.007317
iteration 14430 : loss : 0.025384, loss_ce: 0.008565
iteration 14431 : loss : 0.027457, loss_ce: 0.012686
iteration 14432 : loss : 0.023722, loss_ce: 0.005688
iteration 14433 : loss : 0.018606, loss_ce: 0.007381
iteration 14434 : loss : 0.020333, loss_ce: 0.004657
iteration 14435 : loss : 0.023364, loss_ce: 0.006874
iteration 14436 : loss : 0.020105, loss_ce: 0.008338
iteration 14437 : loss : 0.020837, loss_ce: 0.008721
iteration 14438 : loss : 0.022866, loss_ce: 0.004584
iteration 14439 : loss : 0.022102, loss_ce: 0.006840
iteration 14440 : loss : 0.021961, loss_ce: 0.004717
iteration 14441 : loss : 0.023832, loss_ce: 0.009893
iteration 14442 : loss : 0.024228, loss_ce: 0.005105
iteration 14443 : loss : 0.025129, loss_ce: 0.007741
iteration 14444 : loss : 0.024931, loss_ce: 0.013729
iteration 14445 : loss : 0.023711, loss_ce: 0.006755
iteration 14446 : loss : 0.020815, loss_ce: 0.007556
pred_sum 132
gtsum tensor(138, device='cuda:0')
iteration 14447 : loss : 0.022625, loss_ce: 0.004643
iteration 14448 : loss : 0.023179, loss_ce: 0.008787
iteration 14449 : loss : 0.026940, loss_ce: 0.009970
iteration 14450 : loss : 0.025506, loss_ce: 0.005102
iteration 14451 : loss : 0.075554, loss_ce: 0.010395
iteration 14452 : loss : 0.026927, loss_ce: 0.012055
iteration 14453 : loss : 0.072777, loss_ce: 0.005695
iteration 14454 : loss : 0.022790, loss_ce: 0.006149
iteration 14455 : loss : 0.022893, loss_ce: 0.007377
iteration 14456 : loss : 0.025297, loss_ce: 0.010405
iteration 14457 : loss : 0.021385, loss_ce: 0.004615
iteration 14458 : loss : 0.020793, loss_ce: 0.010481
iteration 14459 : loss : 0.023276, loss_ce: 0.009354
iteration 14460 : loss : 0.022512, loss_ce: 0.007423
iteration 14461 : loss : 0.026089, loss_ce: 0.010728
iteration 14462 : loss : 0.023294, loss_ce: 0.007155
iteration 14463 : loss : 0.019635, loss_ce: 0.006028
iteration 14464 : loss : 0.022855, loss_ce: 0.006252
iteration 14465 : loss : 0.023475, loss_ce: 0.007205
iteration 14466 : loss : 0.024011, loss_ce: 0.011140
iteration 14467 : loss : 0.018945, loss_ce: 0.008336
iteration 14468 : loss : 0.021015, loss_ce: 0.005359
iteration 14469 : loss : 0.019749, loss_ce: 0.006821
iteration 14470 : loss : 0.025741, loss_ce: 0.008356
iteration 14471 : loss : 0.025606, loss_ce: 0.010084
iteration 14472 : loss : 0.020976, loss_ce: 0.005115
iteration 14473 : loss : 0.070632, loss_ce: 0.007107
iteration 14474 : loss : 0.026381, loss_ce: 0.013979
iteration 14475 : loss : 0.025570, loss_ce: 0.009769
iteration 14476 : loss : 0.028335, loss_ce: 0.005975
iteration 14477 : loss : 0.026105, loss_ce: 0.004206
pred_sum 3070
gtsum tensor(2971, device='cuda:0')
iteration 14478 : loss : 0.019809, loss_ce: 0.008785
iteration 14479 : loss : 0.022573, loss_ce: 0.010653
iteration 14480 : loss : 0.023211, loss_ce: 0.005041
iteration 14481 : loss : 0.029592, loss_ce: 0.010626
iteration 14482 : loss : 0.021249, loss_ce: 0.007549
iteration 14483 : loss : 0.020913, loss_ce: 0.006201
iteration 14484 : loss : 0.023686, loss_ce: 0.007026
iteration 14485 : loss : 0.020692, loss_ce: 0.005775
iteration 14486 : loss : 0.022807, loss_ce: 0.005755
iteration 14487 : loss : 0.080935, loss_ce: 0.008047
iteration 14488 : loss : 0.024385, loss_ce: 0.008753
iteration 14489 : loss : 0.018806, loss_ce: 0.007107
iteration 14490 : loss : 0.021028, loss_ce: 0.010532
iteration 14491 : loss : 0.021641, loss_ce: 0.010286
iteration 14492 : loss : 0.023619, loss_ce: 0.008634
iteration 14493 : loss : 0.021970, loss_ce: 0.006465
iteration 14494 : loss : 0.027534, loss_ce: 0.006639
iteration 14495 : loss : 0.024522, loss_ce: 0.009089
iteration 14496 : loss : 0.019891, loss_ce: 0.006441
iteration 14497 : loss : 0.023745, loss_ce: 0.006627
iteration 14498 : loss : 0.023082, loss_ce: 0.007023
iteration 14499 : loss : 0.024903, loss_ce: 0.009776
iteration 14500 : loss : 0.020856, loss_ce: 0.006333
iteration 14501 : loss : 0.020018, loss_ce: 0.008524
iteration 14502 : loss : 0.023863, loss_ce: 0.009148
iteration 14503 : loss : 0.020457, loss_ce: 0.006283
iteration 14504 : loss : 0.022219, loss_ce: 0.006816
iteration 14505 : loss : 0.090305, loss_ce: 0.006162
iteration 14506 : loss : 0.029993, loss_ce: 0.006840
iteration 14507 : loss : 0.018324, loss_ce: 0.006537
iteration 14508 : loss : 0.388717, loss_ce: 0.000809
 78%|██████████████████████▌      | 156/200 [2:21:41<39:59, 54.53s/it]pred_sum 124
gtsum tensor(118, device='cuda:0')
iteration 14509 : loss : 0.041188, loss_ce: 0.007294
iteration 14510 : loss : 0.022636, loss_ce: 0.010248
iteration 14511 : loss : 0.028507, loss_ce: 0.007425
iteration 14512 : loss : 0.079183, loss_ce: 0.006947
iteration 14513 : loss : 0.026824, loss_ce: 0.006421
iteration 14514 : loss : 0.074195, loss_ce: 0.005124
iteration 14515 : loss : 0.023738, loss_ce: 0.007610
iteration 14516 : loss : 0.020053, loss_ce: 0.005651
iteration 14517 : loss : 0.022152, loss_ce: 0.009732
iteration 14518 : loss : 0.021282, loss_ce: 0.009294
iteration 14519 : loss : 0.023701, loss_ce: 0.010954
iteration 14520 : loss : 0.022148, loss_ce: 0.007192
iteration 14521 : loss : 0.025327, loss_ce: 0.007080
iteration 14522 : loss : 0.022075, loss_ce: 0.006850
iteration 14523 : loss : 0.022642, loss_ce: 0.007579
iteration 14524 : loss : 0.017275, loss_ce: 0.007180
iteration 14525 : loss : 0.022058, loss_ce: 0.005646
iteration 14526 : loss : 0.039301, loss_ce: 0.007036
iteration 14527 : loss : 0.018530, loss_ce: 0.007857
iteration 14528 : loss : 0.022394, loss_ce: 0.006215
iteration 14529 : loss : 0.022240, loss_ce: 0.007884
iteration 14530 : loss : 0.019515, loss_ce: 0.005892
iteration 14531 : loss : 0.025991, loss_ce: 0.007172
iteration 14532 : loss : 0.022795, loss_ce: 0.011224
iteration 14533 : loss : 0.021997, loss_ce: 0.006538
iteration 14534 : loss : 0.019980, loss_ce: 0.003387
iteration 14535 : loss : 0.026092, loss_ce: 0.014315
iteration 14536 : loss : 0.021467, loss_ce: 0.007436
iteration 14537 : loss : 0.024190, loss_ce: 0.010067
iteration 14538 : loss : 0.020205, loss_ce: 0.006916
iteration 14539 : loss : 0.023820, loss_ce: 0.005638
pred_sum 44063
gtsum tensor(44638, device='cuda:0')
iteration 14540 : loss : 0.020431, loss_ce: 0.008915
iteration 14541 : loss : 0.031232, loss_ce: 0.011344
iteration 14542 : loss : 0.016782, loss_ce: 0.003633
iteration 14543 : loss : 0.029297, loss_ce: 0.013009
iteration 14544 : loss : 0.048356, loss_ce: 0.005695
iteration 14545 : loss : 0.021618, loss_ce: 0.005652
iteration 14546 : loss : 0.025880, loss_ce: 0.013429
iteration 14547 : loss : 0.025100, loss_ce: 0.007375
iteration 14548 : loss : 0.023601, loss_ce: 0.007208
iteration 14549 : loss : 0.076639, loss_ce: 0.008174
iteration 14550 : loss : 0.020462, loss_ce: 0.007618
iteration 14551 : loss : 0.022236, loss_ce: 0.004492
iteration 14552 : loss : 0.019947, loss_ce: 0.003792
iteration 14553 : loss : 0.021481, loss_ce: 0.005049
iteration 14554 : loss : 0.024978, loss_ce: 0.005707
iteration 14555 : loss : 0.023271, loss_ce: 0.009376
iteration 14556 : loss : 0.020348, loss_ce: 0.006135
iteration 14557 : loss : 0.024900, loss_ce: 0.010897
iteration 14558 : loss : 0.023534, loss_ce: 0.008940
iteration 14559 : loss : 0.021974, loss_ce: 0.009816
iteration 14560 : loss : 0.022607, loss_ce: 0.003595
iteration 14561 : loss : 0.020747, loss_ce: 0.005153
iteration 14562 : loss : 0.021759, loss_ce: 0.009676
iteration 14563 : loss : 0.020856, loss_ce: 0.004914
iteration 14564 : loss : 0.077507, loss_ce: 0.007168
iteration 14565 : loss : 0.024420, loss_ce: 0.006961
iteration 14566 : loss : 0.019055, loss_ce: 0.008743
iteration 14567 : loss : 0.019162, loss_ce: 0.007620
iteration 14568 : loss : 0.029278, loss_ce: 0.005435
iteration 14569 : loss : 0.024863, loss_ce: 0.010125
iteration 14570 : loss : 0.022467, loss_ce: 0.008492
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 14571 : loss : 0.018592, loss_ce: 0.006725
iteration 14572 : loss : 0.022110, loss_ce: 0.010032
iteration 14573 : loss : 0.024969, loss_ce: 0.004583
iteration 14574 : loss : 0.024032, loss_ce: 0.006937
iteration 14575 : loss : 0.027023, loss_ce: 0.008903
iteration 14576 : loss : 0.023403, loss_ce: 0.008936
iteration 14577 : loss : 0.020604, loss_ce: 0.008893
iteration 14578 : loss : 0.023438, loss_ce: 0.009138
iteration 14579 : loss : 0.024030, loss_ce: 0.008306
iteration 14580 : loss : 0.019952, loss_ce: 0.007270
iteration 14581 : loss : 0.022723, loss_ce: 0.007327
iteration 14582 : loss : 0.025268, loss_ce: 0.014372
iteration 14583 : loss : 0.022364, loss_ce: 0.010990
iteration 14584 : loss : 0.020160, loss_ce: 0.006350
iteration 14585 : loss : 0.018417, loss_ce: 0.006085
iteration 14586 : loss : 0.020951, loss_ce: 0.006918
iteration 14587 : loss : 0.026093, loss_ce: 0.010221
iteration 14588 : loss : 0.024346, loss_ce: 0.010301
iteration 14589 : loss : 0.024748, loss_ce: 0.009088
iteration 14590 : loss : 0.020463, loss_ce: 0.005532
iteration 14591 : loss : 0.071517, loss_ce: 0.005361
iteration 14592 : loss : 0.026043, loss_ce: 0.006704
iteration 14593 : loss : 0.018948, loss_ce: 0.007472
iteration 14594 : loss : 0.020611, loss_ce: 0.004152
iteration 14595 : loss : 0.025100, loss_ce: 0.011923
iteration 14596 : loss : 0.077689, loss_ce: 0.012617
iteration 14597 : loss : 0.019836, loss_ce: 0.006848
iteration 14598 : loss : 0.021563, loss_ce: 0.007883
iteration 14599 : loss : 0.017133, loss_ce: 0.003794
iteration 14600 : loss : 0.019820, loss_ce: 0.004132
iteration 14601 : loss : 0.180404, loss_ce: 0.003425
 78%|██████████████████████▊      | 157/200 [2:22:35<39:05, 54.55s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 14602 : loss : 0.073947, loss_ce: 0.007542
iteration 14603 : loss : 0.021658, loss_ce: 0.008317
iteration 14604 : loss : 0.023684, loss_ce: 0.006968
iteration 14605 : loss : 0.021693, loss_ce: 0.011046
iteration 14606 : loss : 0.029056, loss_ce: 0.003573
iteration 14607 : loss : 0.019770, loss_ce: 0.007032
iteration 14608 : loss : 0.030951, loss_ce: 0.007598
iteration 14609 : loss : 0.023859, loss_ce: 0.008891
iteration 14610 : loss : 0.024501, loss_ce: 0.010088
iteration 14611 : loss : 0.070990, loss_ce: 0.003910
iteration 14612 : loss : 0.019982, loss_ce: 0.006670
iteration 14613 : loss : 0.026291, loss_ce: 0.008595
iteration 14614 : loss : 0.024415, loss_ce: 0.005143
iteration 14615 : loss : 0.021776, loss_ce: 0.006433
iteration 14616 : loss : 0.021595, loss_ce: 0.007987
iteration 14617 : loss : 0.024890, loss_ce: 0.006344
iteration 14618 : loss : 0.021266, loss_ce: 0.006275
iteration 14619 : loss : 0.018841, loss_ce: 0.006348
iteration 14620 : loss : 0.025305, loss_ce: 0.006052
iteration 14621 : loss : 0.019018, loss_ce: 0.006140
iteration 14622 : loss : 0.018620, loss_ce: 0.007739
iteration 14623 : loss : 0.026133, loss_ce: 0.009050
iteration 14624 : loss : 0.021555, loss_ce: 0.008966
iteration 14625 : loss : 0.022859, loss_ce: 0.005117
iteration 14626 : loss : 0.022325, loss_ce: 0.011395
iteration 14627 : loss : 0.019742, loss_ce: 0.006055
iteration 14628 : loss : 0.021242, loss_ce: 0.007255
iteration 14629 : loss : 0.022042, loss_ce: 0.009900
iteration 14630 : loss : 0.026929, loss_ce: 0.004359
iteration 14631 : loss : 0.021043, loss_ce: 0.007264
iteration 14632 : loss : 0.018826, loss_ce: 0.006477
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 14633 : loss : 0.024417, loss_ce: 0.007814
iteration 14634 : loss : 0.023134, loss_ce: 0.008003
iteration 14635 : loss : 0.017360, loss_ce: 0.005580
iteration 14636 : loss : 0.023331, loss_ce: 0.007883
iteration 14637 : loss : 0.019826, loss_ce: 0.007188
iteration 14638 : loss : 0.022669, loss_ce: 0.009210
iteration 14639 : loss : 0.020704, loss_ce: 0.007560
iteration 14640 : loss : 0.028427, loss_ce: 0.008427
iteration 14641 : loss : 0.021864, loss_ce: 0.007422
iteration 14642 : loss : 0.020402, loss_ce: 0.006244
iteration 14643 : loss : 0.018651, loss_ce: 0.006317
iteration 14644 : loss : 0.023324, loss_ce: 0.011933
iteration 14645 : loss : 0.026069, loss_ce: 0.010007
iteration 14646 : loss : 0.022612, loss_ce: 0.007496
iteration 14647 : loss : 0.025904, loss_ce: 0.009248
iteration 14648 : loss : 0.023154, loss_ce: 0.006010
iteration 14649 : loss : 0.022341, loss_ce: 0.010760
iteration 14650 : loss : 0.023204, loss_ce: 0.007277
iteration 14651 : loss : 0.023739, loss_ce: 0.008421
iteration 14652 : loss : 0.025797, loss_ce: 0.006720
iteration 14653 : loss : 0.034822, loss_ce: 0.008339
iteration 14654 : loss : 0.022683, loss_ce: 0.008517
iteration 14655 : loss : 0.025077, loss_ce: 0.007093
iteration 14656 : loss : 0.023377, loss_ce: 0.007627
iteration 14657 : loss : 0.020432, loss_ce: 0.007104
iteration 14658 : loss : 0.019670, loss_ce: 0.007323
iteration 14659 : loss : 0.059605, loss_ce: 0.006660
iteration 14660 : loss : 0.022193, loss_ce: 0.007636
iteration 14661 : loss : 0.020516, loss_ce: 0.007554
iteration 14662 : loss : 0.025097, loss_ce: 0.010536
iteration 14663 : loss : 0.023368, loss_ce: 0.008510
pred_sum 12202
gtsum tensor(12246, device='cuda:0')
iteration 14664 : loss : 0.072469, loss_ce: 0.005625
iteration 14665 : loss : 0.023230, loss_ce: 0.009746
iteration 14666 : loss : 0.024905, loss_ce: 0.006626
iteration 14667 : loss : 0.023402, loss_ce: 0.006619
iteration 14668 : loss : 0.027233, loss_ce: 0.011992
iteration 14669 : loss : 0.074658, loss_ce: 0.006069
iteration 14670 : loss : 0.025402, loss_ce: 0.010701
iteration 14671 : loss : 0.024122, loss_ce: 0.010761
iteration 14672 : loss : 0.019106, loss_ce: 0.005624
iteration 14673 : loss : 0.022256, loss_ce: 0.008309
iteration 14674 : loss : 0.021281, loss_ce: 0.008988
iteration 14675 : loss : 0.020957, loss_ce: 0.007467
iteration 14676 : loss : 0.023937, loss_ce: 0.011633
iteration 14677 : loss : 0.029482, loss_ce: 0.008592
iteration 14678 : loss : 0.022855, loss_ce: 0.006788
iteration 14679 : loss : 0.024911, loss_ce: 0.008072
iteration 14680 : loss : 0.025368, loss_ce: 0.005789
iteration 14681 : loss : 0.026899, loss_ce: 0.012013
iteration 14682 : loss : 0.024998, loss_ce: 0.007284
iteration 14683 : loss : 0.026942, loss_ce: 0.010075
iteration 14684 : loss : 0.020754, loss_ce: 0.004877
iteration 14685 : loss : 0.023856, loss_ce: 0.011032
iteration 14686 : loss : 0.021123, loss_ce: 0.008081
iteration 14687 : loss : 0.075737, loss_ce: 0.003958
iteration 14688 : loss : 0.032166, loss_ce: 0.008026
iteration 14689 : loss : 0.026772, loss_ce: 0.005586
iteration 14690 : loss : 0.020051, loss_ce: 0.004248
iteration 14691 : loss : 0.073231, loss_ce: 0.005114
iteration 14692 : loss : 0.023405, loss_ce: 0.006454
iteration 14693 : loss : 0.020831, loss_ce: 0.007457
iteration 14694 : loss : 0.032031, loss_ce: 0.017143
 79%|██████████████████████▉      | 158/200 [2:23:30<38:11, 54.55s/it]pred_sum 8908
gtsum tensor(9325, device='cuda:0')
iteration 14695 : loss : 0.021671, loss_ce: 0.008058
iteration 14696 : loss : 0.021128, loss_ce: 0.008182
iteration 14697 : loss : 0.021921, loss_ce: 0.008642
iteration 14698 : loss : 0.024565, loss_ce: 0.008025
iteration 14699 : loss : 0.026854, loss_ce: 0.010454
iteration 14700 : loss : 0.024629, loss_ce: 0.011223
iteration 14701 : loss : 0.020688, loss_ce: 0.007030
iteration 14702 : loss : 0.019747, loss_ce: 0.007751
iteration 14703 : loss : 0.029151, loss_ce: 0.008508
iteration 14704 : loss : 0.025430, loss_ce: 0.012364
iteration 14705 : loss : 0.019589, loss_ce: 0.005678
iteration 14706 : loss : 0.023747, loss_ce: 0.009832
iteration 14707 : loss : 0.025086, loss_ce: 0.008493
iteration 14708 : loss : 0.075823, loss_ce: 0.006849
iteration 14709 : loss : 0.021061, loss_ce: 0.006598
iteration 14710 : loss : 0.025013, loss_ce: 0.010675
iteration 14711 : loss : 0.023403, loss_ce: 0.003758
iteration 14712 : loss : 0.023343, loss_ce: 0.005564
iteration 14713 : loss : 0.022134, loss_ce: 0.009276
iteration 14714 : loss : 0.021655, loss_ce: 0.007551
iteration 14715 : loss : 0.026402, loss_ce: 0.008677
iteration 14716 : loss : 0.027974, loss_ce: 0.006022
iteration 14717 : loss : 0.022127, loss_ce: 0.011045
iteration 14718 : loss : 0.027982, loss_ce: 0.010417
iteration 14719 : loss : 0.074985, loss_ce: 0.009351
iteration 14720 : loss : 0.074575, loss_ce: 0.006399
iteration 14721 : loss : 0.019407, loss_ce: 0.004790
iteration 14722 : loss : 0.024211, loss_ce: 0.007694
iteration 14723 : loss : 0.025055, loss_ce: 0.005474
iteration 14724 : loss : 0.021371, loss_ce: 0.008534
iteration 14725 : loss : 0.024428, loss_ce: 0.007796
pred_sum 588
gtsum tensor(612, device='cuda:0')
iteration 14726 : loss : 0.020263, loss_ce: 0.005284
iteration 14727 : loss : 0.028612, loss_ce: 0.009970
iteration 14728 : loss : 0.021788, loss_ce: 0.009506
iteration 14729 : loss : 0.021102, loss_ce: 0.007275
iteration 14730 : loss : 0.020176, loss_ce: 0.007493
iteration 14731 : loss : 0.022454, loss_ce: 0.008441
iteration 14732 : loss : 0.020240, loss_ce: 0.008945
iteration 14733 : loss : 0.022569, loss_ce: 0.004112
iteration 14734 : loss : 0.023336, loss_ce: 0.009484
iteration 14735 : loss : 0.022966, loss_ce: 0.007035
iteration 14736 : loss : 0.021141, loss_ce: 0.010377
iteration 14737 : loss : 0.019138, loss_ce: 0.007180
iteration 14738 : loss : 0.032624, loss_ce: 0.004959
iteration 14739 : loss : 0.023414, loss_ce: 0.007673
iteration 14740 : loss : 0.025128, loss_ce: 0.007134
iteration 14741 : loss : 0.027604, loss_ce: 0.006816
iteration 14742 : loss : 0.020911, loss_ce: 0.007543
iteration 14743 : loss : 0.021995, loss_ce: 0.009705
iteration 14744 : loss : 0.022075, loss_ce: 0.008699
iteration 14745 : loss : 0.021551, loss_ce: 0.004373
iteration 14746 : loss : 0.020363, loss_ce: 0.006175
iteration 14747 : loss : 0.018664, loss_ce: 0.005285
iteration 14748 : loss : 0.021516, loss_ce: 0.007897
iteration 14749 : loss : 0.021475, loss_ce: 0.009257
iteration 14750 : loss : 0.026397, loss_ce: 0.006074
iteration 14751 : loss : 0.066604, loss_ce: 0.004904
iteration 14752 : loss : 0.019211, loss_ce: 0.006293
iteration 14753 : loss : 0.031896, loss_ce: 0.004509
iteration 14754 : loss : 0.073119, loss_ce: 0.006354
iteration 14755 : loss : 0.026279, loss_ce: 0.009193
iteration 14756 : loss : 0.024401, loss_ce: 0.008429
pred_sum 258
gtsum tensor(333, device='cuda:0')
iteration 14757 : loss : 0.022815, loss_ce: 0.008137
iteration 14758 : loss : 0.025517, loss_ce: 0.007735
iteration 14759 : loss : 0.023706, loss_ce: 0.008223
iteration 14760 : loss : 0.027155, loss_ce: 0.010209
iteration 14761 : loss : 0.021464, loss_ce: 0.010810
iteration 14762 : loss : 0.023166, loss_ce: 0.008725
iteration 14763 : loss : 0.026883, loss_ce: 0.006447
iteration 14764 : loss : 0.023327, loss_ce: 0.007011
iteration 14765 : loss : 0.020906, loss_ce: 0.004388
iteration 14766 : loss : 0.025012, loss_ce: 0.009358
iteration 14767 : loss : 0.019425, loss_ce: 0.004714
iteration 14768 : loss : 0.026180, loss_ce: 0.007096
iteration 14769 : loss : 0.021294, loss_ce: 0.009797
iteration 14770 : loss : 0.022992, loss_ce: 0.005299
iteration 14771 : loss : 0.021372, loss_ce: 0.007463
iteration 14772 : loss : 0.021370, loss_ce: 0.008118
iteration 14773 : loss : 0.024290, loss_ce: 0.009232
iteration 14774 : loss : 0.025290, loss_ce: 0.011689
iteration 14775 : loss : 0.021141, loss_ce: 0.007867
iteration 14776 : loss : 0.021997, loss_ce: 0.009404
iteration 14777 : loss : 0.022354, loss_ce: 0.007624
iteration 14778 : loss : 0.022021, loss_ce: 0.008106
iteration 14779 : loss : 0.026338, loss_ce: 0.010573
iteration 14780 : loss : 0.024421, loss_ce: 0.005767
iteration 14781 : loss : 0.025454, loss_ce: 0.004215
iteration 14782 : loss : 0.021264, loss_ce: 0.010480
iteration 14783 : loss : 0.074172, loss_ce: 0.002332
iteration 14784 : loss : 0.056672, loss_ce: 0.005089
iteration 14785 : loss : 0.025178, loss_ce: 0.009085
iteration 14786 : loss : 0.020078, loss_ce: 0.004888
iteration 14787 : loss : 0.334583, loss_ce: 0.001920
 80%|███████████████████████      | 159/200 [2:24:24<37:15, 54.52s/it]pred_sum 5811
gtsum tensor(5803, device='cuda:0')
iteration 14788 : loss : 0.025136, loss_ce: 0.008955
iteration 14789 : loss : 0.022947, loss_ce: 0.005593
iteration 14790 : loss : 0.025843, loss_ce: 0.007408
iteration 14791 : loss : 0.041488, loss_ce: 0.005343
iteration 14792 : loss : 0.020678, loss_ce: 0.006989
iteration 14793 : loss : 0.023721, loss_ce: 0.007898
iteration 14794 : loss : 0.022362, loss_ce: 0.009504
iteration 14795 : loss : 0.018803, loss_ce: 0.006275
iteration 14796 : loss : 0.030501, loss_ce: 0.007317
iteration 14797 : loss : 0.025740, loss_ce: 0.009152
iteration 14798 : loss : 0.079295, loss_ce: 0.006730
iteration 14799 : loss : 0.025386, loss_ce: 0.007043
iteration 14800 : loss : 0.074768, loss_ce: 0.005610
iteration 14801 : loss : 0.024357, loss_ce: 0.007468
iteration 14802 : loss : 0.022343, loss_ce: 0.007991
iteration 14803 : loss : 0.028327, loss_ce: 0.004724
iteration 14804 : loss : 0.021626, loss_ce: 0.007634
iteration 14805 : loss : 0.034691, loss_ce: 0.011758
iteration 14806 : loss : 0.030166, loss_ce: 0.006485
iteration 14807 : loss : 0.024056, loss_ce: 0.008213
iteration 14808 : loss : 0.023219, loss_ce: 0.008898
iteration 14809 : loss : 0.021073, loss_ce: 0.007993
iteration 14810 : loss : 0.026144, loss_ce: 0.006812
iteration 14811 : loss : 0.023319, loss_ce: 0.004848
iteration 14812 : loss : 0.023649, loss_ce: 0.009330
iteration 14813 : loss : 0.018557, loss_ce: 0.007900
iteration 14814 : loss : 0.025127, loss_ce: 0.006818
iteration 14815 : loss : 0.027302, loss_ce: 0.011268
iteration 14816 : loss : 0.026754, loss_ce: 0.010966
iteration 14817 : loss : 0.074275, loss_ce: 0.006492
iteration 14818 : loss : 0.027539, loss_ce: 0.006265
pred_sum 6949
gtsum tensor(6712, device='cuda:0')
iteration 14819 : loss : 0.020641, loss_ce: 0.006516
iteration 14820 : loss : 0.023993, loss_ce: 0.007922
iteration 14821 : loss : 0.019868, loss_ce: 0.007133
iteration 14822 : loss : 0.019401, loss_ce: 0.007094
iteration 14823 : loss : 0.024958, loss_ce: 0.008271
iteration 14824 : loss : 0.024464, loss_ce: 0.006176
iteration 14825 : loss : 0.022265, loss_ce: 0.007243
iteration 14826 : loss : 0.020832, loss_ce: 0.004510
iteration 14827 : loss : 0.019939, loss_ce: 0.008022
iteration 14828 : loss : 0.023574, loss_ce: 0.008672
iteration 14829 : loss : 0.024458, loss_ce: 0.011384
iteration 14830 : loss : 0.024021, loss_ce: 0.006753
iteration 14831 : loss : 0.020707, loss_ce: 0.008300
iteration 14832 : loss : 0.020543, loss_ce: 0.006175
iteration 14833 : loss : 0.026284, loss_ce: 0.008591
iteration 14834 : loss : 0.025018, loss_ce: 0.005850
iteration 14835 : loss : 0.017772, loss_ce: 0.004796
iteration 14836 : loss : 0.024196, loss_ce: 0.013761
iteration 14837 : loss : 0.074990, loss_ce: 0.007683
iteration 14838 : loss : 0.038197, loss_ce: 0.006447
iteration 14839 : loss : 0.022666, loss_ce: 0.010472
iteration 14840 : loss : 0.026833, loss_ce: 0.009189
iteration 14841 : loss : 0.023776, loss_ce: 0.007284
iteration 14842 : loss : 0.073604, loss_ce: 0.008252
iteration 14843 : loss : 0.024888, loss_ce: 0.012654
iteration 14844 : loss : 0.024436, loss_ce: 0.005151
iteration 14845 : loss : 0.072014, loss_ce: 0.007625
iteration 14846 : loss : 0.020374, loss_ce: 0.005909
iteration 14847 : loss : 0.022633, loss_ce: 0.011893
iteration 14848 : loss : 0.022394, loss_ce: 0.005352
iteration 14849 : loss : 0.021879, loss_ce: 0.008143
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 14850 : loss : 0.030351, loss_ce: 0.004822
iteration 14851 : loss : 0.023170, loss_ce: 0.009691
iteration 14852 : loss : 0.023106, loss_ce: 0.008099
iteration 14853 : loss : 0.024968, loss_ce: 0.007871
iteration 14854 : loss : 0.024189, loss_ce: 0.007890
iteration 14855 : loss : 0.025627, loss_ce: 0.010549
iteration 14856 : loss : 0.021636, loss_ce: 0.006562
iteration 14857 : loss : 0.022721, loss_ce: 0.004212
iteration 14858 : loss : 0.022116, loss_ce: 0.007584
iteration 14859 : loss : 0.072747, loss_ce: 0.005943
iteration 14860 : loss : 0.026329, loss_ce: 0.011211
iteration 14861 : loss : 0.024491, loss_ce: 0.012837
iteration 14862 : loss : 0.030633, loss_ce: 0.006972
iteration 14863 : loss : 0.028536, loss_ce: 0.005903
iteration 14864 : loss : 0.073317, loss_ce: 0.005100
iteration 14865 : loss : 0.023437, loss_ce: 0.009882
iteration 14866 : loss : 0.020591, loss_ce: 0.004691
iteration 14867 : loss : 0.025790, loss_ce: 0.011076
iteration 14868 : loss : 0.024413, loss_ce: 0.008398
iteration 14869 : loss : 0.020197, loss_ce: 0.006905
iteration 14870 : loss : 0.024995, loss_ce: 0.009572
iteration 14871 : loss : 0.022355, loss_ce: 0.008526
iteration 14872 : loss : 0.019987, loss_ce: 0.008652
iteration 14873 : loss : 0.021485, loss_ce: 0.009622
iteration 14874 : loss : 0.026546, loss_ce: 0.008283
iteration 14875 : loss : 0.024618, loss_ce: 0.008237
iteration 14876 : loss : 0.022365, loss_ce: 0.009829
iteration 14877 : loss : 0.023419, loss_ce: 0.004961
iteration 14878 : loss : 0.023933, loss_ce: 0.005568
iteration 14879 : loss : 0.026324, loss_ce: 0.008350
iteration 14880 : loss : 0.031629, loss_ce: 0.025576
 80%|███████████████████████▏     | 160/200 [2:25:19<36:19, 54.49s/it]pred_sum 70043
gtsum tensor(72550, device='cuda:0')
iteration 14881 : loss : 0.022537, loss_ce: 0.008508
iteration 14882 : loss : 0.032817, loss_ce: 0.010793
iteration 14883 : loss : 0.022610, loss_ce: 0.009783
iteration 14884 : loss : 0.029309, loss_ce: 0.005412
iteration 14885 : loss : 0.075066, loss_ce: 0.009077
iteration 14886 : loss : 0.024506, loss_ce: 0.012213
iteration 14887 : loss : 0.018460, loss_ce: 0.004342
iteration 14888 : loss : 0.027001, loss_ce: 0.011522
iteration 14889 : loss : 0.073761, loss_ce: 0.006812
iteration 14890 : loss : 0.018410, loss_ce: 0.004607
iteration 14891 : loss : 0.026235, loss_ce: 0.008920
iteration 14892 : loss : 0.023258, loss_ce: 0.006424
iteration 14893 : loss : 0.021642, loss_ce: 0.007184
iteration 14894 : loss : 0.022760, loss_ce: 0.006698
iteration 14895 : loss : 0.020190, loss_ce: 0.007023
iteration 14896 : loss : 0.017599, loss_ce: 0.005522
iteration 14897 : loss : 0.023418, loss_ce: 0.011718
iteration 14898 : loss : 0.022317, loss_ce: 0.008932
iteration 14899 : loss : 0.021302, loss_ce: 0.006370
iteration 14900 : loss : 0.022497, loss_ce: 0.005635
iteration 14901 : loss : 0.073109, loss_ce: 0.004220
iteration 14902 : loss : 0.021495, loss_ce: 0.007246
iteration 14903 : loss : 0.019836, loss_ce: 0.006836
iteration 14904 : loss : 0.024418, loss_ce: 0.005912
iteration 14905 : loss : 0.023542, loss_ce: 0.010131
iteration 14906 : loss : 0.021005, loss_ce: 0.005996
iteration 14907 : loss : 0.021279, loss_ce: 0.005577
iteration 14908 : loss : 0.025935, loss_ce: 0.007216
iteration 14909 : loss : 0.024813, loss_ce: 0.008602
iteration 14910 : loss : 0.021052, loss_ce: 0.008609
iteration 14911 : loss : 0.019353, loss_ce: 0.006876
pred_sum 7206
gtsum tensor(7227, device='cuda:0')
iteration 14912 : loss : 0.024469, loss_ce: 0.010514
iteration 14913 : loss : 0.018585, loss_ce: 0.005458
iteration 14914 : loss : 0.022842, loss_ce: 0.007747
iteration 14915 : loss : 0.123548, loss_ce: 0.005281
iteration 14916 : loss : 0.021272, loss_ce: 0.006307
iteration 14917 : loss : 0.022908, loss_ce: 0.007299
iteration 14918 : loss : 0.022164, loss_ce: 0.005531
iteration 14919 : loss : 0.076278, loss_ce: 0.009892
iteration 14920 : loss : 0.024212, loss_ce: 0.008204
iteration 14921 : loss : 0.026921, loss_ce: 0.014137
iteration 14922 : loss : 0.022557, loss_ce: 0.008106
iteration 14923 : loss : 0.020553, loss_ce: 0.006771
iteration 14924 : loss : 0.028553, loss_ce: 0.008106
iteration 14925 : loss : 0.021040, loss_ce: 0.005114
iteration 14926 : loss : 0.021468, loss_ce: 0.006169
iteration 14927 : loss : 0.022815, loss_ce: 0.008315
iteration 14928 : loss : 0.023069, loss_ce: 0.004314
iteration 14929 : loss : 0.023033, loss_ce: 0.007175
iteration 14930 : loss : 0.026705, loss_ce: 0.009430
iteration 14931 : loss : 0.024944, loss_ce: 0.010360
iteration 14932 : loss : 0.019349, loss_ce: 0.006774
iteration 14933 : loss : 0.020720, loss_ce: 0.005150
iteration 14934 : loss : 0.022945, loss_ce: 0.004081
iteration 14935 : loss : 0.021250, loss_ce: 0.006792
iteration 14936 : loss : 0.027293, loss_ce: 0.011167
iteration 14937 : loss : 0.022868, loss_ce: 0.004052
iteration 14938 : loss : 0.025895, loss_ce: 0.004402
iteration 14939 : loss : 0.021809, loss_ce: 0.009860
iteration 14940 : loss : 0.017056, loss_ce: 0.004148
iteration 14941 : loss : 0.018099, loss_ce: 0.003136
iteration 14942 : loss : 0.021387, loss_ce: 0.009690
pred_sum 7980
gtsum tensor(7788, device='cuda:0')
iteration 14943 : loss : 0.021672, loss_ce: 0.009850
iteration 14944 : loss : 0.020373, loss_ce: 0.006134
iteration 14945 : loss : 0.023377, loss_ce: 0.009120
iteration 14946 : loss : 0.023404, loss_ce: 0.009976
iteration 14947 : loss : 0.027448, loss_ce: 0.008930
iteration 14948 : loss : 0.025018, loss_ce: 0.006777
iteration 14949 : loss : 0.027311, loss_ce: 0.008413
iteration 14950 : loss : 0.025463, loss_ce: 0.008369
iteration 14951 : loss : 0.018881, loss_ce: 0.005443
iteration 14952 : loss : 0.022620, loss_ce: 0.008516
iteration 14953 : loss : 0.022496, loss_ce: 0.008169
iteration 14954 : loss : 0.027525, loss_ce: 0.006139
iteration 14955 : loss : 0.017537, loss_ce: 0.006463
iteration 14956 : loss : 0.021131, loss_ce: 0.007005
iteration 14957 : loss : 0.024918, loss_ce: 0.009340
iteration 14958 : loss : 0.022987, loss_ce: 0.010211
iteration 14959 : loss : 0.021739, loss_ce: 0.010161
iteration 14960 : loss : 0.021367, loss_ce: 0.010147
iteration 14961 : loss : 0.081840, loss_ce: 0.005392
iteration 14962 : loss : 0.063705, loss_ce: 0.005456
iteration 14963 : loss : 0.024975, loss_ce: 0.006117
iteration 14964 : loss : 0.028746, loss_ce: 0.014196
iteration 14965 : loss : 0.024773, loss_ce: 0.006091
iteration 14966 : loss : 0.024300, loss_ce: 0.010264
iteration 14967 : loss : 0.022137, loss_ce: 0.008683
iteration 14968 : loss : 0.021818, loss_ce: 0.010014
iteration 14969 : loss : 0.024704, loss_ce: 0.006696
iteration 14970 : loss : 0.022807, loss_ce: 0.009428
iteration 14971 : loss : 0.022625, loss_ce: 0.008457
iteration 14972 : loss : 0.030539, loss_ce: 0.009410
iteration 14973 : loss : 0.392067, loss_ce: 0.003352
 80%|███████████████████████▎     | 161/200 [2:26:13<35:25, 54.50s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 14974 : loss : 0.024201, loss_ce: 0.014740
iteration 14975 : loss : 0.018651, loss_ce: 0.004802
iteration 14976 : loss : 0.019140, loss_ce: 0.006454
iteration 14977 : loss : 0.021474, loss_ce: 0.010275
iteration 14978 : loss : 0.023196, loss_ce: 0.007912
iteration 14979 : loss : 0.021328, loss_ce: 0.008588
iteration 14980 : loss : 0.023689, loss_ce: 0.008313
iteration 14981 : loss : 0.073254, loss_ce: 0.005038
iteration 14982 : loss : 0.023362, loss_ce: 0.005401
iteration 14983 : loss : 0.025090, loss_ce: 0.007812
iteration 14984 : loss : 0.022167, loss_ce: 0.008058
iteration 14985 : loss : 0.021166, loss_ce: 0.009033
iteration 14986 : loss : 0.019103, loss_ce: 0.005944
iteration 14987 : loss : 0.024727, loss_ce: 0.010794
iteration 14988 : loss : 0.019811, loss_ce: 0.007075
iteration 14989 : loss : 0.024981, loss_ce: 0.008428
iteration 14990 : loss : 0.023032, loss_ce: 0.005334
iteration 14991 : loss : 0.024159, loss_ce: 0.007771
iteration 14992 : loss : 0.026345, loss_ce: 0.006464
iteration 14993 : loss : 0.025117, loss_ce: 0.006376
iteration 14994 : loss : 0.017858, loss_ce: 0.006084
iteration 14995 : loss : 0.022164, loss_ce: 0.007111
iteration 14996 : loss : 0.017998, loss_ce: 0.005628
iteration 14997 : loss : 0.025562, loss_ce: 0.008193
iteration 14998 : loss : 0.022921, loss_ce: 0.006985
iteration 14999 : loss : 0.024327, loss_ce: 0.014141
iteration 15000 : loss : 0.025522, loss_ce: 0.007846
iteration 15001 : loss : 0.025668, loss_ce: 0.007131
iteration 15002 : loss : 0.041650, loss_ce: 0.007138
iteration 15003 : loss : 0.020427, loss_ce: 0.006510
iteration 15004 : loss : 0.017479, loss_ce: 0.005122
pred_sum 2124
gtsum tensor(2091, device='cuda:0')
iteration 15005 : loss : 0.022274, loss_ce: 0.009885
iteration 15006 : loss : 0.023105, loss_ce: 0.009249
iteration 15007 : loss : 0.020507, loss_ce: 0.007922
iteration 15008 : loss : 0.032278, loss_ce: 0.004875
iteration 15009 : loss : 0.076595, loss_ce: 0.008634
iteration 15010 : loss : 0.024300, loss_ce: 0.008859
iteration 15011 : loss : 0.021738, loss_ce: 0.006393
iteration 15012 : loss : 0.027346, loss_ce: 0.008142
iteration 15013 : loss : 0.081117, loss_ce: 0.006424
iteration 15014 : loss : 0.018572, loss_ce: 0.004617
iteration 15015 : loss : 0.021492, loss_ce: 0.006479
iteration 15016 : loss : 0.023364, loss_ce: 0.007098
iteration 15017 : loss : 0.069278, loss_ce: 0.002285
iteration 15018 : loss : 0.021639, loss_ce: 0.008466
iteration 15019 : loss : 0.021683, loss_ce: 0.007992
iteration 15020 : loss : 0.020678, loss_ce: 0.009575
iteration 15021 : loss : 0.021968, loss_ce: 0.008404
iteration 15022 : loss : 0.020195, loss_ce: 0.007529
iteration 15023 : loss : 0.019926, loss_ce: 0.008299
iteration 15024 : loss : 0.018874, loss_ce: 0.007392
iteration 15025 : loss : 0.028351, loss_ce: 0.009025
iteration 15026 : loss : 0.020272, loss_ce: 0.007093
iteration 15027 : loss : 0.027017, loss_ce: 0.007059
iteration 15028 : loss : 0.022839, loss_ce: 0.008326
iteration 15029 : loss : 0.023259, loss_ce: 0.004846
iteration 15030 : loss : 0.025618, loss_ce: 0.006432
iteration 15031 : loss : 0.021904, loss_ce: 0.006793
iteration 15032 : loss : 0.022117, loss_ce: 0.006778
iteration 15033 : loss : 0.019147, loss_ce: 0.006142
iteration 15034 : loss : 0.023647, loss_ce: 0.005239
iteration 15035 : loss : 0.021564, loss_ce: 0.008668
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 15036 : loss : 0.020882, loss_ce: 0.007411
iteration 15037 : loss : 0.022531, loss_ce: 0.005927
iteration 15038 : loss : 0.024747, loss_ce: 0.007600
iteration 15039 : loss : 0.022099, loss_ce: 0.007884
iteration 15040 : loss : 0.024329, loss_ce: 0.011771
iteration 15041 : loss : 0.022142, loss_ce: 0.006985
iteration 15042 : loss : 0.024682, loss_ce: 0.007556
iteration 15043 : loss : 0.019545, loss_ce: 0.007075
iteration 15044 : loss : 0.026590, loss_ce: 0.009361
iteration 15045 : loss : 0.021960, loss_ce: 0.005855
iteration 15046 : loss : 0.023410, loss_ce: 0.008840
iteration 15047 : loss : 0.021829, loss_ce: 0.006696
iteration 15048 : loss : 0.023972, loss_ce: 0.009724
iteration 15049 : loss : 0.019602, loss_ce: 0.005919
iteration 15050 : loss : 0.026212, loss_ce: 0.010813
iteration 15051 : loss : 0.022927, loss_ce: 0.009850
iteration 15052 : loss : 0.020619, loss_ce: 0.006918
iteration 15053 : loss : 0.022160, loss_ce: 0.006234
iteration 15054 : loss : 0.023248, loss_ce: 0.011374
iteration 15055 : loss : 0.022128, loss_ce: 0.008209
iteration 15056 : loss : 0.020591, loss_ce: 0.004740
iteration 15057 : loss : 0.023625, loss_ce: 0.010472
iteration 15058 : loss : 0.023038, loss_ce: 0.006175
iteration 15059 : loss : 0.026386, loss_ce: 0.007237
iteration 15060 : loss : 0.024297, loss_ce: 0.010659
iteration 15061 : loss : 0.023277, loss_ce: 0.011954
iteration 15062 : loss : 0.021966, loss_ce: 0.005607
iteration 15063 : loss : 0.020106, loss_ce: 0.006881
iteration 15064 : loss : 0.023517, loss_ce: 0.009486
iteration 15065 : loss : 0.020485, loss_ce: 0.006068
iteration 15066 : loss : 0.082857, loss_ce: 0.011307
 81%|███████████████████████▍     | 162/200 [2:27:08<34:30, 54.49s/it]pred_sum 33313
gtsum tensor(31284, device='cuda:0')
iteration 15067 : loss : 0.020338, loss_ce: 0.007089
iteration 15068 : loss : 0.023122, loss_ce: 0.004810
iteration 15069 : loss : 0.023855, loss_ce: 0.012202
iteration 15070 : loss : 0.023632, loss_ce: 0.005852
iteration 15071 : loss : 0.023325, loss_ce: 0.007409
iteration 15072 : loss : 0.022750, loss_ce: 0.009116
iteration 15073 : loss : 0.022474, loss_ce: 0.007390
iteration 15074 : loss : 0.019078, loss_ce: 0.005537
iteration 15075 : loss : 0.020518, loss_ce: 0.007249
iteration 15076 : loss : 0.019656, loss_ce: 0.004654
iteration 15077 : loss : 0.020900, loss_ce: 0.006817
iteration 15078 : loss : 0.022020, loss_ce: 0.005074
iteration 15079 : loss : 0.027600, loss_ce: 0.011368
iteration 15080 : loss : 0.030915, loss_ce: 0.010062
iteration 15081 : loss : 0.025476, loss_ce: 0.006951
iteration 15082 : loss : 0.022796, loss_ce: 0.006945
iteration 15083 : loss : 0.025182, loss_ce: 0.012153
iteration 15084 : loss : 0.020512, loss_ce: 0.007348
iteration 15085 : loss : 0.017212, loss_ce: 0.004559
iteration 15086 : loss : 0.018244, loss_ce: 0.004489
iteration 15087 : loss : 0.019188, loss_ce: 0.006017
iteration 15088 : loss : 0.022000, loss_ce: 0.008523
iteration 15089 : loss : 0.025337, loss_ce: 0.008079
iteration 15090 : loss : 0.075211, loss_ce: 0.007510
iteration 15091 : loss : 0.024347, loss_ce: 0.007722
iteration 15092 : loss : 0.021356, loss_ce: 0.006448
iteration 15093 : loss : 0.023350, loss_ce: 0.010778
iteration 15094 : loss : 0.029447, loss_ce: 0.011872
iteration 15095 : loss : 0.021040, loss_ce: 0.008288
iteration 15096 : loss : 0.073660, loss_ce: 0.006189
iteration 15097 : loss : 0.020196, loss_ce: 0.007218
pred_sum 68905
gtsum tensor(68257, device='cuda:0')
iteration 15098 : loss : 0.022885, loss_ce: 0.007678
iteration 15099 : loss : 0.020361, loss_ce: 0.008237
iteration 15100 : loss : 0.020237, loss_ce: 0.005468
iteration 15101 : loss : 0.032517, loss_ce: 0.005983
iteration 15102 : loss : 0.022051, loss_ce: 0.007997
iteration 15103 : loss : 0.024150, loss_ce: 0.008653
iteration 15104 : loss : 0.024762, loss_ce: 0.007176
iteration 15105 : loss : 0.072070, loss_ce: 0.005737
iteration 15106 : loss : 0.025805, loss_ce: 0.007918
iteration 15107 : loss : 0.026596, loss_ce: 0.011965
iteration 15108 : loss : 0.024227, loss_ce: 0.010734
iteration 15109 : loss : 0.085297, loss_ce: 0.006995
iteration 15110 : loss : 0.022139, loss_ce: 0.008104
iteration 15111 : loss : 0.024804, loss_ce: 0.006128
iteration 15112 : loss : 0.026420, loss_ce: 0.010804
iteration 15113 : loss : 0.019469, loss_ce: 0.006558
iteration 15114 : loss : 0.021392, loss_ce: 0.008096
iteration 15115 : loss : 0.023408, loss_ce: 0.009464
iteration 15116 : loss : 0.022133, loss_ce: 0.008338
iteration 15117 : loss : 0.025187, loss_ce: 0.009411
iteration 15118 : loss : 0.080012, loss_ce: 0.004876
iteration 15119 : loss : 0.022107, loss_ce: 0.008909
iteration 15120 : loss : 0.021887, loss_ce: 0.008352
iteration 15121 : loss : 0.026018, loss_ce: 0.008779
iteration 15122 : loss : 0.018338, loss_ce: 0.004408
iteration 15123 : loss : 0.022114, loss_ce: 0.007423
iteration 15124 : loss : 0.032571, loss_ce: 0.006669
iteration 15125 : loss : 0.022474, loss_ce: 0.006921
iteration 15126 : loss : 0.020805, loss_ce: 0.006983
iteration 15127 : loss : 0.024044, loss_ce: 0.003086
iteration 15128 : loss : 0.023469, loss_ce: 0.006708
pred_sum 46684
gtsum tensor(48276, device='cuda:0')
iteration 15129 : loss : 0.023679, loss_ce: 0.009449
iteration 15130 : loss : 0.024246, loss_ce: 0.006489
iteration 15131 : loss : 0.023365, loss_ce: 0.006985
iteration 15132 : loss : 0.023075, loss_ce: 0.008288
iteration 15133 : loss : 0.021340, loss_ce: 0.005286
iteration 15134 : loss : 0.025522, loss_ce: 0.013205
iteration 15135 : loss : 0.024005, loss_ce: 0.007449
iteration 15136 : loss : 0.021512, loss_ce: 0.005150
iteration 15137 : loss : 0.022935, loss_ce: 0.007960
iteration 15138 : loss : 0.024740, loss_ce: 0.006187
iteration 15139 : loss : 0.021231, loss_ce: 0.008825
iteration 15140 : loss : 0.025629, loss_ce: 0.009980
iteration 15141 : loss : 0.025643, loss_ce: 0.010023
iteration 15142 : loss : 0.022614, loss_ce: 0.010626
iteration 15143 : loss : 0.025846, loss_ce: 0.005147
iteration 15144 : loss : 0.023653, loss_ce: 0.007808
iteration 15145 : loss : 0.022540, loss_ce: 0.007540
iteration 15146 : loss : 0.027488, loss_ce: 0.009114
iteration 15147 : loss : 0.019974, loss_ce: 0.007285
iteration 15148 : loss : 0.023749, loss_ce: 0.010886
iteration 15149 : loss : 0.024116, loss_ce: 0.010656
iteration 15150 : loss : 0.021727, loss_ce: 0.009577
iteration 15151 : loss : 0.022759, loss_ce: 0.011666
iteration 15152 : loss : 0.020962, loss_ce: 0.010066
iteration 15153 : loss : 0.024321, loss_ce: 0.006929
iteration 15154 : loss : 0.027389, loss_ce: 0.004510
iteration 15155 : loss : 0.021925, loss_ce: 0.006988
iteration 15156 : loss : 0.020264, loss_ce: 0.007011
iteration 15157 : loss : 0.073422, loss_ce: 0.003987
iteration 15158 : loss : 0.022096, loss_ce: 0.004695
iteration 15159 : loss : 0.037010, loss_ce: 0.012246
 82%|███████████████████████▋     | 163/200 [2:28:02<33:36, 54.51s/it]pred_sum 32325
gtsum tensor(33165, device='cuda:0')
iteration 15160 : loss : 0.023000, loss_ce: 0.009383
iteration 15161 : loss : 0.073530, loss_ce: 0.003659
iteration 15162 : loss : 0.073606, loss_ce: 0.004756
iteration 15163 : loss : 0.020896, loss_ce: 0.009013
iteration 15164 : loss : 0.020464, loss_ce: 0.008558
iteration 15165 : loss : 0.024359, loss_ce: 0.003938
iteration 15166 : loss : 0.021116, loss_ce: 0.005507
iteration 15167 : loss : 0.021472, loss_ce: 0.009460
iteration 15168 : loss : 0.018868, loss_ce: 0.006448
iteration 15169 : loss : 0.026858, loss_ce: 0.005258
iteration 15170 : loss : 0.020711, loss_ce: 0.006354
iteration 15171 : loss : 0.022667, loss_ce: 0.011232
iteration 15172 : loss : 0.027656, loss_ce: 0.009286
iteration 15173 : loss : 0.022684, loss_ce: 0.011555
iteration 15174 : loss : 0.021412, loss_ce: 0.007757
iteration 15175 : loss : 0.022218, loss_ce: 0.004747
iteration 15176 : loss : 0.031805, loss_ce: 0.013028
iteration 15177 : loss : 0.024223, loss_ce: 0.009246
iteration 15178 : loss : 0.022279, loss_ce: 0.009861
iteration 15179 : loss : 0.024827, loss_ce: 0.010562
iteration 15180 : loss : 0.022216, loss_ce: 0.009460
iteration 15181 : loss : 0.030300, loss_ce: 0.005849
iteration 15182 : loss : 0.019858, loss_ce: 0.007329
iteration 15183 : loss : 0.026492, loss_ce: 0.007978
iteration 15184 : loss : 0.029454, loss_ce: 0.012383
iteration 15185 : loss : 0.022873, loss_ce: 0.009521
iteration 15186 : loss : 0.022790, loss_ce: 0.006410
iteration 15187 : loss : 0.022865, loss_ce: 0.005473
iteration 15188 : loss : 0.024179, loss_ce: 0.006899
iteration 15189 : loss : 0.022643, loss_ce: 0.009254
iteration 15190 : loss : 0.021874, loss_ce: 0.009021
pred_sum 39850
gtsum tensor(39778, device='cuda:0')
iteration 15191 : loss : 0.029257, loss_ce: 0.008769
iteration 15192 : loss : 0.022253, loss_ce: 0.008695
iteration 15193 : loss : 0.020869, loss_ce: 0.006240
iteration 15194 : loss : 0.023201, loss_ce: 0.005492
iteration 15195 : loss : 0.023806, loss_ce: 0.007721
iteration 15196 : loss : 0.076996, loss_ce: 0.009774
iteration 15197 : loss : 0.025830, loss_ce: 0.010641
iteration 15198 : loss : 0.026482, loss_ce: 0.008710
iteration 15199 : loss : 0.018845, loss_ce: 0.005464
iteration 15200 : loss : 0.020104, loss_ce: 0.007461
iteration 15201 : loss : 0.023185, loss_ce: 0.005216
iteration 15202 : loss : 0.025587, loss_ce: 0.008382
iteration 15203 : loss : 0.024188, loss_ce: 0.008802
iteration 15204 : loss : 0.018191, loss_ce: 0.003112
iteration 15205 : loss : 0.024004, loss_ce: 0.009957
iteration 15206 : loss : 0.024468, loss_ce: 0.006060
iteration 15207 : loss : 0.020129, loss_ce: 0.008828
iteration 15208 : loss : 0.021203, loss_ce: 0.008921
iteration 15209 : loss : 0.022057, loss_ce: 0.008579
iteration 15210 : loss : 0.025103, loss_ce: 0.010187
iteration 15211 : loss : 0.022811, loss_ce: 0.005820
iteration 15212 : loss : 0.021963, loss_ce: 0.006989
iteration 15213 : loss : 0.020302, loss_ce: 0.007981
iteration 15214 : loss : 0.024489, loss_ce: 0.009578
iteration 15215 : loss : 0.024910, loss_ce: 0.003438
iteration 15216 : loss : 0.020785, loss_ce: 0.007557
iteration 15217 : loss : 0.021154, loss_ce: 0.007434
iteration 15218 : loss : 0.022808, loss_ce: 0.007257
iteration 15219 : loss : 0.026157, loss_ce: 0.008767
iteration 15220 : loss : 0.073662, loss_ce: 0.004985
iteration 15221 : loss : 0.026233, loss_ce: 0.005410
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 15222 : loss : 0.075714, loss_ce: 0.004964
iteration 15223 : loss : 0.022642, loss_ce: 0.009010
iteration 15224 : loss : 0.019459, loss_ce: 0.007806
iteration 15225 : loss : 0.027998, loss_ce: 0.006386
iteration 15226 : loss : 0.031465, loss_ce: 0.009349
iteration 15227 : loss : 0.018781, loss_ce: 0.007607
iteration 15228 : loss : 0.020708, loss_ce: 0.007802
iteration 15229 : loss : 0.019820, loss_ce: 0.004630
iteration 15230 : loss : 0.024771, loss_ce: 0.009134
iteration 15231 : loss : 0.023028, loss_ce: 0.008024
iteration 15232 : loss : 0.075935, loss_ce: 0.006395
iteration 15233 : loss : 0.069749, loss_ce: 0.003378
iteration 15234 : loss : 0.024378, loss_ce: 0.010949
iteration 15235 : loss : 0.016113, loss_ce: 0.003391
iteration 15236 : loss : 0.023389, loss_ce: 0.008196
iteration 15237 : loss : 0.030423, loss_ce: 0.010859
iteration 15238 : loss : 0.018808, loss_ce: 0.004479
iteration 15239 : loss : 0.026220, loss_ce: 0.004774
iteration 15240 : loss : 0.021513, loss_ce: 0.011184
iteration 15241 : loss : 0.075075, loss_ce: 0.007908
iteration 15242 : loss : 0.020174, loss_ce: 0.007892
iteration 15243 : loss : 0.023747, loss_ce: 0.007745
iteration 15244 : loss : 0.019005, loss_ce: 0.005780
iteration 15245 : loss : 0.020121, loss_ce: 0.005640
iteration 15246 : loss : 0.025643, loss_ce: 0.009631
iteration 15247 : loss : 0.023143, loss_ce: 0.006702
iteration 15248 : loss : 0.024403, loss_ce: 0.008191
iteration 15249 : loss : 0.049022, loss_ce: 0.008335
iteration 15250 : loss : 0.024085, loss_ce: 0.005673
iteration 15251 : loss : 0.019155, loss_ce: 0.008722
iteration 15252 : loss : 0.080760, loss_ce: 0.009510
 82%|███████████████████████▊     | 164/200 [2:28:57<32:42, 54.52s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 15253 : loss : 0.025097, loss_ce: 0.007327
iteration 15254 : loss : 0.022807, loss_ce: 0.008509
iteration 15255 : loss : 0.018991, loss_ce: 0.004496
iteration 15256 : loss : 0.021915, loss_ce: 0.010801
iteration 15257 : loss : 0.025175, loss_ce: 0.010454
iteration 15258 : loss : 0.021112, loss_ce: 0.005226
iteration 15259 : loss : 0.076762, loss_ce: 0.008479
iteration 15260 : loss : 0.020772, loss_ce: 0.005248
iteration 15261 : loss : 0.022139, loss_ce: 0.007477
iteration 15262 : loss : 0.018952, loss_ce: 0.006481
iteration 15263 : loss : 0.023116, loss_ce: 0.005615
iteration 15264 : loss : 0.076265, loss_ce: 0.009881
iteration 15265 : loss : 0.027558, loss_ce: 0.007338
iteration 15266 : loss : 0.027985, loss_ce: 0.012816
iteration 15267 : loss : 0.025759, loss_ce: 0.008884
iteration 15268 : loss : 0.022743, loss_ce: 0.006439
iteration 15269 : loss : 0.021672, loss_ce: 0.009318
iteration 15270 : loss : 0.023259, loss_ce: 0.009785
iteration 15271 : loss : 0.031229, loss_ce: 0.008413
iteration 15272 : loss : 0.023973, loss_ce: 0.010164
iteration 15273 : loss : 0.021627, loss_ce: 0.003494
iteration 15274 : loss : 0.073605, loss_ce: 0.004787
iteration 15275 : loss : 0.019309, loss_ce: 0.008563
iteration 15276 : loss : 0.022772, loss_ce: 0.009293
iteration 15277 : loss : 0.073385, loss_ce: 0.005599
iteration 15278 : loss : 0.023635, loss_ce: 0.007899
iteration 15279 : loss : 0.038155, loss_ce: 0.005578
iteration 15280 : loss : 0.032533, loss_ce: 0.005536
iteration 15281 : loss : 0.022135, loss_ce: 0.007487
iteration 15282 : loss : 0.021421, loss_ce: 0.007799
iteration 15283 : loss : 0.023395, loss_ce: 0.005853
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 15284 : loss : 0.023095, loss_ce: 0.005208
iteration 15285 : loss : 0.021787, loss_ce: 0.002948
iteration 15286 : loss : 0.023651, loss_ce: 0.006638
iteration 15287 : loss : 0.028240, loss_ce: 0.008531
iteration 15288 : loss : 0.026444, loss_ce: 0.011381
iteration 15289 : loss : 0.023112, loss_ce: 0.007075
iteration 15290 : loss : 0.023233, loss_ce: 0.005316
iteration 15291 : loss : 0.020782, loss_ce: 0.005529
iteration 15292 : loss : 0.020918, loss_ce: 0.007490
iteration 15293 : loss : 0.075106, loss_ce: 0.006645
iteration 15294 : loss : 0.026744, loss_ce: 0.008124
iteration 15295 : loss : 0.021150, loss_ce: 0.008144
iteration 15296 : loss : 0.020930, loss_ce: 0.009340
iteration 15297 : loss : 0.025373, loss_ce: 0.007524
iteration 15298 : loss : 0.023715, loss_ce: 0.010515
iteration 15299 : loss : 0.019863, loss_ce: 0.008261
iteration 15300 : loss : 0.020083, loss_ce: 0.005514
iteration 15301 : loss : 0.027747, loss_ce: 0.006948
iteration 15302 : loss : 0.073537, loss_ce: 0.006270
iteration 15303 : loss : 0.028933, loss_ce: 0.010602
iteration 15304 : loss : 0.025668, loss_ce: 0.008903
iteration 15305 : loss : 0.022108, loss_ce: 0.008301
iteration 15306 : loss : 0.024487, loss_ce: 0.010236
iteration 15307 : loss : 0.034271, loss_ce: 0.005063
iteration 15308 : loss : 0.077684, loss_ce: 0.006758
iteration 15309 : loss : 0.020465, loss_ce: 0.005269
iteration 15310 : loss : 0.021981, loss_ce: 0.008190
iteration 15311 : loss : 0.025165, loss_ce: 0.010431
iteration 15312 : loss : 0.021372, loss_ce: 0.006660
iteration 15313 : loss : 0.022536, loss_ce: 0.008455
iteration 15314 : loss : 0.029233, loss_ce: 0.008573
pred_sum 39804
gtsum tensor(39597, device='cuda:0')
iteration 15315 : loss : 0.023135, loss_ce: 0.006225
iteration 15316 : loss : 0.018117, loss_ce: 0.006133
iteration 15317 : loss : 0.021875, loss_ce: 0.004287
iteration 15318 : loss : 0.023348, loss_ce: 0.008412
iteration 15319 : loss : 0.024236, loss_ce: 0.009859
iteration 15320 : loss : 0.025294, loss_ce: 0.008752
iteration 15321 : loss : 0.026522, loss_ce: 0.007136
iteration 15322 : loss : 0.023854, loss_ce: 0.007138
iteration 15323 : loss : 0.022837, loss_ce: 0.004301
iteration 15324 : loss : 0.020613, loss_ce: 0.007762
iteration 15325 : loss : 0.024783, loss_ce: 0.010138
iteration 15326 : loss : 0.017458, loss_ce: 0.006122
iteration 15327 : loss : 0.026731, loss_ce: 0.009512
iteration 15328 : loss : 0.023278, loss_ce: 0.004490
iteration 15329 : loss : 0.024886, loss_ce: 0.008404
iteration 15330 : loss : 0.022647, loss_ce: 0.009739
iteration 15331 : loss : 0.023794, loss_ce: 0.012585
iteration 15332 : loss : 0.023964, loss_ce: 0.006882
iteration 15333 : loss : 0.032164, loss_ce: 0.011532
iteration 15334 : loss : 0.028741, loss_ce: 0.009543
iteration 15335 : loss : 0.039636, loss_ce: 0.006796
iteration 15336 : loss : 0.023028, loss_ce: 0.010036
iteration 15337 : loss : 0.022668, loss_ce: 0.009146
iteration 15338 : loss : 0.022181, loss_ce: 0.010167
iteration 15339 : loss : 0.021355, loss_ce: 0.009785
iteration 15340 : loss : 0.019828, loss_ce: 0.007379
iteration 15341 : loss : 0.019634, loss_ce: 0.009542
iteration 15342 : loss : 0.021575, loss_ce: 0.006989
iteration 15343 : loss : 0.022278, loss_ce: 0.006863
iteration 15344 : loss : 0.020728, loss_ce: 0.006022
iteration 15345 : loss : 0.287770, loss_ce: 0.004466
 82%|███████████████████████▉     | 165/200 [2:29:51<31:47, 54.49s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 15346 : loss : 0.075882, loss_ce: 0.009919
iteration 15347 : loss : 0.072688, loss_ce: 0.006717
iteration 15348 : loss : 0.020951, loss_ce: 0.007740
iteration 15349 : loss : 0.020211, loss_ce: 0.008404
iteration 15350 : loss : 0.024244, loss_ce: 0.008146
iteration 15351 : loss : 0.023521, loss_ce: 0.009297
iteration 15352 : loss : 0.023633, loss_ce: 0.008350
iteration 15353 : loss : 0.018518, loss_ce: 0.005572
iteration 15354 : loss : 0.019076, loss_ce: 0.008083
iteration 15355 : loss : 0.023343, loss_ce: 0.009063
iteration 15356 : loss : 0.024695, loss_ce: 0.009137
iteration 15357 : loss : 0.073668, loss_ce: 0.003547
iteration 15358 : loss : 0.022756, loss_ce: 0.009027
iteration 15359 : loss : 0.020732, loss_ce: 0.007228
iteration 15360 : loss : 0.019759, loss_ce: 0.006047
iteration 15361 : loss : 0.021675, loss_ce: 0.006902
iteration 15362 : loss : 0.020180, loss_ce: 0.007929
iteration 15363 : loss : 0.019960, loss_ce: 0.006955
iteration 15364 : loss : 0.019401, loss_ce: 0.005567
iteration 15365 : loss : 0.022799, loss_ce: 0.007384
iteration 15366 : loss : 0.019964, loss_ce: 0.004372
iteration 15367 : loss : 0.025307, loss_ce: 0.007956
iteration 15368 : loss : 0.019195, loss_ce: 0.004977
iteration 15369 : loss : 0.023367, loss_ce: 0.008596
iteration 15370 : loss : 0.018850, loss_ce: 0.003037
iteration 15371 : loss : 0.021792, loss_ce: 0.010266
iteration 15372 : loss : 0.022546, loss_ce: 0.010181
iteration 15373 : loss : 0.021830, loss_ce: 0.006660
iteration 15374 : loss : 0.024183, loss_ce: 0.011710
iteration 15375 : loss : 0.074817, loss_ce: 0.005657
iteration 15376 : loss : 0.028799, loss_ce: 0.009221
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 15377 : loss : 0.023531, loss_ce: 0.008638
iteration 15378 : loss : 0.074224, loss_ce: 0.007333
iteration 15379 : loss : 0.025195, loss_ce: 0.004457
iteration 15380 : loss : 0.023332, loss_ce: 0.007284
iteration 15381 : loss : 0.022050, loss_ce: 0.008089
iteration 15382 : loss : 0.026955, loss_ce: 0.008965
iteration 15383 : loss : 0.024295, loss_ce: 0.009325
iteration 15384 : loss : 0.025273, loss_ce: 0.009406
iteration 15385 : loss : 0.022645, loss_ce: 0.011745
iteration 15386 : loss : 0.076090, loss_ce: 0.007647
iteration 15387 : loss : 0.024125, loss_ce: 0.004798
iteration 15388 : loss : 0.020544, loss_ce: 0.006224
iteration 15389 : loss : 0.019500, loss_ce: 0.008791
iteration 15390 : loss : 0.020950, loss_ce: 0.005751
iteration 15391 : loss : 0.018805, loss_ce: 0.005917
iteration 15392 : loss : 0.025386, loss_ce: 0.009054
iteration 15393 : loss : 0.018634, loss_ce: 0.006594
iteration 15394 : loss : 0.024744, loss_ce: 0.010919
iteration 15395 : loss : 0.019549, loss_ce: 0.005181
iteration 15396 : loss : 0.023493, loss_ce: 0.009239
iteration 15397 : loss : 0.024791, loss_ce: 0.009092
iteration 15398 : loss : 0.023097, loss_ce: 0.007745
iteration 15399 : loss : 0.018642, loss_ce: 0.007825
iteration 15400 : loss : 0.018151, loss_ce: 0.005270
iteration 15401 : loss : 0.026987, loss_ce: 0.011573
iteration 15402 : loss : 0.022750, loss_ce: 0.010013
iteration 15403 : loss : 0.025171, loss_ce: 0.007802
iteration 15404 : loss : 0.026520, loss_ce: 0.010067
iteration 15405 : loss : 0.023097, loss_ce: 0.005109
iteration 15406 : loss : 0.023466, loss_ce: 0.009280
iteration 15407 : loss : 0.023605, loss_ce: 0.014074
pred_sum 12184
gtsum tensor(12372, device='cuda:0')
iteration 15408 : loss : 0.024370, loss_ce: 0.007425
iteration 15409 : loss : 0.074246, loss_ce: 0.005247
iteration 15410 : loss : 0.017432, loss_ce: 0.006238
iteration 15411 : loss : 0.021188, loss_ce: 0.006492
iteration 15412 : loss : 0.025459, loss_ce: 0.005019
iteration 15413 : loss : 0.023076, loss_ce: 0.007665
iteration 15414 : loss : 0.025566, loss_ce: 0.004197
iteration 15415 : loss : 0.024112, loss_ce: 0.009882
iteration 15416 : loss : 0.025106, loss_ce: 0.008879
iteration 15417 : loss : 0.023970, loss_ce: 0.004707
iteration 15418 : loss : 0.024799, loss_ce: 0.008443
iteration 15419 : loss : 0.023834, loss_ce: 0.009854
iteration 15420 : loss : 0.019970, loss_ce: 0.006412
iteration 15421 : loss : 0.074901, loss_ce: 0.008257
iteration 15422 : loss : 0.077178, loss_ce: 0.008387
iteration 15423 : loss : 0.029946, loss_ce: 0.009197
iteration 15424 : loss : 0.019234, loss_ce: 0.008320
iteration 15425 : loss : 0.025209, loss_ce: 0.011251
iteration 15426 : loss : 0.074038, loss_ce: 0.006637
iteration 15427 : loss : 0.027988, loss_ce: 0.006594
iteration 15428 : loss : 0.022882, loss_ce: 0.007998
iteration 15429 : loss : 0.075919, loss_ce: 0.007326
iteration 15430 : loss : 0.021267, loss_ce: 0.008830
iteration 15431 : loss : 0.074043, loss_ce: 0.006843
iteration 15432 : loss : 0.022548, loss_ce: 0.009089
iteration 15433 : loss : 0.024339, loss_ce: 0.008910
iteration 15434 : loss : 0.033114, loss_ce: 0.003024
iteration 15435 : loss : 0.027670, loss_ce: 0.004687
iteration 15436 : loss : 0.076908, loss_ce: 0.003718
iteration 15437 : loss : 0.022721, loss_ce: 0.006138
iteration 15438 : loss : 0.128668, loss_ce: 0.005903
 83%|████████████████████████     | 166/200 [2:30:45<30:52, 54.48s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 15439 : loss : 0.020708, loss_ce: 0.007830
iteration 15440 : loss : 0.022847, loss_ce: 0.008330
iteration 15441 : loss : 0.022283, loss_ce: 0.007239
iteration 15442 : loss : 0.022902, loss_ce: 0.009654
iteration 15443 : loss : 0.025349, loss_ce: 0.009712
iteration 15444 : loss : 0.022391, loss_ce: 0.008809
iteration 15445 : loss : 0.024155, loss_ce: 0.009439
iteration 15446 : loss : 0.022981, loss_ce: 0.010738
iteration 15447 : loss : 0.024346, loss_ce: 0.007129
iteration 15448 : loss : 0.027042, loss_ce: 0.011234
iteration 15449 : loss : 0.020802, loss_ce: 0.007953
iteration 15450 : loss : 0.076741, loss_ce: 0.003707
iteration 15451 : loss : 0.021692, loss_ce: 0.008380
iteration 15452 : loss : 0.025567, loss_ce: 0.007932
iteration 15453 : loss : 0.023010, loss_ce: 0.008550
iteration 15454 : loss : 0.022039, loss_ce: 0.007657
iteration 15455 : loss : 0.021620, loss_ce: 0.006071
iteration 15456 : loss : 0.022456, loss_ce: 0.008519
iteration 15457 : loss : 0.074415, loss_ce: 0.004095
iteration 15458 : loss : 0.017101, loss_ce: 0.005312
iteration 15459 : loss : 0.020088, loss_ce: 0.004108
iteration 15460 : loss : 0.020463, loss_ce: 0.005283
iteration 15461 : loss : 0.021206, loss_ce: 0.009538
iteration 15462 : loss : 0.021463, loss_ce: 0.006502
iteration 15463 : loss : 0.022362, loss_ce: 0.008635
iteration 15464 : loss : 0.025199, loss_ce: 0.009048
iteration 15465 : loss : 0.077004, loss_ce: 0.007246
iteration 15466 : loss : 0.073723, loss_ce: 0.006733
iteration 15467 : loss : 0.026124, loss_ce: 0.014218
iteration 15468 : loss : 0.024279, loss_ce: 0.007686
iteration 15469 : loss : 0.028138, loss_ce: 0.006514
pred_sum 27387
gtsum tensor(27329, device='cuda:0')
iteration 15470 : loss : 0.032495, loss_ce: 0.005350
iteration 15471 : loss : 0.019744, loss_ce: 0.007015
iteration 15472 : loss : 0.021920, loss_ce: 0.007259
iteration 15473 : loss : 0.022900, loss_ce: 0.008221
iteration 15474 : loss : 0.022597, loss_ce: 0.007963
iteration 15475 : loss : 0.021339, loss_ce: 0.004770
iteration 15476 : loss : 0.024235, loss_ce: 0.009375
iteration 15477 : loss : 0.024211, loss_ce: 0.009841
iteration 15478 : loss : 0.022636, loss_ce: 0.005809
iteration 15479 : loss : 0.073758, loss_ce: 0.007153
iteration 15480 : loss : 0.020174, loss_ce: 0.006128
iteration 15481 : loss : 0.030308, loss_ce: 0.009318
iteration 15482 : loss : 0.024939, loss_ce: 0.007225
iteration 15483 : loss : 0.020014, loss_ce: 0.005348
iteration 15484 : loss : 0.023267, loss_ce: 0.005791
iteration 15485 : loss : 0.022047, loss_ce: 0.009400
iteration 15486 : loss : 0.028758, loss_ce: 0.006127
iteration 15487 : loss : 0.020768, loss_ce: 0.006814
iteration 15488 : loss : 0.070377, loss_ce: 0.004271
iteration 15489 : loss : 0.020541, loss_ce: 0.006702
iteration 15490 : loss : 0.022230, loss_ce: 0.008210
iteration 15491 : loss : 0.024169, loss_ce: 0.007027
iteration 15492 : loss : 0.022637, loss_ce: 0.007824
iteration 15493 : loss : 0.020811, loss_ce: 0.009898
iteration 15494 : loss : 0.020572, loss_ce: 0.007091
iteration 15495 : loss : 0.022707, loss_ce: 0.005902
iteration 15496 : loss : 0.020339, loss_ce: 0.007512
iteration 15497 : loss : 0.022688, loss_ce: 0.009254
iteration 15498 : loss : 0.023886, loss_ce: 0.007316
iteration 15499 : loss : 0.028378, loss_ce: 0.007155
iteration 15500 : loss : 0.026972, loss_ce: 0.007161
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 15501 : loss : 0.022937, loss_ce: 0.009969
iteration 15502 : loss : 0.023852, loss_ce: 0.008217
iteration 15503 : loss : 0.022525, loss_ce: 0.005552
iteration 15504 : loss : 0.022836, loss_ce: 0.010093
iteration 15505 : loss : 0.020060, loss_ce: 0.007871
iteration 15506 : loss : 0.020784, loss_ce: 0.008026
iteration 15507 : loss : 0.023228, loss_ce: 0.007673
iteration 15508 : loss : 0.024501, loss_ce: 0.008358
iteration 15509 : loss : 0.020220, loss_ce: 0.007433
iteration 15510 : loss : 0.020797, loss_ce: 0.008101
iteration 15511 : loss : 0.025933, loss_ce: 0.010153
iteration 15512 : loss : 0.024890, loss_ce: 0.005641
iteration 15513 : loss : 0.044906, loss_ce: 0.006205
iteration 15514 : loss : 0.020321, loss_ce: 0.006537
iteration 15515 : loss : 0.020943, loss_ce: 0.010660
iteration 15516 : loss : 0.023759, loss_ce: 0.006877
iteration 15517 : loss : 0.027768, loss_ce: 0.007447
iteration 15518 : loss : 0.021784, loss_ce: 0.006058
iteration 15519 : loss : 0.025206, loss_ce: 0.013423
iteration 15520 : loss : 0.016585, loss_ce: 0.004588
iteration 15521 : loss : 0.030911, loss_ce: 0.009705
iteration 15522 : loss : 0.024521, loss_ce: 0.012136
iteration 15523 : loss : 0.025014, loss_ce: 0.005354
iteration 15524 : loss : 0.020333, loss_ce: 0.004997
iteration 15525 : loss : 0.022273, loss_ce: 0.006574
iteration 15526 : loss : 0.051799, loss_ce: 0.007787
iteration 15527 : loss : 0.025305, loss_ce: 0.008257
iteration 15528 : loss : 0.026630, loss_ce: 0.008056
iteration 15529 : loss : 0.023778, loss_ce: 0.007510
iteration 15530 : loss : 0.032424, loss_ce: 0.006066
iteration 15531 : loss : 0.184615, loss_ce: 0.005920
 84%|████████████████████████▏    | 167/200 [2:31:40<29:58, 54.49s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 15532 : loss : 0.023730, loss_ce: 0.010017
iteration 15533 : loss : 0.027097, loss_ce: 0.005003
iteration 15534 : loss : 0.025739, loss_ce: 0.005794
iteration 15535 : loss : 0.021424, loss_ce: 0.007521
iteration 15536 : loss : 0.021894, loss_ce: 0.006930
iteration 15537 : loss : 0.022746, loss_ce: 0.011330
iteration 15538 : loss : 0.024643, loss_ce: 0.008540
iteration 15539 : loss : 0.024278, loss_ce: 0.005358
iteration 15540 : loss : 0.021822, loss_ce: 0.008585
iteration 15541 : loss : 0.022055, loss_ce: 0.007510
iteration 15542 : loss : 0.024610, loss_ce: 0.009310
iteration 15543 : loss : 0.024112, loss_ce: 0.006484
iteration 15544 : loss : 0.022052, loss_ce: 0.008622
iteration 15545 : loss : 0.020961, loss_ce: 0.006013
iteration 15546 : loss : 0.021770, loss_ce: 0.005630
iteration 15547 : loss : 0.020260, loss_ce: 0.007674
iteration 15548 : loss : 0.024333, loss_ce: 0.010053
iteration 15549 : loss : 0.028103, loss_ce: 0.003477
iteration 15550 : loss : 0.023155, loss_ce: 0.005767
iteration 15551 : loss : 0.026666, loss_ce: 0.010088
iteration 15552 : loss : 0.014838, loss_ce: 0.006019
iteration 15553 : loss : 0.032298, loss_ce: 0.007270
iteration 15554 : loss : 0.124142, loss_ce: 0.005084
iteration 15555 : loss : 0.074426, loss_ce: 0.007204
iteration 15556 : loss : 0.021898, loss_ce: 0.007851
iteration 15557 : loss : 0.020519, loss_ce: 0.007095
iteration 15558 : loss : 0.023149, loss_ce: 0.007586
iteration 15559 : loss : 0.025699, loss_ce: 0.010688
iteration 15560 : loss : 0.023655, loss_ce: 0.008876
iteration 15561 : loss : 0.016529, loss_ce: 0.004573
iteration 15562 : loss : 0.022688, loss_ce: 0.010358
pred_sum 45739
gtsum tensor(45821, device='cuda:0')
iteration 15563 : loss : 0.021744, loss_ce: 0.009488
iteration 15564 : loss : 0.019613, loss_ce: 0.005843
iteration 15565 : loss : 0.103106, loss_ce: 0.004947
iteration 15566 : loss : 0.073755, loss_ce: 0.006069
iteration 15567 : loss : 0.021763, loss_ce: 0.009570
iteration 15568 : loss : 0.020309, loss_ce: 0.006276
iteration 15569 : loss : 0.021842, loss_ce: 0.006390
iteration 15570 : loss : 0.080089, loss_ce: 0.008029
iteration 15571 : loss : 0.023756, loss_ce: 0.006480
iteration 15572 : loss : 0.026327, loss_ce: 0.006731
iteration 15573 : loss : 0.021728, loss_ce: 0.006706
iteration 15574 : loss : 0.020225, loss_ce: 0.006998
iteration 15575 : loss : 0.024060, loss_ce: 0.008449
iteration 15576 : loss : 0.020923, loss_ce: 0.004353
iteration 15577 : loss : 0.019344, loss_ce: 0.005381
iteration 15578 : loss : 0.023364, loss_ce: 0.012740
iteration 15579 : loss : 0.018154, loss_ce: 0.007479
iteration 15580 : loss : 0.023350, loss_ce: 0.008317
iteration 15581 : loss : 0.025689, loss_ce: 0.006315
iteration 15582 : loss : 0.025217, loss_ce: 0.006018
iteration 15583 : loss : 0.022044, loss_ce: 0.008478
iteration 15584 : loss : 0.023518, loss_ce: 0.009672
iteration 15585 : loss : 0.021948, loss_ce: 0.008873
iteration 15586 : loss : 0.019962, loss_ce: 0.008521
iteration 15587 : loss : 0.032190, loss_ce: 0.010625
iteration 15588 : loss : 0.021853, loss_ce: 0.007154
iteration 15589 : loss : 0.021755, loss_ce: 0.008382
iteration 15590 : loss : 0.026404, loss_ce: 0.010578
iteration 15591 : loss : 0.024705, loss_ce: 0.007800
iteration 15592 : loss : 0.021574, loss_ce: 0.006802
iteration 15593 : loss : 0.022769, loss_ce: 0.008945
pred_sum 52175
gtsum tensor(51790, device='cuda:0')
iteration 15594 : loss : 0.025323, loss_ce: 0.008995
iteration 15595 : loss : 0.024605, loss_ce: 0.006969
iteration 15596 : loss : 0.020299, loss_ce: 0.009584
iteration 15597 : loss : 0.021148, loss_ce: 0.005557
iteration 15598 : loss : 0.025900, loss_ce: 0.005039
iteration 15599 : loss : 0.024157, loss_ce: 0.005915
iteration 15600 : loss : 0.022530, loss_ce: 0.005572
iteration 15601 : loss : 0.027338, loss_ce: 0.008002
iteration 15602 : loss : 0.030279, loss_ce: 0.007874
iteration 15603 : loss : 0.023117, loss_ce: 0.011742
iteration 15604 : loss : 0.024364, loss_ce: 0.010387
iteration 15605 : loss : 0.021680, loss_ce: 0.009260
iteration 15606 : loss : 0.023096, loss_ce: 0.006515
iteration 15607 : loss : 0.019974, loss_ce: 0.008723
iteration 15608 : loss : 0.025927, loss_ce: 0.009555
iteration 15609 : loss : 0.022921, loss_ce: 0.006893
iteration 15610 : loss : 0.023626, loss_ce: 0.008215
iteration 15611 : loss : 0.022596, loss_ce: 0.011542
iteration 15612 : loss : 0.022693, loss_ce: 0.004640
iteration 15613 : loss : 0.029527, loss_ce: 0.007383
iteration 15614 : loss : 0.018648, loss_ce: 0.005128
iteration 15615 : loss : 0.073392, loss_ce: 0.006467
iteration 15616 : loss : 0.024302, loss_ce: 0.011652
iteration 15617 : loss : 0.019745, loss_ce: 0.003830
iteration 15618 : loss : 0.019957, loss_ce: 0.007381
iteration 15619 : loss : 0.021847, loss_ce: 0.008751
iteration 15620 : loss : 0.020734, loss_ce: 0.007652
iteration 15621 : loss : 0.024573, loss_ce: 0.005989
iteration 15622 : loss : 0.071283, loss_ce: 0.005385
iteration 15623 : loss : 0.023767, loss_ce: 0.007830
iteration 15624 : loss : 0.234764, loss_ce: 0.004720
 84%|████████████████████████▎    | 168/200 [2:32:35<29:04, 54.51s/it]pred_sum 7462
gtsum tensor(7630, device='cuda:0')
iteration 15625 : loss : 0.023098, loss_ce: 0.006295
iteration 15626 : loss : 0.022006, loss_ce: 0.006157
iteration 15627 : loss : 0.024692, loss_ce: 0.011704
iteration 15628 : loss : 0.023561, loss_ce: 0.008241
iteration 15629 : loss : 0.072570, loss_ce: 0.005241
iteration 15630 : loss : 0.019563, loss_ce: 0.006909
iteration 15631 : loss : 0.027837, loss_ce: 0.011507
iteration 15632 : loss : 0.024399, loss_ce: 0.007331
iteration 15633 : loss : 0.027056, loss_ce: 0.006711
iteration 15634 : loss : 0.019491, loss_ce: 0.006288
iteration 15635 : loss : 0.026502, loss_ce: 0.006814
iteration 15636 : loss : 0.021015, loss_ce: 0.005885
iteration 15637 : loss : 0.020573, loss_ce: 0.006533
iteration 15638 : loss : 0.022000, loss_ce: 0.008404
iteration 15639 : loss : 0.021897, loss_ce: 0.010241
iteration 15640 : loss : 0.022525, loss_ce: 0.011050
iteration 15641 : loss : 0.019323, loss_ce: 0.007574
iteration 15642 : loss : 0.023188, loss_ce: 0.006711
iteration 15643 : loss : 0.018946, loss_ce: 0.007310
iteration 15644 : loss : 0.018297, loss_ce: 0.004514
iteration 15645 : loss : 0.020507, loss_ce: 0.007238
iteration 15646 : loss : 0.028373, loss_ce: 0.010161
iteration 15647 : loss : 0.027018, loss_ce: 0.006128
iteration 15648 : loss : 0.020407, loss_ce: 0.008947
iteration 15649 : loss : 0.022824, loss_ce: 0.007560
iteration 15650 : loss : 0.020082, loss_ce: 0.007116
iteration 15651 : loss : 0.022666, loss_ce: 0.011778
iteration 15652 : loss : 0.027876, loss_ce: 0.007279
iteration 15653 : loss : 0.020970, loss_ce: 0.007438
iteration 15654 : loss : 0.024351, loss_ce: 0.008891
iteration 15655 : loss : 0.024253, loss_ce: 0.005446
pred_sum 26847
gtsum tensor(26905, device='cuda:0')
iteration 15656 : loss : 0.026336, loss_ce: 0.004358
iteration 15657 : loss : 0.027496, loss_ce: 0.013419
iteration 15658 : loss : 0.023368, loss_ce: 0.004690
iteration 15659 : loss : 0.019102, loss_ce: 0.006983
iteration 15660 : loss : 0.024979, loss_ce: 0.009096
iteration 15661 : loss : 0.020408, loss_ce: 0.004703
iteration 15662 : loss : 0.023086, loss_ce: 0.010378
iteration 15663 : loss : 0.024371, loss_ce: 0.010625
iteration 15664 : loss : 0.022830, loss_ce: 0.007590
iteration 15665 : loss : 0.022651, loss_ce: 0.008841
iteration 15666 : loss : 0.019160, loss_ce: 0.004591
iteration 15667 : loss : 0.024635, loss_ce: 0.011402
iteration 15668 : loss : 0.024119, loss_ce: 0.010610
iteration 15669 : loss : 0.024536, loss_ce: 0.008196
iteration 15670 : loss : 0.020412, loss_ce: 0.007424
iteration 15671 : loss : 0.021301, loss_ce: 0.009293
iteration 15672 : loss : 0.025436, loss_ce: 0.008637
iteration 15673 : loss : 0.021649, loss_ce: 0.007993
iteration 15674 : loss : 0.024253, loss_ce: 0.008934
iteration 15675 : loss : 0.018635, loss_ce: 0.004942
iteration 15676 : loss : 0.074719, loss_ce: 0.003062
iteration 15677 : loss : 0.021712, loss_ce: 0.010953
iteration 15678 : loss : 0.019374, loss_ce: 0.005213
iteration 15679 : loss : 0.015818, loss_ce: 0.006306
iteration 15680 : loss : 0.021063, loss_ce: 0.005491
iteration 15681 : loss : 0.017342, loss_ce: 0.003402
iteration 15682 : loss : 0.022357, loss_ce: 0.007224
iteration 15683 : loss : 0.024091, loss_ce: 0.007834
iteration 15684 : loss : 0.024303, loss_ce: 0.008749
iteration 15685 : loss : 0.021431, loss_ce: 0.006605
iteration 15686 : loss : 0.021350, loss_ce: 0.007510
pred_sum 3589
gtsum tensor(3607, device='cuda:0')
iteration 15687 : loss : 0.021686, loss_ce: 0.005146
iteration 15688 : loss : 0.031475, loss_ce: 0.006940
iteration 15689 : loss : 0.021349, loss_ce: 0.008441
iteration 15690 : loss : 0.025112, loss_ce: 0.006198
iteration 15691 : loss : 0.073564, loss_ce: 0.005143
iteration 15692 : loss : 0.022164, loss_ce: 0.007448
iteration 15693 : loss : 0.022789, loss_ce: 0.010949
iteration 15694 : loss : 0.072027, loss_ce: 0.006762
iteration 15695 : loss : 0.034709, loss_ce: 0.005980
iteration 15696 : loss : 0.021776, loss_ce: 0.008125
iteration 15697 : loss : 0.022192, loss_ce: 0.006722
iteration 15698 : loss : 0.020105, loss_ce: 0.009360
iteration 15699 : loss : 0.022101, loss_ce: 0.004556
iteration 15700 : loss : 0.021672, loss_ce: 0.010877
iteration 15701 : loss : 0.024203, loss_ce: 0.013169
iteration 15702 : loss : 0.074557, loss_ce: 0.004870
iteration 15703 : loss : 0.023084, loss_ce: 0.008743
iteration 15704 : loss : 0.021832, loss_ce: 0.008802
iteration 15705 : loss : 0.027196, loss_ce: 0.008579
iteration 15706 : loss : 0.023119, loss_ce: 0.008777
iteration 15707 : loss : 0.021574, loss_ce: 0.006407
iteration 15708 : loss : 0.027398, loss_ce: 0.008894
iteration 15709 : loss : 0.017622, loss_ce: 0.007010
iteration 15710 : loss : 0.027334, loss_ce: 0.006424
iteration 15711 : loss : 0.021099, loss_ce: 0.006310
iteration 15712 : loss : 0.019814, loss_ce: 0.006015
iteration 15713 : loss : 0.021462, loss_ce: 0.007871
iteration 15714 : loss : 0.024600, loss_ce: 0.006205
iteration 15715 : loss : 0.046381, loss_ce: 0.005724
iteration 15716 : loss : 0.022038, loss_ce: 0.005209
iteration 15717 : loss : 0.277844, loss_ce: 0.004019
 84%|████████████████████████▌    | 169/200 [2:33:29<28:09, 54.51s/it]pred_sum 1593
gtsum tensor(1521, device='cuda:0')
iteration 15718 : loss : 0.022457, loss_ce: 0.006317
iteration 15719 : loss : 0.021836, loss_ce: 0.006317
iteration 15720 : loss : 0.025410, loss_ce: 0.010236
iteration 15721 : loss : 0.024349, loss_ce: 0.009488
iteration 15722 : loss : 0.019018, loss_ce: 0.004618
iteration 15723 : loss : 0.031512, loss_ce: 0.007244
iteration 15724 : loss : 0.026177, loss_ce: 0.009996
iteration 15725 : loss : 0.020222, loss_ce: 0.006932
iteration 15726 : loss : 0.022810, loss_ce: 0.007796
iteration 15727 : loss : 0.019251, loss_ce: 0.006205
iteration 15728 : loss : 0.020800, loss_ce: 0.008280
iteration 15729 : loss : 0.022889, loss_ce: 0.010190
iteration 15730 : loss : 0.018962, loss_ce: 0.006671
iteration 15731 : loss : 0.072328, loss_ce: 0.006705
iteration 15732 : loss : 0.023092, loss_ce: 0.008961
iteration 15733 : loss : 0.021241, loss_ce: 0.004864
iteration 15734 : loss : 0.024313, loss_ce: 0.007368
iteration 15735 : loss : 0.024649, loss_ce: 0.007456
iteration 15736 : loss : 0.021174, loss_ce: 0.009735
iteration 15737 : loss : 0.024763, loss_ce: 0.009287
iteration 15738 : loss : 0.021461, loss_ce: 0.008314
iteration 15739 : loss : 0.023595, loss_ce: 0.008570
iteration 15740 : loss : 0.019909, loss_ce: 0.007928
iteration 15741 : loss : 0.018953, loss_ce: 0.006577
iteration 15742 : loss : 0.017834, loss_ce: 0.005059
iteration 15743 : loss : 0.019607, loss_ce: 0.007469
iteration 15744 : loss : 0.022042, loss_ce: 0.005560
iteration 15745 : loss : 0.026101, loss_ce: 0.011099
iteration 15746 : loss : 0.020617, loss_ce: 0.005532
iteration 15747 : loss : 0.019801, loss_ce: 0.005884
iteration 15748 : loss : 0.071878, loss_ce: 0.005767
pred_sum 108
gtsum tensor(101, device='cuda:0')
iteration 15749 : loss : 0.023947, loss_ce: 0.009322
iteration 15750 : loss : 0.019834, loss_ce: 0.007946
iteration 15751 : loss : 0.029664, loss_ce: 0.010502
iteration 15752 : loss : 0.025735, loss_ce: 0.007611
iteration 15753 : loss : 0.020055, loss_ce: 0.005904
iteration 15754 : loss : 0.020429, loss_ce: 0.008525
iteration 15755 : loss : 0.025753, loss_ce: 0.007989
iteration 15756 : loss : 0.027925, loss_ce: 0.008881
iteration 15757 : loss : 0.027249, loss_ce: 0.007232
iteration 15758 : loss : 0.020271, loss_ce: 0.008252
iteration 15759 : loss : 0.177321, loss_ce: 0.005647
iteration 15760 : loss : 0.023317, loss_ce: 0.009091
iteration 15761 : loss : 0.020064, loss_ce: 0.005934
iteration 15762 : loss : 0.021673, loss_ce: 0.007079
iteration 15763 : loss : 0.022267, loss_ce: 0.007493
iteration 15764 : loss : 0.022115, loss_ce: 0.009156
iteration 15765 : loss : 0.021299, loss_ce: 0.006634
iteration 15766 : loss : 0.026980, loss_ce: 0.004278
iteration 15767 : loss : 0.020726, loss_ce: 0.007439
iteration 15768 : loss : 0.023063, loss_ce: 0.006287
iteration 15769 : loss : 0.020024, loss_ce: 0.006729
iteration 15770 : loss : 0.022863, loss_ce: 0.005916
iteration 15771 : loss : 0.019241, loss_ce: 0.004617
iteration 15772 : loss : 0.022620, loss_ce: 0.008962
iteration 15773 : loss : 0.021532, loss_ce: 0.007276
iteration 15774 : loss : 0.024346, loss_ce: 0.007546
iteration 15775 : loss : 0.019662, loss_ce: 0.005862
iteration 15776 : loss : 0.024957, loss_ce: 0.008888
iteration 15777 : loss : 0.025432, loss_ce: 0.010158
iteration 15778 : loss : 0.022195, loss_ce: 0.007186
iteration 15779 : loss : 0.021362, loss_ce: 0.007339
pred_sum 32164
gtsum tensor(32711, device='cuda:0')
iteration 15780 : loss : 0.022507, loss_ce: 0.007778
iteration 15781 : loss : 0.021270, loss_ce: 0.008476
iteration 15782 : loss : 0.019839, loss_ce: 0.008774
iteration 15783 : loss : 0.031198, loss_ce: 0.008962
iteration 15784 : loss : 0.021224, loss_ce: 0.007355
iteration 15785 : loss : 0.026662, loss_ce: 0.007145
iteration 15786 : loss : 0.027984, loss_ce: 0.010214
iteration 15787 : loss : 0.021747, loss_ce: 0.006537
iteration 15788 : loss : 0.023179, loss_ce: 0.008935
iteration 15789 : loss : 0.123907, loss_ce: 0.004632
iteration 15790 : loss : 0.021413, loss_ce: 0.008219
iteration 15791 : loss : 0.021022, loss_ce: 0.008526
iteration 15792 : loss : 0.019758, loss_ce: 0.006376
iteration 15793 : loss : 0.021141, loss_ce: 0.008584
iteration 15794 : loss : 0.019874, loss_ce: 0.010568
iteration 15795 : loss : 0.024018, loss_ce: 0.004844
iteration 15796 : loss : 0.024526, loss_ce: 0.005578
iteration 15797 : loss : 0.024264, loss_ce: 0.009823
iteration 15798 : loss : 0.072275, loss_ce: 0.005231
iteration 15799 : loss : 0.027892, loss_ce: 0.010256
iteration 15800 : loss : 0.023691, loss_ce: 0.007919
iteration 15801 : loss : 0.020741, loss_ce: 0.006521
iteration 15802 : loss : 0.022816, loss_ce: 0.011800
iteration 15803 : loss : 0.020079, loss_ce: 0.003748
iteration 15804 : loss : 0.022378, loss_ce: 0.004802
iteration 15805 : loss : 0.019187, loss_ce: 0.008703
iteration 15806 : loss : 0.074808, loss_ce: 0.006811
iteration 15807 : loss : 0.020800, loss_ce: 0.010017
iteration 15808 : loss : 0.032892, loss_ce: 0.008675
iteration 15809 : loss : 0.020185, loss_ce: 0.005328
iteration 15810 : loss : 0.189865, loss_ce: 0.016044
 85%|████████████████████████▋    | 170/200 [2:34:24<27:15, 54.52s/it]pred_sum 52152
gtsum tensor(55538, device='cuda:0')
iteration 15811 : loss : 0.026562, loss_ce: 0.005877
iteration 15812 : loss : 0.024139, loss_ce: 0.011100
iteration 15813 : loss : 0.024823, loss_ce: 0.009739
iteration 15814 : loss : 0.023168, loss_ce: 0.009863
iteration 15815 : loss : 0.022778, loss_ce: 0.007165
iteration 15816 : loss : 0.072591, loss_ce: 0.007038
iteration 15817 : loss : 0.023107, loss_ce: 0.009207
iteration 15818 : loss : 0.023693, loss_ce: 0.009626
iteration 15819 : loss : 0.081438, loss_ce: 0.005937
iteration 15820 : loss : 0.024741, loss_ce: 0.009691
iteration 15821 : loss : 0.022026, loss_ce: 0.009683
iteration 15822 : loss : 0.018234, loss_ce: 0.006538
iteration 15823 : loss : 0.018553, loss_ce: 0.005362
iteration 15824 : loss : 0.020539, loss_ce: 0.007866
iteration 15825 : loss : 0.021232, loss_ce: 0.008241
iteration 15826 : loss : 0.022663, loss_ce: 0.007872
iteration 15827 : loss : 0.073137, loss_ce: 0.007625
iteration 15828 : loss : 0.024945, loss_ce: 0.007409
iteration 15829 : loss : 0.027773, loss_ce: 0.007774
iteration 15830 : loss : 0.024759, loss_ce: 0.007342
iteration 15831 : loss : 0.020461, loss_ce: 0.008343
iteration 15832 : loss : 0.023565, loss_ce: 0.010295
iteration 15833 : loss : 0.025556, loss_ce: 0.009857
iteration 15834 : loss : 0.022772, loss_ce: 0.007692
iteration 15835 : loss : 0.022336, loss_ce: 0.008826
iteration 15836 : loss : 0.019287, loss_ce: 0.006123
iteration 15837 : loss : 0.021740, loss_ce: 0.008262
iteration 15838 : loss : 0.024113, loss_ce: 0.006804
iteration 15839 : loss : 0.028196, loss_ce: 0.012081
iteration 15840 : loss : 0.023020, loss_ce: 0.006763
iteration 15841 : loss : 0.021788, loss_ce: 0.008077
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 15842 : loss : 0.021133, loss_ce: 0.004915
iteration 15843 : loss : 0.020217, loss_ce: 0.007802
iteration 15844 : loss : 0.019617, loss_ce: 0.006038
iteration 15845 : loss : 0.019834, loss_ce: 0.007654
iteration 15846 : loss : 0.027541, loss_ce: 0.008671
iteration 15847 : loss : 0.019629, loss_ce: 0.007167
iteration 15848 : loss : 0.021218, loss_ce: 0.006813
iteration 15849 : loss : 0.024395, loss_ce: 0.011553
iteration 15850 : loss : 0.019016, loss_ce: 0.005344
iteration 15851 : loss : 0.020147, loss_ce: 0.007471
iteration 15852 : loss : 0.022122, loss_ce: 0.007462
iteration 15853 : loss : 0.022641, loss_ce: 0.007099
iteration 15854 : loss : 0.023638, loss_ce: 0.009350
iteration 15855 : loss : 0.020598, loss_ce: 0.006782
iteration 15856 : loss : 0.023003, loss_ce: 0.007869
iteration 15857 : loss : 0.023826, loss_ce: 0.007221
iteration 15858 : loss : 0.019787, loss_ce: 0.006633
iteration 15859 : loss : 0.075515, loss_ce: 0.006240
iteration 15860 : loss : 0.019680, loss_ce: 0.005680
iteration 15861 : loss : 0.024510, loss_ce: 0.008199
iteration 15862 : loss : 0.020466, loss_ce: 0.007384
iteration 15863 : loss : 0.026475, loss_ce: 0.006449
iteration 15864 : loss : 0.022000, loss_ce: 0.005325
iteration 15865 : loss : 0.072979, loss_ce: 0.004068
iteration 15866 : loss : 0.070433, loss_ce: 0.004981
iteration 15867 : loss : 0.020411, loss_ce: 0.005698
iteration 15868 : loss : 0.073684, loss_ce: 0.007299
iteration 15869 : loss : 0.025574, loss_ce: 0.012789
iteration 15870 : loss : 0.086298, loss_ce: 0.003297
iteration 15871 : loss : 0.023063, loss_ce: 0.008603
iteration 15872 : loss : 0.019908, loss_ce: 0.007040
pred_sum 54404
gtsum tensor(53140, device='cuda:0')
iteration 15873 : loss : 0.018937, loss_ce: 0.007061
iteration 15874 : loss : 0.019702, loss_ce: 0.004853
iteration 15875 : loss : 0.026278, loss_ce: 0.009659
iteration 15876 : loss : 0.020142, loss_ce: 0.008044
iteration 15877 : loss : 0.027620, loss_ce: 0.007808
iteration 15878 : loss : 0.019333, loss_ce: 0.005900
iteration 15879 : loss : 0.022006, loss_ce: 0.006885
iteration 15880 : loss : 0.027167, loss_ce: 0.012209
iteration 15881 : loss : 0.021703, loss_ce: 0.010435
iteration 15882 : loss : 0.070430, loss_ce: 0.006000
iteration 15883 : loss : 0.021547, loss_ce: 0.004708
iteration 15884 : loss : 0.017971, loss_ce: 0.006946
iteration 15885 : loss : 0.019961, loss_ce: 0.007201
iteration 15886 : loss : 0.019361, loss_ce: 0.003408
iteration 15887 : loss : 0.019079, loss_ce: 0.005714
iteration 15888 : loss : 0.021996, loss_ce: 0.006085
iteration 15889 : loss : 0.021642, loss_ce: 0.007181
iteration 15890 : loss : 0.023197, loss_ce: 0.008566
iteration 15891 : loss : 0.018451, loss_ce: 0.008004
iteration 15892 : loss : 0.022335, loss_ce: 0.006248
iteration 15893 : loss : 0.021572, loss_ce: 0.008341
iteration 15894 : loss : 0.021865, loss_ce: 0.009843
iteration 15895 : loss : 0.022121, loss_ce: 0.006939
iteration 15896 : loss : 0.070051, loss_ce: 0.004793
iteration 15897 : loss : 0.025043, loss_ce: 0.010019
iteration 15898 : loss : 0.027319, loss_ce: 0.010153
iteration 15899 : loss : 0.074345, loss_ce: 0.004939
iteration 15900 : loss : 0.023983, loss_ce: 0.009700
iteration 15901 : loss : 0.075122, loss_ce: 0.004653
iteration 15902 : loss : 0.074058, loss_ce: 0.007574
iteration 15903 : loss : 0.234552, loss_ce: 0.004484
 86%|████████████████████████▊    | 171/200 [2:35:18<26:21, 54.52s/it]pred_sum 4665
gtsum tensor(4458, device='cuda:0')
iteration 15904 : loss : 0.023247, loss_ce: 0.006479
iteration 15905 : loss : 0.023148, loss_ce: 0.007726
iteration 15906 : loss : 0.023086, loss_ce: 0.009803
iteration 15907 : loss : 0.020002, loss_ce: 0.006781
iteration 15908 : loss : 0.017799, loss_ce: 0.004697
iteration 15909 : loss : 0.022945, loss_ce: 0.008068
iteration 15910 : loss : 0.022586, loss_ce: 0.006816
iteration 15911 : loss : 0.019811, loss_ce: 0.005342
iteration 15912 : loss : 0.022513, loss_ce: 0.003505
iteration 15913 : loss : 0.024627, loss_ce: 0.004866
iteration 15914 : loss : 0.024137, loss_ce: 0.009282
iteration 15915 : loss : 0.022188, loss_ce: 0.008162
iteration 15916 : loss : 0.019319, loss_ce: 0.007118
iteration 15917 : loss : 0.023616, loss_ce: 0.007936
iteration 15918 : loss : 0.022829, loss_ce: 0.007507
iteration 15919 : loss : 0.022221, loss_ce: 0.006402
iteration 15920 : loss : 0.022648, loss_ce: 0.012521
iteration 15921 : loss : 0.023304, loss_ce: 0.009842
iteration 15922 : loss : 0.021512, loss_ce: 0.006567
iteration 15923 : loss : 0.024161, loss_ce: 0.009108
iteration 15924 : loss : 0.021145, loss_ce: 0.008890
iteration 15925 : loss : 0.027665, loss_ce: 0.011793
iteration 15926 : loss : 0.021911, loss_ce: 0.006015
iteration 15927 : loss : 0.024572, loss_ce: 0.012237
iteration 15928 : loss : 0.021441, loss_ce: 0.010475
iteration 15929 : loss : 0.020880, loss_ce: 0.006619
iteration 15930 : loss : 0.019973, loss_ce: 0.008364
iteration 15931 : loss : 0.074017, loss_ce: 0.006514
iteration 15932 : loss : 0.073597, loss_ce: 0.004276
iteration 15933 : loss : 0.021168, loss_ce: 0.005892
iteration 15934 : loss : 0.020292, loss_ce: 0.009070
pred_sum 9412
gtsum tensor(9608, device='cuda:0')
iteration 15935 : loss : 0.021979, loss_ce: 0.005123
iteration 15936 : loss : 0.022264, loss_ce: 0.007312
iteration 15937 : loss : 0.025386, loss_ce: 0.008595
iteration 15938 : loss : 0.027878, loss_ce: 0.007991
iteration 15939 : loss : 0.021356, loss_ce: 0.004978
iteration 15940 : loss : 0.021015, loss_ce: 0.007761
iteration 15941 : loss : 0.022826, loss_ce: 0.006031
iteration 15942 : loss : 0.021442, loss_ce: 0.007605
iteration 15943 : loss : 0.020853, loss_ce: 0.005527
iteration 15944 : loss : 0.024167, loss_ce: 0.011688
iteration 15945 : loss : 0.021582, loss_ce: 0.008630
iteration 15946 : loss : 0.023536, loss_ce: 0.006897
iteration 15947 : loss : 0.021312, loss_ce: 0.006328
iteration 15948 : loss : 0.020250, loss_ce: 0.007601
iteration 15949 : loss : 0.025437, loss_ce: 0.005378
iteration 15950 : loss : 0.024980, loss_ce: 0.007956
iteration 15951 : loss : 0.019234, loss_ce: 0.007655
iteration 15952 : loss : 0.025989, loss_ce: 0.012180
iteration 15953 : loss : 0.020573, loss_ce: 0.005672
iteration 15954 : loss : 0.025208, loss_ce: 0.007888
iteration 15955 : loss : 0.020050, loss_ce: 0.006735
iteration 15956 : loss : 0.020569, loss_ce: 0.007409
iteration 15957 : loss : 0.023189, loss_ce: 0.005102
iteration 15958 : loss : 0.021500, loss_ce: 0.006698
iteration 15959 : loss : 0.021252, loss_ce: 0.006895
iteration 15960 : loss : 0.020014, loss_ce: 0.005746
iteration 15961 : loss : 0.022519, loss_ce: 0.007228
iteration 15962 : loss : 0.022083, loss_ce: 0.008383
iteration 15963 : loss : 0.020028, loss_ce: 0.009950
iteration 15964 : loss : 0.027695, loss_ce: 0.009131
iteration 15965 : loss : 0.045363, loss_ce: 0.004770
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 15966 : loss : 0.023217, loss_ce: 0.009762
iteration 15967 : loss : 0.021970, loss_ce: 0.007017
iteration 15968 : loss : 0.023741, loss_ce: 0.004482
iteration 15969 : loss : 0.019428, loss_ce: 0.007847
iteration 15970 : loss : 0.022177, loss_ce: 0.008872
iteration 15971 : loss : 0.021890, loss_ce: 0.005589
iteration 15972 : loss : 0.022062, loss_ce: 0.010247
iteration 15973 : loss : 0.023644, loss_ce: 0.013331
iteration 15974 : loss : 0.023303, loss_ce: 0.009119
iteration 15975 : loss : 0.024553, loss_ce: 0.009684
iteration 15976 : loss : 0.021042, loss_ce: 0.005930
iteration 15977 : loss : 0.022174, loss_ce: 0.008382
iteration 15978 : loss : 0.027867, loss_ce: 0.007102
iteration 15979 : loss : 0.087393, loss_ce: 0.001821
iteration 15980 : loss : 0.021590, loss_ce: 0.006986
iteration 15981 : loss : 0.024613, loss_ce: 0.005066
iteration 15982 : loss : 0.024106, loss_ce: 0.005671
iteration 15983 : loss : 0.023938, loss_ce: 0.004820
iteration 15984 : loss : 0.022293, loss_ce: 0.006749
iteration 15985 : loss : 0.026240, loss_ce: 0.011225
iteration 15986 : loss : 0.020694, loss_ce: 0.007489
iteration 15987 : loss : 0.028663, loss_ce: 0.009565
iteration 15988 : loss : 0.026876, loss_ce: 0.012930
iteration 15989 : loss : 0.021691, loss_ce: 0.007587
iteration 15990 : loss : 0.021968, loss_ce: 0.007519
iteration 15991 : loss : 0.020665, loss_ce: 0.006343
iteration 15992 : loss : 0.025077, loss_ce: 0.005104
iteration 15993 : loss : 0.019898, loss_ce: 0.007207
iteration 15994 : loss : 0.022536, loss_ce: 0.007137
iteration 15995 : loss : 0.023871, loss_ce: 0.006679
iteration 15996 : loss : 0.244397, loss_ce: 0.024078
 86%|████████████████████████▉    | 172/200 [2:36:13<25:26, 54.52s/it]pred_sum 26787
gtsum tensor(29200, device='cuda:0')
iteration 15997 : loss : 0.020999, loss_ce: 0.006953
iteration 15998 : loss : 0.022192, loss_ce: 0.008604
iteration 15999 : loss : 0.023440, loss_ce: 0.006730
iteration 16000 : loss : 0.024542, loss_ce: 0.010607
iteration 16001 : loss : 0.020081, loss_ce: 0.006648
iteration 16002 : loss : 0.070892, loss_ce: 0.002915
iteration 16003 : loss : 0.024777, loss_ce: 0.007474
iteration 16004 : loss : 0.020284, loss_ce: 0.007729
iteration 16005 : loss : 0.023296, loss_ce: 0.010033
iteration 16006 : loss : 0.026927, loss_ce: 0.006035
iteration 16007 : loss : 0.027637, loss_ce: 0.006351
iteration 16008 : loss : 0.023016, loss_ce: 0.008347
iteration 16009 : loss : 0.020729, loss_ce: 0.008181
iteration 16010 : loss : 0.022726, loss_ce: 0.007108
iteration 16011 : loss : 0.023377, loss_ce: 0.008899
iteration 16012 : loss : 0.019324, loss_ce: 0.004840
iteration 16013 : loss : 0.021920, loss_ce: 0.004669
iteration 16014 : loss : 0.023601, loss_ce: 0.007792
iteration 16015 : loss : 0.022687, loss_ce: 0.008164
iteration 16016 : loss : 0.018811, loss_ce: 0.009326
iteration 16017 : loss : 0.027843, loss_ce: 0.006615
iteration 16018 : loss : 0.023622, loss_ce: 0.007292
iteration 16019 : loss : 0.020693, loss_ce: 0.008054
iteration 16020 : loss : 0.021451, loss_ce: 0.005768
iteration 16021 : loss : 0.022894, loss_ce: 0.008054
iteration 16022 : loss : 0.020133, loss_ce: 0.004520
iteration 16023 : loss : 0.072616, loss_ce: 0.005372
iteration 16024 : loss : 0.024125, loss_ce: 0.004699
iteration 16025 : loss : 0.020441, loss_ce: 0.010801
iteration 16026 : loss : 0.021622, loss_ce: 0.006364
iteration 16027 : loss : 0.020886, loss_ce: 0.008626
pred_sum 17674
gtsum tensor(18087, device='cuda:0')
iteration 16028 : loss : 0.020897, loss_ce: 0.007047
iteration 16029 : loss : 0.019693, loss_ce: 0.007941
iteration 16030 : loss : 0.019370, loss_ce: 0.006033
iteration 16031 : loss : 0.021645, loss_ce: 0.006992
iteration 16032 : loss : 0.021531, loss_ce: 0.006398
iteration 16033 : loss : 0.022237, loss_ce: 0.007840
iteration 16034 : loss : 0.022255, loss_ce: 0.008120
iteration 16035 : loss : 0.024642, loss_ce: 0.007311
iteration 16036 : loss : 0.028619, loss_ce: 0.009536
iteration 16037 : loss : 0.022353, loss_ce: 0.007086
iteration 16038 : loss : 0.021059, loss_ce: 0.005866
iteration 16039 : loss : 0.027456, loss_ce: 0.006744
iteration 16040 : loss : 0.023497, loss_ce: 0.007792
iteration 16041 : loss : 0.020213, loss_ce: 0.007938
iteration 16042 : loss : 0.021643, loss_ce: 0.006927
iteration 16043 : loss : 0.025604, loss_ce: 0.010320
iteration 16044 : loss : 0.022915, loss_ce: 0.007179
iteration 16045 : loss : 0.021800, loss_ce: 0.007801
iteration 16046 : loss : 0.034206, loss_ce: 0.006299
iteration 16047 : loss : 0.027425, loss_ce: 0.015308
iteration 16048 : loss : 0.020535, loss_ce: 0.009840
iteration 16049 : loss : 0.027454, loss_ce: 0.003998
iteration 16050 : loss : 0.030117, loss_ce: 0.008505
iteration 16051 : loss : 0.021216, loss_ce: 0.005981
iteration 16052 : loss : 0.072643, loss_ce: 0.006679
iteration 16053 : loss : 0.020541, loss_ce: 0.006872
iteration 16054 : loss : 0.019158, loss_ce: 0.002919
iteration 16055 : loss : 0.024233, loss_ce: 0.006560
iteration 16056 : loss : 0.023658, loss_ce: 0.008660
iteration 16057 : loss : 0.020405, loss_ce: 0.006057
iteration 16058 : loss : 0.020691, loss_ce: 0.008378
pred_sum 37989
gtsum tensor(37505, device='cuda:0')
iteration 16059 : loss : 0.023769, loss_ce: 0.006946
iteration 16060 : loss : 0.020660, loss_ce: 0.008413
iteration 16061 : loss : 0.027875, loss_ce: 0.009744
iteration 16062 : loss : 0.022874, loss_ce: 0.007445
iteration 16063 : loss : 0.019165, loss_ce: 0.007131
iteration 16064 : loss : 0.022809, loss_ce: 0.009584
iteration 16065 : loss : 0.023730, loss_ce: 0.005966
iteration 16066 : loss : 0.024010, loss_ce: 0.005946
iteration 16067 : loss : 0.019410, loss_ce: 0.005206
iteration 16068 : loss : 0.021728, loss_ce: 0.008895
iteration 16069 : loss : 0.021985, loss_ce: 0.008957
iteration 16070 : loss : 0.021182, loss_ce: 0.007887
iteration 16071 : loss : 0.025811, loss_ce: 0.009499
iteration 16072 : loss : 0.020139, loss_ce: 0.006527
iteration 16073 : loss : 0.023563, loss_ce: 0.007850
iteration 16074 : loss : 0.021698, loss_ce: 0.011927
iteration 16075 : loss : 0.024797, loss_ce: 0.011673
iteration 16076 : loss : 0.072703, loss_ce: 0.005934
iteration 16077 : loss : 0.022394, loss_ce: 0.007321
iteration 16078 : loss : 0.028302, loss_ce: 0.006910
iteration 16079 : loss : 0.019320, loss_ce: 0.005193
iteration 16080 : loss : 0.024665, loss_ce: 0.006612
iteration 16081 : loss : 0.025860, loss_ce: 0.012899
iteration 16082 : loss : 0.074534, loss_ce: 0.007653
iteration 16083 : loss : 0.026009, loss_ce: 0.004881
iteration 16084 : loss : 0.019563, loss_ce: 0.008772
iteration 16085 : loss : 0.019491, loss_ce: 0.007879
iteration 16086 : loss : 0.024785, loss_ce: 0.007840
iteration 16087 : loss : 0.023529, loss_ce: 0.012356
iteration 16088 : loss : 0.018397, loss_ce: 0.005200
iteration 16089 : loss : 0.076178, loss_ce: 0.022112
 86%|█████████████████████████    | 173/200 [2:37:07<24:32, 54.53s/it]pred_sum 45635
gtsum tensor(45523, device='cuda:0')
iteration 16090 : loss : 0.021584, loss_ce: 0.007060
iteration 16091 : loss : 0.022612, loss_ce: 0.008715
iteration 16092 : loss : 0.021468, loss_ce: 0.005056
iteration 16093 : loss : 0.022655, loss_ce: 0.007254
iteration 16094 : loss : 0.022901, loss_ce: 0.010485
iteration 16095 : loss : 0.021648, loss_ce: 0.007607
iteration 16096 : loss : 0.019601, loss_ce: 0.005731
iteration 16097 : loss : 0.021082, loss_ce: 0.008296
iteration 16098 : loss : 0.025285, loss_ce: 0.005580
iteration 16099 : loss : 0.021522, loss_ce: 0.006301
iteration 16100 : loss : 0.022053, loss_ce: 0.011746
iteration 16101 : loss : 0.018621, loss_ce: 0.005351
iteration 16102 : loss : 0.027560, loss_ce: 0.005982
iteration 16103 : loss : 0.016218, loss_ce: 0.005359
iteration 16104 : loss : 0.022243, loss_ce: 0.006956
iteration 16105 : loss : 0.018707, loss_ce: 0.005582
iteration 16106 : loss : 0.020034, loss_ce: 0.008503
iteration 16107 : loss : 0.024986, loss_ce: 0.012281
iteration 16108 : loss : 0.016673, loss_ce: 0.008287
iteration 16109 : loss : 0.021538, loss_ce: 0.005494
iteration 16110 : loss : 0.023174, loss_ce: 0.005964
iteration 16111 : loss : 0.019349, loss_ce: 0.007716
iteration 16112 : loss : 0.025444, loss_ce: 0.010447
iteration 16113 : loss : 0.024283, loss_ce: 0.010171
iteration 16114 : loss : 0.022819, loss_ce: 0.011226
iteration 16115 : loss : 0.023389, loss_ce: 0.007708
iteration 16116 : loss : 0.022994, loss_ce: 0.008923
iteration 16117 : loss : 0.020086, loss_ce: 0.006172
iteration 16118 : loss : 0.072749, loss_ce: 0.004083
iteration 16119 : loss : 0.024031, loss_ce: 0.009522
iteration 16120 : loss : 0.023512, loss_ce: 0.007569
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 16121 : loss : 0.070691, loss_ce: 0.005123
iteration 16122 : loss : 0.020106, loss_ce: 0.007757
iteration 16123 : loss : 0.020547, loss_ce: 0.008228
iteration 16124 : loss : 0.037257, loss_ce: 0.006149
iteration 16125 : loss : 0.028632, loss_ce: 0.006642
iteration 16126 : loss : 0.026780, loss_ce: 0.005297
iteration 16127 : loss : 0.028773, loss_ce: 0.012264
iteration 16128 : loss : 0.026748, loss_ce: 0.008776
iteration 16129 : loss : 0.025450, loss_ce: 0.008025
iteration 16130 : loss : 0.021950, loss_ce: 0.009586
iteration 16131 : loss : 0.028831, loss_ce: 0.008232
iteration 16132 : loss : 0.022893, loss_ce: 0.010490
iteration 16133 : loss : 0.020128, loss_ce: 0.005067
iteration 16134 : loss : 0.022435, loss_ce: 0.007196
iteration 16135 : loss : 0.077137, loss_ce: 0.008929
iteration 16136 : loss : 0.023073, loss_ce: 0.005983
iteration 16137 : loss : 0.018752, loss_ce: 0.007041
iteration 16138 : loss : 0.020834, loss_ce: 0.005989
iteration 16139 : loss : 0.030173, loss_ce: 0.007692
iteration 16140 : loss : 0.021168, loss_ce: 0.008426
iteration 16141 : loss : 0.019660, loss_ce: 0.006129
iteration 16142 : loss : 0.021233, loss_ce: 0.006762
iteration 16143 : loss : 0.023389, loss_ce: 0.009228
iteration 16144 : loss : 0.025259, loss_ce: 0.009474
iteration 16145 : loss : 0.020641, loss_ce: 0.005629
iteration 16146 : loss : 0.021891, loss_ce: 0.007151
iteration 16147 : loss : 0.019646, loss_ce: 0.007880
iteration 16148 : loss : 0.031241, loss_ce: 0.007627
iteration 16149 : loss : 0.022887, loss_ce: 0.008788
iteration 16150 : loss : 0.023321, loss_ce: 0.007752
iteration 16151 : loss : 0.019766, loss_ce: 0.003614
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 16152 : loss : 0.021960, loss_ce: 0.010111
iteration 16153 : loss : 0.021934, loss_ce: 0.005831
iteration 16154 : loss : 0.022811, loss_ce: 0.009660
iteration 16155 : loss : 0.023126, loss_ce: 0.007088
iteration 16156 : loss : 0.022308, loss_ce: 0.004140
iteration 16157 : loss : 0.018411, loss_ce: 0.004577
iteration 16158 : loss : 0.021442, loss_ce: 0.009289
iteration 16159 : loss : 0.022300, loss_ce: 0.006635
iteration 16160 : loss : 0.020518, loss_ce: 0.009932
iteration 16161 : loss : 0.023335, loss_ce: 0.008026
iteration 16162 : loss : 0.022441, loss_ce: 0.007189
iteration 16163 : loss : 0.029098, loss_ce: 0.007670
iteration 16164 : loss : 0.076519, loss_ce: 0.002648
iteration 16165 : loss : 0.022101, loss_ce: 0.007866
iteration 16166 : loss : 0.020975, loss_ce: 0.006229
iteration 16167 : loss : 0.023869, loss_ce: 0.009066
iteration 16168 : loss : 0.021898, loss_ce: 0.007267
iteration 16169 : loss : 0.022884, loss_ce: 0.011082
iteration 16170 : loss : 0.023545, loss_ce: 0.006946
iteration 16171 : loss : 0.021386, loss_ce: 0.008499
iteration 16172 : loss : 0.018761, loss_ce: 0.007918
iteration 16173 : loss : 0.073543, loss_ce: 0.003338
iteration 16174 : loss : 0.028182, loss_ce: 0.012675
iteration 16175 : loss : 0.021560, loss_ce: 0.009371
iteration 16176 : loss : 0.020184, loss_ce: 0.004126
iteration 16177 : loss : 0.022600, loss_ce: 0.007961
iteration 16178 : loss : 0.073246, loss_ce: 0.008236
iteration 16179 : loss : 0.023168, loss_ce: 0.011025
iteration 16180 : loss : 0.022676, loss_ce: 0.007704
iteration 16181 : loss : 0.017866, loss_ce: 0.004406
iteration 16182 : loss : 0.079867, loss_ce: 0.010769
 87%|█████████████████████████▏   | 174/200 [2:38:02<23:37, 54.53s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 16183 : loss : 0.022360, loss_ce: 0.009362
iteration 16184 : loss : 0.022628, loss_ce: 0.007503
iteration 16185 : loss : 0.074124, loss_ce: 0.005185
iteration 16186 : loss : 0.022973, loss_ce: 0.007391
iteration 16187 : loss : 0.075402, loss_ce: 0.009751
iteration 16188 : loss : 0.021363, loss_ce: 0.007025
iteration 16189 : loss : 0.023144, loss_ce: 0.005340
iteration 16190 : loss : 0.019309, loss_ce: 0.008646
iteration 16191 : loss : 0.022033, loss_ce: 0.006071
iteration 16192 : loss : 0.022066, loss_ce: 0.008087
iteration 16193 : loss : 0.022647, loss_ce: 0.008258
iteration 16194 : loss : 0.071408, loss_ce: 0.007056
iteration 16195 : loss : 0.019004, loss_ce: 0.005445
iteration 16196 : loss : 0.023253, loss_ce: 0.009128
iteration 16197 : loss : 0.021785, loss_ce: 0.006990
iteration 16198 : loss : 0.019434, loss_ce: 0.007026
iteration 16199 : loss : 0.020871, loss_ce: 0.006804
iteration 16200 : loss : 0.022990, loss_ce: 0.007408
iteration 16201 : loss : 0.020421, loss_ce: 0.007248
iteration 16202 : loss : 0.019751, loss_ce: 0.003104
iteration 16203 : loss : 0.023766, loss_ce: 0.010617
iteration 16204 : loss : 0.018867, loss_ce: 0.009876
iteration 16205 : loss : 0.072216, loss_ce: 0.005037
iteration 16206 : loss : 0.024697, loss_ce: 0.007570
iteration 16207 : loss : 0.022414, loss_ce: 0.008869
iteration 16208 : loss : 0.022521, loss_ce: 0.008971
iteration 16209 : loss : 0.023120, loss_ce: 0.006559
iteration 16210 : loss : 0.022941, loss_ce: 0.010219
iteration 16211 : loss : 0.021547, loss_ce: 0.007289
iteration 16212 : loss : 0.027488, loss_ce: 0.006420
iteration 16213 : loss : 0.022153, loss_ce: 0.007732
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 16214 : loss : 0.027452, loss_ce: 0.008277
iteration 16215 : loss : 0.020284, loss_ce: 0.008232
iteration 16216 : loss : 0.018962, loss_ce: 0.007102
iteration 16217 : loss : 0.023183, loss_ce: 0.007838
iteration 16218 : loss : 0.028995, loss_ce: 0.011554
iteration 16219 : loss : 0.019774, loss_ce: 0.006169
iteration 16220 : loss : 0.019204, loss_ce: 0.005706
iteration 16221 : loss : 0.020769, loss_ce: 0.005649
iteration 16222 : loss : 0.035843, loss_ce: 0.010222
iteration 16223 : loss : 0.021109, loss_ce: 0.009819
iteration 16224 : loss : 0.021412, loss_ce: 0.005706
iteration 16225 : loss : 0.020581, loss_ce: 0.006573
iteration 16226 : loss : 0.024995, loss_ce: 0.006352
iteration 16227 : loss : 0.022351, loss_ce: 0.011560
iteration 16228 : loss : 0.020189, loss_ce: 0.004402
iteration 16229 : loss : 0.020620, loss_ce: 0.008295
iteration 16230 : loss : 0.019058, loss_ce: 0.007752
iteration 16231 : loss : 0.022472, loss_ce: 0.005889
iteration 16232 : loss : 0.020172, loss_ce: 0.008978
iteration 16233 : loss : 0.026388, loss_ce: 0.013142
iteration 16234 : loss : 0.027825, loss_ce: 0.005889
iteration 16235 : loss : 0.017294, loss_ce: 0.005770
iteration 16236 : loss : 0.021580, loss_ce: 0.003476
iteration 16237 : loss : 0.023111, loss_ce: 0.011629
iteration 16238 : loss : 0.069575, loss_ce: 0.005164
iteration 16239 : loss : 0.021884, loss_ce: 0.009141
iteration 16240 : loss : 0.023050, loss_ce: 0.005588
iteration 16241 : loss : 0.030902, loss_ce: 0.006079
iteration 16242 : loss : 0.017587, loss_ce: 0.006389
iteration 16243 : loss : 0.021944, loss_ce: 0.009029
iteration 16244 : loss : 0.024649, loss_ce: 0.006159
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 16245 : loss : 0.018499, loss_ce: 0.004738
iteration 16246 : loss : 0.021347, loss_ce: 0.004289
iteration 16247 : loss : 0.023004, loss_ce: 0.005922
iteration 16248 : loss : 0.074806, loss_ce: 0.006652
iteration 16249 : loss : 0.018723, loss_ce: 0.004526
iteration 16250 : loss : 0.024618, loss_ce: 0.007481
iteration 16251 : loss : 0.072527, loss_ce: 0.002866
iteration 16252 : loss : 0.074926, loss_ce: 0.006108
iteration 16253 : loss : 0.023296, loss_ce: 0.004839
iteration 16254 : loss : 0.020184, loss_ce: 0.007931
iteration 16255 : loss : 0.022134, loss_ce: 0.008141
iteration 16256 : loss : 0.020405, loss_ce: 0.007446
iteration 16257 : loss : 0.025481, loss_ce: 0.008367
iteration 16258 : loss : 0.021216, loss_ce: 0.006637
iteration 16259 : loss : 0.020240, loss_ce: 0.008807
iteration 16260 : loss : 0.021071, loss_ce: 0.008367
iteration 16261 : loss : 0.022675, loss_ce: 0.009890
iteration 16262 : loss : 0.022393, loss_ce: 0.011636
iteration 16263 : loss : 0.026541, loss_ce: 0.005519
iteration 16264 : loss : 0.020608, loss_ce: 0.008274
iteration 16265 : loss : 0.026199, loss_ce: 0.006510
iteration 16266 : loss : 0.023249, loss_ce: 0.008701
iteration 16267 : loss : 0.023245, loss_ce: 0.010250
iteration 16268 : loss : 0.024263, loss_ce: 0.005798
iteration 16269 : loss : 0.020626, loss_ce: 0.007185
iteration 16270 : loss : 0.020300, loss_ce: 0.009411
iteration 16271 : loss : 0.019907, loss_ce: 0.006602
iteration 16272 : loss : 0.022838, loss_ce: 0.006039
iteration 16273 : loss : 0.026781, loss_ce: 0.011698
iteration 16274 : loss : 0.021054, loss_ce: 0.008964
iteration 16275 : loss : 0.238610, loss_ce: 0.018100
 88%|█████████████████████████▍   | 175/200 [2:38:56<22:43, 54.53s/it]pred_sum 58009
gtsum tensor(57869, device='cuda:0')
iteration 16276 : loss : 0.025903, loss_ce: 0.010625
iteration 16277 : loss : 0.024657, loss_ce: 0.009955
iteration 16278 : loss : 0.023872, loss_ce: 0.012985
iteration 16279 : loss : 0.021530, loss_ce: 0.009972
iteration 16280 : loss : 0.030238, loss_ce: 0.008578
iteration 16281 : loss : 0.023736, loss_ce: 0.007573
iteration 16282 : loss : 0.023403, loss_ce: 0.006360
iteration 16283 : loss : 0.020320, loss_ce: 0.004966
iteration 16284 : loss : 0.022175, loss_ce: 0.007848
iteration 16285 : loss : 0.021337, loss_ce: 0.008463
iteration 16286 : loss : 0.019848, loss_ce: 0.007563
iteration 16287 : loss : 0.016362, loss_ce: 0.003722
iteration 16288 : loss : 0.023623, loss_ce: 0.010689
iteration 16289 : loss : 0.022933, loss_ce: 0.011864
iteration 16290 : loss : 0.019512, loss_ce: 0.007852
iteration 16291 : loss : 0.024477, loss_ce: 0.005956
iteration 16292 : loss : 0.019166, loss_ce: 0.006013
iteration 16293 : loss : 0.021286, loss_ce: 0.007626
iteration 16294 : loss : 0.071543, loss_ce: 0.005205
iteration 16295 : loss : 0.019863, loss_ce: 0.008836
iteration 16296 : loss : 0.022225, loss_ce: 0.006417
iteration 16297 : loss : 0.020784, loss_ce: 0.008674
iteration 16298 : loss : 0.022765, loss_ce: 0.009201
iteration 16299 : loss : 0.023539, loss_ce: 0.010914
iteration 16300 : loss : 0.021481, loss_ce: 0.004600
iteration 16301 : loss : 0.019632, loss_ce: 0.004385
iteration 16302 : loss : 0.024901, loss_ce: 0.008533
iteration 16303 : loss : 0.022044, loss_ce: 0.004826
iteration 16304 : loss : 0.020700, loss_ce: 0.008954
iteration 16305 : loss : 0.018800, loss_ce: 0.007765
iteration 16306 : loss : 0.021044, loss_ce: 0.005668
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 16307 : loss : 0.020603, loss_ce: 0.008877
iteration 16308 : loss : 0.023000, loss_ce: 0.010139
iteration 16309 : loss : 0.020152, loss_ce: 0.006587
iteration 16310 : loss : 0.023987, loss_ce: 0.008503
iteration 16311 : loss : 0.070048, loss_ce: 0.003098
iteration 16312 : loss : 0.022142, loss_ce: 0.005312
iteration 16313 : loss : 0.023429, loss_ce: 0.008031
iteration 16314 : loss : 0.025787, loss_ce: 0.005443
iteration 16315 : loss : 0.022921, loss_ce: 0.006273
iteration 16316 : loss : 0.020266, loss_ce: 0.007034
iteration 16317 : loss : 0.024815, loss_ce: 0.010318
iteration 16318 : loss : 0.020911, loss_ce: 0.005938
iteration 16319 : loss : 0.018333, loss_ce: 0.006019
iteration 16320 : loss : 0.024181, loss_ce: 0.008466
iteration 16321 : loss : 0.020845, loss_ce: 0.007245
iteration 16322 : loss : 0.021676, loss_ce: 0.009182
iteration 16323 : loss : 0.022411, loss_ce: 0.006310
iteration 16324 : loss : 0.024353, loss_ce: 0.008654
iteration 16325 : loss : 0.032231, loss_ce: 0.009860
iteration 16326 : loss : 0.017538, loss_ce: 0.006147
iteration 16327 : loss : 0.020337, loss_ce: 0.007396
iteration 16328 : loss : 0.023250, loss_ce: 0.007991
iteration 16329 : loss : 0.029000, loss_ce: 0.006812
iteration 16330 : loss : 0.022510, loss_ce: 0.006034
iteration 16331 : loss : 0.024255, loss_ce: 0.005045
iteration 16332 : loss : 0.025073, loss_ce: 0.012933
iteration 16333 : loss : 0.019747, loss_ce: 0.007268
iteration 16334 : loss : 0.020859, loss_ce: 0.006679
iteration 16335 : loss : 0.019065, loss_ce: 0.005821
iteration 16336 : loss : 0.022205, loss_ce: 0.006768
iteration 16337 : loss : 0.020108, loss_ce: 0.005366
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 16338 : loss : 0.071425, loss_ce: 0.006113
iteration 16339 : loss : 0.020576, loss_ce: 0.008370
iteration 16340 : loss : 0.018587, loss_ce: 0.004392
iteration 16341 : loss : 0.022546, loss_ce: 0.007589
iteration 16342 : loss : 0.019418, loss_ce: 0.004847
iteration 16343 : loss : 0.076182, loss_ce: 0.007137
iteration 16344 : loss : 0.019698, loss_ce: 0.007881
iteration 16345 : loss : 0.025077, loss_ce: 0.012573
iteration 16346 : loss : 0.023082, loss_ce: 0.006445
iteration 16347 : loss : 0.018461, loss_ce: 0.005989
iteration 16348 : loss : 0.031100, loss_ce: 0.006492
iteration 16349 : loss : 0.021996, loss_ce: 0.006410
iteration 16350 : loss : 0.023421, loss_ce: 0.009803
iteration 16351 : loss : 0.072129, loss_ce: 0.004507
iteration 16352 : loss : 0.023886, loss_ce: 0.007052
iteration 16353 : loss : 0.023321, loss_ce: 0.012105
iteration 16354 : loss : 0.019349, loss_ce: 0.006433
iteration 16355 : loss : 0.073704, loss_ce: 0.004970
iteration 16356 : loss : 0.019936, loss_ce: 0.006302
iteration 16357 : loss : 0.021808, loss_ce: 0.009593
iteration 16358 : loss : 0.021703, loss_ce: 0.010007
iteration 16359 : loss : 0.026200, loss_ce: 0.009163
iteration 16360 : loss : 0.022621, loss_ce: 0.008078
iteration 16361 : loss : 0.024947, loss_ce: 0.009701
iteration 16362 : loss : 0.023980, loss_ce: 0.002943
iteration 16363 : loss : 0.025427, loss_ce: 0.006593
iteration 16364 : loss : 0.026308, loss_ce: 0.010073
iteration 16365 : loss : 0.022549, loss_ce: 0.005557
iteration 16366 : loss : 0.020294, loss_ce: 0.007243
iteration 16367 : loss : 0.019269, loss_ce: 0.007620
iteration 16368 : loss : 0.087679, loss_ce: 0.009810
 88%|█████████████████████████▌   | 176/200 [2:39:51<21:48, 54.52s/it]pred_sum 37625
gtsum tensor(36250, device='cuda:0')
iteration 16369 : loss : 0.021392, loss_ce: 0.005059
iteration 16370 : loss : 0.030787, loss_ce: 0.007256
iteration 16371 : loss : 0.022454, loss_ce: 0.006570
iteration 16372 : loss : 0.023653, loss_ce: 0.009956
iteration 16373 : loss : 0.026940, loss_ce: 0.005489
iteration 16374 : loss : 0.026236, loss_ce: 0.004867
iteration 16375 : loss : 0.019580, loss_ce: 0.007144
iteration 16376 : loss : 0.072712, loss_ce: 0.008419
iteration 16377 : loss : 0.018701, loss_ce: 0.006191
iteration 16378 : loss : 0.022400, loss_ce: 0.010215
iteration 16379 : loss : 0.021842, loss_ce: 0.007165
iteration 16380 : loss : 0.021545, loss_ce: 0.006474
iteration 16381 : loss : 0.123071, loss_ce: 0.002859
iteration 16382 : loss : 0.023948, loss_ce: 0.007824
iteration 16383 : loss : 0.025471, loss_ce: 0.009209
iteration 16384 : loss : 0.020532, loss_ce: 0.007120
iteration 16385 : loss : 0.018660, loss_ce: 0.006426
iteration 16386 : loss : 0.022654, loss_ce: 0.006726
iteration 16387 : loss : 0.018579, loss_ce: 0.007673
iteration 16388 : loss : 0.021286, loss_ce: 0.008132
iteration 16389 : loss : 0.022087, loss_ce: 0.008577
iteration 16390 : loss : 0.023805, loss_ce: 0.005017
iteration 16391 : loss : 0.021053, loss_ce: 0.007469
iteration 16392 : loss : 0.021495, loss_ce: 0.009216
iteration 16393 : loss : 0.019951, loss_ce: 0.008855
iteration 16394 : loss : 0.018401, loss_ce: 0.003516
iteration 16395 : loss : 0.073630, loss_ce: 0.004417
iteration 16396 : loss : 0.024507, loss_ce: 0.008314
iteration 16397 : loss : 0.024726, loss_ce: 0.007539
iteration 16398 : loss : 0.023946, loss_ce: 0.004901
iteration 16399 : loss : 0.019623, loss_ce: 0.007501
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 16400 : loss : 0.024131, loss_ce: 0.006520
iteration 16401 : loss : 0.018442, loss_ce: 0.004287
iteration 16402 : loss : 0.020082, loss_ce: 0.006040
iteration 16403 : loss : 0.023659, loss_ce: 0.005725
iteration 16404 : loss : 0.024489, loss_ce: 0.009045
iteration 16405 : loss : 0.023021, loss_ce: 0.005540
iteration 16406 : loss : 0.026090, loss_ce: 0.012751
iteration 16407 : loss : 0.028699, loss_ce: 0.010471
iteration 16408 : loss : 0.020455, loss_ce: 0.010114
iteration 16409 : loss : 0.018280, loss_ce: 0.006045
iteration 16410 : loss : 0.025061, loss_ce: 0.006177
iteration 16411 : loss : 0.022359, loss_ce: 0.009383
iteration 16412 : loss : 0.021875, loss_ce: 0.007705
iteration 16413 : loss : 0.024791, loss_ce: 0.009887
iteration 16414 : loss : 0.021198, loss_ce: 0.006664
iteration 16415 : loss : 0.021490, loss_ce: 0.007152
iteration 16416 : loss : 0.021080, loss_ce: 0.008503
iteration 16417 : loss : 0.029998, loss_ce: 0.006935
iteration 16418 : loss : 0.075306, loss_ce: 0.005970
iteration 16419 : loss : 0.023131, loss_ce: 0.009943
iteration 16420 : loss : 0.023604, loss_ce: 0.007309
iteration 16421 : loss : 0.023942, loss_ce: 0.004998
iteration 16422 : loss : 0.023359, loss_ce: 0.008429
iteration 16423 : loss : 0.016485, loss_ce: 0.005124
iteration 16424 : loss : 0.018583, loss_ce: 0.005874
iteration 16425 : loss : 0.023086, loss_ce: 0.007729
iteration 16426 : loss : 0.023863, loss_ce: 0.004782
iteration 16427 : loss : 0.022435, loss_ce: 0.008268
iteration 16428 : loss : 0.021464, loss_ce: 0.009790
iteration 16429 : loss : 0.021879, loss_ce: 0.007829
iteration 16430 : loss : 0.019020, loss_ce: 0.005096
pred_sum 24067
gtsum tensor(22812, device='cuda:0')
iteration 16431 : loss : 0.025338, loss_ce: 0.008374
iteration 16432 : loss : 0.020408, loss_ce: 0.010506
iteration 16433 : loss : 0.021930, loss_ce: 0.008143
iteration 16434 : loss : 0.021777, loss_ce: 0.007580
iteration 16435 : loss : 0.020970, loss_ce: 0.006722
iteration 16436 : loss : 0.021787, loss_ce: 0.006386
iteration 16437 : loss : 0.024027, loss_ce: 0.012605
iteration 16438 : loss : 0.025678, loss_ce: 0.006031
iteration 16439 : loss : 0.021401, loss_ce: 0.007396
iteration 16440 : loss : 0.021535, loss_ce: 0.010717
iteration 16441 : loss : 0.022188, loss_ce: 0.007835
iteration 16442 : loss : 0.021522, loss_ce: 0.009191
iteration 16443 : loss : 0.076448, loss_ce: 0.004214
iteration 16444 : loss : 0.018867, loss_ce: 0.006455
iteration 16445 : loss : 0.028636, loss_ce: 0.005023
iteration 16446 : loss : 0.023973, loss_ce: 0.011115
iteration 16447 : loss : 0.021712, loss_ce: 0.010387
iteration 16448 : loss : 0.019386, loss_ce: 0.006814
iteration 16449 : loss : 0.021513, loss_ce: 0.006990
iteration 16450 : loss : 0.026205, loss_ce: 0.008997
iteration 16451 : loss : 0.019916, loss_ce: 0.005491
iteration 16452 : loss : 0.026184, loss_ce: 0.011776
iteration 16453 : loss : 0.074666, loss_ce: 0.007609
iteration 16454 : loss : 0.023829, loss_ce: 0.009340
iteration 16455 : loss : 0.021428, loss_ce: 0.008850
iteration 16456 : loss : 0.018417, loss_ce: 0.007742
iteration 16457 : loss : 0.022398, loss_ce: 0.008245
iteration 16458 : loss : 0.021273, loss_ce: 0.007384
iteration 16459 : loss : 0.022000, loss_ce: 0.008008
iteration 16460 : loss : 0.019294, loss_ce: 0.007954
iteration 16461 : loss : 0.178728, loss_ce: 0.006140
 88%|█████████████████████████▋   | 177/200 [2:40:45<20:53, 54.50s/it]pred_sum 295
gtsum tensor(304, device='cuda:0')
iteration 16462 : loss : 0.024718, loss_ce: 0.008733
iteration 16463 : loss : 0.024753, loss_ce: 0.009331
iteration 16464 : loss : 0.019913, loss_ce: 0.009515
iteration 16465 : loss : 0.021656, loss_ce: 0.009009
iteration 16466 : loss : 0.026009, loss_ce: 0.008544
iteration 16467 : loss : 0.018622, loss_ce: 0.004630
iteration 16468 : loss : 0.025137, loss_ce: 0.006461
iteration 16469 : loss : 0.017788, loss_ce: 0.007632
iteration 16470 : loss : 0.020998, loss_ce: 0.006454
iteration 16471 : loss : 0.023005, loss_ce: 0.008949
iteration 16472 : loss : 0.019080, loss_ce: 0.005404
iteration 16473 : loss : 0.020862, loss_ce: 0.008945
iteration 16474 : loss : 0.021772, loss_ce: 0.005448
iteration 16475 : loss : 0.021104, loss_ce: 0.007905
iteration 16476 : loss : 0.021515, loss_ce: 0.006392
iteration 16477 : loss : 0.020471, loss_ce: 0.007012
iteration 16478 : loss : 0.020987, loss_ce: 0.005298
iteration 16479 : loss : 0.025115, loss_ce: 0.008852
iteration 16480 : loss : 0.020840, loss_ce: 0.004425
iteration 16481 : loss : 0.021457, loss_ce: 0.006480
iteration 16482 : loss : 0.080052, loss_ce: 0.002473
iteration 16483 : loss : 0.020397, loss_ce: 0.007545
iteration 16484 : loss : 0.080851, loss_ce: 0.003725
iteration 16485 : loss : 0.023275, loss_ce: 0.007613
iteration 16486 : loss : 0.021777, loss_ce: 0.008164
iteration 16487 : loss : 0.022860, loss_ce: 0.006481
iteration 16488 : loss : 0.022657, loss_ce: 0.006482
iteration 16489 : loss : 0.024553, loss_ce: 0.010924
iteration 16490 : loss : 0.022584, loss_ce: 0.006399
iteration 16491 : loss : 0.021194, loss_ce: 0.010618
iteration 16492 : loss : 0.023822, loss_ce: 0.011663
pred_sum 53989
gtsum tensor(53728, device='cuda:0')
iteration 16493 : loss : 0.123418, loss_ce: 0.005715
iteration 16494 : loss : 0.022726, loss_ce: 0.009018
iteration 16495 : loss : 0.030647, loss_ce: 0.009470
iteration 16496 : loss : 0.021633, loss_ce: 0.004482
iteration 16497 : loss : 0.025122, loss_ce: 0.009314
iteration 16498 : loss : 0.019477, loss_ce: 0.008780
iteration 16499 : loss : 0.074874, loss_ce: 0.006038
iteration 16500 : loss : 0.023434, loss_ce: 0.006818
iteration 16501 : loss : 0.017927, loss_ce: 0.004511
iteration 16502 : loss : 0.021352, loss_ce: 0.006540
iteration 16503 : loss : 0.023623, loss_ce: 0.007308
iteration 16504 : loss : 0.020409, loss_ce: 0.008890
iteration 16505 : loss : 0.069085, loss_ce: 0.002521
iteration 16506 : loss : 0.024293, loss_ce: 0.009653
iteration 16507 : loss : 0.025022, loss_ce: 0.004927
iteration 16508 : loss : 0.041277, loss_ce: 0.005389
iteration 16509 : loss : 0.024539, loss_ce: 0.006972
iteration 16510 : loss : 0.021547, loss_ce: 0.005046
iteration 16511 : loss : 0.023485, loss_ce: 0.008135
iteration 16512 : loss : 0.018851, loss_ce: 0.004272
iteration 16513 : loss : 0.021706, loss_ce: 0.009845
iteration 16514 : loss : 0.074908, loss_ce: 0.005784
iteration 16515 : loss : 0.021239, loss_ce: 0.009824
iteration 16516 : loss : 0.022432, loss_ce: 0.012529
iteration 16517 : loss : 0.024228, loss_ce: 0.009432
iteration 16518 : loss : 0.023226, loss_ce: 0.008270
iteration 16519 : loss : 0.019972, loss_ce: 0.009141
iteration 16520 : loss : 0.024732, loss_ce: 0.008072
iteration 16521 : loss : 0.019994, loss_ce: 0.006274
iteration 16522 : loss : 0.022179, loss_ce: 0.008197
iteration 16523 : loss : 0.020215, loss_ce: 0.006567
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 16524 : loss : 0.072714, loss_ce: 0.005132
iteration 16525 : loss : 0.023241, loss_ce: 0.009534
iteration 16526 : loss : 0.022899, loss_ce: 0.008111
iteration 16527 : loss : 0.018978, loss_ce: 0.006193
iteration 16528 : loss : 0.022136, loss_ce: 0.009364
iteration 16529 : loss : 0.077586, loss_ce: 0.006547
iteration 16530 : loss : 0.019736, loss_ce: 0.005957
iteration 16531 : loss : 0.020008, loss_ce: 0.005212
iteration 16532 : loss : 0.026096, loss_ce: 0.009456
iteration 16533 : loss : 0.026430, loss_ce: 0.011615
iteration 16534 : loss : 0.024636, loss_ce: 0.006121
iteration 16535 : loss : 0.024300, loss_ce: 0.012159
iteration 16536 : loss : 0.022646, loss_ce: 0.007877
iteration 16537 : loss : 0.023318, loss_ce: 0.006622
iteration 16538 : loss : 0.018174, loss_ce: 0.006855
iteration 16539 : loss : 0.018492, loss_ce: 0.005629
iteration 16540 : loss : 0.021393, loss_ce: 0.006456
iteration 16541 : loss : 0.021447, loss_ce: 0.005901
iteration 16542 : loss : 0.022240, loss_ce: 0.007749
iteration 16543 : loss : 0.023954, loss_ce: 0.007748
iteration 16544 : loss : 0.022623, loss_ce: 0.009389
iteration 16545 : loss : 0.024399, loss_ce: 0.006484
iteration 16546 : loss : 0.031111, loss_ce: 0.008149
iteration 16547 : loss : 0.073195, loss_ce: 0.006319
iteration 16548 : loss : 0.022711, loss_ce: 0.009629
iteration 16549 : loss : 0.024529, loss_ce: 0.010970
iteration 16550 : loss : 0.018655, loss_ce: 0.006113
iteration 16551 : loss : 0.020956, loss_ce: 0.007291
iteration 16552 : loss : 0.018103, loss_ce: 0.007179
iteration 16553 : loss : 0.020710, loss_ce: 0.008515
iteration 16554 : loss : 0.025864, loss_ce: 0.015351
 89%|█████████████████████████▊   | 178/200 [2:41:40<19:58, 54.48s/it]pred_sum 20490
gtsum tensor(20870, device='cuda:0')
iteration 16555 : loss : 0.023105, loss_ce: 0.005335
iteration 16556 : loss : 0.023304, loss_ce: 0.008937
iteration 16557 : loss : 0.020112, loss_ce: 0.006860
iteration 16558 : loss : 0.022200, loss_ce: 0.010334
iteration 16559 : loss : 0.072357, loss_ce: 0.002790
iteration 16560 : loss : 0.022616, loss_ce: 0.008442
iteration 16561 : loss : 0.020925, loss_ce: 0.007591
iteration 16562 : loss : 0.023526, loss_ce: 0.011085
iteration 16563 : loss : 0.073053, loss_ce: 0.005150
iteration 16564 : loss : 0.021994, loss_ce: 0.010242
iteration 16565 : loss : 0.024246, loss_ce: 0.009239
iteration 16566 : loss : 0.023309, loss_ce: 0.010453
iteration 16567 : loss : 0.019773, loss_ce: 0.005982
iteration 16568 : loss : 0.018298, loss_ce: 0.006488
iteration 16569 : loss : 0.072824, loss_ce: 0.006200
iteration 16570 : loss : 0.026659, loss_ce: 0.011048
iteration 16571 : loss : 0.024519, loss_ce: 0.007644
iteration 16572 : loss : 0.026388, loss_ce: 0.008520
iteration 16573 : loss : 0.074152, loss_ce: 0.007851
iteration 16574 : loss : 0.018055, loss_ce: 0.004983
iteration 16575 : loss : 0.025197, loss_ce: 0.008181
iteration 16576 : loss : 0.020795, loss_ce: 0.007872
iteration 16577 : loss : 0.021665, loss_ce: 0.007153
iteration 16578 : loss : 0.023265, loss_ce: 0.008408
iteration 16579 : loss : 0.020753, loss_ce: 0.004000
iteration 16580 : loss : 0.021832, loss_ce: 0.008677
iteration 16581 : loss : 0.018790, loss_ce: 0.006267
iteration 16582 : loss : 0.023628, loss_ce: 0.009443
iteration 16583 : loss : 0.070977, loss_ce: 0.004241
iteration 16584 : loss : 0.072912, loss_ce: 0.006963
iteration 16585 : loss : 0.022712, loss_ce: 0.005202
pred_sum 42822
gtsum tensor(42653, device='cuda:0')
iteration 16586 : loss : 0.021695, loss_ce: 0.006072
iteration 16587 : loss : 0.021382, loss_ce: 0.008658
iteration 16588 : loss : 0.021416, loss_ce: 0.009828
iteration 16589 : loss : 0.020006, loss_ce: 0.005728
iteration 16590 : loss : 0.023609, loss_ce: 0.011660
iteration 16591 : loss : 0.022756, loss_ce: 0.009448
iteration 16592 : loss : 0.077589, loss_ce: 0.010587
iteration 16593 : loss : 0.023035, loss_ce: 0.008933
iteration 16594 : loss : 0.018792, loss_ce: 0.007845
iteration 16595 : loss : 0.026367, loss_ce: 0.008927
iteration 16596 : loss : 0.021532, loss_ce: 0.007938
iteration 16597 : loss : 0.018966, loss_ce: 0.006223
iteration 16598 : loss : 0.021297, loss_ce: 0.009406
iteration 16599 : loss : 0.021490, loss_ce: 0.004806
iteration 16600 : loss : 0.021433, loss_ce: 0.005139
iteration 16601 : loss : 0.026290, loss_ce: 0.004742
iteration 16602 : loss : 0.020925, loss_ce: 0.005948
iteration 16603 : loss : 0.020937, loss_ce: 0.008967
iteration 16604 : loss : 0.022963, loss_ce: 0.009639
iteration 16605 : loss : 0.022433, loss_ce: 0.010142
iteration 16606 : loss : 0.024214, loss_ce: 0.005159
iteration 16607 : loss : 0.021253, loss_ce: 0.007124
iteration 16608 : loss : 0.016231, loss_ce: 0.003973
iteration 16609 : loss : 0.021199, loss_ce: 0.008593
iteration 16610 : loss : 0.023007, loss_ce: 0.008484
iteration 16611 : loss : 0.020751, loss_ce: 0.006422
iteration 16612 : loss : 0.023466, loss_ce: 0.005147
iteration 16613 : loss : 0.022654, loss_ce: 0.004238
iteration 16614 : loss : 0.024217, loss_ce: 0.009165
iteration 16615 : loss : 0.021438, loss_ce: 0.007446
iteration 16616 : loss : 0.022905, loss_ce: 0.005062
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 16617 : loss : 0.021673, loss_ce: 0.012036
iteration 16618 : loss : 0.022142, loss_ce: 0.007384
iteration 16619 : loss : 0.020435, loss_ce: 0.010149
iteration 16620 : loss : 0.022746, loss_ce: 0.007672
iteration 16621 : loss : 0.020524, loss_ce: 0.009867
iteration 16622 : loss : 0.022935, loss_ce: 0.006827
iteration 16623 : loss : 0.028114, loss_ce: 0.004770
iteration 16624 : loss : 0.022438, loss_ce: 0.009664
iteration 16625 : loss : 0.118743, loss_ce: 0.001162
iteration 16626 : loss : 0.020987, loss_ce: 0.004954
iteration 16627 : loss : 0.024284, loss_ce: 0.007289
iteration 16628 : loss : 0.023409, loss_ce: 0.006667
iteration 16629 : loss : 0.019782, loss_ce: 0.006444
iteration 16630 : loss : 0.023002, loss_ce: 0.008679
iteration 16631 : loss : 0.023203, loss_ce: 0.011678
iteration 16632 : loss : 0.022739, loss_ce: 0.006236
iteration 16633 : loss : 0.021700, loss_ce: 0.007566
iteration 16634 : loss : 0.024316, loss_ce: 0.005480
iteration 16635 : loss : 0.025200, loss_ce: 0.012486
iteration 16636 : loss : 0.021054, loss_ce: 0.006642
iteration 16637 : loss : 0.024713, loss_ce: 0.010324
iteration 16638 : loss : 0.023643, loss_ce: 0.008298
iteration 16639 : loss : 0.025353, loss_ce: 0.004364
iteration 16640 : loss : 0.024115, loss_ce: 0.007429
iteration 16641 : loss : 0.024768, loss_ce: 0.007470
iteration 16642 : loss : 0.019061, loss_ce: 0.006982
iteration 16643 : loss : 0.021424, loss_ce: 0.009828
iteration 16644 : loss : 0.020910, loss_ce: 0.006824
iteration 16645 : loss : 0.020547, loss_ce: 0.005029
iteration 16646 : loss : 0.017929, loss_ce: 0.006385
iteration 16647 : loss : 0.385041, loss_ce: 0.002667
 90%|█████████████████████████▉   | 179/200 [2:42:34<19:04, 54.50s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 16648 : loss : 0.021327, loss_ce: 0.008244
iteration 16649 : loss : 0.025303, loss_ce: 0.006354
iteration 16650 : loss : 0.075535, loss_ce: 0.007822
iteration 16651 : loss : 0.017451, loss_ce: 0.004259
iteration 16652 : loss : 0.019285, loss_ce: 0.008540
iteration 16653 : loss : 0.024915, loss_ce: 0.005268
iteration 16654 : loss : 0.079527, loss_ce: 0.006256
iteration 16655 : loss : 0.019553, loss_ce: 0.006459
iteration 16656 : loss : 0.022508, loss_ce: 0.004321
iteration 16657 : loss : 0.019783, loss_ce: 0.006670
iteration 16658 : loss : 0.022418, loss_ce: 0.005291
iteration 16659 : loss : 0.020786, loss_ce: 0.007621
iteration 16660 : loss : 0.020865, loss_ce: 0.008493
iteration 16661 : loss : 0.021092, loss_ce: 0.008789
iteration 16662 : loss : 0.024305, loss_ce: 0.008792
iteration 16663 : loss : 0.026449, loss_ce: 0.006775
iteration 16664 : loss : 0.019865, loss_ce: 0.005136
iteration 16665 : loss : 0.074647, loss_ce: 0.008065
iteration 16666 : loss : 0.019277, loss_ce: 0.007221
iteration 16667 : loss : 0.019825, loss_ce: 0.007923
iteration 16668 : loss : 0.020748, loss_ce: 0.005514
iteration 16669 : loss : 0.023709, loss_ce: 0.008784
iteration 16670 : loss : 0.073547, loss_ce: 0.006369
iteration 16671 : loss : 0.020540, loss_ce: 0.007277
iteration 16672 : loss : 0.022747, loss_ce: 0.008294
iteration 16673 : loss : 0.020091, loss_ce: 0.007487
iteration 16674 : loss : 0.019980, loss_ce: 0.007974
iteration 16675 : loss : 0.023359, loss_ce: 0.007078
iteration 16676 : loss : 0.019867, loss_ce: 0.004795
iteration 16677 : loss : 0.027603, loss_ce: 0.009173
iteration 16678 : loss : 0.028076, loss_ce: 0.010925
pred_sum 16196
gtsum tensor(16066, device='cuda:0')
iteration 16679 : loss : 0.024922, loss_ce: 0.006879
iteration 16680 : loss : 0.020524, loss_ce: 0.005503
iteration 16681 : loss : 0.071222, loss_ce: 0.007192
iteration 16682 : loss : 0.023347, loss_ce: 0.011919
iteration 16683 : loss : 0.021014, loss_ce: 0.009519
iteration 16684 : loss : 0.020704, loss_ce: 0.006307
iteration 16685 : loss : 0.022899, loss_ce: 0.010496
iteration 16686 : loss : 0.021591, loss_ce: 0.007588
iteration 16687 : loss : 0.023490, loss_ce: 0.008714
iteration 16688 : loss : 0.020276, loss_ce: 0.006538
iteration 16689 : loss : 0.017134, loss_ce: 0.005080
iteration 16690 : loss : 0.023637, loss_ce: 0.007827
iteration 16691 : loss : 0.020357, loss_ce: 0.007597
iteration 16692 : loss : 0.025427, loss_ce: 0.003027
iteration 16693 : loss : 0.022174, loss_ce: 0.006078
iteration 16694 : loss : 0.020971, loss_ce: 0.009252
iteration 16695 : loss : 0.017877, loss_ce: 0.005859
iteration 16696 : loss : 0.019872, loss_ce: 0.008782
iteration 16697 : loss : 0.020933, loss_ce: 0.006863
iteration 16698 : loss : 0.024207, loss_ce: 0.008919
iteration 16699 : loss : 0.072221, loss_ce: 0.005806
iteration 16700 : loss : 0.021069, loss_ce: 0.006425
iteration 16701 : loss : 0.019204, loss_ce: 0.008856
iteration 16702 : loss : 0.024857, loss_ce: 0.005078
iteration 16703 : loss : 0.025521, loss_ce: 0.006310
iteration 16704 : loss : 0.025459, loss_ce: 0.008943
iteration 16705 : loss : 0.020287, loss_ce: 0.007181
iteration 16706 : loss : 0.027354, loss_ce: 0.007290
iteration 16707 : loss : 0.021912, loss_ce: 0.008598
iteration 16708 : loss : 0.026114, loss_ce: 0.005877
iteration 16709 : loss : 0.023922, loss_ce: 0.007716
pred_sum 32533
gtsum tensor(32073, device='cuda:0')
iteration 16710 : loss : 0.027572, loss_ce: 0.007814
iteration 16711 : loss : 0.022999, loss_ce: 0.008473
iteration 16712 : loss : 0.021140, loss_ce: 0.007821
iteration 16713 : loss : 0.022134, loss_ce: 0.008347
iteration 16714 : loss : 0.021161, loss_ce: 0.006519
iteration 16715 : loss : 0.025469, loss_ce: 0.011854
iteration 16716 : loss : 0.022332, loss_ce: 0.007579
iteration 16717 : loss : 0.023777, loss_ce: 0.006950
iteration 16718 : loss : 0.028050, loss_ce: 0.006765
iteration 16719 : loss : 0.019187, loss_ce: 0.006901
iteration 16720 : loss : 0.021722, loss_ce: 0.006576
iteration 16721 : loss : 0.018874, loss_ce: 0.006552
iteration 16722 : loss : 0.026151, loss_ce: 0.008542
iteration 16723 : loss : 0.020682, loss_ce: 0.007600
iteration 16724 : loss : 0.024159, loss_ce: 0.013095
iteration 16725 : loss : 0.075591, loss_ce: 0.005670
iteration 16726 : loss : 0.020314, loss_ce: 0.007403
iteration 16727 : loss : 0.048061, loss_ce: 0.007879
iteration 16728 : loss : 0.028441, loss_ce: 0.009730
iteration 16729 : loss : 0.025066, loss_ce: 0.008498
iteration 16730 : loss : 0.023728, loss_ce: 0.011354
iteration 16731 : loss : 0.019631, loss_ce: 0.006432
iteration 16732 : loss : 0.072644, loss_ce: 0.003530
iteration 16733 : loss : 0.023647, loss_ce: 0.007807
iteration 16734 : loss : 0.021162, loss_ce: 0.007857
iteration 16735 : loss : 0.026083, loss_ce: 0.010043
iteration 16736 : loss : 0.020104, loss_ce: 0.007243
iteration 16737 : loss : 0.022276, loss_ce: 0.009933
iteration 16738 : loss : 0.020951, loss_ce: 0.007242
iteration 16739 : loss : 0.018921, loss_ce: 0.006114
iteration 16740 : loss : 0.283177, loss_ce: 0.002377
 90%|██████████████████████████   | 180/200 [2:43:29<18:09, 54.49s/it]pred_sum 8103
gtsum tensor(7490, device='cuda:0')
iteration 16741 : loss : 0.022657, loss_ce: 0.007125
iteration 16742 : loss : 0.072609, loss_ce: 0.004664
iteration 16743 : loss : 0.024022, loss_ce: 0.007458
iteration 16744 : loss : 0.020557, loss_ce: 0.009321
iteration 16745 : loss : 0.028684, loss_ce: 0.011003
iteration 16746 : loss : 0.022565, loss_ce: 0.007521
iteration 16747 : loss : 0.027636, loss_ce: 0.006877
iteration 16748 : loss : 0.022002, loss_ce: 0.008292
iteration 16749 : loss : 0.072906, loss_ce: 0.004444
iteration 16750 : loss : 0.027338, loss_ce: 0.010534
iteration 16751 : loss : 0.032175, loss_ce: 0.008350
iteration 16752 : loss : 0.024028, loss_ce: 0.007125
iteration 16753 : loss : 0.022484, loss_ce: 0.006916
iteration 16754 : loss : 0.033703, loss_ce: 0.008336
iteration 16755 : loss : 0.022587, loss_ce: 0.007950
iteration 16756 : loss : 0.023718, loss_ce: 0.007315
iteration 16757 : loss : 0.023819, loss_ce: 0.005934
iteration 16758 : loss : 0.022799, loss_ce: 0.005247
iteration 16759 : loss : 0.018111, loss_ce: 0.005281
iteration 16760 : loss : 0.020442, loss_ce: 0.008107
iteration 16761 : loss : 0.020022, loss_ce: 0.005093
iteration 16762 : loss : 0.018327, loss_ce: 0.005047
iteration 16763 : loss : 0.020847, loss_ce: 0.006801
iteration 16764 : loss : 0.020281, loss_ce: 0.005082
iteration 16765 : loss : 0.022634, loss_ce: 0.009405
iteration 16766 : loss : 0.022047, loss_ce: 0.008216
iteration 16767 : loss : 0.019892, loss_ce: 0.006454
iteration 16768 : loss : 0.022986, loss_ce: 0.010181
iteration 16769 : loss : 0.073263, loss_ce: 0.003108
iteration 16770 : loss : 0.022039, loss_ce: 0.008099
iteration 16771 : loss : 0.021283, loss_ce: 0.008462
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 16772 : loss : 0.022271, loss_ce: 0.007800
iteration 16773 : loss : 0.024306, loss_ce: 0.010440
iteration 16774 : loss : 0.020206, loss_ce: 0.005788
iteration 16775 : loss : 0.021525, loss_ce: 0.009306
iteration 16776 : loss : 0.023868, loss_ce: 0.005293
iteration 16777 : loss : 0.025501, loss_ce: 0.007015
iteration 16778 : loss : 0.020833, loss_ce: 0.007441
iteration 16779 : loss : 0.075919, loss_ce: 0.006453
iteration 16780 : loss : 0.020688, loss_ce: 0.009699
iteration 16781 : loss : 0.022769, loss_ce: 0.007448
iteration 16782 : loss : 0.020497, loss_ce: 0.005711
iteration 16783 : loss : 0.022194, loss_ce: 0.008264
iteration 16784 : loss : 0.021935, loss_ce: 0.008786
iteration 16785 : loss : 0.023947, loss_ce: 0.005853
iteration 16786 : loss : 0.073878, loss_ce: 0.006534
iteration 16787 : loss : 0.024125, loss_ce: 0.005016
iteration 16788 : loss : 0.074124, loss_ce: 0.007387
iteration 16789 : loss : 0.023841, loss_ce: 0.007674
iteration 16790 : loss : 0.016671, loss_ce: 0.005111
iteration 16791 : loss : 0.022426, loss_ce: 0.011704
iteration 16792 : loss : 0.021639, loss_ce: 0.011631
iteration 16793 : loss : 0.017460, loss_ce: 0.003423
iteration 16794 : loss : 0.022071, loss_ce: 0.007548
iteration 16795 : loss : 0.018351, loss_ce: 0.006564
iteration 16796 : loss : 0.020995, loss_ce: 0.005413
iteration 16797 : loss : 0.020365, loss_ce: 0.006886
iteration 16798 : loss : 0.021699, loss_ce: 0.006626
iteration 16799 : loss : 0.019812, loss_ce: 0.009786
iteration 16800 : loss : 0.022491, loss_ce: 0.007928
iteration 16801 : loss : 0.021371, loss_ce: 0.008985
iteration 16802 : loss : 0.041107, loss_ce: 0.006670
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 16803 : loss : 0.025612, loss_ce: 0.009470
iteration 16804 : loss : 0.018772, loss_ce: 0.011115
iteration 16805 : loss : 0.023208, loss_ce: 0.008123
iteration 16806 : loss : 0.021022, loss_ce: 0.009211
iteration 16807 : loss : 0.021158, loss_ce: 0.009332
iteration 16808 : loss : 0.025062, loss_ce: 0.012839
iteration 16809 : loss : 0.020235, loss_ce: 0.004949
iteration 16810 : loss : 0.023402, loss_ce: 0.006318
iteration 16811 : loss : 0.023815, loss_ce: 0.008650
iteration 16812 : loss : 0.024369, loss_ce: 0.011268
iteration 16813 : loss : 0.033627, loss_ce: 0.006248
iteration 16814 : loss : 0.020126, loss_ce: 0.006672
iteration 16815 : loss : 0.021408, loss_ce: 0.007215
iteration 16816 : loss : 0.022849, loss_ce: 0.008215
iteration 16817 : loss : 0.024894, loss_ce: 0.007220
iteration 16818 : loss : 0.021115, loss_ce: 0.006243
iteration 16819 : loss : 0.020569, loss_ce: 0.007237
iteration 16820 : loss : 0.019599, loss_ce: 0.005257
iteration 16821 : loss : 0.019988, loss_ce: 0.006078
iteration 16822 : loss : 0.021906, loss_ce: 0.007370
iteration 16823 : loss : 0.018006, loss_ce: 0.005235
iteration 16824 : loss : 0.018167, loss_ce: 0.007130
iteration 16825 : loss : 0.019262, loss_ce: 0.008872
iteration 16826 : loss : 0.024285, loss_ce: 0.011669
iteration 16827 : loss : 0.022379, loss_ce: 0.009914
iteration 16828 : loss : 0.026769, loss_ce: 0.007474
iteration 16829 : loss : 0.022675, loss_ce: 0.006809
iteration 16830 : loss : 0.071645, loss_ce: 0.003442
iteration 16831 : loss : 0.020727, loss_ce: 0.004670
iteration 16832 : loss : 0.020556, loss_ce: 0.008133
iteration 16833 : loss : 0.389319, loss_ce: 0.001230
 90%|██████████████████████████▏  | 181/200 [2:44:23<17:15, 54.50s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 16834 : loss : 0.023974, loss_ce: 0.008343
iteration 16835 : loss : 0.039079, loss_ce: 0.009867
iteration 16836 : loss : 0.020669, loss_ce: 0.007874
iteration 16837 : loss : 0.021829, loss_ce: 0.008141
iteration 16838 : loss : 0.026898, loss_ce: 0.005862
iteration 16839 : loss : 0.021623, loss_ce: 0.004994
iteration 16840 : loss : 0.024285, loss_ce: 0.010631
iteration 16841 : loss : 0.023750, loss_ce: 0.005211
iteration 16842 : loss : 0.018867, loss_ce: 0.008145
iteration 16843 : loss : 0.022149, loss_ce: 0.006991
iteration 16844 : loss : 0.072454, loss_ce: 0.005938
iteration 16845 : loss : 0.020455, loss_ce: 0.007750
iteration 16846 : loss : 0.023293, loss_ce: 0.005509
iteration 16847 : loss : 0.017542, loss_ce: 0.005637
iteration 16848 : loss : 0.024543, loss_ce: 0.007766
iteration 16849 : loss : 0.019683, loss_ce: 0.007734
iteration 16850 : loss : 0.021109, loss_ce: 0.006565
iteration 16851 : loss : 0.019526, loss_ce: 0.006694
iteration 16852 : loss : 0.021363, loss_ce: 0.005619
iteration 16853 : loss : 0.021359, loss_ce: 0.007407
iteration 16854 : loss : 0.022370, loss_ce: 0.006619
iteration 16855 : loss : 0.024722, loss_ce: 0.009529
iteration 16856 : loss : 0.020039, loss_ce: 0.006135
iteration 16857 : loss : 0.022225, loss_ce: 0.009511
iteration 16858 : loss : 0.024641, loss_ce: 0.010968
iteration 16859 : loss : 0.022732, loss_ce: 0.007455
iteration 16860 : loss : 0.022328, loss_ce: 0.008225
iteration 16861 : loss : 0.019581, loss_ce: 0.006320
iteration 16862 : loss : 0.017542, loss_ce: 0.005374
iteration 16863 : loss : 0.020735, loss_ce: 0.009100
iteration 16864 : loss : 0.022310, loss_ce: 0.008274
pred_sum 30508
gtsum tensor(29587, device='cuda:0')
iteration 16865 : loss : 0.030802, loss_ce: 0.004760
iteration 16866 : loss : 0.017877, loss_ce: 0.004379
iteration 16867 : loss : 0.020174, loss_ce: 0.007274
iteration 16868 : loss : 0.020991, loss_ce: 0.010098
iteration 16869 : loss : 0.036811, loss_ce: 0.003736
iteration 16870 : loss : 0.021968, loss_ce: 0.009501
iteration 16871 : loss : 0.020964, loss_ce: 0.010387
iteration 16872 : loss : 0.020989, loss_ce: 0.008208
iteration 16873 : loss : 0.029585, loss_ce: 0.008999
iteration 16874 : loss : 0.027192, loss_ce: 0.005113
iteration 16875 : loss : 0.124630, loss_ce: 0.004923
iteration 16876 : loss : 0.024101, loss_ce: 0.005631
iteration 16877 : loss : 0.022851, loss_ce: 0.009368
iteration 16878 : loss : 0.023267, loss_ce: 0.012990
iteration 16879 : loss : 0.017834, loss_ce: 0.008122
iteration 16880 : loss : 0.020445, loss_ce: 0.005650
iteration 16881 : loss : 0.021595, loss_ce: 0.007914
iteration 16882 : loss : 0.018397, loss_ce: 0.005790
iteration 16883 : loss : 0.074374, loss_ce: 0.007411
iteration 16884 : loss : 0.024343, loss_ce: 0.007989
iteration 16885 : loss : 0.021550, loss_ce: 0.005136
iteration 16886 : loss : 0.021124, loss_ce: 0.007929
iteration 16887 : loss : 0.024231, loss_ce: 0.010407
iteration 16888 : loss : 0.021993, loss_ce: 0.008978
iteration 16889 : loss : 0.023058, loss_ce: 0.005937
iteration 16890 : loss : 0.020841, loss_ce: 0.005475
iteration 16891 : loss : 0.020323, loss_ce: 0.007350
iteration 16892 : loss : 0.018514, loss_ce: 0.007035
iteration 16893 : loss : 0.073586, loss_ce: 0.006300
iteration 16894 : loss : 0.022380, loss_ce: 0.008515
iteration 16895 : loss : 0.020127, loss_ce: 0.007219
pred_sum 3882
gtsum tensor(4051, device='cuda:0')
iteration 16896 : loss : 0.027008, loss_ce: 0.006914
iteration 16897 : loss : 0.019159, loss_ce: 0.005432
iteration 16898 : loss : 0.022262, loss_ce: 0.006011
iteration 16899 : loss : 0.020068, loss_ce: 0.005968
iteration 16900 : loss : 0.026243, loss_ce: 0.008927
iteration 16901 : loss : 0.024061, loss_ce: 0.007727
iteration 16902 : loss : 0.020793, loss_ce: 0.006069
iteration 16903 : loss : 0.019493, loss_ce: 0.010184
iteration 16904 : loss : 0.019889, loss_ce: 0.007695
iteration 16905 : loss : 0.020846, loss_ce: 0.008822
iteration 16906 : loss : 0.027213, loss_ce: 0.004977
iteration 16907 : loss : 0.024228, loss_ce: 0.012726
iteration 16908 : loss : 0.025212, loss_ce: 0.007684
iteration 16909 : loss : 0.020454, loss_ce: 0.006337
iteration 16910 : loss : 0.020410, loss_ce: 0.012646
iteration 16911 : loss : 0.026649, loss_ce: 0.007753
iteration 16912 : loss : 0.023025, loss_ce: 0.007625
iteration 16913 : loss : 0.023372, loss_ce: 0.007420
iteration 16914 : loss : 0.020315, loss_ce: 0.005644
iteration 16915 : loss : 0.022480, loss_ce: 0.007568
iteration 16916 : loss : 0.023651, loss_ce: 0.008602
iteration 16917 : loss : 0.018315, loss_ce: 0.005402
iteration 16918 : loss : 0.080370, loss_ce: 0.003779
iteration 16919 : loss : 0.019244, loss_ce: 0.006844
iteration 16920 : loss : 0.024040, loss_ce: 0.011588
iteration 16921 : loss : 0.022128, loss_ce: 0.006537
iteration 16922 : loss : 0.019885, loss_ce: 0.005529
iteration 16923 : loss : 0.075088, loss_ce: 0.008245
iteration 16924 : loss : 0.123602, loss_ce: 0.003795
iteration 16925 : loss : 0.023382, loss_ce: 0.008942
iteration 16926 : loss : 0.229004, loss_ce: 0.003012
 91%|██████████████████████████▍  | 182/200 [2:45:18<16:21, 54.51s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 16927 : loss : 0.021912, loss_ce: 0.008165
iteration 16928 : loss : 0.020904, loss_ce: 0.009908
iteration 16929 : loss : 0.024888, loss_ce: 0.009617
iteration 16930 : loss : 0.022396, loss_ce: 0.010175
iteration 16931 : loss : 0.024321, loss_ce: 0.004935
iteration 16932 : loss : 0.022145, loss_ce: 0.004323
iteration 16933 : loss : 0.026121, loss_ce: 0.008301
iteration 16934 : loss : 0.020061, loss_ce: 0.007336
iteration 16935 : loss : 0.019678, loss_ce: 0.006942
iteration 16936 : loss : 0.027307, loss_ce: 0.005369
iteration 16937 : loss : 0.018870, loss_ce: 0.006538
iteration 16938 : loss : 0.019660, loss_ce: 0.005489
iteration 16939 : loss : 0.022208, loss_ce: 0.007559
iteration 16940 : loss : 0.021356, loss_ce: 0.009701
iteration 16941 : loss : 0.019037, loss_ce: 0.006198
iteration 16942 : loss : 0.046004, loss_ce: 0.005764
iteration 16943 : loss : 0.020429, loss_ce: 0.006468
iteration 16944 : loss : 0.019396, loss_ce: 0.005510
iteration 16945 : loss : 0.019290, loss_ce: 0.005619
iteration 16946 : loss : 0.022191, loss_ce: 0.008417
iteration 16947 : loss : 0.017202, loss_ce: 0.006031
iteration 16948 : loss : 0.073769, loss_ce: 0.005799
iteration 16949 : loss : 0.019870, loss_ce: 0.008058
iteration 16950 : loss : 0.021286, loss_ce: 0.004436
iteration 16951 : loss : 0.020011, loss_ce: 0.007531
iteration 16952 : loss : 0.022306, loss_ce: 0.008262
iteration 16953 : loss : 0.023131, loss_ce: 0.010459
iteration 16954 : loss : 0.020467, loss_ce: 0.007750
iteration 16955 : loss : 0.024577, loss_ce: 0.009522
iteration 16956 : loss : 0.028864, loss_ce: 0.006509
iteration 16957 : loss : 0.019911, loss_ce: 0.007023
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 16958 : loss : 0.023633, loss_ce: 0.006493
iteration 16959 : loss : 0.021488, loss_ce: 0.004852
iteration 16960 : loss : 0.017810, loss_ce: 0.003643
iteration 16961 : loss : 0.023549, loss_ce: 0.013334
iteration 16962 : loss : 0.027419, loss_ce: 0.007503
iteration 16963 : loss : 0.020794, loss_ce: 0.006760
iteration 16964 : loss : 0.024896, loss_ce: 0.012141
iteration 16965 : loss : 0.025243, loss_ce: 0.009952
iteration 16966 : loss : 0.019223, loss_ce: 0.007496
iteration 16967 : loss : 0.022138, loss_ce: 0.007933
iteration 16968 : loss : 0.022191, loss_ce: 0.007171
iteration 16969 : loss : 0.020898, loss_ce: 0.006155
iteration 16970 : loss : 0.020355, loss_ce: 0.003905
iteration 16971 : loss : 0.021412, loss_ce: 0.007677
iteration 16972 : loss : 0.023524, loss_ce: 0.009688
iteration 16973 : loss : 0.016937, loss_ce: 0.006984
iteration 16974 : loss : 0.022727, loss_ce: 0.007676
iteration 16975 : loss : 0.019666, loss_ce: 0.006218
iteration 16976 : loss : 0.022595, loss_ce: 0.005761
iteration 16977 : loss : 0.024409, loss_ce: 0.005832
iteration 16978 : loss : 0.021069, loss_ce: 0.006705
iteration 16979 : loss : 0.023226, loss_ce: 0.009281
iteration 16980 : loss : 0.072131, loss_ce: 0.006238
iteration 16981 : loss : 0.018054, loss_ce: 0.004437
iteration 16982 : loss : 0.021786, loss_ce: 0.006784
iteration 16983 : loss : 0.017935, loss_ce: 0.009026
iteration 16984 : loss : 0.023636, loss_ce: 0.008745
iteration 16985 : loss : 0.022523, loss_ce: 0.007353
iteration 16986 : loss : 0.016843, loss_ce: 0.005591
iteration 16987 : loss : 0.021358, loss_ce: 0.007055
iteration 16988 : loss : 0.025359, loss_ce: 0.005787
pred_sum 3108
gtsum tensor(3272, device='cuda:0')
iteration 16989 : loss : 0.023986, loss_ce: 0.006196
iteration 16990 : loss : 0.019826, loss_ce: 0.005551
iteration 16991 : loss : 0.021827, loss_ce: 0.007290
iteration 16992 : loss : 0.025474, loss_ce: 0.006636
iteration 16993 : loss : 0.019929, loss_ce: 0.006146
iteration 16994 : loss : 0.022527, loss_ce: 0.009290
iteration 16995 : loss : 0.019571, loss_ce: 0.008996
iteration 16996 : loss : 0.025636, loss_ce: 0.007692
iteration 16997 : loss : 0.020190, loss_ce: 0.008525
iteration 16998 : loss : 0.022018, loss_ce: 0.007116
iteration 16999 : loss : 0.019806, loss_ce: 0.006672
iteration 17000 : loss : 0.018692, loss_ce: 0.007995
iteration 17001 : loss : 0.021560, loss_ce: 0.008102
iteration 17002 : loss : 0.022267, loss_ce: 0.009838
iteration 17003 : loss : 0.019316, loss_ce: 0.007082
iteration 17004 : loss : 0.019328, loss_ce: 0.005333
iteration 17005 : loss : 0.019856, loss_ce: 0.007728
iteration 17006 : loss : 0.024981, loss_ce: 0.004760
iteration 17007 : loss : 0.025995, loss_ce: 0.008293
iteration 17008 : loss : 0.022815, loss_ce: 0.006502
iteration 17009 : loss : 0.023589, loss_ce: 0.008244
iteration 17010 : loss : 0.027326, loss_ce: 0.011297
iteration 17011 : loss : 0.022984, loss_ce: 0.008349
iteration 17012 : loss : 0.024188, loss_ce: 0.011412
iteration 17013 : loss : 0.026294, loss_ce: 0.005328
iteration 17014 : loss : 0.021411, loss_ce: 0.009779
iteration 17015 : loss : 0.024944, loss_ce: 0.006631
iteration 17016 : loss : 0.019921, loss_ce: 0.008628
iteration 17017 : loss : 0.025287, loss_ce: 0.008881
iteration 17018 : loss : 0.021890, loss_ce: 0.009458
iteration 17019 : loss : 0.080524, loss_ce: 0.011046
 92%|██████████████████████████▌  | 183/200 [2:46:12<15:26, 54.50s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 17020 : loss : 0.082614, loss_ce: 0.007692
iteration 17021 : loss : 0.020829, loss_ce: 0.007982
iteration 17022 : loss : 0.020342, loss_ce: 0.010781
iteration 17023 : loss : 0.021838, loss_ce: 0.008512
iteration 17024 : loss : 0.027450, loss_ce: 0.009003
iteration 17025 : loss : 0.023585, loss_ce: 0.009849
iteration 17026 : loss : 0.022425, loss_ce: 0.008650
iteration 17027 : loss : 0.017675, loss_ce: 0.005555
iteration 17028 : loss : 0.020506, loss_ce: 0.007634
iteration 17029 : loss : 0.018573, loss_ce: 0.007532
iteration 17030 : loss : 0.023678, loss_ce: 0.008237
iteration 17031 : loss : 0.029832, loss_ce: 0.007319
iteration 17032 : loss : 0.027239, loss_ce: 0.011157
iteration 17033 : loss : 0.020006, loss_ce: 0.006205
iteration 17034 : loss : 0.023694, loss_ce: 0.004787
iteration 17035 : loss : 0.021631, loss_ce: 0.009303
iteration 17036 : loss : 0.018616, loss_ce: 0.007218
iteration 17037 : loss : 0.025161, loss_ce: 0.008687
iteration 17038 : loss : 0.021499, loss_ce: 0.009220
iteration 17039 : loss : 0.021394, loss_ce: 0.006444
iteration 17040 : loss : 0.023466, loss_ce: 0.005573
iteration 17041 : loss : 0.021810, loss_ce: 0.009922
iteration 17042 : loss : 0.021612, loss_ce: 0.006363
iteration 17043 : loss : 0.023526, loss_ce: 0.010152
iteration 17044 : loss : 0.026036, loss_ce: 0.010353
iteration 17045 : loss : 0.022091, loss_ce: 0.006835
iteration 17046 : loss : 0.020443, loss_ce: 0.005669
iteration 17047 : loss : 0.021035, loss_ce: 0.007507
iteration 17048 : loss : 0.020855, loss_ce: 0.007526
iteration 17049 : loss : 0.024674, loss_ce: 0.005276
iteration 17050 : loss : 0.069840, loss_ce: 0.005896
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 17051 : loss : 0.021901, loss_ce: 0.007823
iteration 17052 : loss : 0.074714, loss_ce: 0.008919
iteration 17053 : loss : 0.021414, loss_ce: 0.006347
iteration 17054 : loss : 0.021520, loss_ce: 0.007164
iteration 17055 : loss : 0.023490, loss_ce: 0.006251
iteration 17056 : loss : 0.074503, loss_ce: 0.007222
iteration 17057 : loss : 0.020692, loss_ce: 0.007899
iteration 17058 : loss : 0.019168, loss_ce: 0.006957
iteration 17059 : loss : 0.021793, loss_ce: 0.010262
iteration 17060 : loss : 0.019581, loss_ce: 0.004844
iteration 17061 : loss : 0.023290, loss_ce: 0.008803
iteration 17062 : loss : 0.021346, loss_ce: 0.003875
iteration 17063 : loss : 0.023969, loss_ce: 0.008486
iteration 17064 : loss : 0.019591, loss_ce: 0.007738
iteration 17065 : loss : 0.021387, loss_ce: 0.006700
iteration 17066 : loss : 0.018674, loss_ce: 0.006411
iteration 17067 : loss : 0.018946, loss_ce: 0.008424
iteration 17068 : loss : 0.024081, loss_ce: 0.004561
iteration 17069 : loss : 0.021789, loss_ce: 0.004791
iteration 17070 : loss : 0.019779, loss_ce: 0.006586
iteration 17071 : loss : 0.024401, loss_ce: 0.009193
iteration 17072 : loss : 0.070948, loss_ce: 0.004111
iteration 17073 : loss : 0.022105, loss_ce: 0.007193
iteration 17074 : loss : 0.018290, loss_ce: 0.007932
iteration 17075 : loss : 0.021776, loss_ce: 0.008254
iteration 17076 : loss : 0.024391, loss_ce: 0.005322
iteration 17077 : loss : 0.021674, loss_ce: 0.007084
iteration 17078 : loss : 0.020465, loss_ce: 0.007004
iteration 17079 : loss : 0.017910, loss_ce: 0.005472
iteration 17080 : loss : 0.075635, loss_ce: 0.010171
iteration 17081 : loss : 0.019183, loss_ce: 0.006031
pred_sum 30063
gtsum tensor(30231, device='cuda:0')
iteration 17082 : loss : 0.022221, loss_ce: 0.009030
iteration 17083 : loss : 0.023380, loss_ce: 0.009627
iteration 17084 : loss : 0.020999, loss_ce: 0.006928
iteration 17085 : loss : 0.022785, loss_ce: 0.006706
iteration 17086 : loss : 0.027119, loss_ce: 0.007633
iteration 17087 : loss : 0.069690, loss_ce: 0.004457
iteration 17088 : loss : 0.016360, loss_ce: 0.006415
iteration 17089 : loss : 0.072768, loss_ce: 0.003578
iteration 17090 : loss : 0.020882, loss_ce: 0.006426
iteration 17091 : loss : 0.023468, loss_ce: 0.004999
iteration 17092 : loss : 0.020213, loss_ce: 0.007057
iteration 17093 : loss : 0.021147, loss_ce: 0.010485
iteration 17094 : loss : 0.024386, loss_ce: 0.008104
iteration 17095 : loss : 0.022351, loss_ce: 0.010323
iteration 17096 : loss : 0.019148, loss_ce: 0.005323
iteration 17097 : loss : 0.020173, loss_ce: 0.008717
iteration 17098 : loss : 0.023090, loss_ce: 0.008706
iteration 17099 : loss : 0.025324, loss_ce: 0.007145
iteration 17100 : loss : 0.022739, loss_ce: 0.005437
iteration 17101 : loss : 0.026583, loss_ce: 0.008567
iteration 17102 : loss : 0.024712, loss_ce: 0.008516
iteration 17103 : loss : 0.019892, loss_ce: 0.005708
iteration 17104 : loss : 0.069984, loss_ce: 0.005312
iteration 17105 : loss : 0.025794, loss_ce: 0.008910
iteration 17106 : loss : 0.022629, loss_ce: 0.006062
iteration 17107 : loss : 0.020960, loss_ce: 0.009508
iteration 17108 : loss : 0.022210, loss_ce: 0.007181
iteration 17109 : loss : 0.019485, loss_ce: 0.006471
iteration 17110 : loss : 0.025019, loss_ce: 0.007517
iteration 17111 : loss : 0.020390, loss_ce: 0.006598
iteration 17112 : loss : 0.025958, loss_ce: 0.010466
 92%|██████████████████████████▋  | 184/200 [2:47:07<14:31, 54.49s/it]pred_sum 46933
gtsum tensor(46675, device='cuda:0')
iteration 17113 : loss : 0.021124, loss_ce: 0.007304
iteration 17114 : loss : 0.023044, loss_ce: 0.006840
iteration 17115 : loss : 0.023215, loss_ce: 0.011757
iteration 17116 : loss : 0.020633, loss_ce: 0.005253
iteration 17117 : loss : 0.023031, loss_ce: 0.007397
iteration 17118 : loss : 0.024308, loss_ce: 0.007538
iteration 17119 : loss : 0.069731, loss_ce: 0.006707
iteration 17120 : loss : 0.021296, loss_ce: 0.007034
iteration 17121 : loss : 0.021005, loss_ce: 0.008416
iteration 17122 : loss : 0.020195, loss_ce: 0.006152
iteration 17123 : loss : 0.018811, loss_ce: 0.008047
iteration 17124 : loss : 0.072112, loss_ce: 0.003968
iteration 17125 : loss : 0.022548, loss_ce: 0.008531
iteration 17126 : loss : 0.069546, loss_ce: 0.003612
iteration 17127 : loss : 0.020919, loss_ce: 0.008706
iteration 17128 : loss : 0.019513, loss_ce: 0.006376
iteration 17129 : loss : 0.022147, loss_ce: 0.006132
iteration 17130 : loss : 0.020308, loss_ce: 0.007830
iteration 17131 : loss : 0.021770, loss_ce: 0.008481
iteration 17132 : loss : 0.025176, loss_ce: 0.010015
iteration 17133 : loss : 0.019627, loss_ce: 0.005655
iteration 17134 : loss : 0.020656, loss_ce: 0.006865
iteration 17135 : loss : 0.018637, loss_ce: 0.006397
iteration 17136 : loss : 0.019030, loss_ce: 0.007733
iteration 17137 : loss : 0.024076, loss_ce: 0.004708
iteration 17138 : loss : 0.029243, loss_ce: 0.005476
iteration 17139 : loss : 0.022009, loss_ce: 0.008822
iteration 17140 : loss : 0.023233, loss_ce: 0.004896
iteration 17141 : loss : 0.021237, loss_ce: 0.006766
iteration 17142 : loss : 0.017759, loss_ce: 0.005302
iteration 17143 : loss : 0.036819, loss_ce: 0.003347
pred_sum 26042
gtsum tensor(25927, device='cuda:0')
iteration 17144 : loss : 0.022341, loss_ce: 0.006004
iteration 17145 : loss : 0.022745, loss_ce: 0.011739
iteration 17146 : loss : 0.021205, loss_ce: 0.005080
iteration 17147 : loss : 0.025010, loss_ce: 0.009106
iteration 17148 : loss : 0.021623, loss_ce: 0.007534
iteration 17149 : loss : 0.020365, loss_ce: 0.008177
iteration 17150 : loss : 0.019406, loss_ce: 0.003918
iteration 17151 : loss : 0.020180, loss_ce: 0.010948
iteration 17152 : loss : 0.024914, loss_ce: 0.007620
iteration 17153 : loss : 0.021744, loss_ce: 0.009935
iteration 17154 : loss : 0.021468, loss_ce: 0.009331
iteration 17155 : loss : 0.021390, loss_ce: 0.008377
iteration 17156 : loss : 0.017637, loss_ce: 0.007305
iteration 17157 : loss : 0.021082, loss_ce: 0.006483
iteration 17158 : loss : 0.020168, loss_ce: 0.007770
iteration 17159 : loss : 0.023528, loss_ce: 0.008020
iteration 17160 : loss : 0.022821, loss_ce: 0.010540
iteration 17161 : loss : 0.024615, loss_ce: 0.009645
iteration 17162 : loss : 0.028531, loss_ce: 0.007487
iteration 17163 : loss : 0.023973, loss_ce: 0.009029
iteration 17164 : loss : 0.023558, loss_ce: 0.011593
iteration 17165 : loss : 0.020682, loss_ce: 0.007295
iteration 17166 : loss : 0.020835, loss_ce: 0.006239
iteration 17167 : loss : 0.021954, loss_ce: 0.009342
iteration 17168 : loss : 0.017207, loss_ce: 0.004698
iteration 17169 : loss : 0.021837, loss_ce: 0.006791
iteration 17170 : loss : 0.019182, loss_ce: 0.005593
iteration 17171 : loss : 0.021465, loss_ce: 0.006091
iteration 17172 : loss : 0.019732, loss_ce: 0.008135
iteration 17173 : loss : 0.018367, loss_ce: 0.007675
iteration 17174 : loss : 0.023937, loss_ce: 0.006040
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 17175 : loss : 0.023439, loss_ce: 0.003913
iteration 17176 : loss : 0.031804, loss_ce: 0.005541
iteration 17177 : loss : 0.023080, loss_ce: 0.005430
iteration 17178 : loss : 0.025269, loss_ce: 0.009950
iteration 17179 : loss : 0.018940, loss_ce: 0.003302
iteration 17180 : loss : 0.020359, loss_ce: 0.005765
iteration 17181 : loss : 0.021162, loss_ce: 0.008134
iteration 17182 : loss : 0.021866, loss_ce: 0.005333
iteration 17183 : loss : 0.074783, loss_ce: 0.006157
iteration 17184 : loss : 0.024968, loss_ce: 0.009198
iteration 17185 : loss : 0.075330, loss_ce: 0.006310
iteration 17186 : loss : 0.022758, loss_ce: 0.009399
iteration 17187 : loss : 0.023925, loss_ce: 0.009871
iteration 17188 : loss : 0.020274, loss_ce: 0.009523
iteration 17189 : loss : 0.021599, loss_ce: 0.008304
iteration 17190 : loss : 0.024103, loss_ce: 0.007810
iteration 17191 : loss : 0.022926, loss_ce: 0.011581
iteration 17192 : loss : 0.024061, loss_ce: 0.013104
iteration 17193 : loss : 0.019921, loss_ce: 0.005033
iteration 17194 : loss : 0.021519, loss_ce: 0.007037
iteration 17195 : loss : 0.024402, loss_ce: 0.010872
iteration 17196 : loss : 0.019364, loss_ce: 0.005623
iteration 17197 : loss : 0.024567, loss_ce: 0.007871
iteration 17198 : loss : 0.018891, loss_ce: 0.005611
iteration 17199 : loss : 0.022714, loss_ce: 0.007047
iteration 17200 : loss : 0.021500, loss_ce: 0.005068
iteration 17201 : loss : 0.021644, loss_ce: 0.008501
iteration 17202 : loss : 0.022097, loss_ce: 0.009275
iteration 17203 : loss : 0.024863, loss_ce: 0.006960
iteration 17204 : loss : 0.024347, loss_ce: 0.006229
iteration 17205 : loss : 0.284527, loss_ce: 0.004955
 92%|██████████████████████████▊  | 185/200 [2:48:01<13:36, 54.46s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 17206 : loss : 0.022697, loss_ce: 0.005401
iteration 17207 : loss : 0.028515, loss_ce: 0.006160
iteration 17208 : loss : 0.020916, loss_ce: 0.004011
iteration 17209 : loss : 0.021566, loss_ce: 0.010023
iteration 17210 : loss : 0.024867, loss_ce: 0.008762
iteration 17211 : loss : 0.022065, loss_ce: 0.009420
iteration 17212 : loss : 0.020608, loss_ce: 0.007379
iteration 17213 : loss : 0.021053, loss_ce: 0.008708
iteration 17214 : loss : 0.022167, loss_ce: 0.009588
iteration 17215 : loss : 0.023414, loss_ce: 0.009943
iteration 17216 : loss : 0.020922, loss_ce: 0.009360
iteration 17217 : loss : 0.074963, loss_ce: 0.003799
iteration 17218 : loss : 0.024311, loss_ce: 0.006730
iteration 17219 : loss : 0.127729, loss_ce: 0.004841
iteration 17220 : loss : 0.019769, loss_ce: 0.007631
iteration 17221 : loss : 0.023374, loss_ce: 0.007767
iteration 17222 : loss : 0.021910, loss_ce: 0.010828
iteration 17223 : loss : 0.022026, loss_ce: 0.012086
iteration 17224 : loss : 0.020860, loss_ce: 0.009353
iteration 17225 : loss : 0.018524, loss_ce: 0.005883
iteration 17226 : loss : 0.019163, loss_ce: 0.005192
iteration 17227 : loss : 0.022612, loss_ce: 0.010209
iteration 17228 : loss : 0.022547, loss_ce: 0.006447
iteration 17229 : loss : 0.021860, loss_ce: 0.005813
iteration 17230 : loss : 0.018868, loss_ce: 0.005445
iteration 17231 : loss : 0.020682, loss_ce: 0.009432
iteration 17232 : loss : 0.020390, loss_ce: 0.005019
iteration 17233 : loss : 0.022033, loss_ce: 0.008407
iteration 17234 : loss : 0.017576, loss_ce: 0.005278
iteration 17235 : loss : 0.022116, loss_ce: 0.003950
iteration 17236 : loss : 0.021000, loss_ce: 0.005772
pred_sum 35637
gtsum tensor(35400, device='cuda:0')
iteration 17237 : loss : 0.022559, loss_ce: 0.008722
iteration 17238 : loss : 0.021565, loss_ce: 0.010359
iteration 17239 : loss : 0.024014, loss_ce: 0.009937
iteration 17240 : loss : 0.022647, loss_ce: 0.009643
iteration 17241 : loss : 0.021641, loss_ce: 0.008640
iteration 17242 : loss : 0.021995, loss_ce: 0.010154
iteration 17243 : loss : 0.023109, loss_ce: 0.006979
iteration 17244 : loss : 0.021482, loss_ce: 0.009593
iteration 17245 : loss : 0.020453, loss_ce: 0.006574
iteration 17246 : loss : 0.027589, loss_ce: 0.004718
iteration 17247 : loss : 0.021189, loss_ce: 0.010410
iteration 17248 : loss : 0.023004, loss_ce: 0.006796
iteration 17249 : loss : 0.023891, loss_ce: 0.008208
iteration 17250 : loss : 0.023344, loss_ce: 0.010849
iteration 17251 : loss : 0.019547, loss_ce: 0.005334
iteration 17252 : loss : 0.025455, loss_ce: 0.010348
iteration 17253 : loss : 0.026246, loss_ce: 0.006453
iteration 17254 : loss : 0.021267, loss_ce: 0.006976
iteration 17255 : loss : 0.025889, loss_ce: 0.007378
iteration 17256 : loss : 0.018457, loss_ce: 0.005774
iteration 17257 : loss : 0.019798, loss_ce: 0.008619
iteration 17258 : loss : 0.022782, loss_ce: 0.006158
iteration 17259 : loss : 0.021852, loss_ce: 0.008466
iteration 17260 : loss : 0.023892, loss_ce: 0.010210
iteration 17261 : loss : 0.022177, loss_ce: 0.006895
iteration 17262 : loss : 0.018494, loss_ce: 0.007246
iteration 17263 : loss : 0.019276, loss_ce: 0.003218
iteration 17264 : loss : 0.020038, loss_ce: 0.009449
iteration 17265 : loss : 0.074130, loss_ce: 0.008533
iteration 17266 : loss : 0.020732, loss_ce: 0.009108
iteration 17267 : loss : 0.022207, loss_ce: 0.007399
pred_sum 50555
gtsum tensor(49932, device='cuda:0')
iteration 17268 : loss : 0.022678, loss_ce: 0.006774
iteration 17269 : loss : 0.020832, loss_ce: 0.007796
iteration 17270 : loss : 0.023830, loss_ce: 0.006716
iteration 17271 : loss : 0.074955, loss_ce: 0.009208
iteration 17272 : loss : 0.023886, loss_ce: 0.005744
iteration 17273 : loss : 0.023932, loss_ce: 0.010694
iteration 17274 : loss : 0.072587, loss_ce: 0.005552
iteration 17275 : loss : 0.020866, loss_ce: 0.005068
iteration 17276 : loss : 0.025106, loss_ce: 0.004643
iteration 17277 : loss : 0.021515, loss_ce: 0.008268
iteration 17278 : loss : 0.021790, loss_ce: 0.005504
iteration 17279 : loss : 0.020860, loss_ce: 0.005598
iteration 17280 : loss : 0.019729, loss_ce: 0.007729
iteration 17281 : loss : 0.014687, loss_ce: 0.002910
iteration 17282 : loss : 0.020118, loss_ce: 0.005927
iteration 17283 : loss : 0.026081, loss_ce: 0.007580
iteration 17284 : loss : 0.022570, loss_ce: 0.008615
iteration 17285 : loss : 0.019502, loss_ce: 0.006396
iteration 17286 : loss : 0.026819, loss_ce: 0.007520
iteration 17287 : loss : 0.024364, loss_ce: 0.008664
iteration 17288 : loss : 0.024670, loss_ce: 0.007686
iteration 17289 : loss : 0.025075, loss_ce: 0.006042
iteration 17290 : loss : 0.019412, loss_ce: 0.005957
iteration 17291 : loss : 0.020248, loss_ce: 0.007609
iteration 17292 : loss : 0.023745, loss_ce: 0.009859
iteration 17293 : loss : 0.019404, loss_ce: 0.005118
iteration 17294 : loss : 0.072451, loss_ce: 0.005867
iteration 17295 : loss : 0.024463, loss_ce: 0.006576
iteration 17296 : loss : 0.022403, loss_ce: 0.003979
iteration 17297 : loss : 0.021092, loss_ce: 0.005129
iteration 17298 : loss : 0.285708, loss_ce: 0.001793
 93%|██████████████████████████▉  | 186/200 [2:48:56<12:42, 54.46s/it]pred_sum 2927
gtsum tensor(2891, device='cuda:0')
iteration 17299 : loss : 0.021902, loss_ce: 0.009122
iteration 17300 : loss : 0.022173, loss_ce: 0.009139
iteration 17301 : loss : 0.025625, loss_ce: 0.008112
iteration 17302 : loss : 0.020017, loss_ce: 0.005533
iteration 17303 : loss : 0.023951, loss_ce: 0.007419
iteration 17304 : loss : 0.021393, loss_ce: 0.007715
iteration 17305 : loss : 0.029974, loss_ce: 0.003627
iteration 17306 : loss : 0.020317, loss_ce: 0.008241
iteration 17307 : loss : 0.023755, loss_ce: 0.008397
iteration 17308 : loss : 0.024272, loss_ce: 0.007553
iteration 17309 : loss : 0.021058, loss_ce: 0.009504
iteration 17310 : loss : 0.071143, loss_ce: 0.003208
iteration 17311 : loss : 0.022513, loss_ce: 0.005838
iteration 17312 : loss : 0.025309, loss_ce: 0.009526
iteration 17313 : loss : 0.016825, loss_ce: 0.005503
iteration 17314 : loss : 0.021070, loss_ce: 0.007731
iteration 17315 : loss : 0.017382, loss_ce: 0.005031
iteration 17316 : loss : 0.019943, loss_ce: 0.007746
iteration 17317 : loss : 0.019825, loss_ce: 0.005564
iteration 17318 : loss : 0.020875, loss_ce: 0.008751
iteration 17319 : loss : 0.022549, loss_ce: 0.010036
iteration 17320 : loss : 0.018875, loss_ce: 0.007228
iteration 17321 : loss : 0.025071, loss_ce: 0.005323
iteration 17322 : loss : 0.024467, loss_ce: 0.008380
iteration 17323 : loss : 0.021463, loss_ce: 0.007183
iteration 17324 : loss : 0.020453, loss_ce: 0.007824
iteration 17325 : loss : 0.018922, loss_ce: 0.006003
iteration 17326 : loss : 0.019257, loss_ce: 0.005496
iteration 17327 : loss : 0.021055, loss_ce: 0.005947
iteration 17328 : loss : 0.018829, loss_ce: 0.007196
iteration 17329 : loss : 0.019571, loss_ce: 0.006645
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 17330 : loss : 0.017018, loss_ce: 0.006813
iteration 17331 : loss : 0.023224, loss_ce: 0.010756
iteration 17332 : loss : 0.030586, loss_ce: 0.003408
iteration 17333 : loss : 0.023946, loss_ce: 0.006108
iteration 17334 : loss : 0.029537, loss_ce: 0.006714
iteration 17335 : loss : 0.075318, loss_ce: 0.006387
iteration 17336 : loss : 0.024785, loss_ce: 0.007902
iteration 17337 : loss : 0.021614, loss_ce: 0.007379
iteration 17338 : loss : 0.020726, loss_ce: 0.009134
iteration 17339 : loss : 0.022475, loss_ce: 0.011123
iteration 17340 : loss : 0.025507, loss_ce: 0.009993
iteration 17341 : loss : 0.019985, loss_ce: 0.007363
iteration 17342 : loss : 0.070015, loss_ce: 0.005974
iteration 17343 : loss : 0.019321, loss_ce: 0.008992
iteration 17344 : loss : 0.023830, loss_ce: 0.009286
iteration 17345 : loss : 0.021418, loss_ce: 0.005058
iteration 17346 : loss : 0.020465, loss_ce: 0.004873
iteration 17347 : loss : 0.021816, loss_ce: 0.007746
iteration 17348 : loss : 0.022223, loss_ce: 0.010163
iteration 17349 : loss : 0.070666, loss_ce: 0.002930
iteration 17350 : loss : 0.022784, loss_ce: 0.007851
iteration 17351 : loss : 0.023496, loss_ce: 0.008194
iteration 17352 : loss : 0.020563, loss_ce: 0.006541
iteration 17353 : loss : 0.020200, loss_ce: 0.007467
iteration 17354 : loss : 0.022621, loss_ce: 0.010243
iteration 17355 : loss : 0.020325, loss_ce: 0.004379
iteration 17356 : loss : 0.023975, loss_ce: 0.009921
iteration 17357 : loss : 0.023070, loss_ce: 0.011260
iteration 17358 : loss : 0.018444, loss_ce: 0.005155
iteration 17359 : loss : 0.070516, loss_ce: 0.005069
iteration 17360 : loss : 0.021508, loss_ce: 0.004848
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 17361 : loss : 0.023751, loss_ce: 0.005344
iteration 17362 : loss : 0.070118, loss_ce: 0.005770
iteration 17363 : loss : 0.021194, loss_ce: 0.009649
iteration 17364 : loss : 0.020706, loss_ce: 0.007783
iteration 17365 : loss : 0.024025, loss_ce: 0.005462
iteration 17366 : loss : 0.020784, loss_ce: 0.006852
iteration 17367 : loss : 0.020940, loss_ce: 0.007233
iteration 17368 : loss : 0.020909, loss_ce: 0.008671
iteration 17369 : loss : 0.024341, loss_ce: 0.009761
iteration 17370 : loss : 0.022502, loss_ce: 0.004836
iteration 17371 : loss : 0.019298, loss_ce: 0.007232
iteration 17372 : loss : 0.020557, loss_ce: 0.006076
iteration 17373 : loss : 0.022342, loss_ce: 0.008075
iteration 17374 : loss : 0.022603, loss_ce: 0.009473
iteration 17375 : loss : 0.021787, loss_ce: 0.012944
iteration 17376 : loss : 0.023196, loss_ce: 0.006873
iteration 17377 : loss : 0.022777, loss_ce: 0.004372
iteration 17378 : loss : 0.021399, loss_ce: 0.009142
iteration 17379 : loss : 0.019976, loss_ce: 0.008051
iteration 17380 : loss : 0.019512, loss_ce: 0.006876
iteration 17381 : loss : 0.022717, loss_ce: 0.009928
iteration 17382 : loss : 0.024631, loss_ce: 0.006398
iteration 17383 : loss : 0.024065, loss_ce: 0.009292
iteration 17384 : loss : 0.073459, loss_ce: 0.007633
iteration 17385 : loss : 0.071599, loss_ce: 0.005668
iteration 17386 : loss : 0.021564, loss_ce: 0.008263
iteration 17387 : loss : 0.021851, loss_ce: 0.008342
iteration 17388 : loss : 0.026297, loss_ce: 0.004610
iteration 17389 : loss : 0.023683, loss_ce: 0.007672
iteration 17390 : loss : 0.019957, loss_ce: 0.007633
iteration 17391 : loss : 0.089802, loss_ce: 0.020786
 94%|███████████████████████████  | 187/200 [2:49:50<11:47, 54.46s/it]pred_sum 25587
gtsum tensor(26948, device='cuda:0')
iteration 17392 : loss : 0.023043, loss_ce: 0.008036
iteration 17393 : loss : 0.024069, loss_ce: 0.010510
iteration 17394 : loss : 0.021757, loss_ce: 0.008098
iteration 17395 : loss : 0.024282, loss_ce: 0.009326
iteration 17396 : loss : 0.021545, loss_ce: 0.008436
iteration 17397 : loss : 0.072397, loss_ce: 0.004931
iteration 17398 : loss : 0.019573, loss_ce: 0.006587
iteration 17399 : loss : 0.021635, loss_ce: 0.008461
iteration 17400 : loss : 0.021797, loss_ce: 0.010008
iteration 17401 : loss : 0.022424, loss_ce: 0.009263
iteration 17402 : loss : 0.019921, loss_ce: 0.005863
iteration 17403 : loss : 0.022671, loss_ce: 0.009988
iteration 17404 : loss : 0.023814, loss_ce: 0.006549
iteration 17405 : loss : 0.017192, loss_ce: 0.007748
iteration 17406 : loss : 0.019315, loss_ce: 0.007302
iteration 17407 : loss : 0.021953, loss_ce: 0.008396
iteration 17408 : loss : 0.020123, loss_ce: 0.008629
iteration 17409 : loss : 0.021988, loss_ce: 0.009464
iteration 17410 : loss : 0.022282, loss_ce: 0.010984
iteration 17411 : loss : 0.017242, loss_ce: 0.005119
iteration 17412 : loss : 0.018920, loss_ce: 0.005840
iteration 17413 : loss : 0.018395, loss_ce: 0.007724
iteration 17414 : loss : 0.021305, loss_ce: 0.010628
iteration 17415 : loss : 0.024458, loss_ce: 0.008006
iteration 17416 : loss : 0.020351, loss_ce: 0.007815
iteration 17417 : loss : 0.022337, loss_ce: 0.003102
iteration 17418 : loss : 0.023681, loss_ce: 0.007218
iteration 17419 : loss : 0.020995, loss_ce: 0.005596
iteration 17420 : loss : 0.018830, loss_ce: 0.007401
iteration 17421 : loss : 0.022622, loss_ce: 0.005679
iteration 17422 : loss : 0.021450, loss_ce: 0.004848
pred_sum 453
gtsum tensor(458, device='cuda:0')
iteration 17423 : loss : 0.026246, loss_ce: 0.006409
iteration 17424 : loss : 0.022888, loss_ce: 0.006527
iteration 17425 : loss : 0.020995, loss_ce: 0.008968
iteration 17426 : loss : 0.023306, loss_ce: 0.010304
iteration 17427 : loss : 0.020687, loss_ce: 0.006955
iteration 17428 : loss : 0.072867, loss_ce: 0.005888
iteration 17429 : loss : 0.017902, loss_ce: 0.007919
iteration 17430 : loss : 0.022268, loss_ce: 0.009932
iteration 17431 : loss : 0.022768, loss_ce: 0.010986
iteration 17432 : loss : 0.069942, loss_ce: 0.003212
iteration 17433 : loss : 0.022587, loss_ce: 0.008119
iteration 17434 : loss : 0.019197, loss_ce: 0.004376
iteration 17435 : loss : 0.020415, loss_ce: 0.005758
iteration 17436 : loss : 0.022441, loss_ce: 0.008007
iteration 17437 : loss : 0.025378, loss_ce: 0.009877
iteration 17438 : loss : 0.026050, loss_ce: 0.012121
iteration 17439 : loss : 0.021994, loss_ce: 0.008418
iteration 17440 : loss : 0.024436, loss_ce: 0.006659
iteration 17441 : loss : 0.025885, loss_ce: 0.004450
iteration 17442 : loss : 0.021950, loss_ce: 0.007737
iteration 17443 : loss : 0.018087, loss_ce: 0.004998
iteration 17444 : loss : 0.023443, loss_ce: 0.009938
iteration 17445 : loss : 0.019427, loss_ce: 0.004907
iteration 17446 : loss : 0.020438, loss_ce: 0.005239
iteration 17447 : loss : 0.020477, loss_ce: 0.006503
iteration 17448 : loss : 0.070001, loss_ce: 0.005438
iteration 17449 : loss : 0.071305, loss_ce: 0.003966
iteration 17450 : loss : 0.024271, loss_ce: 0.008843
iteration 17451 : loss : 0.021820, loss_ce: 0.007078
iteration 17452 : loss : 0.026823, loss_ce: 0.006876
iteration 17453 : loss : 0.024138, loss_ce: 0.003818
pred_sum 9588
gtsum tensor(10309, device='cuda:0')
iteration 17454 : loss : 0.021717, loss_ce: 0.006635
iteration 17455 : loss : 0.018560, loss_ce: 0.007782
iteration 17456 : loss : 0.024627, loss_ce: 0.006610
iteration 17457 : loss : 0.022742, loss_ce: 0.007386
iteration 17458 : loss : 0.024966, loss_ce: 0.009917
iteration 17459 : loss : 0.018878, loss_ce: 0.007356
iteration 17460 : loss : 0.019712, loss_ce: 0.007034
iteration 17461 : loss : 0.018762, loss_ce: 0.007514
iteration 17462 : loss : 0.018572, loss_ce: 0.007646
iteration 17463 : loss : 0.023156, loss_ce: 0.006652
iteration 17464 : loss : 0.019035, loss_ce: 0.005909
iteration 17465 : loss : 0.024041, loss_ce: 0.010681
iteration 17466 : loss : 0.021267, loss_ce: 0.008220
iteration 17467 : loss : 0.074796, loss_ce: 0.006965
iteration 17468 : loss : 0.021331, loss_ce: 0.003829
iteration 17469 : loss : 0.019649, loss_ce: 0.006925
iteration 17470 : loss : 0.020970, loss_ce: 0.008616
iteration 17471 : loss : 0.023838, loss_ce: 0.007849
iteration 17472 : loss : 0.020277, loss_ce: 0.007047
iteration 17473 : loss : 0.021379, loss_ce: 0.005232
iteration 17474 : loss : 0.018976, loss_ce: 0.005570
iteration 17475 : loss : 0.018374, loss_ce: 0.006493
iteration 17476 : loss : 0.026229, loss_ce: 0.008866
iteration 17477 : loss : 0.024326, loss_ce: 0.012235
iteration 17478 : loss : 0.022506, loss_ce: 0.009017
iteration 17479 : loss : 0.022148, loss_ce: 0.004912
iteration 17480 : loss : 0.021460, loss_ce: 0.009020
iteration 17481 : loss : 0.023273, loss_ce: 0.005307
iteration 17482 : loss : 0.018959, loss_ce: 0.007062
iteration 17483 : loss : 0.030071, loss_ce: 0.005279
iteration 17484 : loss : 0.129206, loss_ce: 0.007893
 94%|███████████████████████████▎ | 188/200 [2:50:44<10:52, 54.40s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 17485 : loss : 0.072033, loss_ce: 0.006811
iteration 17486 : loss : 0.023040, loss_ce: 0.007089
iteration 17487 : loss : 0.073142, loss_ce: 0.005849
iteration 17488 : loss : 0.020325, loss_ce: 0.005391
iteration 17489 : loss : 0.027108, loss_ce: 0.006363
iteration 17490 : loss : 0.018141, loss_ce: 0.003019
iteration 17491 : loss : 0.023175, loss_ce: 0.007288
iteration 17492 : loss : 0.022452, loss_ce: 0.008966
iteration 17493 : loss : 0.019994, loss_ce: 0.006780
iteration 17494 : loss : 0.019832, loss_ce: 0.008234
iteration 17495 : loss : 0.024073, loss_ce: 0.008476
iteration 17496 : loss : 0.023377, loss_ce: 0.007694
iteration 17497 : loss : 0.018813, loss_ce: 0.007425
iteration 17498 : loss : 0.021619, loss_ce: 0.006950
iteration 17499 : loss : 0.021616, loss_ce: 0.006747
iteration 17500 : loss : 0.020544, loss_ce: 0.005455
iteration 17501 : loss : 0.025118, loss_ce: 0.011495
iteration 17502 : loss : 0.020391, loss_ce: 0.008135
iteration 17503 : loss : 0.020535, loss_ce: 0.005232
iteration 17504 : loss : 0.024514, loss_ce: 0.009952
iteration 17505 : loss : 0.019865, loss_ce: 0.005120
iteration 17506 : loss : 0.021228, loss_ce: 0.005889
iteration 17507 : loss : 0.020322, loss_ce: 0.009163
iteration 17508 : loss : 0.019566, loss_ce: 0.007719
iteration 17509 : loss : 0.019021, loss_ce: 0.006473
iteration 17510 : loss : 0.027479, loss_ce: 0.009804
iteration 17511 : loss : 0.026134, loss_ce: 0.007580
iteration 17512 : loss : 0.021161, loss_ce: 0.006834
iteration 17513 : loss : 0.019647, loss_ce: 0.005979
iteration 17514 : loss : 0.021577, loss_ce: 0.008203
iteration 17515 : loss : 0.018563, loss_ce: 0.004932
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 17516 : loss : 0.022371, loss_ce: 0.006050
iteration 17517 : loss : 0.021881, loss_ce: 0.005228
iteration 17518 : loss : 0.023292, loss_ce: 0.011046
iteration 17519 : loss : 0.026170, loss_ce: 0.005828
iteration 17520 : loss : 0.021529, loss_ce: 0.009011
iteration 17521 : loss : 0.018015, loss_ce: 0.006904
iteration 17522 : loss : 0.025633, loss_ce: 0.009205
iteration 17523 : loss : 0.019844, loss_ce: 0.006061
iteration 17524 : loss : 0.020731, loss_ce: 0.005948
iteration 17525 : loss : 0.076697, loss_ce: 0.006057
iteration 17526 : loss : 0.022830, loss_ce: 0.009881
iteration 17527 : loss : 0.022048, loss_ce: 0.008217
iteration 17528 : loss : 0.023379, loss_ce: 0.009943
iteration 17529 : loss : 0.021929, loss_ce: 0.009187
iteration 17530 : loss : 0.025268, loss_ce: 0.008955
iteration 17531 : loss : 0.022303, loss_ce: 0.006768
iteration 17532 : loss : 0.022049, loss_ce: 0.011557
iteration 17533 : loss : 0.021233, loss_ce: 0.008006
iteration 17534 : loss : 0.022615, loss_ce: 0.012151
iteration 17535 : loss : 0.023909, loss_ce: 0.009661
iteration 17536 : loss : 0.017232, loss_ce: 0.005181
iteration 17537 : loss : 0.023072, loss_ce: 0.007168
iteration 17538 : loss : 0.018880, loss_ce: 0.007168
iteration 17539 : loss : 0.022455, loss_ce: 0.007398
iteration 17540 : loss : 0.027519, loss_ce: 0.012850
iteration 17541 : loss : 0.025835, loss_ce: 0.008292
iteration 17542 : loss : 0.019498, loss_ce: 0.007493
iteration 17543 : loss : 0.025682, loss_ce: 0.008328
iteration 17544 : loss : 0.022088, loss_ce: 0.009967
iteration 17545 : loss : 0.024732, loss_ce: 0.006338
iteration 17546 : loss : 0.019294, loss_ce: 0.004731
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 17547 : loss : 0.022605, loss_ce: 0.006099
iteration 17548 : loss : 0.019856, loss_ce: 0.007314
iteration 17549 : loss : 0.017921, loss_ce: 0.003838
iteration 17550 : loss : 0.021730, loss_ce: 0.005709
iteration 17551 : loss : 0.031482, loss_ce: 0.007295
iteration 17552 : loss : 0.024475, loss_ce: 0.008217
iteration 17553 : loss : 0.023653, loss_ce: 0.005402
iteration 17554 : loss : 0.023499, loss_ce: 0.005759
iteration 17555 : loss : 0.018717, loss_ce: 0.005724
iteration 17556 : loss : 0.071642, loss_ce: 0.006482
iteration 17557 : loss : 0.021151, loss_ce: 0.005948
iteration 17558 : loss : 0.019063, loss_ce: 0.006939
iteration 17559 : loss : 0.025662, loss_ce: 0.009771
iteration 17560 : loss : 0.017630, loss_ce: 0.005978
iteration 17561 : loss : 0.016581, loss_ce: 0.005140
iteration 17562 : loss : 0.017542, loss_ce: 0.006614
iteration 17563 : loss : 0.021939, loss_ce: 0.007515
iteration 17564 : loss : 0.020665, loss_ce: 0.008026
iteration 17565 : loss : 0.020329, loss_ce: 0.007763
iteration 17566 : loss : 0.020747, loss_ce: 0.007528
iteration 17567 : loss : 0.019826, loss_ce: 0.006642
iteration 17568 : loss : 0.020829, loss_ce: 0.008345
iteration 17569 : loss : 0.020435, loss_ce: 0.008316
iteration 17570 : loss : 0.022977, loss_ce: 0.007621
iteration 17571 : loss : 0.021601, loss_ce: 0.005628
iteration 17572 : loss : 0.020872, loss_ce: 0.006795
iteration 17573 : loss : 0.017945, loss_ce: 0.006752
iteration 17574 : loss : 0.034323, loss_ce: 0.005884
iteration 17575 : loss : 0.020505, loss_ce: 0.006999
iteration 17576 : loss : 0.019882, loss_ce: 0.008225
iteration 17577 : loss : 0.439166, loss_ce: 0.000658
 94%|███████████████████████████▍ | 189/200 [2:51:39<09:58, 54.42s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 17578 : loss : 0.023926, loss_ce: 0.007779
iteration 17579 : loss : 0.025731, loss_ce: 0.012222
iteration 17580 : loss : 0.074273, loss_ce: 0.005634
iteration 17581 : loss : 0.026451, loss_ce: 0.011539
iteration 17582 : loss : 0.019005, loss_ce: 0.006066
iteration 17583 : loss : 0.019702, loss_ce: 0.006347
iteration 17584 : loss : 0.020083, loss_ce: 0.006546
iteration 17585 : loss : 0.020246, loss_ce: 0.007120
iteration 17586 : loss : 0.025212, loss_ce: 0.008748
iteration 17587 : loss : 0.023744, loss_ce: 0.009432
iteration 17588 : loss : 0.021996, loss_ce: 0.006195
iteration 17589 : loss : 0.021952, loss_ce: 0.007606
iteration 17590 : loss : 0.075272, loss_ce: 0.008646
iteration 17591 : loss : 0.020273, loss_ce: 0.007204
iteration 17592 : loss : 0.023424, loss_ce: 0.006166
iteration 17593 : loss : 0.022517, loss_ce: 0.010044
iteration 17594 : loss : 0.020041, loss_ce: 0.010181
iteration 17595 : loss : 0.025174, loss_ce: 0.009451
iteration 17596 : loss : 0.019216, loss_ce: 0.007541
iteration 17597 : loss : 0.026785, loss_ce: 0.009681
iteration 17598 : loss : 0.024203, loss_ce: 0.005876
iteration 17599 : loss : 0.025403, loss_ce: 0.007667
iteration 17600 : loss : 0.023113, loss_ce: 0.007535
iteration 17601 : loss : 0.023033, loss_ce: 0.007669
iteration 17602 : loss : 0.025218, loss_ce: 0.003093
iteration 17603 : loss : 0.022897, loss_ce: 0.006701
iteration 17604 : loss : 0.071335, loss_ce: 0.004401
iteration 17605 : loss : 0.019784, loss_ce: 0.006721
iteration 17606 : loss : 0.071867, loss_ce: 0.006833
iteration 17607 : loss : 0.020356, loss_ce: 0.008470
iteration 17608 : loss : 0.026112, loss_ce: 0.011832
pred_sum 3725
gtsum tensor(3612, device='cuda:0')
iteration 17609 : loss : 0.017696, loss_ce: 0.006810
iteration 17610 : loss : 0.020538, loss_ce: 0.008662
iteration 17611 : loss : 0.019886, loss_ce: 0.005216
iteration 17612 : loss : 0.024443, loss_ce: 0.008143
iteration 17613 : loss : 0.019682, loss_ce: 0.005495
iteration 17614 : loss : 0.019814, loss_ce: 0.008843
iteration 17615 : loss : 0.020610, loss_ce: 0.006571
iteration 17616 : loss : 0.020078, loss_ce: 0.007005
iteration 17617 : loss : 0.020908, loss_ce: 0.005676
iteration 17618 : loss : 0.021174, loss_ce: 0.007066
iteration 17619 : loss : 0.023598, loss_ce: 0.006928
iteration 17620 : loss : 0.024120, loss_ce: 0.010958
iteration 17621 : loss : 0.021638, loss_ce: 0.005617
iteration 17622 : loss : 0.030395, loss_ce: 0.002779
iteration 17623 : loss : 0.075073, loss_ce: 0.003940
iteration 17624 : loss : 0.022048, loss_ce: 0.005165
iteration 17625 : loss : 0.023016, loss_ce: 0.007377
iteration 17626 : loss : 0.020944, loss_ce: 0.006396
iteration 17627 : loss : 0.023178, loss_ce: 0.004047
iteration 17628 : loss : 0.029232, loss_ce: 0.006304
iteration 17629 : loss : 0.018435, loss_ce: 0.007380
iteration 17630 : loss : 0.022663, loss_ce: 0.009387
iteration 17631 : loss : 0.021301, loss_ce: 0.006790
iteration 17632 : loss : 0.021274, loss_ce: 0.004974
iteration 17633 : loss : 0.022654, loss_ce: 0.008791
iteration 17634 : loss : 0.020916, loss_ce: 0.008437
iteration 17635 : loss : 0.018740, loss_ce: 0.004723
iteration 17636 : loss : 0.019226, loss_ce: 0.006049
iteration 17637 : loss : 0.022008, loss_ce: 0.004323
iteration 17638 : loss : 0.021025, loss_ce: 0.005982
iteration 17639 : loss : 0.024004, loss_ce: 0.007421
pred_sum 27268
gtsum tensor(26948, device='cuda:0')
iteration 17640 : loss : 0.023948, loss_ce: 0.011246
iteration 17641 : loss : 0.023030, loss_ce: 0.008302
iteration 17642 : loss : 0.074154, loss_ce: 0.008021
iteration 17643 : loss : 0.021783, loss_ce: 0.009429
iteration 17644 : loss : 0.019742, loss_ce: 0.009842
iteration 17645 : loss : 0.020772, loss_ce: 0.007415
iteration 17646 : loss : 0.020861, loss_ce: 0.008491
iteration 17647 : loss : 0.023192, loss_ce: 0.009430
iteration 17648 : loss : 0.021251, loss_ce: 0.007944
iteration 17649 : loss : 0.022807, loss_ce: 0.006605
iteration 17650 : loss : 0.021766, loss_ce: 0.007660
iteration 17651 : loss : 0.020559, loss_ce: 0.006959
iteration 17652 : loss : 0.021849, loss_ce: 0.010114
iteration 17653 : loss : 0.023556, loss_ce: 0.011329
iteration 17654 : loss : 0.018064, loss_ce: 0.004527
iteration 17655 : loss : 0.021975, loss_ce: 0.008883
iteration 17656 : loss : 0.022771, loss_ce: 0.010353
iteration 17657 : loss : 0.022384, loss_ce: 0.008472
iteration 17658 : loss : 0.024375, loss_ce: 0.008461
iteration 17659 : loss : 0.024340, loss_ce: 0.007605
iteration 17660 : loss : 0.018627, loss_ce: 0.007758
iteration 17661 : loss : 0.020519, loss_ce: 0.005120
iteration 17662 : loss : 0.020692, loss_ce: 0.004996
iteration 17663 : loss : 0.019123, loss_ce: 0.008628
iteration 17664 : loss : 0.023050, loss_ce: 0.009826
iteration 17665 : loss : 0.020479, loss_ce: 0.005708
iteration 17666 : loss : 0.020729, loss_ce: 0.005247
iteration 17667 : loss : 0.024615, loss_ce: 0.010333
iteration 17668 : loss : 0.022760, loss_ce: 0.006121
iteration 17669 : loss : 0.016385, loss_ce: 0.003136
iteration 17670 : loss : 0.134320, loss_ce: 0.006265
 95%|███████████████████████████▌ | 190/200 [2:52:33<09:04, 54.43s/it]pred_sum 43888
gtsum tensor(44073, device='cuda:0')
iteration 17671 : loss : 0.073091, loss_ce: 0.004688
iteration 17672 : loss : 0.027747, loss_ce: 0.007299
iteration 17673 : loss : 0.020318, loss_ce: 0.005592
iteration 17674 : loss : 0.021951, loss_ce: 0.006593
iteration 17675 : loss : 0.022185, loss_ce: 0.008911
iteration 17676 : loss : 0.019192, loss_ce: 0.005569
iteration 17677 : loss : 0.020173, loss_ce: 0.004790
iteration 17678 : loss : 0.023204, loss_ce: 0.008547
iteration 17679 : loss : 0.030032, loss_ce: 0.008405
iteration 17680 : loss : 0.021665, loss_ce: 0.008319
iteration 17681 : loss : 0.020117, loss_ce: 0.006789
iteration 17682 : loss : 0.020067, loss_ce: 0.006139
iteration 17683 : loss : 0.021427, loss_ce: 0.008074
iteration 17684 : loss : 0.019391, loss_ce: 0.006759
iteration 17685 : loss : 0.074095, loss_ce: 0.006495
iteration 17686 : loss : 0.016790, loss_ce: 0.005311
iteration 17687 : loss : 0.022125, loss_ce: 0.009137
iteration 17688 : loss : 0.026298, loss_ce: 0.012857
iteration 17689 : loss : 0.078435, loss_ce: 0.004779
iteration 17690 : loss : 0.023197, loss_ce: 0.009021
iteration 17691 : loss : 0.021984, loss_ce: 0.009430
iteration 17692 : loss : 0.021217, loss_ce: 0.007701
iteration 17693 : loss : 0.022299, loss_ce: 0.010388
iteration 17694 : loss : 0.021926, loss_ce: 0.008533
iteration 17695 : loss : 0.074331, loss_ce: 0.005875
iteration 17696 : loss : 0.071306, loss_ce: 0.003798
iteration 17697 : loss : 0.019364, loss_ce: 0.007557
iteration 17698 : loss : 0.028809, loss_ce: 0.010867
iteration 17699 : loss : 0.021720, loss_ce: 0.004856
iteration 17700 : loss : 0.022640, loss_ce: 0.008489
iteration 17701 : loss : 0.070007, loss_ce: 0.004344
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 17702 : loss : 0.019726, loss_ce: 0.006050
iteration 17703 : loss : 0.074708, loss_ce: 0.005507
iteration 17704 : loss : 0.019779, loss_ce: 0.009460
iteration 17705 : loss : 0.027718, loss_ce: 0.011531
iteration 17706 : loss : 0.021018, loss_ce: 0.005731
iteration 17707 : loss : 0.021132, loss_ce: 0.007896
iteration 17708 : loss : 0.023675, loss_ce: 0.011028
iteration 17709 : loss : 0.071778, loss_ce: 0.006772
iteration 17710 : loss : 0.022542, loss_ce: 0.008553
iteration 17711 : loss : 0.020330, loss_ce: 0.008938
iteration 17712 : loss : 0.017085, loss_ce: 0.004796
iteration 17713 : loss : 0.071934, loss_ce: 0.004813
iteration 17714 : loss : 0.021786, loss_ce: 0.005684
iteration 17715 : loss : 0.018738, loss_ce: 0.007432
iteration 17716 : loss : 0.023420, loss_ce: 0.008125
iteration 17717 : loss : 0.023961, loss_ce: 0.004691
iteration 17718 : loss : 0.018718, loss_ce: 0.004263
iteration 17719 : loss : 0.022490, loss_ce: 0.007854
iteration 17720 : loss : 0.023508, loss_ce: 0.009338
iteration 17721 : loss : 0.026306, loss_ce: 0.011491
iteration 17722 : loss : 0.022705, loss_ce: 0.009910
iteration 17723 : loss : 0.020839, loss_ce: 0.007784
iteration 17724 : loss : 0.021210, loss_ce: 0.008855
iteration 17725 : loss : 0.021907, loss_ce: 0.009001
iteration 17726 : loss : 0.022712, loss_ce: 0.007284
iteration 17727 : loss : 0.019406, loss_ce: 0.008165
iteration 17728 : loss : 0.023084, loss_ce: 0.009141
iteration 17729 : loss : 0.073714, loss_ce: 0.005977
iteration 17730 : loss : 0.021601, loss_ce: 0.009210
iteration 17731 : loss : 0.020150, loss_ce: 0.007123
iteration 17732 : loss : 0.022760, loss_ce: 0.007861
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 17733 : loss : 0.075032, loss_ce: 0.006123
iteration 17734 : loss : 0.021126, loss_ce: 0.006941
iteration 17735 : loss : 0.073307, loss_ce: 0.002767
iteration 17736 : loss : 0.020483, loss_ce: 0.009246
iteration 17737 : loss : 0.019283, loss_ce: 0.006061
iteration 17738 : loss : 0.026066, loss_ce: 0.009869
iteration 17739 : loss : 0.021600, loss_ce: 0.010189
iteration 17740 : loss : 0.072977, loss_ce: 0.005103
iteration 17741 : loss : 0.023712, loss_ce: 0.006808
iteration 17742 : loss : 0.021769, loss_ce: 0.007475
iteration 17743 : loss : 0.023462, loss_ce: 0.010615
iteration 17744 : loss : 0.016518, loss_ce: 0.006375
iteration 17745 : loss : 0.019169, loss_ce: 0.006967
iteration 17746 : loss : 0.019512, loss_ce: 0.004852
iteration 17747 : loss : 0.021305, loss_ce: 0.008169
iteration 17748 : loss : 0.044751, loss_ce: 0.003067
iteration 17749 : loss : 0.022593, loss_ce: 0.009918
iteration 17750 : loss : 0.021672, loss_ce: 0.010061
iteration 17751 : loss : 0.018445, loss_ce: 0.005150
iteration 17752 : loss : 0.025504, loss_ce: 0.008017
iteration 17753 : loss : 0.018884, loss_ce: 0.004719
iteration 17754 : loss : 0.022448, loss_ce: 0.006981
iteration 17755 : loss : 0.024260, loss_ce: 0.011153
iteration 17756 : loss : 0.017806, loss_ce: 0.004189
iteration 17757 : loss : 0.020091, loss_ce: 0.006692
iteration 17758 : loss : 0.021317, loss_ce: 0.010737
iteration 17759 : loss : 0.020102, loss_ce: 0.006746
iteration 17760 : loss : 0.032959, loss_ce: 0.006995
iteration 17761 : loss : 0.028567, loss_ce: 0.006385
iteration 17762 : loss : 0.021567, loss_ce: 0.003311
iteration 17763 : loss : 0.126320, loss_ce: 0.005621
 96%|███████████████████████████▋ | 191/200 [2:53:28<08:10, 54.45s/it]pred_sum 756
gtsum tensor(753, device='cuda:0')
iteration 17764 : loss : 0.016199, loss_ce: 0.007044
iteration 17765 : loss : 0.023750, loss_ce: 0.005974
iteration 17766 : loss : 0.020764, loss_ce: 0.008010
iteration 17767 : loss : 0.024203, loss_ce: 0.010296
iteration 17768 : loss : 0.022299, loss_ce: 0.010273
iteration 17769 : loss : 0.021092, loss_ce: 0.005614
iteration 17770 : loss : 0.023334, loss_ce: 0.008689
iteration 17771 : loss : 0.024324, loss_ce: 0.008642
iteration 17772 : loss : 0.023400, loss_ce: 0.007680
iteration 17773 : loss : 0.019144, loss_ce: 0.009124
iteration 17774 : loss : 0.021445, loss_ce: 0.006612
iteration 17775 : loss : 0.023230, loss_ce: 0.005873
iteration 17776 : loss : 0.020093, loss_ce: 0.007152
iteration 17777 : loss : 0.022055, loss_ce: 0.008857
iteration 17778 : loss : 0.019722, loss_ce: 0.008047
iteration 17779 : loss : 0.024091, loss_ce: 0.008858
iteration 17780 : loss : 0.019627, loss_ce: 0.005770
iteration 17781 : loss : 0.020533, loss_ce: 0.009119
iteration 17782 : loss : 0.028159, loss_ce: 0.007834
iteration 17783 : loss : 0.026289, loss_ce: 0.004671
iteration 17784 : loss : 0.023918, loss_ce: 0.005728
iteration 17785 : loss : 0.019173, loss_ce: 0.007653
iteration 17786 : loss : 0.023809, loss_ce: 0.010341
iteration 17787 : loss : 0.016740, loss_ce: 0.003554
iteration 17788 : loss : 0.019279, loss_ce: 0.006978
iteration 17789 : loss : 0.021291, loss_ce: 0.008809
iteration 17790 : loss : 0.025011, loss_ce: 0.009681
iteration 17791 : loss : 0.019626, loss_ce: 0.007779
iteration 17792 : loss : 0.019413, loss_ce: 0.007298
iteration 17793 : loss : 0.022028, loss_ce: 0.009282
iteration 17794 : loss : 0.020692, loss_ce: 0.006487
pred_sum 81
gtsum tensor(82, device='cuda:0')
iteration 17795 : loss : 0.019098, loss_ce: 0.008114
iteration 17796 : loss : 0.015732, loss_ce: 0.004149
iteration 17797 : loss : 0.018447, loss_ce: 0.008189
iteration 17798 : loss : 0.077392, loss_ce: 0.005673
iteration 17799 : loss : 0.020480, loss_ce: 0.003530
iteration 17800 : loss : 0.024942, loss_ce: 0.006837
iteration 17801 : loss : 0.070724, loss_ce: 0.003477
iteration 17802 : loss : 0.072025, loss_ce: 0.004931
iteration 17803 : loss : 0.020163, loss_ce: 0.006021
iteration 17804 : loss : 0.022278, loss_ce: 0.009381
iteration 17805 : loss : 0.020074, loss_ce: 0.006472
iteration 17806 : loss : 0.020529, loss_ce: 0.008894
iteration 17807 : loss : 0.022920, loss_ce: 0.008680
iteration 17808 : loss : 0.123452, loss_ce: 0.004405
iteration 17809 : loss : 0.021013, loss_ce: 0.006794
iteration 17810 : loss : 0.023700, loss_ce: 0.006694
iteration 17811 : loss : 0.020746, loss_ce: 0.009399
iteration 17812 : loss : 0.019312, loss_ce: 0.007648
iteration 17813 : loss : 0.027547, loss_ce: 0.006280
iteration 17814 : loss : 0.025245, loss_ce: 0.009180
iteration 17815 : loss : 0.020983, loss_ce: 0.007162
iteration 17816 : loss : 0.020753, loss_ce: 0.009486
iteration 17817 : loss : 0.050819, loss_ce: 0.005322
iteration 17818 : loss : 0.022212, loss_ce: 0.008544
iteration 17819 : loss : 0.022318, loss_ce: 0.007905
iteration 17820 : loss : 0.022736, loss_ce: 0.006008
iteration 17821 : loss : 0.022124, loss_ce: 0.008441
iteration 17822 : loss : 0.023493, loss_ce: 0.009642
iteration 17823 : loss : 0.019214, loss_ce: 0.006007
iteration 17824 : loss : 0.021813, loss_ce: 0.009462
iteration 17825 : loss : 0.021608, loss_ce: 0.005593
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 17826 : loss : 0.023103, loss_ce: 0.009236
iteration 17827 : loss : 0.021752, loss_ce: 0.007254
iteration 17828 : loss : 0.022526, loss_ce: 0.010846
iteration 17829 : loss : 0.021972, loss_ce: 0.004380
iteration 17830 : loss : 0.021843, loss_ce: 0.005840
iteration 17831 : loss : 0.021915, loss_ce: 0.008468
iteration 17832 : loss : 0.026099, loss_ce: 0.005925
iteration 17833 : loss : 0.029593, loss_ce: 0.008721
iteration 17834 : loss : 0.021408, loss_ce: 0.006910
iteration 17835 : loss : 0.020510, loss_ce: 0.005138
iteration 17836 : loss : 0.025248, loss_ce: 0.010047
iteration 17837 : loss : 0.021104, loss_ce: 0.009030
iteration 17838 : loss : 0.018392, loss_ce: 0.004185
iteration 17839 : loss : 0.025338, loss_ce: 0.009758
iteration 17840 : loss : 0.020588, loss_ce: 0.009659
iteration 17841 : loss : 0.074101, loss_ce: 0.006118
iteration 17842 : loss : 0.021513, loss_ce: 0.008465
iteration 17843 : loss : 0.021456, loss_ce: 0.007015
iteration 17844 : loss : 0.018912, loss_ce: 0.006176
iteration 17845 : loss : 0.074191, loss_ce: 0.003253
iteration 17846 : loss : 0.020704, loss_ce: 0.006919
iteration 17847 : loss : 0.023918, loss_ce: 0.007226
iteration 17848 : loss : 0.022594, loss_ce: 0.006635
iteration 17849 : loss : 0.024325, loss_ce: 0.007408
iteration 17850 : loss : 0.023838, loss_ce: 0.007557
iteration 17851 : loss : 0.023402, loss_ce: 0.006484
iteration 17852 : loss : 0.022093, loss_ce: 0.009782
iteration 17853 : loss : 0.022547, loss_ce: 0.009239
iteration 17854 : loss : 0.034495, loss_ce: 0.006610
iteration 17855 : loss : 0.019411, loss_ce: 0.009047
iteration 17856 : loss : 0.034443, loss_ce: 0.022543
 96%|███████████████████████████▊ | 192/200 [2:54:22<07:15, 54.46s/it]pred_sum 35383
gtsum tensor(37727, device='cuda:0')
iteration 17857 : loss : 0.024238, loss_ce: 0.011062
iteration 17858 : loss : 0.021145, loss_ce: 0.008455
iteration 17859 : loss : 0.042068, loss_ce: 0.008453
iteration 17860 : loss : 0.020763, loss_ce: 0.008889
iteration 17861 : loss : 0.020610, loss_ce: 0.008499
iteration 17862 : loss : 0.022824, loss_ce: 0.008146
iteration 17863 : loss : 0.019342, loss_ce: 0.004912
iteration 17864 : loss : 0.025012, loss_ce: 0.009352
iteration 17865 : loss : 0.020204, loss_ce: 0.005423
iteration 17866 : loss : 0.021191, loss_ce: 0.006289
iteration 17867 : loss : 0.020134, loss_ce: 0.007392
iteration 17868 : loss : 0.020488, loss_ce: 0.006913
iteration 17869 : loss : 0.020583, loss_ce: 0.006178
iteration 17870 : loss : 0.023895, loss_ce: 0.006560
iteration 17871 : loss : 0.019824, loss_ce: 0.008793
iteration 17872 : loss : 0.030564, loss_ce: 0.005368
iteration 17873 : loss : 0.019483, loss_ce: 0.007573
iteration 17874 : loss : 0.021801, loss_ce: 0.007496
iteration 17875 : loss : 0.020891, loss_ce: 0.005873
iteration 17876 : loss : 0.021797, loss_ce: 0.005684
iteration 17877 : loss : 0.022141, loss_ce: 0.007261
iteration 17878 : loss : 0.022001, loss_ce: 0.005205
iteration 17879 : loss : 0.025500, loss_ce: 0.009025
iteration 17880 : loss : 0.020752, loss_ce: 0.008870
iteration 17881 : loss : 0.023441, loss_ce: 0.008634
iteration 17882 : loss : 0.019242, loss_ce: 0.006127
iteration 17883 : loss : 0.019540, loss_ce: 0.007750
iteration 17884 : loss : 0.020946, loss_ce: 0.006904
iteration 17885 : loss : 0.022730, loss_ce: 0.007455
iteration 17886 : loss : 0.020800, loss_ce: 0.005767
iteration 17887 : loss : 0.023864, loss_ce: 0.009282
pred_sum 7216
gtsum tensor(7227, device='cuda:0')
iteration 17888 : loss : 0.019156, loss_ce: 0.007744
iteration 17889 : loss : 0.020856, loss_ce: 0.007251
iteration 17890 : loss : 0.019426, loss_ce: 0.007515
iteration 17891 : loss : 0.024046, loss_ce: 0.007461
iteration 17892 : loss : 0.022443, loss_ce: 0.007891
iteration 17893 : loss : 0.022325, loss_ce: 0.008377
iteration 17894 : loss : 0.024484, loss_ce: 0.010017
iteration 17895 : loss : 0.028805, loss_ce: 0.006701
iteration 17896 : loss : 0.019685, loss_ce: 0.007896
iteration 17897 : loss : 0.019463, loss_ce: 0.005591
iteration 17898 : loss : 0.022827, loss_ce: 0.005909
iteration 17899 : loss : 0.074649, loss_ce: 0.004665
iteration 17900 : loss : 0.023006, loss_ce: 0.009314
iteration 17901 : loss : 0.021297, loss_ce: 0.009212
iteration 17902 : loss : 0.024994, loss_ce: 0.007955
iteration 17903 : loss : 0.026843, loss_ce: 0.009001
iteration 17904 : loss : 0.020022, loss_ce: 0.008010
iteration 17905 : loss : 0.020837, loss_ce: 0.007567
iteration 17906 : loss : 0.024091, loss_ce: 0.005675
iteration 17907 : loss : 0.019350, loss_ce: 0.005251
iteration 17908 : loss : 0.022315, loss_ce: 0.009675
iteration 17909 : loss : 0.021573, loss_ce: 0.010671
iteration 17910 : loss : 0.023168, loss_ce: 0.009507
iteration 17911 : loss : 0.028486, loss_ce: 0.007614
iteration 17912 : loss : 0.018822, loss_ce: 0.006147
iteration 17913 : loss : 0.017992, loss_ce: 0.005820
iteration 17914 : loss : 0.019031, loss_ce: 0.007479
iteration 17915 : loss : 0.021666, loss_ce: 0.008289
iteration 17916 : loss : 0.075715, loss_ce: 0.003138
iteration 17917 : loss : 0.028147, loss_ce: 0.009233
iteration 17918 : loss : 0.023295, loss_ce: 0.008609
pred_sum 9551
gtsum tensor(9836, device='cuda:0')
iteration 17919 : loss : 0.021990, loss_ce: 0.010337
iteration 17920 : loss : 0.024515, loss_ce: 0.004462
iteration 17921 : loss : 0.022937, loss_ce: 0.008850
iteration 17922 : loss : 0.029605, loss_ce: 0.007598
iteration 17923 : loss : 0.020371, loss_ce: 0.007788
iteration 17924 : loss : 0.019611, loss_ce: 0.006814
iteration 17925 : loss : 0.022073, loss_ce: 0.008216
iteration 17926 : loss : 0.024629, loss_ce: 0.010173
iteration 17927 : loss : 0.021693, loss_ce: 0.008082
iteration 17928 : loss : 0.019935, loss_ce: 0.005686
iteration 17929 : loss : 0.021055, loss_ce: 0.007160
iteration 17930 : loss : 0.019000, loss_ce: 0.008129
iteration 17931 : loss : 0.028863, loss_ce: 0.004017
iteration 17932 : loss : 0.021904, loss_ce: 0.007440
iteration 17933 : loss : 0.023371, loss_ce: 0.009111
iteration 17934 : loss : 0.021259, loss_ce: 0.007757
iteration 17935 : loss : 0.020795, loss_ce: 0.007565
iteration 17936 : loss : 0.081245, loss_ce: 0.002602
iteration 17937 : loss : 0.021654, loss_ce: 0.007554
iteration 17938 : loss : 0.019967, loss_ce: 0.006562
iteration 17939 : loss : 0.071973, loss_ce: 0.004514
iteration 17940 : loss : 0.020828, loss_ce: 0.008145
iteration 17941 : loss : 0.020357, loss_ce: 0.007442
iteration 17942 : loss : 0.023508, loss_ce: 0.010790
iteration 17943 : loss : 0.026573, loss_ce: 0.006809
iteration 17944 : loss : 0.071804, loss_ce: 0.005248
iteration 17945 : loss : 0.022623, loss_ce: 0.010497
iteration 17946 : loss : 0.074985, loss_ce: 0.008313
iteration 17947 : loss : 0.020774, loss_ce: 0.007196
iteration 17948 : loss : 0.070234, loss_ce: 0.003766
iteration 17949 : loss : 0.342246, loss_ce: 0.001618
 96%|███████████████████████████▉ | 193/200 [2:55:17<06:21, 54.49s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 17950 : loss : 0.017961, loss_ce: 0.007403
iteration 17951 : loss : 0.025587, loss_ce: 0.014392
iteration 17952 : loss : 0.023264, loss_ce: 0.005475
iteration 17953 : loss : 0.020962, loss_ce: 0.005800
iteration 17954 : loss : 0.074773, loss_ce: 0.005863
iteration 17955 : loss : 0.026569, loss_ce: 0.007720
iteration 17956 : loss : 0.033594, loss_ce: 0.007534
iteration 17957 : loss : 0.025551, loss_ce: 0.010008
iteration 17958 : loss : 0.030589, loss_ce: 0.004051
iteration 17959 : loss : 0.021519, loss_ce: 0.008488
iteration 17960 : loss : 0.023292, loss_ce: 0.007173
iteration 17961 : loss : 0.019857, loss_ce: 0.004719
iteration 17962 : loss : 0.019004, loss_ce: 0.006592
iteration 17963 : loss : 0.023350, loss_ce: 0.009870
iteration 17964 : loss : 0.021354, loss_ce: 0.008780
iteration 17965 : loss : 0.020179, loss_ce: 0.005166
iteration 17966 : loss : 0.017900, loss_ce: 0.005572
iteration 17967 : loss : 0.021029, loss_ce: 0.007746
iteration 17968 : loss : 0.018740, loss_ce: 0.003884
iteration 17969 : loss : 0.020941, loss_ce: 0.006370
iteration 17970 : loss : 0.020960, loss_ce: 0.008296
iteration 17971 : loss : 0.023535, loss_ce: 0.009268
iteration 17972 : loss : 0.024020, loss_ce: 0.006694
iteration 17973 : loss : 0.020962, loss_ce: 0.008517
iteration 17974 : loss : 0.073459, loss_ce: 0.007635
iteration 17975 : loss : 0.023638, loss_ce: 0.008252
iteration 17976 : loss : 0.020896, loss_ce: 0.007271
iteration 17977 : loss : 0.021215, loss_ce: 0.006825
iteration 17978 : loss : 0.021826, loss_ce: 0.006657
iteration 17979 : loss : 0.020337, loss_ce: 0.008018
iteration 17980 : loss : 0.021574, loss_ce: 0.009003
pred_sum 32878
gtsum tensor(32471, device='cuda:0')
iteration 17981 : loss : 0.019841, loss_ce: 0.008690
iteration 17982 : loss : 0.021224, loss_ce: 0.004738
iteration 17983 : loss : 0.025136, loss_ce: 0.010779
iteration 17984 : loss : 0.021537, loss_ce: 0.005972
iteration 17985 : loss : 0.021328, loss_ce: 0.006123
iteration 17986 : loss : 0.024837, loss_ce: 0.008385
iteration 17987 : loss : 0.021697, loss_ce: 0.006363
iteration 17988 : loss : 0.022736, loss_ce: 0.008321
iteration 17989 : loss : 0.021260, loss_ce: 0.004502
iteration 17990 : loss : 0.025220, loss_ce: 0.008235
iteration 17991 : loss : 0.022077, loss_ce: 0.008938
iteration 17992 : loss : 0.024793, loss_ce: 0.007553
iteration 17993 : loss : 0.026855, loss_ce: 0.008720
iteration 17994 : loss : 0.018476, loss_ce: 0.006449
iteration 17995 : loss : 0.021465, loss_ce: 0.008128
iteration 17996 : loss : 0.020437, loss_ce: 0.007468
iteration 17997 : loss : 0.019716, loss_ce: 0.008624
iteration 17998 : loss : 0.024335, loss_ce: 0.008853
iteration 17999 : loss : 0.023397, loss_ce: 0.007747
iteration 18000 : loss : 0.020049, loss_ce: 0.008051
iteration 18001 : loss : 0.019606, loss_ce: 0.010233
iteration 18002 : loss : 0.021608, loss_ce: 0.006109
iteration 18003 : loss : 0.022359, loss_ce: 0.006821
iteration 18004 : loss : 0.017522, loss_ce: 0.003911
iteration 18005 : loss : 0.073282, loss_ce: 0.007491
iteration 18006 : loss : 0.022581, loss_ce: 0.009043
iteration 18007 : loss : 0.021405, loss_ce: 0.008281
iteration 18008 : loss : 0.023413, loss_ce: 0.004136
iteration 18009 : loss : 0.037354, loss_ce: 0.002827
iteration 18010 : loss : 0.022459, loss_ce: 0.008619
iteration 18011 : loss : 0.077866, loss_ce: 0.007057
pred_sum 11433
gtsum tensor(11498, device='cuda:0')
iteration 18012 : loss : 0.073993, loss_ce: 0.006277
iteration 18013 : loss : 0.019238, loss_ce: 0.006986
iteration 18014 : loss : 0.023449, loss_ce: 0.007213
iteration 18015 : loss : 0.021437, loss_ce: 0.009714
iteration 18016 : loss : 0.070307, loss_ce: 0.003517
iteration 18017 : loss : 0.028999, loss_ce: 0.004898
iteration 18018 : loss : 0.021664, loss_ce: 0.007230
iteration 18019 : loss : 0.020265, loss_ce: 0.008497
iteration 18020 : loss : 0.021207, loss_ce: 0.010055
iteration 18021 : loss : 0.021672, loss_ce: 0.010326
iteration 18022 : loss : 0.072406, loss_ce: 0.004561
iteration 18023 : loss : 0.020499, loss_ce: 0.006586
iteration 18024 : loss : 0.028018, loss_ce: 0.007819
iteration 18025 : loss : 0.020450, loss_ce: 0.008985
iteration 18026 : loss : 0.020210, loss_ce: 0.009495
iteration 18027 : loss : 0.020353, loss_ce: 0.006752
iteration 18028 : loss : 0.022655, loss_ce: 0.004459
iteration 18029 : loss : 0.073997, loss_ce: 0.009307
iteration 18030 : loss : 0.024715, loss_ce: 0.004593
iteration 18031 : loss : 0.019876, loss_ce: 0.006682
iteration 18032 : loss : 0.020707, loss_ce: 0.007787
iteration 18033 : loss : 0.019206, loss_ce: 0.006384
iteration 18034 : loss : 0.022480, loss_ce: 0.006390
iteration 18035 : loss : 0.024882, loss_ce: 0.009088
iteration 18036 : loss : 0.021810, loss_ce: 0.007614
iteration 18037 : loss : 0.022277, loss_ce: 0.009958
iteration 18038 : loss : 0.019875, loss_ce: 0.004247
iteration 18039 : loss : 0.022703, loss_ce: 0.010408
iteration 18040 : loss : 0.073803, loss_ce: 0.007341
iteration 18041 : loss : 0.019892, loss_ce: 0.008870
iteration 18042 : loss : 0.276235, loss_ce: 0.004350
 97%|████████████████████████████▏| 194/200 [2:56:11<05:26, 54.49s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 18043 : loss : 0.016508, loss_ce: 0.004295
iteration 18044 : loss : 0.017499, loss_ce: 0.005751
iteration 18045 : loss : 0.024194, loss_ce: 0.007118
iteration 18046 : loss : 0.021690, loss_ce: 0.007278
iteration 18047 : loss : 0.020075, loss_ce: 0.007305
iteration 18048 : loss : 0.021862, loss_ce: 0.007610
iteration 18049 : loss : 0.024042, loss_ce: 0.007277
iteration 18050 : loss : 0.024567, loss_ce: 0.010832
iteration 18051 : loss : 0.022658, loss_ce: 0.008825
iteration 18052 : loss : 0.023745, loss_ce: 0.010366
iteration 18053 : loss : 0.022371, loss_ce: 0.007264
iteration 18054 : loss : 0.018850, loss_ce: 0.007653
iteration 18055 : loss : 0.026212, loss_ce: 0.009773
iteration 18056 : loss : 0.021807, loss_ce: 0.006530
iteration 18057 : loss : 0.021556, loss_ce: 0.007499
iteration 18058 : loss : 0.034573, loss_ce: 0.005449
iteration 18059 : loss : 0.019914, loss_ce: 0.006715
iteration 18060 : loss : 0.070246, loss_ce: 0.002699
iteration 18061 : loss : 0.021315, loss_ce: 0.006287
iteration 18062 : loss : 0.020570, loss_ce: 0.004998
iteration 18063 : loss : 0.019348, loss_ce: 0.005759
iteration 18064 : loss : 0.019046, loss_ce: 0.006650
iteration 18065 : loss : 0.023368, loss_ce: 0.010496
iteration 18066 : loss : 0.087404, loss_ce: 0.005857
iteration 18067 : loss : 0.021310, loss_ce: 0.009191
iteration 18068 : loss : 0.017465, loss_ce: 0.005184
iteration 18069 : loss : 0.018112, loss_ce: 0.005527
iteration 18070 : loss : 0.020305, loss_ce: 0.006067
iteration 18071 : loss : 0.022574, loss_ce: 0.008435
iteration 18072 : loss : 0.022072, loss_ce: 0.006486
iteration 18073 : loss : 0.021024, loss_ce: 0.007545
pred_sum 8570
gtsum tensor(8982, device='cuda:0')
iteration 18074 : loss : 0.022330, loss_ce: 0.008395
iteration 18075 : loss : 0.019262, loss_ce: 0.008302
iteration 18076 : loss : 0.022958, loss_ce: 0.008731
iteration 18077 : loss : 0.077261, loss_ce: 0.006242
iteration 18078 : loss : 0.025466, loss_ce: 0.008201
iteration 18079 : loss : 0.023278, loss_ce: 0.007972
iteration 18080 : loss : 0.032418, loss_ce: 0.005899
iteration 18081 : loss : 0.021091, loss_ce: 0.006621
iteration 18082 : loss : 0.021464, loss_ce: 0.010099
iteration 18083 : loss : 0.019861, loss_ce: 0.004624
iteration 18084 : loss : 0.022778, loss_ce: 0.005664
iteration 18085 : loss : 0.025495, loss_ce: 0.008956
iteration 18086 : loss : 0.022539, loss_ce: 0.011076
iteration 18087 : loss : 0.020580, loss_ce: 0.007323
iteration 18088 : loss : 0.018422, loss_ce: 0.006732
iteration 18089 : loss : 0.022339, loss_ce: 0.010637
iteration 18090 : loss : 0.017994, loss_ce: 0.005868
iteration 18091 : loss : 0.025134, loss_ce: 0.008554
iteration 18092 : loss : 0.073978, loss_ce: 0.005870
iteration 18093 : loss : 0.019738, loss_ce: 0.005244
iteration 18094 : loss : 0.023356, loss_ce: 0.009500
iteration 18095 : loss : 0.022054, loss_ce: 0.004144
iteration 18096 : loss : 0.018339, loss_ce: 0.004288
iteration 18097 : loss : 0.023196, loss_ce: 0.008234
iteration 18098 : loss : 0.075429, loss_ce: 0.007020
iteration 18099 : loss : 0.022434, loss_ce: 0.007718
iteration 18100 : loss : 0.021918, loss_ce: 0.007544
iteration 18101 : loss : 0.020830, loss_ce: 0.007576
iteration 18102 : loss : 0.020565, loss_ce: 0.008072
iteration 18103 : loss : 0.021346, loss_ce: 0.011471
iteration 18104 : loss : 0.075758, loss_ce: 0.004784
pred_sum 178
gtsum tensor(196, device='cuda:0')
iteration 18105 : loss : 0.021623, loss_ce: 0.008095
iteration 18106 : loss : 0.019696, loss_ce: 0.007557
iteration 18107 : loss : 0.027250, loss_ce: 0.007319
iteration 18108 : loss : 0.021717, loss_ce: 0.005953
iteration 18109 : loss : 0.023611, loss_ce: 0.008002
iteration 18110 : loss : 0.022833, loss_ce: 0.006032
iteration 18111 : loss : 0.023328, loss_ce: 0.007419
iteration 18112 : loss : 0.019710, loss_ce: 0.004934
iteration 18113 : loss : 0.022406, loss_ce: 0.006001
iteration 18114 : loss : 0.021092, loss_ce: 0.010592
iteration 18115 : loss : 0.020060, loss_ce: 0.007966
iteration 18116 : loss : 0.019699, loss_ce: 0.004599
iteration 18117 : loss : 0.023100, loss_ce: 0.010285
iteration 18118 : loss : 0.021504, loss_ce: 0.009579
iteration 18119 : loss : 0.020034, loss_ce: 0.007377
iteration 18120 : loss : 0.018657, loss_ce: 0.006787
iteration 18121 : loss : 0.077142, loss_ce: 0.006547
iteration 18122 : loss : 0.022357, loss_ce: 0.010665
iteration 18123 : loss : 0.019533, loss_ce: 0.005929
iteration 18124 : loss : 0.020896, loss_ce: 0.011500
iteration 18125 : loss : 0.020557, loss_ce: 0.006998
iteration 18126 : loss : 0.025090, loss_ce: 0.007764
iteration 18127 : loss : 0.028678, loss_ce: 0.008516
iteration 18128 : loss : 0.021180, loss_ce: 0.006068
iteration 18129 : loss : 0.022893, loss_ce: 0.007378
iteration 18130 : loss : 0.021105, loss_ce: 0.005756
iteration 18131 : loss : 0.024711, loss_ce: 0.009172
iteration 18132 : loss : 0.023755, loss_ce: 0.005910
iteration 18133 : loss : 0.022000, loss_ce: 0.008589
iteration 18134 : loss : 0.019634, loss_ce: 0.006368
iteration 18135 : loss : 0.036724, loss_ce: 0.029250
 98%|████████████████████████████▎| 195/200 [2:57:06<04:32, 54.47s/it]pred_sum 70707
gtsum tensor(73027, device='cuda:0')
iteration 18136 : loss : 0.020504, loss_ce: 0.007369
iteration 18137 : loss : 0.025550, loss_ce: 0.008949
iteration 18138 : loss : 0.024723, loss_ce: 0.004728
iteration 18139 : loss : 0.022832, loss_ce: 0.006430
iteration 18140 : loss : 0.018972, loss_ce: 0.007744
iteration 18141 : loss : 0.019923, loss_ce: 0.005572
iteration 18142 : loss : 0.024312, loss_ce: 0.009392
iteration 18143 : loss : 0.019256, loss_ce: 0.005047
iteration 18144 : loss : 0.021170, loss_ce: 0.007533
iteration 18145 : loss : 0.022866, loss_ce: 0.009404
iteration 18146 : loss : 0.017555, loss_ce: 0.006228
iteration 18147 : loss : 0.020160, loss_ce: 0.007964
iteration 18148 : loss : 0.023684, loss_ce: 0.014465
iteration 18149 : loss : 0.024945, loss_ce: 0.007955
iteration 18150 : loss : 0.021032, loss_ce: 0.008301
iteration 18151 : loss : 0.023082, loss_ce: 0.009959
iteration 18152 : loss : 0.023331, loss_ce: 0.009946
iteration 18153 : loss : 0.021022, loss_ce: 0.004683
iteration 18154 : loss : 0.025891, loss_ce: 0.008306
iteration 18155 : loss : 0.023814, loss_ce: 0.004281
iteration 18156 : loss : 0.020220, loss_ce: 0.008813
iteration 18157 : loss : 0.018574, loss_ce: 0.007016
iteration 18158 : loss : 0.073235, loss_ce: 0.007696
iteration 18159 : loss : 0.021131, loss_ce: 0.005162
iteration 18160 : loss : 0.071100, loss_ce: 0.003171
iteration 18161 : loss : 0.021759, loss_ce: 0.007345
iteration 18162 : loss : 0.023106, loss_ce: 0.012750
iteration 18163 : loss : 0.020586, loss_ce: 0.010837
iteration 18164 : loss : 0.021948, loss_ce: 0.004937
iteration 18165 : loss : 0.023195, loss_ce: 0.009304
iteration 18166 : loss : 0.015640, loss_ce: 0.004613
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 18167 : loss : 0.018562, loss_ce: 0.005115
iteration 18168 : loss : 0.017205, loss_ce: 0.005208
iteration 18169 : loss : 0.022919, loss_ce: 0.009798
iteration 18170 : loss : 0.028464, loss_ce: 0.006219
iteration 18171 : loss : 0.023152, loss_ce: 0.008213
iteration 18172 : loss : 0.020465, loss_ce: 0.005931
iteration 18173 : loss : 0.030847, loss_ce: 0.008147
iteration 18174 : loss : 0.023794, loss_ce: 0.007679
iteration 18175 : loss : 0.021176, loss_ce: 0.006976
iteration 18176 : loss : 0.021180, loss_ce: 0.010306
iteration 18177 : loss : 0.023878, loss_ce: 0.008115
iteration 18178 : loss : 0.023147, loss_ce: 0.006290
iteration 18179 : loss : 0.020834, loss_ce: 0.006869
iteration 18180 : loss : 0.023364, loss_ce: 0.009846
iteration 18181 : loss : 0.023473, loss_ce: 0.007473
iteration 18182 : loss : 0.022127, loss_ce: 0.006255
iteration 18183 : loss : 0.021298, loss_ce: 0.003550
iteration 18184 : loss : 0.026056, loss_ce: 0.007576
iteration 18185 : loss : 0.025401, loss_ce: 0.008972
iteration 18186 : loss : 0.024711, loss_ce: 0.009088
iteration 18187 : loss : 0.020507, loss_ce: 0.007211
iteration 18188 : loss : 0.021855, loss_ce: 0.004482
iteration 18189 : loss : 0.021087, loss_ce: 0.010212
iteration 18190 : loss : 0.021557, loss_ce: 0.008441
iteration 18191 : loss : 0.022430, loss_ce: 0.005849
iteration 18192 : loss : 0.019473, loss_ce: 0.008716
iteration 18193 : loss : 0.018061, loss_ce: 0.006223
iteration 18194 : loss : 0.086030, loss_ce: 0.005874
iteration 18195 : loss : 0.021576, loss_ce: 0.007644
iteration 18196 : loss : 0.020772, loss_ce: 0.008488
iteration 18197 : loss : 0.021444, loss_ce: 0.007883
pred_sum 13626
gtsum tensor(13651, device='cuda:0')
iteration 18198 : loss : 0.020935, loss_ce: 0.008108
iteration 18199 : loss : 0.018712, loss_ce: 0.004726
iteration 18200 : loss : 0.021016, loss_ce: 0.007364
iteration 18201 : loss : 0.019625, loss_ce: 0.004079
iteration 18202 : loss : 0.022702, loss_ce: 0.009259
iteration 18203 : loss : 0.019223, loss_ce: 0.004457
iteration 18204 : loss : 0.023743, loss_ce: 0.006465
iteration 18205 : loss : 0.018493, loss_ce: 0.005902
iteration 18206 : loss : 0.023900, loss_ce: 0.008731
iteration 18207 : loss : 0.072286, loss_ce: 0.005069
iteration 18208 : loss : 0.022658, loss_ce: 0.010299
iteration 18209 : loss : 0.025695, loss_ce: 0.008947
iteration 18210 : loss : 0.040414, loss_ce: 0.004224
iteration 18211 : loss : 0.027970, loss_ce: 0.009204
iteration 18212 : loss : 0.019793, loss_ce: 0.008358
iteration 18213 : loss : 0.021876, loss_ce: 0.005999
iteration 18214 : loss : 0.020975, loss_ce: 0.010577
iteration 18215 : loss : 0.020889, loss_ce: 0.007350
iteration 18216 : loss : 0.019713, loss_ce: 0.007637
iteration 18217 : loss : 0.034755, loss_ce: 0.003713
iteration 18218 : loss : 0.019740, loss_ce: 0.008058
iteration 18219 : loss : 0.021178, loss_ce: 0.006792
iteration 18220 : loss : 0.025079, loss_ce: 0.006179
iteration 18221 : loss : 0.019721, loss_ce: 0.007145
iteration 18222 : loss : 0.020446, loss_ce: 0.005466
iteration 18223 : loss : 0.026536, loss_ce: 0.004611
iteration 18224 : loss : 0.023502, loss_ce: 0.010863
iteration 18225 : loss : 0.024122, loss_ce: 0.005748
iteration 18226 : loss : 0.020441, loss_ce: 0.008720
iteration 18227 : loss : 0.019766, loss_ce: 0.009178
iteration 18228 : loss : 0.289082, loss_ce: 0.006113
 98%|████████████████████████████▍| 196/200 [2:58:00<03:37, 54.44s/it]pred_sum 26610
gtsum tensor(25618, device='cuda:0')
iteration 18229 : loss : 0.018318, loss_ce: 0.004328
iteration 18230 : loss : 0.020470, loss_ce: 0.005733
iteration 18231 : loss : 0.072607, loss_ce: 0.005667
iteration 18232 : loss : 0.026310, loss_ce: 0.007639
iteration 18233 : loss : 0.021145, loss_ce: 0.006355
iteration 18234 : loss : 0.018535, loss_ce: 0.004860
iteration 18235 : loss : 0.024631, loss_ce: 0.007690
iteration 18236 : loss : 0.024040, loss_ce: 0.009471
iteration 18237 : loss : 0.024028, loss_ce: 0.013264
iteration 18238 : loss : 0.022302, loss_ce: 0.005250
iteration 18239 : loss : 0.022417, loss_ce: 0.009066
iteration 18240 : loss : 0.022751, loss_ce: 0.009377
iteration 18241 : loss : 0.022801, loss_ce: 0.008687
iteration 18242 : loss : 0.022919, loss_ce: 0.006291
iteration 18243 : loss : 0.016965, loss_ce: 0.005476
iteration 18244 : loss : 0.020670, loss_ce: 0.007567
iteration 18245 : loss : 0.024043, loss_ce: 0.005220
iteration 18246 : loss : 0.026471, loss_ce: 0.009774
iteration 18247 : loss : 0.022005, loss_ce: 0.008041
iteration 18248 : loss : 0.018979, loss_ce: 0.005049
iteration 18249 : loss : 0.021901, loss_ce: 0.009447
iteration 18250 : loss : 0.024773, loss_ce: 0.004193
iteration 18251 : loss : 0.020271, loss_ce: 0.007363
iteration 18252 : loss : 0.024722, loss_ce: 0.011676
iteration 18253 : loss : 0.024178, loss_ce: 0.006785
iteration 18254 : loss : 0.022509, loss_ce: 0.008702
iteration 18255 : loss : 0.022880, loss_ce: 0.008064
iteration 18256 : loss : 0.020061, loss_ce: 0.003642
iteration 18257 : loss : 0.020149, loss_ce: 0.006022
iteration 18258 : loss : 0.023692, loss_ce: 0.011362
iteration 18259 : loss : 0.018886, loss_ce: 0.006888
pred_sum 115
gtsum tensor(117, device='cuda:0')
iteration 18260 : loss : 0.019541, loss_ce: 0.007465
iteration 18261 : loss : 0.022783, loss_ce: 0.005371
iteration 18262 : loss : 0.021314, loss_ce: 0.006567
iteration 18263 : loss : 0.019573, loss_ce: 0.006182
iteration 18264 : loss : 0.022447, loss_ce: 0.007655
iteration 18265 : loss : 0.019392, loss_ce: 0.006442
iteration 18266 : loss : 0.020985, loss_ce: 0.007504
iteration 18267 : loss : 0.022390, loss_ce: 0.007663
iteration 18268 : loss : 0.071805, loss_ce: 0.003598
iteration 18269 : loss : 0.020131, loss_ce: 0.007587
iteration 18270 : loss : 0.021942, loss_ce: 0.007061
iteration 18271 : loss : 0.024742, loss_ce: 0.009490
iteration 18272 : loss : 0.076550, loss_ce: 0.010366
iteration 18273 : loss : 0.023186, loss_ce: 0.005245
iteration 18274 : loss : 0.020649, loss_ce: 0.006697
iteration 18275 : loss : 0.020494, loss_ce: 0.007424
iteration 18276 : loss : 0.023010, loss_ce: 0.005823
iteration 18277 : loss : 0.020512, loss_ce: 0.006172
iteration 18278 : loss : 0.021204, loss_ce: 0.007609
iteration 18279 : loss : 0.023450, loss_ce: 0.011268
iteration 18280 : loss : 0.019581, loss_ce: 0.008966
iteration 18281 : loss : 0.021579, loss_ce: 0.008645
iteration 18282 : loss : 0.018145, loss_ce: 0.004413
iteration 18283 : loss : 0.017233, loss_ce: 0.006651
iteration 18284 : loss : 0.024411, loss_ce: 0.006342
iteration 18285 : loss : 0.070458, loss_ce: 0.005162
iteration 18286 : loss : 0.019809, loss_ce: 0.008052
iteration 18287 : loss : 0.021963, loss_ce: 0.008799
iteration 18288 : loss : 0.021151, loss_ce: 0.007331
iteration 18289 : loss : 0.025586, loss_ce: 0.012174
iteration 18290 : loss : 0.019955, loss_ce: 0.009766
pred_sum 199
gtsum tensor(200, device='cuda:0')
iteration 18291 : loss : 0.028590, loss_ce: 0.012235
iteration 18292 : loss : 0.017311, loss_ce: 0.004110
iteration 18293 : loss : 0.020792, loss_ce: 0.006151
iteration 18294 : loss : 0.022220, loss_ce: 0.008221
iteration 18295 : loss : 0.020815, loss_ce: 0.007001
iteration 18296 : loss : 0.021853, loss_ce: 0.006858
iteration 18297 : loss : 0.019662, loss_ce: 0.005663
iteration 18298 : loss : 0.024052, loss_ce: 0.008153
iteration 18299 : loss : 0.020592, loss_ce: 0.007756
iteration 18300 : loss : 0.023626, loss_ce: 0.005866
iteration 18301 : loss : 0.024797, loss_ce: 0.010136
iteration 18302 : loss : 0.075570, loss_ce: 0.006424
iteration 18303 : loss : 0.020971, loss_ce: 0.008009
iteration 18304 : loss : 0.016770, loss_ce: 0.005751
iteration 18305 : loss : 0.021503, loss_ce: 0.007032
iteration 18306 : loss : 0.071301, loss_ce: 0.005535
iteration 18307 : loss : 0.017563, loss_ce: 0.007786
iteration 18308 : loss : 0.018400, loss_ce: 0.006178
iteration 18309 : loss : 0.024559, loss_ce: 0.010690
iteration 18310 : loss : 0.021893, loss_ce: 0.009326
iteration 18311 : loss : 0.019704, loss_ce: 0.006819
iteration 18312 : loss : 0.025101, loss_ce: 0.008299
iteration 18313 : loss : 0.022981, loss_ce: 0.006224
iteration 18314 : loss : 0.021641, loss_ce: 0.007446
iteration 18315 : loss : 0.022112, loss_ce: 0.006265
iteration 18316 : loss : 0.024387, loss_ce: 0.010275
iteration 18317 : loss : 0.017611, loss_ce: 0.004492
iteration 18318 : loss : 0.076450, loss_ce: 0.006147
iteration 18319 : loss : 0.020441, loss_ce: 0.004980
iteration 18320 : loss : 0.016139, loss_ce: 0.004498
iteration 18321 : loss : 0.227502, loss_ce: 0.003859
 98%|████████████████████████████▌| 197/200 [2:58:54<02:43, 54.45s/it]pred_sum 13493
gtsum tensor(13753, device='cuda:0')
iteration 18322 : loss : 0.021979, loss_ce: 0.007887
iteration 18323 : loss : 0.018694, loss_ce: 0.009137
iteration 18324 : loss : 0.071104, loss_ce: 0.005629
iteration 18325 : loss : 0.020338, loss_ce: 0.008655
iteration 18326 : loss : 0.020666, loss_ce: 0.004410
iteration 18327 : loss : 0.023604, loss_ce: 0.003615
iteration 18328 : loss : 0.017768, loss_ce: 0.004421
iteration 18329 : loss : 0.019759, loss_ce: 0.005513
iteration 18330 : loss : 0.023628, loss_ce: 0.007345
iteration 18331 : loss : 0.021568, loss_ce: 0.007362
iteration 18332 : loss : 0.018899, loss_ce: 0.009023
iteration 18333 : loss : 0.025461, loss_ce: 0.008343
iteration 18334 : loss : 0.026200, loss_ce: 0.007303
iteration 18335 : loss : 0.024623, loss_ce: 0.006532
iteration 18336 : loss : 0.022107, loss_ce: 0.009258
iteration 18337 : loss : 0.018715, loss_ce: 0.006080
iteration 18338 : loss : 0.021678, loss_ce: 0.008870
iteration 18339 : loss : 0.021693, loss_ce: 0.009293
iteration 18340 : loss : 0.019566, loss_ce: 0.006206
iteration 18341 : loss : 0.017342, loss_ce: 0.002743
iteration 18342 : loss : 0.021215, loss_ce: 0.006477
iteration 18343 : loss : 0.020477, loss_ce: 0.005548
iteration 18344 : loss : 0.022960, loss_ce: 0.008388
iteration 18345 : loss : 0.022625, loss_ce: 0.008351
iteration 18346 : loss : 0.022726, loss_ce: 0.011251
iteration 18347 : loss : 0.069515, loss_ce: 0.003371
iteration 18348 : loss : 0.023033, loss_ce: 0.005880
iteration 18349 : loss : 0.024701, loss_ce: 0.008847
iteration 18350 : loss : 0.019443, loss_ce: 0.003742
iteration 18351 : loss : 0.020380, loss_ce: 0.007882
iteration 18352 : loss : 0.021747, loss_ce: 0.007775
pred_sum 42922
gtsum tensor(43044, device='cuda:0')
iteration 18353 : loss : 0.074481, loss_ce: 0.005975
iteration 18354 : loss : 0.019096, loss_ce: 0.005531
iteration 18355 : loss : 0.021290, loss_ce: 0.009149
iteration 18356 : loss : 0.024598, loss_ce: 0.008787
iteration 18357 : loss : 0.020240, loss_ce: 0.003487
iteration 18358 : loss : 0.073245, loss_ce: 0.006726
iteration 18359 : loss : 0.016584, loss_ce: 0.006020
iteration 18360 : loss : 0.022117, loss_ce: 0.010309
iteration 18361 : loss : 0.021572, loss_ce: 0.009294
iteration 18362 : loss : 0.019127, loss_ce: 0.007394
iteration 18363 : loss : 0.022310, loss_ce: 0.008368
iteration 18364 : loss : 0.020892, loss_ce: 0.006009
iteration 18365 : loss : 0.022829, loss_ce: 0.008005
iteration 18366 : loss : 0.020343, loss_ce: 0.007268
iteration 18367 : loss : 0.021881, loss_ce: 0.008301
iteration 18368 : loss : 0.027301, loss_ce: 0.006967
iteration 18369 : loss : 0.018588, loss_ce: 0.004871
iteration 18370 : loss : 0.019592, loss_ce: 0.008759
iteration 18371 : loss : 0.035215, loss_ce: 0.009188
iteration 18372 : loss : 0.016593, loss_ce: 0.003545
iteration 18373 : loss : 0.019530, loss_ce: 0.006446
iteration 18374 : loss : 0.028467, loss_ce: 0.007745
iteration 18375 : loss : 0.020762, loss_ce: 0.005599
iteration 18376 : loss : 0.022056, loss_ce: 0.007449
iteration 18377 : loss : 0.025074, loss_ce: 0.006921
iteration 18378 : loss : 0.076766, loss_ce: 0.007256
iteration 18379 : loss : 0.022003, loss_ce: 0.008291
iteration 18380 : loss : 0.021422, loss_ce: 0.010256
iteration 18381 : loss : 0.022739, loss_ce: 0.008591
iteration 18382 : loss : 0.022984, loss_ce: 0.007727
iteration 18383 : loss : 0.019238, loss_ce: 0.006865
pred_sum 50114
gtsum tensor(49558, device='cuda:0')
iteration 18384 : loss : 0.020867, loss_ce: 0.009266
iteration 18385 : loss : 0.019734, loss_ce: 0.007178
iteration 18386 : loss : 0.022783, loss_ce: 0.007890
iteration 18387 : loss : 0.019260, loss_ce: 0.005786
iteration 18388 : loss : 0.025570, loss_ce: 0.011025
iteration 18389 : loss : 0.026688, loss_ce: 0.006009
iteration 18390 : loss : 0.023027, loss_ce: 0.011490
iteration 18391 : loss : 0.019474, loss_ce: 0.007884
iteration 18392 : loss : 0.025171, loss_ce: 0.008116
iteration 18393 : loss : 0.018467, loss_ce: 0.007462
iteration 18394 : loss : 0.022961, loss_ce: 0.009593
iteration 18395 : loss : 0.021953, loss_ce: 0.007479
iteration 18396 : loss : 0.021745, loss_ce: 0.006600
iteration 18397 : loss : 0.069018, loss_ce: 0.005694
iteration 18398 : loss : 0.021548, loss_ce: 0.008199
iteration 18399 : loss : 0.017508, loss_ce: 0.006591
iteration 18400 : loss : 0.126275, loss_ce: 0.003739
iteration 18401 : loss : 0.022219, loss_ce: 0.009121
iteration 18402 : loss : 0.070639, loss_ce: 0.005739
iteration 18403 : loss : 0.022600, loss_ce: 0.005759
iteration 18404 : loss : 0.024246, loss_ce: 0.008456
iteration 18405 : loss : 0.019731, loss_ce: 0.005004
iteration 18406 : loss : 0.022262, loss_ce: 0.006371
iteration 18407 : loss : 0.023789, loss_ce: 0.008632
iteration 18408 : loss : 0.024006, loss_ce: 0.012436
iteration 18409 : loss : 0.018764, loss_ce: 0.007541
iteration 18410 : loss : 0.021713, loss_ce: 0.008455
iteration 18411 : loss : 0.021260, loss_ce: 0.008758
iteration 18412 : loss : 0.022872, loss_ce: 0.010201
iteration 18413 : loss : 0.021362, loss_ce: 0.008071
iteration 18414 : loss : 0.097626, loss_ce: 0.006822
 99%|████████████████████████████▋| 198/200 [2:59:49<01:48, 54.42s/it]pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 18415 : loss : 0.024918, loss_ce: 0.008688
iteration 18416 : loss : 0.024161, loss_ce: 0.007079
iteration 18417 : loss : 0.074479, loss_ce: 0.006422
iteration 18418 : loss : 0.021840, loss_ce: 0.005229
iteration 18419 : loss : 0.021867, loss_ce: 0.008806
iteration 18420 : loss : 0.019784, loss_ce: 0.003932
iteration 18421 : loss : 0.016703, loss_ce: 0.005017
iteration 18422 : loss : 0.022641, loss_ce: 0.008608
iteration 18423 : loss : 0.020104, loss_ce: 0.009688
iteration 18424 : loss : 0.022994, loss_ce: 0.007784
iteration 18425 : loss : 0.029231, loss_ce: 0.007222
iteration 18426 : loss : 0.021189, loss_ce: 0.008267
iteration 18427 : loss : 0.022445, loss_ce: 0.011254
iteration 18428 : loss : 0.020169, loss_ce: 0.006576
iteration 18429 : loss : 0.021609, loss_ce: 0.008824
iteration 18430 : loss : 0.072757, loss_ce: 0.003375
iteration 18431 : loss : 0.025475, loss_ce: 0.007872
iteration 18432 : loss : 0.021931, loss_ce: 0.007911
iteration 18433 : loss : 0.021961, loss_ce: 0.008454
iteration 18434 : loss : 0.021552, loss_ce: 0.007707
iteration 18435 : loss : 0.019247, loss_ce: 0.007416
iteration 18436 : loss : 0.022608, loss_ce: 0.010494
iteration 18437 : loss : 0.021479, loss_ce: 0.006574
iteration 18438 : loss : 0.020311, loss_ce: 0.007929
iteration 18439 : loss : 0.024693, loss_ce: 0.007218
iteration 18440 : loss : 0.021579, loss_ce: 0.005067
iteration 18441 : loss : 0.028344, loss_ce: 0.005515
iteration 18442 : loss : 0.024625, loss_ce: 0.011768
iteration 18443 : loss : 0.018779, loss_ce: 0.005325
iteration 18444 : loss : 0.019268, loss_ce: 0.005281
iteration 18445 : loss : 0.022017, loss_ce: 0.007553
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 18446 : loss : 0.019641, loss_ce: 0.006361
iteration 18447 : loss : 0.021311, loss_ce: 0.008916
iteration 18448 : loss : 0.039548, loss_ce: 0.003959
iteration 18449 : loss : 0.020024, loss_ce: 0.005250
iteration 18450 : loss : 0.072103, loss_ce: 0.005805
iteration 18451 : loss : 0.019142, loss_ce: 0.007534
iteration 18452 : loss : 0.016497, loss_ce: 0.004764
iteration 18453 : loss : 0.023517, loss_ce: 0.008196
iteration 18454 : loss : 0.018764, loss_ce: 0.006427
iteration 18455 : loss : 0.024952, loss_ce: 0.012854
iteration 18456 : loss : 0.019996, loss_ce: 0.006842
iteration 18457 : loss : 0.022931, loss_ce: 0.005217
iteration 18458 : loss : 0.019766, loss_ce: 0.006310
iteration 18459 : loss : 0.026375, loss_ce: 0.008731
iteration 18460 : loss : 0.022120, loss_ce: 0.007345
iteration 18461 : loss : 0.022094, loss_ce: 0.010839
iteration 18462 : loss : 0.021274, loss_ce: 0.007756
iteration 18463 : loss : 0.022803, loss_ce: 0.008934
iteration 18464 : loss : 0.022687, loss_ce: 0.007037
iteration 18465 : loss : 0.019463, loss_ce: 0.006531
iteration 18466 : loss : 0.024312, loss_ce: 0.012000
iteration 18467 : loss : 0.022195, loss_ce: 0.008835
iteration 18468 : loss : 0.020018, loss_ce: 0.005138
iteration 18469 : loss : 0.016555, loss_ce: 0.005834
iteration 18470 : loss : 0.019576, loss_ce: 0.005703
iteration 18471 : loss : 0.022572, loss_ce: 0.006956
iteration 18472 : loss : 0.022341, loss_ce: 0.010056
iteration 18473 : loss : 0.030833, loss_ce: 0.008132
iteration 18474 : loss : 0.019160, loss_ce: 0.005790
iteration 18475 : loss : 0.018713, loss_ce: 0.008406
iteration 18476 : loss : 0.024426, loss_ce: 0.005706
pred_sum 7041
gtsum tensor(6925, device='cuda:0')
iteration 18477 : loss : 0.020034, loss_ce: 0.004902
iteration 18478 : loss : 0.024652, loss_ce: 0.006207
iteration 18479 : loss : 0.017695, loss_ce: 0.005597
iteration 18480 : loss : 0.024338, loss_ce: 0.005539
iteration 18481 : loss : 0.019245, loss_ce: 0.005068
iteration 18482 : loss : 0.023874, loss_ce: 0.009534
iteration 18483 : loss : 0.023535, loss_ce: 0.009033
iteration 18484 : loss : 0.018364, loss_ce: 0.004719
iteration 18485 : loss : 0.018527, loss_ce: 0.005862
iteration 18486 : loss : 0.022015, loss_ce: 0.008651
iteration 18487 : loss : 0.022210, loss_ce: 0.005435
iteration 18488 : loss : 0.018736, loss_ce: 0.007681
iteration 18489 : loss : 0.019772, loss_ce: 0.006724
iteration 18490 : loss : 0.021155, loss_ce: 0.010615
iteration 18491 : loss : 0.017923, loss_ce: 0.007085
iteration 18492 : loss : 0.024311, loss_ce: 0.009779
iteration 18493 : loss : 0.071132, loss_ce: 0.006265
iteration 18494 : loss : 0.020516, loss_ce: 0.007192
iteration 18495 : loss : 0.031307, loss_ce: 0.011252
iteration 18496 : loss : 0.026324, loss_ce: 0.004585
iteration 18497 : loss : 0.021582, loss_ce: 0.007859
iteration 18498 : loss : 0.073131, loss_ce: 0.002950
iteration 18499 : loss : 0.025670, loss_ce: 0.011442
iteration 18500 : loss : 0.019485, loss_ce: 0.005406
iteration 18501 : loss : 0.020523, loss_ce: 0.010035
iteration 18502 : loss : 0.022615, loss_ce: 0.008154
iteration 18503 : loss : 0.020774, loss_ce: 0.006995
iteration 18504 : loss : 0.019608, loss_ce: 0.009146
iteration 18505 : loss : 0.024164, loss_ce: 0.007624
iteration 18506 : loss : 0.019314, loss_ce: 0.005609
iteration 18507 : loss : 0.028600, loss_ce: 0.024574
100%|████████████████████████████▊| 199/200 [3:00:43<00:54, 54.43s/it]pred_sum 52395
gtsum tensor(52629, device='cuda:0')
iteration 18508 : loss : 0.019134, loss_ce: 0.006664
iteration 18509 : loss : 0.040119, loss_ce: 0.005227
iteration 18510 : loss : 0.051655, loss_ce: 0.004216
iteration 18511 : loss : 0.023082, loss_ce: 0.009075
iteration 18512 : loss : 0.019110, loss_ce: 0.008268
iteration 18513 : loss : 0.020763, loss_ce: 0.006964
iteration 18514 : loss : 0.073861, loss_ce: 0.007245
iteration 18515 : loss : 0.016503, loss_ce: 0.006077
iteration 18516 : loss : 0.030393, loss_ce: 0.006427
iteration 18517 : loss : 0.019930, loss_ce: 0.003335
iteration 18518 : loss : 0.036303, loss_ce: 0.004368
iteration 18519 : loss : 0.019149, loss_ce: 0.006247
iteration 18520 : loss : 0.021511, loss_ce: 0.008026
iteration 18521 : loss : 0.024091, loss_ce: 0.008253
iteration 18522 : loss : 0.022064, loss_ce: 0.006636
iteration 18523 : loss : 0.023671, loss_ce: 0.003599
iteration 18524 : loss : 0.020609, loss_ce: 0.006353
iteration 18525 : loss : 0.026132, loss_ce: 0.009103
iteration 18526 : loss : 0.019225, loss_ce: 0.008890
iteration 18527 : loss : 0.021318, loss_ce: 0.009339
iteration 18528 : loss : 0.018641, loss_ce: 0.006525
iteration 18529 : loss : 0.021954, loss_ce: 0.007668
iteration 18530 : loss : 0.020604, loss_ce: 0.009895
iteration 18531 : loss : 0.021724, loss_ce: 0.006679
iteration 18532 : loss : 0.021506, loss_ce: 0.006763
iteration 18533 : loss : 0.020782, loss_ce: 0.005657
iteration 18534 : loss : 0.020179, loss_ce: 0.007269
iteration 18535 : loss : 0.026441, loss_ce: 0.010689
iteration 18536 : loss : 0.078176, loss_ce: 0.007739
iteration 18537 : loss : 0.022454, loss_ce: 0.009930
iteration 18538 : loss : 0.021214, loss_ce: 0.008234
pred_sum 29221
gtsum tensor(28547, device='cuda:0')
iteration 18539 : loss : 0.022392, loss_ce: 0.006922
iteration 18540 : loss : 0.021238, loss_ce: 0.009539
iteration 18541 : loss : 0.072453, loss_ce: 0.005582
iteration 18542 : loss : 0.031719, loss_ce: 0.008202
iteration 18543 : loss : 0.022120, loss_ce: 0.005282
iteration 18544 : loss : 0.029442, loss_ce: 0.008110
iteration 18545 : loss : 0.026222, loss_ce: 0.009471
iteration 18546 : loss : 0.019168, loss_ce: 0.006078
iteration 18547 : loss : 0.021861, loss_ce: 0.007575
iteration 18548 : loss : 0.034920, loss_ce: 0.003723
iteration 18549 : loss : 0.024053, loss_ce: 0.005071
iteration 18550 : loss : 0.023093, loss_ce: 0.010617
iteration 18551 : loss : 0.022007, loss_ce: 0.006162
iteration 18552 : loss : 0.018571, loss_ce: 0.004829
iteration 18553 : loss : 0.026603, loss_ce: 0.008059
iteration 18554 : loss : 0.019522, loss_ce: 0.005077
iteration 18555 : loss : 0.021308, loss_ce: 0.009096
iteration 18556 : loss : 0.018645, loss_ce: 0.006575
iteration 18557 : loss : 0.028178, loss_ce: 0.007805
iteration 18558 : loss : 0.019596, loss_ce: 0.009361
iteration 18559 : loss : 0.021564, loss_ce: 0.004971
iteration 18560 : loss : 0.022518, loss_ce: 0.007839
iteration 18561 : loss : 0.024186, loss_ce: 0.006018
iteration 18562 : loss : 0.021179, loss_ce: 0.008097
iteration 18563 : loss : 0.022526, loss_ce: 0.009534
iteration 18564 : loss : 0.023142, loss_ce: 0.008959
iteration 18565 : loss : 0.018945, loss_ce: 0.005292
iteration 18566 : loss : 0.023892, loss_ce: 0.008228
iteration 18567 : loss : 0.020829, loss_ce: 0.008397
iteration 18568 : loss : 0.072686, loss_ce: 0.005165
iteration 18569 : loss : 0.025861, loss_ce: 0.004851
pred_sum 0
gtsum tensor(0, device='cuda:0')
iteration 18570 : loss : 0.018419, loss_ce: 0.006760
iteration 18571 : loss : 0.022007, loss_ce: 0.007562
iteration 18572 : loss : 0.021345, loss_ce: 0.007290
iteration 18573 : loss : 0.022546, loss_ce: 0.006788
iteration 18574 : loss : 0.023189, loss_ce: 0.009472
iteration 18575 : loss : 0.020824, loss_ce: 0.007666
iteration 18576 : loss : 0.020468, loss_ce: 0.007971
iteration 18577 : loss : 0.024452, loss_ce: 0.008347
iteration 18578 : loss : 0.017943, loss_ce: 0.005433
iteration 18579 : loss : 0.020419, loss_ce: 0.007881
iteration 18580 : loss : 0.018697, loss_ce: 0.006313
iteration 18581 : loss : 0.021298, loss_ce: 0.009094
iteration 18582 : loss : 0.019754, loss_ce: 0.008375
iteration 18583 : loss : 0.020128, loss_ce: 0.010627
iteration 18584 : loss : 0.022346, loss_ce: 0.009519
iteration 18585 : loss : 0.019226, loss_ce: 0.004681
iteration 18586 : loss : 0.020296, loss_ce: 0.010261
iteration 18587 : loss : 0.024584, loss_ce: 0.008555
iteration 18588 : loss : 0.023154, loss_ce: 0.006024
iteration 18589 : loss : 0.026804, loss_ce: 0.008858
iteration 18590 : loss : 0.020672, loss_ce: 0.008159
iteration 18591 : loss : 0.023231, loss_ce: 0.007924
iteration 18592 : loss : 0.018738, loss_ce: 0.005239
iteration 18593 : loss : 0.030392, loss_ce: 0.006079
iteration 18594 : loss : 0.021984, loss_ce: 0.006959
iteration 18595 : loss : 0.025688, loss_ce: 0.011969
iteration 18596 : loss : 0.021843, loss_ce: 0.007574
iteration 18597 : loss : 0.018516, loss_ce: 0.007104
iteration 18598 : loss : 0.014933, loss_ce: 0.004253
iteration 18599 : loss : 0.022814, loss_ce: 0.009931
iteration 18600 : loss : 0.130130, loss_ce: 0.006004
pred_sum 2211
gtsum tensor(1967, device='cuda:0')
save model to ../model/TU_Synapse224/TU_pretrain_R50-ViT-B_16_skip3_epo200_bs24_224/epoch_199.pth
save model to ../model/TU_Synapse224/TU_pretrain_R50-ViT-B_16_skip3_epo200_bs24_224/epoch_199.pth
100%|████████████████████████████▊| 199/200 [3:01:39<00:54, 54.77s/it]
wandb: Waiting for W&B process to finish... (success).
wandb: - 24.984 MB of 24.984 MB uploaded (0.000 MB deduped)wandb: \ 24.984 MB of 24.984 MB uploaded (0.000 MB deduped)wandb: | 24.984 MB of 24.984 MB uploaded (0.000 MB deduped)wandb: / 24.984 MB of 24.984 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  iteration ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:    loss_ce █▄▃▂▂▂▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         lr ████▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁
wandb: total_loss █▅▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  iteration 18600
wandb:    loss_ce 0.006
wandb:         lr 0.0
wandb: total_loss 0.13013
wandb: 
wandb: 🚀 View run legendary-glade-108 at: https://wandb.ai/niko_k98/TransUnet/runs/73ibihjx
wandb: ️⚡ View job at https://wandb.ai/niko_k98/TransUnet/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjkxNTQwMjc5/version_details/v18
wandb: Synced 5 W&B file(s), 600 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230820_181148-73ibihjx/logs
